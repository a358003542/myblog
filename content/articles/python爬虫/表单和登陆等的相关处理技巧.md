Title: python爬虫之-表单和登陆等相关
Date: 2018-06-14

[TOC]



表单简单来说就是一个前端友好的界面，其实质就是发送了 一个 POST 请求。

关键是要理解前端的表单界面，具体POST了哪些参量。

```
<form method="POST" action="???"
    <input type=... name="firstname" ... >
    <input type ...
    submit
</form>
```

input 的  **name** 就是具体 POST 的参量，然后就是action那边就是你要 POST 的目的地。

类似的表单还有很多其他元素，比如checkbox之类的，其都不过是为了让用户快速地设置某个参量罢了。





## 登录的cookies问题

因为http无状态，所以有cookies 和 session ，服务端数据库记录session，cookies就是客户端。爬虫要正常登录，记得保留好登录成功之后的cookies。

多次请求的时候，用requests的cookies保存和设置就不好用了。记得使用requests的session机制。



```
import requests
session = requests.Session()
data = {'username':'user', 'password': '123456' }
s = session.post('login.html', data)

##### 继续用这个session来请求，没有任何问题
s.get('profile.html')
```



