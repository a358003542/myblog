Title: 数据处理的程序的设计原则讨论
Slug: data-process-design-principle
Date: 2018-03-06 15:34
Modified: 2018-03-06 15:34
Tags: talk
[TOC]

数据量很大的情况下，通常指数据库下数据量较大的情况下，我们编写数据处理程序应该具有怎样的设计原则：

我对分布式流式计算框架不太熟悉，也许使用那些框架是个思路，现在是我纯粹从自己面对的问题作出的一些然后提出的一些原则：



1. 大的基本操作应考虑以从数据库的某处移动到某处来标记操作的完成，因为大的基本操作变动性并不是太大，这样数据库某个地方的数据都是有特别含义的。

2. 大的基本操作下还有一些小的操作步骤，这是一个难点，第一入口数据不断更新甚至老数据也会有变化，第二处理代码也可能会有变更，这部分并没有一劳永逸的完美的可扩展方案，有有的时候也是带来了太多的复杂性。一个比较好的建议是记录如下operations的处理信息：

```
operations: op_name op_state last_op_time op_day
```

2.1 操作名

2.2 op_state 操作状态，每个操作前都将state调为2，最后程序快结束的最后一行，state调为1，这样确保了op操作 state=0 或者 =2 或者没有state这个参量都表示本操作有问题

2.3 操作碎片化，一个好的建议以目标数据的 进入天数 作为一个小的处理单元，这样某一步出现问题，可以重复刷，保证数据处理的可中断，状态可记录。

2.4 上一次的操作时间，这个信息的记录是为了便于处理某种情况下老数据发生了更新，我们把这种模式成为update模式，就是只有经过一个稍长的时间后（减轻服务器压力），然后再update更新目标数据，然后更新last_op_time ，加入update模式主要在系统初期或者某些老数据变化的情况下，读者需要根据自己情况考虑是否引入这个记录，但上一次的操作时间记录一下是没有问题的。

3.  数据聚合操作，数据聚合操作一个问题就是按照上面的操作，可能对于确定op_day 不是很方便，因为不同的数据入口来源可能不同，一个好的思路是数据聚合确定一个 主数据源， 然后 op_day 是以这个主数据源的目标数据进入时间为准。

4. 原则上我们设计工作流程一般是某一日事今日毕，当然如果读者如果有其他考虑处理手段也是可以的，但让操作碎片化我确定这个思路还是不错的。



