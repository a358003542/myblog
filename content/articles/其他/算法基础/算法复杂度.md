Category: algorithm
Slug: algorithmic-complexity
Date: 20190909

[TOC]

一般讨论算法复杂度主要关注的是算法的时间复杂度，真到了该思考算法的时间复杂度了，那么这时算法将应对的是一个输入规模n很大的情况。人们提出大O表示法来描述一个算法在面对操作数n很大，或者输入数规模n很大的情况时，算法的计算时间和这个操作数n的关系。对于一个输入规模n很大的情况，还关心最开始某个变量的赋值啊，那个条件的判断啊，或者某个文件的加载那多出来的几步是没有意义的，因为随着操作数n的扩大，这些步骤如果和n无关，那么就是耗费的常数时间项，即使是这个时间有几秒，在后面的也会变得无足轻重起来。

若算法和输入规模n无关，则记为O(1) 常数运行时间。

然后我们经常看到这样的循环语句：

```python
for i in range(n):
    print(i)
```

这个循环和输入规模n相关，我们记作 O(n) 线性运行时间。

假设一个算法里面又有上面提到的O(1) ，又有上面的O(n) ，那么我们应该将O(1) 项去掉：

> 如果运行时间是一个多项式的和，那么保留增长速度最快的项，去掉其他各项

那么上面提到的算法复杂度就可简单记为 O(n) 。

又假设有个算法，有两个这样的循环：

```python
for i in range(n):
    print(i)
for i in range(n):
    print(i)
```

按照道理讲其算法复杂度应该记作 2n ，大O表示法还有下面规则：

> 如果各个项是一个乘积，去掉所有的常数

也就是上面的算法复杂度是 O(2n) 最后简化为 O(n) ，这样整个算法仍然是线性运行时间。

如果是两个循环嵌套的情况：

```python
for i in range(n):
    for j in range(n):
        print(i,j)
```

其具体运行了 `n*n`次，这个算法复杂度记为 $O(n^2)$ ，是二次多项式运行时间。此外可能会有其他情况，就是第二层循环会多运行几次或者少运行几次，这些都是细枝末节了，按照上面说的第一条规则：最后展开那些增长速度较慢的项将被去除，最后还是只剩下 $O(n^2)$ 。

## 递归的情况

以阶乘函数为例，递归函数的计算复杂度是递归函数最后展开为：
$$
fac(n) * fac(n-1) ... fac(1)
$$
这个展开序列的长度也就是递归的次数就是计算复杂度 O(n) 。

## 对数复杂度

在考量对数复杂度的时候是不关心对数的底数的，因为上面提及的第二条规则乘积的常数项可以忽略。

```python
while n > 0:
    print(1)
    n = n//10
```

上面的例子读者看的出来这个循环次数大约为输入规模n的对数次，也就是 O(logn) 。

二分查找算法的计算复杂度也是对数复杂度，其大致以2为底数逐步压缩查找空间。

## 对数线性复杂度

O(nlog(n)) 快速排序算法的计算复杂度就是对数线性复杂度。

```python
def quick_sort(seq):
    """
    10000 的随机数列表排序：
    select_sort use time 3.0919713973999023
    quick sort use time 0.024930477142333984

    :param seq:
    :return:
    """
    if len(seq) < 2:
        return seq
    else:
        pivot = seq[0]

        less_part = [i for i in seq[1:] if i <= pivot]

        greater_part = [i for i in seq[1:] if i > pivot]

        return quick_sort(less_part) + [pivot] + quick_sort(greater_part)
```

```python
def selection_sort(seq):
    """
    两种写法速度都差不多的，那么优先写的直白点的。
    :param seq:
    :return:
    """

    def find_smallest_index(seq):
        smallest = seq[0]
        smallest_index = 0
        for i in range(1, len(seq)):
            target = seq[i]
            if target < smallest:
                smallest = target
                smallest_index = i
        return smallest_index

    res = []
    seq_copy = seq.copy()

    for i in range(0, len(seq)):
        smallest_index = find_smallest_index(seq_copy)
        res.append(seq_copy.pop(smallest_index))

    return res
```

选择排序计算复杂度粗略估计是长度的 $O(n^2)$ ，非常直观的算法里面有个循环套循环。

选择排序和快速排序可以说非常直观地说明了计算复杂度等级不同，运算效率的提升有多明显。我测试的结果是：

```
    10000 的随机数列表排序：
    select_sort use time 3.0919713973999023
    quick sort use time 0.024930477142333984
```

是的，速度提升了接近100倍。

快速排序计算复杂度的估算里面有两部分：

1. 小部分和大部分合计约n的比较判断操作

2. 递归层级展开，递归层级深度展开要看你选的那个pivot分割点情况如何，最不好的情况这个pivot总是最小的，那么递归树深度带来的复杂度将达到O(n)；最好的情况就是pivot分割点均分列表，于是递归树深度带来的复杂度是 $log_2n$ 。

实际情况既不是最好也不是最坏，考虑到对数复杂度是可以不考虑log函数的底数因子的，所以可以认为快速排序计算复杂度就是 $O(n\log(n))$ 。





## python语言里面使用的排序算法

蒂姆·彼得斯因不满python以前的排序算法（估计应该是类似于快速排序的存在），于2002年发明了timsort算法，其基本思路应该也是类似于快速排序，不过利用了数据集数据已经部分有序的情况，进行了优化。

python里面的list.sort或者sorted函数就是使用的timsort算法。



## 字典

字典里面查找key计算复杂度是O(1)，和字典长度无关，其内部使用的散列表算法。

我以前认为python的字典是基于红黑树或者二叉搜索树实现的，理解错了。python中的字典是基于hash table 散列表实现的，其查、插入、删除的计算复杂度都是 O(1) ，具体就是引入一个散列函数，将一个大规模输入空间映射到一个小的输出空间，将数量巨大的key转换成为数量较少的整数索引。
