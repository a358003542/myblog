Title: 机器学习第五谈之数据预处理
Slug: machine-learning-talk-five
Date: 2018-12-13
Modified: 2019-04-10
Tags: machine-learning

[TOC]

## 前言

sklearn里面有很多数据预处理支持函数，下面主要重点理解这些数据预处理技术。



本文介绍的内容，以下面代码形式展示出来：

```python

import pandas as pd
import numpy as np

from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import MinMaxScaler

from sklearn.preprocessing import normalize as sk_normalize
from sklearn.preprocessing import binarize as sk_binarize


def combine_df(df_value, old_df):
    """
    输入ndarray值，然后根据给的老df的column列名来输出一个新的df
    :param df_value:
    :param old_df:
    :return:
    """
    new_df = pd.DataFrame(df_value, columns=old_df.columns)
    return new_df

"""

- scale 缩放操作 (缩放器 df) 返回df
- inverse_scale 反向缩放操作 (缩放器 df) 返回df
- normalize(df, norm='l1') 归一化
- binarize 二值化 阈值默认为0

- encode 编码
- inverse_encode 反编码 

### 缩放器
- z-score标准化 get_standard_scaler
- minmax缩放 get_minmax_scaler


"""

from sklearn.preprocessing import OneHotEncoder

"""

one hot encoding
"""

from sklearn.preprocessing import LabelEncoder

"""

LabelEncoder  标记编码
"""


def scale(scaler, df):
    """
    缩放操作
    :param scaler:
    :param df:
    :return:
    """
    if isinstance(df, pd.DataFrame):
        df_value = scaler.fit_transform(df)
        new_df = combine_df(df_value, df)
        return new_df
    elif isinstance(df, np.ndarray):
        df_value = scaler.fit_transform(df)
        return df_value


def inverse_scale(scaler, df):
    """
    反向缩放操作 - 反向缩放的有：

    - minmax
    - stand

    :param scaler:
    :param df:
    :return:
    """
    if isinstance(df, pd.DataFrame):
        df_value = scaler.inverse_transform(df)
        new_df = combine_df(df_value, df)
        return new_df
    elif isinstance(df, np.ndarray):
        df_value = scaler.inverse_transform(df)
        return df_value


def normalize(df, norm='l1'):
    """
    归一化 norm选项有 l1 范数 和 l2 范数 选项
    :param df:
    :param norm:
    :return:
    """
    if isinstance(df, pd.DataFrame):
        df_value = sk_normalize(df, norm=norm)
        new_df = combine_df(df_value, df)
        return new_df
    elif isinstance(df, np.ndarray):
        df_value = sk_normalize(df, norm=norm)
        return df_value


def binarize(df, threshold=0):
    """
    二值化 给定阈值默认为0, 然后根据阈值来返回0和1
    :param df:
    :param threshold:
    :return:
    """
    if isinstance(df, pd.DataFrame):
        df_value = sk_binarize(df, threshold=threshold)
        new_df = combine_df(df_value, df)
        return new_df
    elif isinstance(df, np.ndarray):
        df_value = sk_binarize(df, threshold=threshold)
        return df_value


def encode(encoder, df, fit_data=None):
    """
    编码
    :param encoder:
    :param df:
    :return:
    """
    if fit_data is not None:
        encoder.fit(fit_data)

    if isinstance(encoder, OneHotEncoder):
        df_value = encoder.transform(df).toarray()
        return df_value
    elif isinstance(encoder, LabelEncoder):
        df_value = encoder.transform(df)
        return df_value


def inverse_encode(encoder, df):
    """
    反向编码

    可以反向编码的有：
    - onehot
    - label

    :param encoder:
    :param df:
    :return:
    """

    df_value = encoder.inverse_transform(df)
    return df_value


def get_standard_scaler():
    """
    均值移除 或者 z-score标准化
    :param scaler:
    :param df:
    :return:
    """
    return StandardScaler()


def get_minmax_scaler(feature_range=(0, 1)):
    """
    范围缩放，同样缩放到0-1，所以也叫做 0-1缩放
    :param scaler:
    :param df:
    :return:
    """
    scaler = MinMaxScaler(feature_range=feature_range)
    return scaler

```



代码不是很具实用性，但大概也说明了sklearn对于数据预处理这块的相关支持情况。



## 缩放操作

### 均值移除

我更喜欢称之为z-score缩放，因为学习过统计学的就知道z-score标准分的含义，大体也知道这个缩放操作在做些什么事情。简单来说就是讲你的张量数据沿着各个特征维度，均值都为0，标准差都为1。

sklearn提供了 `StandardScaler` ，然后你利用它进行fit和tranform操作即可，你还可以继续利用之前的缩放器反向回滚 `inverse_transform`。


### minmax缩放

就是控制你的张量数据的最小值和最大值范围。

sklearn提供了 `MinMaxScaler` 缩放器类，类似上面的你可以进行fit和tranform操作，同样可以利用之前的缩放器进行回滚操作。



## 归一化

sklearn提供了normalize函数来支持你的张量数据的归一化操作，这是一个不可逆的操作。具体就是让特征维度的数据绝对值之和为1。



## 二值化

就是给定一个阈值，你的张量数据转变成为0 1 值。这个估计在神经网络中有用。





## onehot编码

onehot编码可以算是神经网络里面的基本入门知识了，简单来说就是将 数值或者字符 编码为空间扩展的  0 1 数值特征向量。 具体sklearn提供了 `OneHotEncoder` 来进行相关操作。

比如说 

```
[
	['male', 10],
	['female',5],
	['male', 1]
]
```
其中性别特征列有值 male female 两个值 这一列需要两个bit位 。
而后面的数字列有 1 5 10 三个值   这个特征列需要三个bit位 。
上面的例子一共需要 5 个bit位。


```python
df = pd.DataFrame( [
    ['male', 10],
    ['female',5],
    ['male', 1]
])
encoder = get_onehot_encoder()
encoder.fit(df)
encoder.transform([['female',10]]).toarray()
array([[1., 0., 0., 0., 1.]])
```

上面的例子中 `1 0` 表示 female `0 0 1` 表示 10 。

## label编码

label编码的含义也是很直接简单的，就是给定一个字典值，然后给这些字典里面的单词赋值0,2,3...这样你的张量数据就变成了数值型了。

具体sklearn提供了 `LabelEncoder` 来进行相关操作。



## 计算误差
### 平均绝对误差MAE
数据集所有数据点的绝对误差的平均值
```
import sklearn.metrics as sm
sm.mean_absolute_error(test_data, test_pred)
```
### 均方误差MSE
数据集所有数据点的误差的平方的平均值
```
sm.mean_squared_error(test_data, test_pred)
```
### 均方根误差RMSE
均方误差开个根号，为了更好地描述模型的误差


### 中位数绝对误差
数据集所有数据点的误差的中位数
```
sm.median_absolute_error(test_data, test_pred)
```
### 解释方差分
这个分数用来衡量我们的模型对于数据集波动的解释能力
```
sm.explained_variance_score(test_data, test_pred)
```
### R方得分 R2 score
用来衡量模型对于未知样本的预测效果。
```
sm.r2_score(test_data, test_pred)
```



## 缩放和归一化的再讨论

关于物品的特征，可能有些算法对特征的数值差异容忍度很高，但一般来说一般的算法都是要求我们对特征值进行缩放处理的。尤其是那些基于特征值计算距离的算法，则是必须要对各个不同的特征值进行缩放，才能进入后面的算法处理的。某些情况可能可以通过通过二值化就能解决，剩下的问题则需要你对特征值进行缩放，z-score缩放和minmax缩放。

这两个缩放手段其实都是可以的，如果时间充裕，两种缩放手段和算法评估工作都应该做的。

这里顺便提一下归一化手段，归一化normalize默认是使用的l2范数，就是横向【是的其默认axis=1，不是特征维axis=0】所有的值的平方和等于1，而l1范数是横向所有的值【绝对值？】相加等于1。

具体l1范数是否是绝对值这不是重点，归一化并不属于缩放范畴，其实严格意义上讲属于算法里面的一部分数据处理了。比如说频数列表 `[2,3,0,0]` 利用l1归一化，我们就能得到 `array([[0.4, 0.6, 0. , 0. ]])` 这里的0.4 就可以看做 2 发生的概率是0.4 ，然后l1范数正好满足 所有的概率的和等于1。具体某些应用场景是需要这个计算的。





## 参考资料

1. python机器学习经典案例 Prateek Joshi 著  陶俊杰 陈小莉译
2. [这篇文章不错](https://blog.csdn.net/weixin_40040404/article/details/81291799)