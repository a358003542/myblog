Title: 软件即服务的12因素方法论
Slug: 12factor-app-talk
Date: 2018-06-13
Status: draft

[TOC]

本文主要学习 [这个网站](https://12factor.net/zh_cn/) ，这个网站提出了软件即服务架构的12因素方法论。在目前软件开发，部署docker化，微服务，云服务，分布式架构等大趋势下，软件即对外提供一种http api服务的定位是很具有普遍性的。本文的一些讨论是很值得我们细细去思考的。



## 前言

Adam Wiggins 研究了数以百计的应用程序的开发和部署，并在Heroku平台上数十万应用程序的开发运作和扩展过程，写作了这个博客： <https://12factor.net/zh_cn/> 。

在互联网Internet的大背景下，软件作为一种服务，更确切来说作为一种api服务而存在是一种具有普适性的架构模式，不管软件自身功能如何，但软件本身只是一个提供了一些对外api接口的工具的定位，无疑是面向整个互联网和面向未来的。

同时这里的讨论不光涉及到部署和运维，实际上，在软件开始编写时的架构设计和具体编码部分内部细节，编码者的思路也需要作出相应的调整。



## 总的原则

- 使用**标准化**流程自动配置，从而使新的开发者花费最少的学习成本加入这个项目。
- 和操作系统之间尽可能的**划清界限**，在各个系统中提供**最大的可移植性**。
- 适合**部署**在现代的**云计算平台**，从而在服务器和系统管理方面节省资源。
- 将开发环境和生产环境的**差异降至最低**，并使用**持续交付**实施敏捷开发。
- 可以在工具、架构和开发流程不发生明显变化的前提下实现**扩展**。

这套理论适用于任意语言和后端服务（数据库、消息队列、缓存等）开发的应用程序。



## 一套基准代码多份部署

我看到人们经常对于 development testting 或者 production 等状态采用的是git不同版本号来控制的，这种做法不是很优雅，通常软件开发的不同状态是由软件的相关配置决定的，而这正是下面要讨论关于配置管理要讨论的问题。

我们在git代码管理的时候应该做到一个应用，一个对外api接口，一个git仓库，一个docker部署。具体多份部署无非是修改项目根目录下某个没进入git管理的文件环境变量。



## 在环境中存储配置

程序编码者在一开始编码的时候就应该做到，软件立刻开源，是不会泄露任何敏感信息的。而对于不同的部署的某些无差异配置，是可以写入代码的，这是没有问题的。

目前推荐的做法是将应用的相关核心配置存储于环境变量中。下面以python生态圈来讨论之。

1. 在项目根目录下写一个 `.env` 文件，一般只需要写上一个核心环境配置变量即可：

```
ENV_FOR_DYNACONF=development
```

2. 在项目根目录下写上一个 `.secrets.toml` 文件，toml配置文件很好用，也很简单，是dynaconf模块推荐使用的，读者简单了解下即可。里面如下格式写上一些私密信息:

```toml
[default]
   
[development]
MONGODB_USERNAME = ''
MONGODB_PASSWORD = ''
   
[testing]
MONGODB_USERNAME = ''
MONGODB_PASSWORD = ''
   
[production]
MONGODB_USERNAME = ''
MONGODB_PASSWORD = ''
```

这两个文件不进入版本控制。

3. 在项目根目录下写上 `settings.toml` 文件，这个配置文件格式如上，写上一些不太私密的配置信息，这些文件将进入版本控制。
4. 实际使用时修改 `.env` 即改变了整个项目的环境变量状态。实际python编码如下：
```
from dynaconf import settings
```

然后这个settings里面就可以取各种配置变量值了。而dynaconf稍作配置，就可以集成django或者flask的配置。更多信息请参看 dynaconf 官方文档。

在实际使用的时候，使用pipenv工具的 `pipenv shell` 或者 pipenv run 或者pycharm等等很多工具，他们都会默认加载 `.env` 这个环境变量配置文件的。

## 显式声明依赖关系

python生态圈有很多依赖关系管理工具，推荐使用pipenv，pipenv会输出一个lock文件，这个lock并不一定要进入版本库，按照官方文档的介绍，如果你的不同部署python版本号不太一致，那么最好不要将这个lock文件写入版本库。然后`requirments.txt` 也可以输出一份。这个随个人喜好了，总之软件项目的这些依赖关系对软件部署是非常友好的，强烈推荐具体使用和Dockerfile集成起来。

其他语言也有其他相对应的依赖关系，这些都要声明好。



## 通过端口绑定提供服务

## 把其他后端服务作为附加资源

上面这两条是一起的，在实际编写软件即服务架构时，本地的服务，第三方提供的服务和本软件应用提供的服务是不区分的。

这些服务包括：一般服务，数据库服务，消息队列服务，缓存服务等等。

在使用docker部署的时候，其他后端附加资源服务，推荐完全集成进去。

## 严格分离构建、发布和运行

- 构建是将代码仓库转化成为可执行包的过程。
- 发布时将构建的结果和相应配置结合的过程。
- 运行是针对发布的版本实际启动运行进程的过程。

应该严格分离构建、发布和运行这三个过程。

实践中针对互联网应用，构建指的可能不是发布一个exe文件，而是一个docker的image文件，然后运行image的时候配置一些环境变量，然后运行。



## 进程和并发

把进程作为第一等公民，实际以一个无状态进程来启动应用，具体和简单运行 `python script.py` 没有任何区别。

用专门的工具来实现进程并发，比如gunicorn等，比如就是一个进程，多个worker模型。实际进程不推荐使用supervisor这样的守护进程，而推荐和操作系统的进程管理或者说服务比如systemd集成起来。



## 快速启动，优雅终止

## 尽可能开发环境和线上环境相同

这两点应用docker化之后不存在任何问题。

## 日志

不用太在意日志，目前互联网应用开发都是快速开发，快速迭代，线上修改风格。所有如果需要监控软件应用运行情况，应该优先的终端输出流。这样开发人员在开发的时候就可以实时查看应用运行情况。

在确定需要某些存放在文件里面的日志信息时，推荐发送给某个日志管理工具来统一管理。



## 零碎的一次性任务提供命令行接口

比如django的迁移数据库操作 `python manage.py migrate` 等，有零碎的一次性任务应该编写相应的命令行接口。