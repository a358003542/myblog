{"pages":[{"title":"关于本网站","text":"说明 本网站的搜索功能还是有点用的，有几次不太想玩pelican这个东西了，然后发现不管是本地markdown写作体验，还是搜索功能支持等等，都比某书要好，当然其他的就更加不用提了。 网站挂在外面有时查阅一些信息还是很便捷的。 本网站定位主要是和IT相关的技术知识，其他相关不会放在这里了，只会污染了搜索池。 本网站域名 docs.cdwanze.work ，以后都是这个了，不想动了，也许以后没钱续费域名了，相关的文章域名请改成 cdwanze.github.io 。 LISENSE 本网站文章版权归作者所有，读者可以阅读学习研究，极小部分复制粘贴是没有问题的，但请勿大量抄袭。【如果读者只是私底下一个人自我学习保存，那是没有问题的。】 请不要用爬虫爬本网站。 打赏是不可能的，这辈子是不指望你们打赏的。只能靠偷电瓶车，这样子维持下生活。","tags":"pages","url":"guan-yu-ben-wang-zhan.html"},{"title":"公告","text":"色即是空，空即是色","tags":"pages","url":"gong-gao.html"},{"title":"flask模块","text":"前言 django是一种构建大型商务网站的解决方案，但现在这一块需求已经很分散了，实际上很多语言，javascript方面甚至小程序等等，各种轻量级的应用，传统的那种重量级网站技术已经很成熟了，而在应用的背后，微服务api，小型博客应用，一般机器学习api接口等等，使用flask或者其他轻量级的模块现在显得更合适一些了。 本文只介绍flask模块自身相关的一些东西，实际上即使是flask自身，也是多个python模块的组合：click，Werkzeug，jinja2等。这些都会分开讨论的，而其他一些flask扩展，除了基本和flask接口相关的外，都另外当做一个模块来介绍了。至于实际应用根据需要引入的其他python模块就更加不用说了。 初始运行 windows set FLASK_APP=hello.py flask run linux export FLASK_APP=hello.py flask run flask的调试模式： 开启调试模式是： export FLASK_DEBUG=1 重载器 所有源码文件变动自动重启服务器 调试器 出现异常在浏览器中显示异常信息 在生产服务器上一定要把调试模式关闭！ flask run 额外的选项 --host 0.0.0.0 --port 8080 flask的上下文设计 flask的上下文设计：多个线程处理不同的请求，request对于每个线程都是不同的，request上下文属于线程内的全局变量。 应用上下文 current_app g 请求上下文 request session current_app 当前的应用实例 g 每次请求都会重设该值，也就是对于每个请求都有不同的全局变量g。 request 请求对象 session 会话对象 每次请求都会推送（激活）应用和请求上下文，请求完就会删除。应用上下文被推送了，就可以在当前线程使用current_app 和g变量，请求上下文被推送了，就可以在当前线程使用request session变量。 激活应用上下文： from hello import app from flask import current_app app_ctx = app . app_context () app_ctx . push () print ( current_app . name ) flask的请求分发 查看flask当前app的url分发情况 app.url_map 默认flask有个额外的路由 /static/<filename> flask的请求对象 request请求对象有： form dict 存储请求的表单字段 args dict 存储URL上传递的参数 values form和args的合集 cookies dict 存储请求的所有cookies headers dict 存储http的headers files dict 存储请求上传的所有文件 get_data 返回请求主体缓冲的数据 get_json return dict 包含解析请求主题后得到的json blueprint 处理请求的Flask蓝本 endpoint 处理请求的Flask端点名称 method HTTP请求方法 scheme http或https is_secure 通过HTTPS发送的请求返回True host 请求主机名 path 请求URL路径 query_string URL查询字符串部分 full_path URL 路径和查询字符串部分 url 完整URL base_url 同url但没有查询字符串部分 remote_addr 远程IP地址 environ dict 请求原始WSGI环境 flask的请求钩子 请求钩子用装饰器来实现，flask有以下四种钩子： before_request 请求之前执行 before_first_request 只在第一次请求前执行 after_request 每次请求后执行 如果程序没有抛出异常的话 teardown_request 每次请求之后执行，即使抛出异常 请求钩子和视图函数之间变量互通一般用上下文全局变量 g flask的响应对象 response = make_response(content, status_code) response.set_cookie('a',1) 响应对象有以下属性或方法： status_code headers set_cookies 设置cookies delete_cookies 删除一个cookies content_length 内容长度 content_type 响应主体的媒体类型 set_data get_data 特殊的响应： 重定向响应 状态码 302 Location部分写上目标URL flask提供 redirect函数快速生成这个重定向响应对象。 abort函数 其返回的是状态码404 其是抛出异常 加入错误页面 @app.errorhandler(404) def page_not_found(e): return render_template('404.html'),404 url_for url_for('index', _external=True) 名字， 送入一些参数进去 _external 绝对路径 ，一般使用相对路径即可，浏览器之外的某些链接一定要使用绝对路径 静态文件 url('static', filename='favicon.ico') flask-moment Moment JS 送入UTC时间会自动转换成为本地时间，服务器那边的时间戳最好是记录UTC时间。用户则应该看到本地时间。 {% block scripts %} {{ super () }} {{ moment.include_moment () }} {{ moment.lang ( \"zh-cn\" ) }} {% endblock %} 在模板上使用： <p> 当前时间是： {{ moment ( current_time ) .format ( 'LLLL' ) }} . </p> <p> {{ moment ( current_time ) .fromNow ( refresh = True ) }} 刷新过. </p> 具体格式请参看 MomentJs 官网 。 表单 flask-wtf from flask_wtf import FlaskForm from wtforms import StringField , SubmitField from wtforms.validators import DataRequired app . config [ 'SECRET_KEY' ] = 'hard to guess string' class NameForm ( FlaskForm ): name = StringField ( '请输入您的名字？' , validators = [ DataRequired ()]) submit = SubmitField ( '提交' ) WTForms支持的HTML字段 BooleanField 复选框 DateField 文本字段 for datetime.date DateTimeField 文本字段 for datetime.datetime DecimalField 文本字段 for decimal.Decimal FileField 文件上传字段 HiddenField 隐藏文本字段 FieldList 一组指定类型的字段 FloatField 文本字段 for float FormField 把一个表单作为字段嵌入另一个表单 IntegerField 文本字段 for integer PasswordField 密码文本字段 RadioField 单选按钮 SelectField 下拉列表 SelectmultipleField 下拉多选列表 SubmitField 表单提交按钮 StringField 文本字段 TextAreaField 多行文本字段 WTForms提供的验证函数 DataRequired 确保类型转换后字段有数据 Email 验证电子邮箱 EqualTo 比较两个字段的值 常用于比较两次密码是否输入一致 InputRequired 确保类型转换前字段有数据 IPAddress 验证IPv4地址 Length 长度验证 MacAddress 验证MAC地址 NumberRange 数字范围校验 Optional 允许字段没有输入，将跳过其他校验函数 Regexp 正则表达式校验 URL URL校验 UUID UUID校验 AnyOf 输入值在任一可能值中 NoneOf 输入值不在一组可能值中 表单提交模式 一般表单提交模式是 POST 重定向到本视图函数 GET ，POST操作需要保存用户的一些信息则修改session中的值。 flash消息 flash消息方便让用户知道一些必要的信息。flash函数可以实现这点。然后模板文件上需要加上： {% for message in get_flashed_messages () %} <div class= \"alert alert-warning\" > <button type= \"button\" class= \"close\" data-dismiss= \"alert\" > &times; </button> {{ message }} </div> {% endfor %} 对接数据库 __tablename__ 定义表名，默认的表名没有遵循使用复数命名的约定 like users 。 这一块东西后面会补充一些，但更多的是sqlalchemy和sql那边的知识。 集成python shell @app.shell_context_processor def make_shell_context (): return dict ( db = db , User = User , Role = Role ) 运行： flask shell db那些变量是可以正常使用的。 cmd里面要配置好环境变量 export FLASK_APP=hello.py 数据库版本管理 flask-migrate 其基于sqlalchemy 的 alembic ，然后做了一些额外的工作。 from flask_migrate import Migrate migrate = Migrate ( app , db ) 然后运行 flask db init 一般工作流程： 修改数据库模型或者说数据库模型发生了变动 flask db migrate 创建迁移脚本 检查自动生成的脚本，改正不正确的地方 flask db upgrade 将改动应用到数据库 电子邮件 flask-mail 大型应用结构","tags":"python好伙伴","url":"articles/flask-module.html"},{"title":"机器学习第六谈之pipeline","text":"机器学习第六谈之pipeline 前面的学习讨论从keras到numpy，从验证测试到各个算法，大概讨论是很零零碎碎的。甚至会让人产生机器学习内容太多了，太难了的感觉。前面的那些基础知识很多都是可以后面再慢慢补充学习的，说到底机器学习应用属于工程领域，工程上的思维更多的偏向用，偏向从顶向下的学习方法——即不是从底向上的，学习基础知识一步步上的，而是先跟着已经成熟的项目来学习，来看看别人是怎样做的，最好马上手头上就能编写出一个针对某个问题的某个粗糙的解决方案，然后再针对性的学习和一步步地优化。 在之前的学习中应该说那个数据处理流如何去做的思考还是藏在脑子里面的，而慢慢接触到sklearn项目的pipeline概念，我们就会发现这个问题sklearn不说很完美地解决了，至少已经是部分解决了。并且在理解这个pipeline概念之后，我发现我的视角似乎更加的宏观和开阔了，甚至之前似乎分裂了的神经网络领域知识也融合进来了。下面是重点理解sklearn的Pipeline这个概念，然后试着在自己的机器学习项目中加以实践。 sklearn的pipeline是进行机器学习数据处理流的很重要的一个工具，下面的这个图很重要，大概说明了pipeline的主要工作原理。 【pipeline工作流程图】 本图片摘自 这篇文章 其中pipeline前面的叫做transformer，最后一个叫做estimator。 transformer transformer必须要有fit和tranform两个方法，当你调用 pipeline.fit 的时候，你的dataset (X, y) --> 会逐个通过前面所有的transformer，其中fit方法是进行一些数据的内部处理，一般会返回self，然后transform方法会返回输出数据集 X ，一般你自定义的transformer都应该继承 TransformerMixin 这个类，这样你只需要定义fit和transform方法就有 fit_transform 方法了。 下面是一个什么都没做的自定义的transformer的大概样子。 from sklearn.base import TransformerMixin class MyTransformer ( TransformerMixin ): \"\"\" 定义自己的Transformer \"\"\" def fit ( self , X , y = None , ** kwargs ): \"\"\" :param X: :param y: :param kwargs: :return: \"\"\" return self def transform ( self , X , ** kwargs ): \"\"\" :param X: :param kwargs: :return: \"\"\" return X 当你调用 pipeline.predict 方法，你的输入X同样也会经过前面所有的transformer的transform方法处理【没有调用fit方法了，因为你之前已经调用pipeline.fit了，然后你的模型或者说你的pipeline中的各个transformer已经处理过了，换句话说，你的pipeline中的各个模型都已经训练好了】，然后再调用的是你最后哪个 estimator的 predict 方法再得到结果。 也就是说，我们完全可以将pipeline当做一个更大型的组合模型，现在在这个综合模型下，你输入数据集，训练，然后predict，而数据集的minmax scale或者各个标签标记等等都会自动处理，不需要你再这样考虑问题了：训练集已经scale了，我等下要输入一个实际的数据来使用模型，是不是还要先把数据scale一下，然后输出的结果我该转换成什么标记之类的问题了。 sklearn真的是一个很Great的项目，如果你找到有些老旧教材来学习机器学习的话，你会发现机器学习中存在着太多的通用处理模式，你会考虑该怎么形成一种数据处理流模式，而sklearn的pipeline可以说初步解决这个问题了。在使用pipeline，基于pipeline之上构建你的机器学习项目，你完全可以把最终你搭建起来的某个pipeline当做某个综合模型，最后就剩下很简单的这样一个问题：选择参数，输入数据，训练模型，利用模型进行预测，评估模型。 而关于选择参数，sklearn还基于pipeline提出了GridSearchCV网格搜索的概念，我只能说这是sklearn大成式的豪迈宣言了。通过GridSearchCV，在训练pipeline模型的时候，一些参数结合评估模型是可以自动完成优化工作的。 这里还顺便提一下神经网络框架keras和sklearn的关系，正如机器学习是包含神经网络这门学科一样，sklearn模块在使用上是可以包含keras的，keras只是作为神经网络模型算法里面最核心的一部分，至少从输入数据处理流向上应该是这样的，这方面还要继续尝试——多个神经模型，和传统机器学习算法和其他数据处理等等最终形成一个大型的综合模型。 estimator estimator只需要fit方法就可以了，这个fit方法的任务就是通过某种学习算法——从简单的线性回归到神经网络等等，训练好模型。然后其还应该提供 predict方法，这也是学习算法的本质要求，来利用训练好的这个模型。 特征的联合 前面提到sklearn的pipeline相当于一个综合模型了，在进一步使用 FeatureUnion 之后可以让你对特征的操作和添加新特征更加的灵活，FeatureUnion类其实际上对应于一个 transformer，你可以提取然后组合出你想要的那几个特征。请读者多看看 kaggle 的 这个小项目 ，个人觉得这种写法风格非常的优雅。 针对每个特征进行了提取和处理工作，然后特征联合。此外FeatureUnion 哪里你当然还可以加上额外的特征，进行额外的运算之后得到的新的特征。 还有这个小项目有一点很值得我们注意，也是这篇文章提醒了我，sklearn的train_test_split 分割pandas的DataFrame之后返回也是pandas的DataFrame或者Series【labels】对象。这种和pandas的无缝对接的写法也是很好的。 我在构建pipeline的时候还参考了 这篇文章 来更连贯地构建了一个综合模型，大概如下所示： text = Pipeline ([ ( 'selector' , TextSelector ( key = 'processed' )), ( 'tfidf' , TfidfVectorizer ( stop_words = 'english' )) ]) length = Pipeline ([ ( 'selector' , NumberSelector ( key = 'length' )), ( 'standard' , StandardScaler ()) ]) words = Pipeline ([ ( 'selector' , NumberSelector ( key = 'words' )), ( 'standard' , StandardScaler ()) ]) words_not_stopword = Pipeline ([ ( 'selector' , NumberSelector ( key = 'words_not_stopword' )), ( 'standard' , StandardScaler ()) ]) avg_word_length = Pipeline ([ ( 'selector' , NumberSelector ( key = 'avg_word_length' )), ( 'standard' , StandardScaler ()) ]) commas = Pipeline ([ ( 'selector' , NumberSelector ( key = 'commas' )), ( 'standard' , StandardScaler ()), ]) feats = FeatureUnion ([( 'text' , text ), ( 'length' , length ), ( 'words' , words ), ( 'words_not_stopword' , words_not_stopword ), ( 'avg_word_length' , avg_word_length ), ( 'commas' , commas )]) pipeline = Pipeline ([ ( 'features' , feats ), ( 'classifier' , RandomForestClassifier ( random_state = 42 )), ]) 然后pipeline就好像一个大的综合模型一样，fit predict 等等之类的。 GridSearchCV 网格搜索用于调参，具体pipeline的参数名字是 : f '{transformer_or_estimator_name}__{parameter_name}' from sklearn.model_selection import GridSearchCV hyperparameters = { 'features__text__tfidf__max_df' : [ 0.9 , 0.95 ], 'features__text__tfidf__ngram_range' : [( 1 , 1 ), ( 1 , 2 )], 'classifier__max_depth' : [ 50 , 70 ], 'classifier__min_samples_leaf' : [ 1 , 2 ] } clf = GridSearchCV ( pipeline , hyperparameters , cv = 5 ) # Fit and tune model clf . fit ( X_train , y_train ) print ( clf . best_params_ ) 上面这个例子名字有点长，因为要往下找，features --> text --> tfidf --> 实际传进去的参数是 max_df 这里运算稍微有点耗时，如果程序化的话可以考虑将这些最佳参数最后保存起来： from sklearn.externals import joblib joblib . dump ( clf . best_estimator_ , 'filename.pkl' , compress = 1 ) 下次直接使用最佳clf是： reclf = joblib . load ( 'filename.pkl' ) preds = reclf . predict ( X_test ) 还有种保存方法，就是直接保存clf，这更加直观，估计兼容性也更好一点，只是模型文件稍微大了些： from sklearn.externals import joblib joblib . dump ( clf , 'filename.pkl' , compress = 1 ) reclf = joblib . load ( 'filename.pkl' ) 机器学习的一般过程整理 下面将机器学习的一般过程在Pipeline的基础上再整理一下： 从各个数据来源中获取数据并汇总，这里pandas的io工具非常好用，没必要拒绝使用它。 基于pandas的普遍性数据预处理【这个就要根据实际情况来了】 分割训练集和测试集 针对训练集编写Pipeline pipeline的过程大致涉及到目标特征的提取或者新特征的计算和特征融合，缩放，特征选择，直到最终算法的选择。 pipeline.fit 训练模型 pipeline.predict 使用模型 K折基于训练数据的验证得分 cross_val_score(pipeline, train_data, train_labels, cv=4) pipeline.test 基于测试集的测试 上面讨论的模型如何保存和再利用 绘图表现也很重要，虽然这个工作可以往后面放一放。 基于GridSearchCV的参数调优 更多更多手段调优","tags":"机器学习","url":"articles/machine-learning-talk-six.html"},{"title":"python和c++的dll的对接_in_windows","text":"ctypes模块 如果你的python程序需要和别人的dll进行交互，那么你就必须了解ctypes模块了。ctypes在linux也可以和c语言的so库进行交互，本文重点讨论的是在windows下和dll交互的问题。 基本的使用如下： lib_comm = ctypes . windll . LoadLibrary ( get_dll_path ( 'your_dll.dll' )) 假设你的your_dll.dll 里面 helloworld 函数，那么就可以这样调用这个函数了。 lib_comm . helloworld () 接下的使用主要就是考虑python的数据类型和dll里面的c语言数据类型的对接问题（可能还会牵涉到字符串编码问题。） 官方文档 的那个数据类型对应表格是必看的。基本类型都还好，主要是指针和结构体这两块要理解清楚。 首先你需要在python脚本中大概类似下面的创建一个对应于C语言的里面定义的结构体： class YOU_STRUCTURE ( ctypes . Structure ): \"\"\" 基础信息结构体 \"\"\" _fields_ = [ ( 'a' , ctypes . c_int ), ( 'b' , ctypes . c_char * 24 ), ( 'c' , ctypes . c_char * 40 ), ] 然后实际使用如下： s = YOU_STRUCTURE () _ref_s = ctypes . byref ( s ) 通过 byref 来获取到目标结构体的指针，实际调用dll里面的函数传递对应的结构体数据，就是把对应的指针，即上面的 _ref_s 传递过去。 lib_comm . test ( _ref_s ) 如何创建c++的dll 下面是我阅读官方 这篇文章 关于如何利用visual studio 2017 创建 基于c++语言的dll的过程整理： 首先是visual studio 要安装 C++的桌面开发环境。 新建项目 新建项目选择 c++ 的windows 桌面 里的 windows 桌面向导 点击下一步下一个界面选择 动态链接库 dll 添加头文件 源文件里面的dllmain.cpp 一开始不需要做任何修改，然后你需要在头文件哪里新建一个.h文件，具体内容如下： #pragma once #ifdef MATHLIBRARY_EXPORTS #define MATHLIBRARY_API __declspec(dllexport) #else #define MATHLIBRARY_API __declspec(dllimport) #endif extern \"C\" MATHLIBRARY_API int _stdcall test_call (); extern \"C\" MATHLIBRARY_API int _stdcall test_buf ( char * buf , int num , char * outbuf ); 这里 MATHLIBRARY 名字是可以更改的，暂时懒得改了。是关于声明dll对外开放函数的一个修饰符。具体涉及到dll的相关知识，其实就是这样一种写法就是了，不用太深究的，毕竟重点还是c++语言写的函数。 下面的 _stdcall ，说是什么标准windows API 调用，其实暂时也不用太深究这个，就是记得头文件和源文件函数定义哪里都加上这个修饰符，然后python那边 ctypes对接的时候要使用 windll，而如果不加则要使用 cdll。 添加源文件 #include \"stdafx.h\" #include <utility> #include <limits.h> #include \"MathLibrary.h\" int _stdcall test_call () { return 2 ; } int _stdcall test_buf ( char * buf , int num , char * outbuf ) { int i = 0 ; for ( i = 0 ; i < num ; ++ i ) { outbuf [ i ] = 'a' ; } return num ; } 然后点击 生成解决方案就在 debug文件夹下面 生成 dll了。下面讲如何和python项目集成起来。 和python项目集成 首先我们新建一个简单的python项目，就是一个最简单的那个python项目即可。 这里主要做的事情就是把前面我们创建的那个生成dll的c++项目在本解决方案中添加进来。 然后在python项目的引用中，把那个项目添加进来。 这样那个生成dll的c++项目点击生成之后dll会输出到本解决方案的debug文件夹下面。 然后python脚本这样引用即可： import ctypes dll = ctypes . windll . LoadLibrary ( '..\\Debug\\MathLibrary.dll' ) print ( dll . test_call ()) test_buf = dll . test_buf data_in = ctypes . c_char_p ( 'abcd' . encode ()) data_out = ctypes . create_string_buffer ( 4 ) numbytes = ctypes . c_long ( 4 ) res = test_buf ( data_in , numbytes , data_out ) print ( res ) res2 = data_out . value . decode () assert str == type ( res2 ) print ( res2 ) 我们看到实际上就是把路径指向上一层的debug文件里面的dll文件，这样python和dll就可以联动调试了。 参考资料 python ctypes探究 这篇文章关于ctypes和c++语言之间如何进行字符串沟通说明得很好","tags":"python语言","url":"articles/python-c++-dll-in-windows.html"},{"title":"机器学习第五谈之数据预处理","text":"前言 sklearn里面有很多数据预处理支持函数，下面主要重点理解这些数据预处理技术。 本文可能涉及的函数在我写的 bihu模块 的ml部分的preprocessing里面，大体包含内容如下： - scale 缩放操作 (缩放器 df) 返回df - inverse_scale 反向缩放操作 (缩放器 df) 返回df - normalize(df, norm='l1') 归一化 - binarize 二值化 阈值默认为0 - encode 编码 - inverse_encode 反编码 ### 缩放器 - z-score标准化 get_standard_scaler - minmax缩放 get_minmax_scaler ### 编码器 - get_onehot_encoder - get_label_encoder 缩放操作 均值移除 我更喜欢称之为z-score缩放，因为学习过统计学的就知道z-score标准分的含义，大体也知道这个缩放操作在做些事情。简单来说就是讲你的张量数据沿着各个特征维度，均值都为0，标准差都为1。 sklearn提供了 StandardScaler ，然后你利用它进行fit和tranform操作即可，你还可以继续利用之前的缩放器反向回滚 inverse_transform 。 minmax缩放 就是控制你的张量数据的最小值和最大值范围。 sklearn提供了 MinMaxScaler 缩放器类，类似上面的你可以进行fit和tranform操作，同样可以利用之前的缩放器进行回滚操作。 归一化 sklearn提供了normalize函数来支持你的张量数据的归一化操作，这是一个不可逆的操作。具体就是让特征维度的数据绝对值之和为1，不太清楚这么做有什么用。 二值化 就是给定一个阈值，你的张量数据转变成为0 1 值。这个估计在神经网络中有用。 onehot编码 onehot编码可以算是神经网络里面的基本入门知识了，简单来说就是将 数值或者字符 编码为空间扩展的 0 1 数值特征向量。 具体sklearn提供了 OneHotEncoder 来进行相关操作。 比如说 [ ['male', 10], ['female',5], ['male', 1] ] 其中性别特征列有值 male female 两个值 这一列需要两个bit位 。 而后面的数字列有 1 5 10 三个值 这个特征列需要三个bit位 。 上面的例子一共需要 5 个bit位。 df = pd . DataFrame ( [ [ 'male' , 10 ], [ 'female' , 5 ], [ 'male' , 1 ] ]) encoder = get_onehot_encoder () encoder . fit ( df ) encoder . transform ([[ 'female' , 10 ]]) . toarray () array ([[ 1. , 0. , 0. , 0. , 1. ]]) 上面的例子中 1 0 表示 female 0 0 1 表示 10 。 label编码 label编码的含义也是很直接简单的，就是给定一个字典值，然后给这些字典里面的单词赋值0,2,3...这样你的张量数据就变成了数值型了。 具体sklearn提供了 LabelEncoder 来进行相关操作。 计算误差 平均绝对误差MAE 数据集所有数据点的绝对误差的平均值 import sklearn.metrics as sm sm . mean_absolute_error ( test_data , test_pred ) 均方误差MSE 数据集所有数据点的误差的平方的平均值 sm.mean_squared_error(test_data, test_pred) 均方根误差RMSE 均方误差开个根号，为了更好地描述模型的误差 中位数绝对误差 数据集所有数据点的误差的中位数 sm.median_absolute_error(test_data, test_pred) 解释方差分 这个分数用来衡量我们的模型对于数据集波动的解释能力 sm.explained_variance_score(test_data, test_pred) R方得分 R2 score 用来衡量模型对于未知样本的预测效果。 sm.r2_score(test_data, test_pred) 参考资料 python机器学习经典案例 Prateek Joshi 著 陶俊杰 陈小莉译 这篇文章不错","tags":"机器学习","url":"articles/machine-learning-talk-five.html"},{"title":"wxpython第三谈","text":"TextCtrl用代码改变文本 TextCtrl用代码直接改变文本的方法有： AppendText 尾部添加文本 Clear EmulateKeyPress 产生一个按键事件 SetInsertionPoint 设置插入点 SetValue WriteText 在当前插入点插入文本 Remove 删除指定范围文本 Replace 替换指定范围文本 对接系统的剪贴板 将文本放入剪贴板 data = wx . TextDataObject () text = \"your text\" data . SetText ( text ) if wx . TheClipboard . Open (): wx . TheClipboard . SetData ( data ) #将数据放置到剪贴板上 wx . TheClipboard . Close () else : print ( '剪贴板打不开..' ) 从剪贴板中取内容 data = wx . TextDataObject () if wx . TheClipboard . Open (): success = wx . TheClipboard . GetData ( data ) wx . TheClipboard . Close () if success : return data . GetText () 此外还有清空剪贴板的动作： Clear 方法。 ScrolledPanel 带滚动条的面板，下面是一些值得额外一提的东西： SetupScrolling SetupScrolling ( self , scroll_x = True , scroll_y = True , rate_x = 20 , rate_y = 20 , scrollToTop = True , scrollIntoView = True ) 这个方法很重要，前面谈到，带滚动条的面板如果内容发生变动，除了 Layout 之外，还需要加上 SetupScrolling 这一句。 然后后面的这些选项也很重要： scroll_x 如果设置为False 则横向滚动条不显示 scroll_y 如果设置为False 则竖向滚动条不显示 rate_x 最小一步滚动的距离 rate_y 最小一步竖向滚动距离， scroolIntoView 滚动是尽可能让子面板合适的显示 此外你可以通过 Scroll 方法来程序进行滚动。 wxpython里面的鼠标图案 一般面板，也就是继承自Window的类都有 SetCursor 方法来设置当前的鼠标图形 self.SetCursor(wx.Cursor(wx.CURSOR_HAND)) 默认的是： wx.CURSOR_ARROW ，常用的显示要点击的手型是 wx.CURSOR_HAND ，此外还有： wx.CURSOR_ARROWWAIT 只能在windows下有效，表示繁忙的光标 wx.CURSOR_BLANK 不可见的光标 wx.CURSOR_WAIT 沙漏等待光标 wx.CURSOR_WATCH 手表等待光标 wx.CURSOR_SPRAYCAN 绘图用光标 wx.CURSOR_SIZING 尺寸调整时光标，四个指向 wx.CURSOR_SIZEWE 水平尺寸调整光标，左右指向 wx.CURSOR_SIZENS 垂直尺寸调整光标，上下指向 wx.CURSOR_RIGHT_BUTTON 右按键按下光标 wx.CURSOR_PENCIL 钢笔样光标 wx.CURSOR_PAINT_BRUSH 画刷样光标，同样在绘图程序中 wx.CURSOR_MAGNIFIER 放大镜，表示缩放 wx.CURSOR_MIDDLE_BUTTON 一个中间按键按下的鼠标 此外你还可以自定义光标图案： wx.CursorFromImage(image) ComboBox内容的修改 参考了 这个问题 。 ComboBox的官方手册上找不到相关方法，原来ComboBox继承自 ItemContainer ，调用这里的方法，就可以动态修改ComboBox里面的内容。 Clear 清空 Append 附加 Delete(self, n) 删除 Insert 插入 Set(self, items) 整个替换 自定义对话框 某些情况下直接继承自 SizedDialog 会很方便： import wx.lib.sized_controls as sc class Dialog ( sc . SizedDialog ): def __init__ ( self , parent , * args , data = None , type = 'simple' , ** kwargs ): sc . SizedDialog . __init__ ( self , parent , * args , size = ( 400 , 300 ), ** kwargs ) self . parent = parent pane = self . GetContentsPane () pane . SetSizerType ( \"form\" ) # 科目名称 wx . StaticText ( pane , - 1 , \"科目名称\" ) self . nameText = wx . StaticText ( pane , - 1 , label = self . name ) self . Fit () self . SetMinSize ( self . GetSize ()) self . Layout () self . Center () 或者直接继承自 wx.Dialog ，然后就像自定义panel一样做，除了里面添加button推荐使用一些标准ID，这样可以类似下面关闭对话框之后判断具体点击了那个按钮： val = dlg.ShowModal() if val == wx.ID_DELETE ... 列表控件 列表控件支持三种模式： style=wx.LC_ICON 图标模式，大概看上去像windows上的文件浏览的样子 style=wx.LC_SMALL_ICON 小图标模式 style=wx.LC_LIST 列表模式 有点类似于小图标模式，不同的是按列排列的 style=wx.LC_REPORT 报告模式 类似于excel表单的那种 具体更详尽的使用还是需要查阅文档的，此外如果你需要在某个item里面添加Panel或者其他控件，那么建议读者了解下 wx.lib.agw.ultimatelistctrl.UltimateListCtrl ，如果读者需要某一列可排序，了解下 wx.lib.mixins.listctrl.ColumnSorterMixin 如果需要item成为 textctrl 可以输入，了解下 wx.lib.mixins.listctrl.TextEditMixin ，还有其他的mixin，不过在使用 ultimatelistctrl的时候就没必要使用那些mixin了。 网格控件 网格控件 wx.grid.Grid 感觉比列表控件更加复杂，具体涉及到的方法很多，建议根据需要查阅文档之。 树型控件 TreeCtrl 显示复杂的层次数据，比如目录结构时可以用到。 HTMLWindow 对于某些复杂的文本显示需求，可以使用HTMLWindow用一种类html标记语言来渲染而成，其底层并不是用的浏览器渲染，而是wxpython自己完成了的渲染，简单来说这只是wxpython通过一种类html标记语言完成的一种快速定义文本显示界面的功能。 此外wxpython还提供了html2包，其是利用浏览器底层渲染，然后显示的，这样更接近浏览器显示效果。 wxpython的打印支持 这一块暂时略过 DateTime和python的datetime对象互转 这一节参考了 python cook book 的 #12 recipe。这里记录下，后面有时候应该会用到的： import datetime import wx def pydate2wxdate ( date ): assert isinstance ( date , ( datetime . datetime , datetime . date )) tt = date . timetuple () dmy = ( tt [ 2 ], tt [ 1 ] - 1 , tt [ 0 ]) return wx . DateTimeFromDMY ( * dmy ) def wxdate2pydate ( date ): assert isinstance ( date , wx . DateTime ) if date . IsValid (): ymd = map ( int , date . FormatISODate () . split ( '-' )) return datetime . date ( * ymd ) else : return None boxsizer两个值得注意的方法 AddSpacer 作用就是增加一段固定的空白距离，boxsizer覆写了sizer的AddSpacer方法，横向竖向不能混淆的。 def add_vspace ( box , size ): \"\"\" boxsizer竖向增加空白距离，如果不是VERTICAL则将抛异常 :param box: :param size: :return: \"\"\" if box . GetOrientation () == wx . VERTICAL : box . AddSpacer ( size ) else : raise NotVerticalSizer def add_hspace ( box , size ): \"\"\" boxsizer横向增加空白距离，如果不是HORIZONTAL则将抛异常 :param box: :param size: :return: \"\"\" if box . GetOrientation () == wx . HORIZONTAL : box . AddSpacer ( size ) else : raise NotHorizontalSizer AddStretchSpacer 这个方法是sizer里面的，boxsizer也可以调用，一开始我还没注意到。这个方法和上面方法的区别就是增加了一段可缩放的空白距离，其在Qt里面就是一段弹簧样的东西。利用这个缩放器很方便实现某个空间的居中或者某个比例的位置调整。 参考资料 zetcode 的wxpython教程 wxpython官方参考文档 wxpython in action , Author by Harri Pasanen and Robin Dunn","tags":"wxpython","url":"articles/wxpython-talk-three.html"},{"title":"pypubsub模块","text":"前言 pypubsub模块的基本使用这里就不赘述了，简单的看下官方文档即可。这里我要说的是debug问题： pypubsub引入之后程序经常出现问题之后是没有任何异常信息直接退出，这给日常编码带来了很多困扰，下面重点解决这个问题。 官方文档的高级使用部分有相关介绍，不过似乎有点杂乱，然后语焉不详。 搜索到 这个页面 ，似乎是要这样配置就能捕捉到异常信息。 我试着跟着他写了一下，然后发现 listenerID 和 topicObj.getName() 只有消息的名字，具体程序捕捉到了什么异常并没有写明。 在简单了解Topic和Linstener对象之后发现也找不到存储异常信息的地方。 只好翻文档，在API的utils里面有个ExcPublisher引起来了我的兴趣，看了下源码，简单的使用哪个 ExcPublisher 发现能够打印出异常信息，但是还是有其他异常。然后发现其核心实际上就是这里： def __call__ ( self , listenerID : str , topicObj ): \"\"\" Handle the exception raised by given listener. Send the Traceback to all subscribers of topic self.topicUncaughtExc. \"\"\" tbInfo = TracebackInfo () self . __topicObj . publish ( listenerStr = listenerID , excTraceback = tbInfo ) 他有新建了topic发送了消息，而哪个tbInfo就是异常信息，然后看了下，发现其实际上是从python的traceback异常堆栈哪里搜索到的，这也是奇怪，因为python的全局异常信息在这里，但是程序却没有抛出异常，可能pypubsub已经中途拦截了吧。 这样我们简单写了这样一个东西： from pubsub.utils.exchandling import TracebackInfo , IListenerExcHandler class MyExcPublisher ( IListenerExcHandler ): \"\"\" Example exception handler that simply publishes the exception traceback. The messages will have topic name given by topicUncaughtExc. \"\"\" def __call__ ( self , listenerID : str , topicObj ): \"\"\" Handle the exception raised by given listener. Send the Traceback to all subscribers of topic self.topicUncaughtExc. \"\"\" tbInfo = TracebackInfo () logger . error ( f 'message {topicObj.getName()} caught a error: \\n {tbInfo}' ) 然后定义： pub.setListenerExcHandler(MyExcPublisher()) 发现工作的还行。到这里我已经完事了，就基本的异常捕捉已经差不多了。不过下面有些东西建议读者稍微了解下，可能后面遇到某些情况debug就需要用于这些知识。 听所有的topic >>> def snoop ( topicObj = pub . AUTO_TOPIC , ** mesgData ): >>> print 'topic \" %s \": %s ' % ( topicObj . getName (), mesgData ) >>> >>> pub . subscribe ( snoop , pub . ALL_TOPICS ) ( < pubsub . core . listenerimpl . Listener instance at 0x01A040A8 > , True ) >>> pub . sendMessage ( 'some.topic.name' , a = 1 , b = 2 ) topic \"some.topic.name\" : { 'a' : 1 , 'b' : 2 } 打印topic层级 如果你用到了topic的层级，可能需要这个。 pubsub . utils . printTreeDocs () 消息缓冲再释放 我就遇到这样一个问题，那就是因为一种程序设计，模型层那边有数据更改会自动发送消息，大部分情况都没问题，就是GUI还没完全初始化的时候，出了问题。这里我们需要把消息先缓冲起来，然后再释放。 我写了这么一个简单的类： from pubsub import pub class PreGUIController (): \"\"\" GUI初始化之前接受的信号缓冲起来 GUI初始化之后再发送出去 \"\"\" def __init__ ( self ): self . info_queue = [] self . listener , _ = pub . subscribe ( self . remember_it , pub . ALL_TOPICS ) def stop_listen ( self ): pub . unsubscribe ( self . listener , pub . ALL_TOPICS ) def repeat_it ( self ): \"\"\" 再次发送那些信号 :return: \"\"\" for msg in self . info_queue : name = msg [ 'name' ] kwargs = msg [ 'kwargs' ] pub . sendMessage ( f '{name}' , ** kwargs ) import time time . sleep ( 0.1 ) def remember_it ( self , topicObj = pub . AUTO_TOPIC , ** kwargs ): msg = { 'name' : topicObj . getName (), 'kwargs' : kwargs } self . info_queue . append ( msg ) 具体使用如下： pre_controller = PreGUIController() # GUI初始化 pre_controller.stop_listen() pre_controller.repeat_it() 这里用到的知识实际上就是前面的听所有topic和一些的方法编写，唯一的一个新的知识点就是如何让某个listener取消监听某个topic。","tags":"wxpython","url":"articles/pypubsub-module.html"},{"title":"推荐系统第一谈","text":"前言 推荐系统本质上是隶属于机器学习系统的，所以在简单了解下推荐系统相关算法之后，具体实现推荐系统的架构，是应该基于机器学习系统架构，然后在这之上引入新的处理流即可。 推荐系统的定义 我们首先看到维基上对于推荐系统的定义： 推荐系统是一种信息过滤系统，用来预测用户对物品的\"评分\"或\"偏好\"。 这句话暗含了很多信息，很值得我们去玩味。第一推荐系统是一个信息过滤系统，我们可以假设用户进行了某种搜索行为，然后出来了很多搜索结果，这个时候推荐系统对这些搜索结果进行了过滤，筛选出最好的那几条呈现给用户，这大概就是推荐系统做的事情。 我们都已经熟悉推荐系统了，上面澄清了推荐系统和搜索系统的区别，一般推荐系统是没有输入搜索词这个动作的，不过不同的推荐主题我们可以假设对应不同的搜索词。然后平时我们看到的热门榜单页面，排行榜页面一般都不是推荐系统干的事，因为这些页面结果的生成是和用户无关的，这就提到了推荐系统的第二个特性：推荐系统是个性化的，千人千面的。 然后我们再来看推荐系统是用来预测用户对物品的\"评分\"或\"偏好\"这句话。这句话除了上面谈及的推荐系统是个性化的之外，还几乎把推荐系统最核心的数据结构和要做的事情给描述出来了。 物品1 物品2 物品3 物品4 用户1 2 ? 3 ? 用户2 1 2 5 ? 用户3 ? ? ? ? 推荐系统就是要维护这样的用户和物品评分矩阵，这是推荐系统内部最核心的数据。 然后推荐系统是负责进行预测工作的，所以一般推荐的物品是用户没有用过的物品（这里主要指推荐系统内部最核心的工作）。 上面这个数据结构也可以表示成为这样一条条记录： user item rating timestamp 一般一条条记录还会加上timestamp时间戳，因为记录的时间戳可以调控记录权重，让最近的记录更重要。 上面谈及的评分矩阵有完备的数据当然好，那么就剩下新物品和新用户到来的时候，那么接下来的评分数据如何填充，这是我们在搭建推荐系统的时候需要思考解决的问题；而实践中可能这个评分矩阵有大量的数据缺失，也就是数据稀疏性问题，这也是推荐系统的一个难点问题；此外甚至可能推荐系统在刚开始搭建的时候，完善没有这样的评分数据，这就是推荐系统中的冷启动问题。 那么我们为什么要维护这样一个评分矩阵，这里的评分的含义其实是非常明显的，就算没有用户直接给物品的评分数据，你也应该暗地里计算一个这样的分数，来标明用户对物品的喜好程度，然后根据这些喜好得分，选择TopN，推荐给用户。所以这样的评分数据就算没有用户直接给出，我们也要自己这边定义算法得到的。 推荐系统的类型 目前主流的推荐系统就两个类型：基于用户的协同过滤推荐和基于物品相似度的推荐。 推荐系统的python模块支持 推荐系统在python生态圈里面似乎有个已经较为成熟的模块了： https://github.com/NicolasHug/Surprise 简单看了一下，其提供了一个基本的推荐系统内部基本数据规范接口和基本算法接口，可以对接好进行使用。 但我们也要看到推荐系统是一个和业务贴得非常近的，然后我们也要看到，推荐系统的从搭建到调试到优化，到后期业务需求跟进等等都不是一朝一夕的功夫，是一个从算法上来讲算不上很难，更偏工程实践的领域。 如果后面有需求那么就会开始利用python的相关科学计算模块了，numpy，sklearn等等。 推荐系统的可解释性 从个人使用推荐系统情况来，推荐系统的输出页面最好解释性强一点，尽量少一些潜在的模糊的推荐，比如说我跟踪你点了哪里点了哪里所以我推荐给你这个内容，这种话谁都说不出口，连推荐理由都说不出来的推荐系统我们最好不要做，这样给用户的感觉不是很好。 所以我的一个建议是不要收集类似用户的点击或者其他意图不明确的记录，下面这些记录是能被用户认可的，而且意图非常的明显可以作为推荐系统推荐理由。 你购买过这个物品，这个物品的标签有什么，根据你喜爱的这个标签，我们给你推荐什么。实际上用户在网站上购买多个物品之后，将会有多个物品的多个标签，多个标签有个计数，每个标签都将输出一个推荐页面。 推荐系统页面的输出过滤：推荐系统可以暗含比如距离优先权重，文章时间优先权重等，热度优选权重等，而在实际输出的推荐页面，应该再给用户这些排序选项，这实际上也再暗地里告诉用户我们的推荐是考虑了这些因素的。 你购买的物品基因和那些用户相同，他们也喜欢这些物品。这里明确告诉用户你购买过这些物品，我们是根据你的购买记录来做出这些判断的。非常不喜欢推荐系统使用这些信息来进行推荐，你的年龄是多少，你的学历是多少等等，这些推荐第一推荐效果实际上我看了非常的不好，很多网站都用他来解决推荐系统冷启动问题，但我觉得完全没有必要，强制推送用户一堆不喜欢的东西，就好像推销一样是推荐系统的大忌；其次你的这些推荐就是明摆着告诉用户我要收集你的这些个人信息，给人的感觉更加不好。 推荐系统的可定制性 前面提到了推荐系统输出页面可以增加一些过滤选项，同样页面还可以加入推荐系统的高级定制选项。这里讨论的可定制性包括时间遗忘权重，喜好标签和自定义标签的标记等等。这些高级定制界面一般用户可能用不到，后面有时间精力可以去开发。 推荐系统的效果最终评判方实际上就在每个用户身上，没有任何人，没有任何算法可以做这个工作；其次推荐系统的很多信息收集也可以放在这个定制页面，实际上某些用户对于上传这些信息也会很热心的，而这将很快的提高推荐系统的质量；最后这个可定制页面对于早期人工输入收集和后期推荐系统某些数据维护也很有帮助。 还是那句话，推荐系统更多的不是某种高难度的算法，而是一个不断完善的工程上的事。 推荐系统的数据埋点需求 正如前面提及的目前大概需要这些信息： 用户对某个物品的消费记录 物品的标签 后期网站页面和推荐系统操作页面需要进行合并融合工作。 按照上面的讨论，推荐系统需要的最核心的数据就是用户对于某个物品的购买记录，不需要其他花里胡哨的瞎猜逻辑。 如果用户没有购买记录，我觉得更好的做法是将某个问题页面，也就是前面提到的推荐系统的可定制性相关页面，在用户查看到推荐栏的时候放出，用户选择之后，立马放出推荐结果。 推荐系统的后期 这个是后面的事情了，这里简单提一下，除了上面说到的推荐系统的可定制性外，我觉得推荐系统后期可能面对的最大问题是大数据量下的快速反应问题。 至于人们提及的更高大上的比如更加智能的猜测用户的心意【这里指的是搭建用户的记录知识库】，和用户更优化的对话交互推荐，我觉得这都不算推荐系统的事情，而是智能系统的事情了。 推荐系统的实时性和相似扎堆问题 目前我看到的推荐系统在实时性上已经提到了很高的一个程度，基本上做到了用户点击什么立马反应改变推荐结果。总的说来推荐系统实时改变这是很好的，但感觉现在的推荐系统太实时了，也就是那个时间戳权重可能提的太高了，以至于我感觉现在的推荐系统已经没有记忆性了，只是一个实时反映的系统，而没有很好地去维护用户的个性特征特性。这就造成了现在的推荐系统经常出现相似的内容一股脑的扎堆进来，实时性是要的，但过分的提高实时性，实际上就完全放弃了推荐系统的下一步的可改进性。 而推荐系统的下一步可改进性就是除了高大上的猜测用户心意上下功夫，搭建用户模型，更好地为用户画像。 此外还有一个改进路线就是进一步提高推荐系统的推荐结果可解释性和相关可解释路线的多样性。这就好比给用户多增加几个谋士，可能有几个谋士不合乎用户心意，但多增加几个之后，用户的使用体验和满意度肯定会上升的。 具体多种推荐路线那可能就要联系到用户的画像，抓住用户的某个特征然后得出结论，比如说射手座的喜欢购买这些；星期天大家喜欢买这些等。这些谋士的建议可能很不靠谱，但这些推荐建议多几个是不会引起用户的讨厌的，毕竟是用户自己主动去下拉翻动的。 推荐系统的早期搭建 基于物品的推荐非常适合早期运行，数据也适合进行线下预处理，即使后期物品数据非常庞大也能做到实时计算和推荐。 所以我们工作推荐系统搭建早期重点精力应该在基于物品的相似度上的推荐。下面是最基础版本的构想： 物品的标签 根据用户的购买记录，找到对应物品的各个标签 根据物品相似度判断得到推荐结果 刚开始的版本就是最粗糙的那个版本，正如前面提及的，推荐系统是个不断优化完善上的工程上的事，随着物品变多，物品标签变多，用户购买记录变多等会出现越来越多要考虑的问题。 先对接线上数据库数据做出一个基本的雏形再说。 参考资料 推荐系统 Dietmar Jannach Markus Zanker 著 蒋凡译","tags":"机器学习","url":"articles/recommender-talk-one.html"},{"title":"wxpython绘图和自定义窗体","text":"前言 本文重点讨论wxpython较为底层的绘图知识和利用这些知识来建立自定义的一些窗体。 GDI wxpython底层绘图有个GDI（Graphics Device Interface）的概念，可以理解为通用绘图接口，利用这个通用绘图接口，一套绘图方法，就可以向显示器，打印机等绘图。这样程序员可以不用考虑硬件底层来进行绘图编程了。 这个GDI具体来说就是一些绘图的类和方法。 DC 在开始绘图前，你需要创建一个设备上下文DC（device context），这个DC具体来说就是wx.DC类。实际使用中不应该使用wx.DC类，而应该选择更具体的设备向的DC子类。这些子类具体分为三类： 用于绘制到屏幕的上下文 用于绘制到另外地方而非屏幕 用于缓冲一个设备上下文 用于绘制到屏幕 wx.ClientDC wx.PaintDC 如果你是在EVT_PAINT事件中，那么你应该使用这个设备上下文，其他时候必须使用wx.ClientDC 。 wx.WindowDC 如果你不光希望在客户区绘制，窗体的边框，标题栏等你都想绘制，那么就使用这个。 wx.ScreenDC 如果你希望在整个屏幕上绘制，那么就使用这个。 非屏幕设备上下文 wx.MemoryDC 用于内存中的位图bitmap上绘制 wx.MetafileDC 这个只在windows下有效，将绘制并写入到文件中 wx.PostScriptDC 这个是跨平台的，将写入eps文件中 wx.PrinterDC 这个只在windows下有效，将写入打印机中 缓冲设备上下文 wx.BufferedDC wx.BufferedPaintDC 缓冲一个设备上下文，当你做几个重绘的时候，防止屏幕闪烁，缓冲是个选择。复杂的绘制防止屏幕闪烁，推荐使用 dc = wx.BufferedPaintDC(self) 带颜色的线条 wxpython里的StaticLine是不可以定制颜色的，请看下面这个类实现了一个可以定义颜色的线条功能。这个例子基本演示了如何自定义窗体，具体就是在OnPaint上画上窗体图形，然后Bind好你想要的事件和动作。 绘图变得也来越复杂和更多的定制需求，你的窗体可能需要加入更多的方法来支持这些特性。 import wx class ColorStaticLine ( wx . Panel ): \"\"\" 带颜色的线段 \"\"\" def __init__ ( self , parent , color = 'black' , mode = 'hline' , ** kwargs ): super ( ColorStaticLine , self ) . __init__ ( parent = parent , ** kwargs ) self . parent = parent self . color = color self . mode = mode self . Bind ( wx . EVT_PAINT , self . OnPaint ) def OnPaint ( self , event ): dc = wx . PaintDC ( self ) width , height = self . GetClientSize () dc . SetPen ( wx . Pen ( wx . Colour ( self . color ))) if self . mode == 'hline' : dc . DrawLine ( 0 , 0 , width , 0 ) elif self . mode == 'vline' : dc . DrawLine ( 0 , 0 , 0 , height ) 虽然这是一个很简单的例子，但我们可以学到很多东西： 定义重画事件，然后使用 wx.PaintDC 。 具体绘画区域x,y的计算是重新开始的，即 (0,0) 具体本面板的绘画区域可以由 self.GetClientSize() 方法获得。 通过 dc.SetPen 来设置画笔，这是可以设置颜色，然后dc.DrawLine画一条直线，这就是整个绘画过程了。 这样我们就定义了一个自己个性化的可复用小面板组件了。 TODO ： 一个问题，为什么这里要继承自 wx.Panel 才行，这其中的道理暂时还没想明白。 基本形状绘制 带颜色的方块 dc.SetBrush(wx.Brush('#1ac500')) dc.DrawRectangle(130, 15, 90, 60) 设置画刷，然后画一个矩形。 绘制圆弧 DrawArc(x1, y1, x2, y2, xc, yc) 绘制一个圆弧，起点 x1 y1 终点 x2 y2 中心点 xc yc 弧线逆时针绘制，如果设置了画刷，而会填充圆弧区域。 画一个圆 DrawCircle(x, y, radius) 以x y 为中心， radius为半径，画一个圆。 画一直线 DrawLine(x1, y1, x2, y2) 起点 x1 y1 终点 x2 y2 画一直线 画多边形 DrawPolygon(points) 定义一系列的点，画一多边形，起点和终点自动相连 画圆角矩形 DrawRoundedRectangle(x, y, width, height, radius) radius控制曲率 绘制文本 DrawText(text, x, y) 绘制文本之前你可以通过： SetTextForeground 来设置字体颜色 此外还有 GetTextForeground dc.SetBackgroundMode(wx.SOLID) 默认 wx.SOLID 文本有背景颜色，或者设置 wx.TRANSPARENT ，文本无背景颜色。 dc.SetTextBackground 设置文本背景颜色 dc.SetFont 设置字体 绘图图片 DrawBitmap DrawIcon 设置画笔 上面提到的一些基本形状的绘制，填充区域由画刷控制，而那些形状的线条颜色，则是由画笔控制的。 SetPen wx.Pen(wx.Colour, width=1, style=wx.PENSTYLE_SOLID) 画笔的样式 wx.PENSTYLE_SOLID 默认的实线就是这个 wx.PENSTYLE_DOT 小点 wx.PENSTYLE_LONG_DASH 虚线 wx.PENSTYLE_SHORT_DASH 短虚线 wx.PENSTYLE_DOT_DASH 点划线 wx.PENSTYLE_TRANSPARENT 没有笔线 wx.PENSTYLE_STIPPLE 使用提供的位图作为笔触 wx.PENSTYLE_BDIAGONAL_HATCH 反斜线 wx.PENSTYLE_CROSSDIAG_HATCH XXX 线 wx.PENSTYLE_FDIAGONAL_HATCH 正斜线 wx.PENSTYLE_CROSS_HATCH +++ 线 wx.PENSTYLE_HORIZONTAL_HATCH 水平线 wx.PENSTYLE_VERTICAL_HATCH 垂直线 设置画刷 SetBrush() wx.Brush(colour, style=wx.SOLID) 画刷的样式 画刷的样式下面列举如下： wx.BRUSHSTYLE_SOLID 默认实心填充 wx.BRUSHSTYLE_TRANSPARENT 透明，也就是没有填充 wx.BRUSHSTYLE_STIPPLE_MASK_OPAQUE 用位图做笔触，the mask is used for blitting monochrome using text foreground and background colors. wx.BRUSHSTYLE_STIPPLE_MASK 用位图做笔触， mask is used for masking areas in the stipple bitmap. wx.BRUSHSTYLE_STIPPLE 用位图做笔触 wx.BRUSHSTYLE_BDIAGONAL_HATCH 反斜线 wx.BRUSHSTYLE_CROSSDIAG_HATCH XXX 线 wx.BRUSHSTYLE_FDIAGONAL_HATCH 正斜线 wx.BRUSHSTYLE_CROSS_HATCH +++ 线 wx.BRUSHSTYLE_HORIZONTAL_HATCH 水平线 wx.BRUSHSTYLE_VERTICAL_HATCH 垂直线 自定义画刷图案 brush1 = wx.Brush(wx.Bitmap('pattern1.png')) dc.SetBrush(brush1) dc.DrawRectangle(10, 15, 90, 60) 画刷可以指定某个图片来作为其刷出来的图案。 获取绘图区域尺寸 width, height = self.GetClientSize() 获取某个窗体的尺寸 wxpython内的窗体（继承自Window）都有 GetSize 这个方法，这样你可以得到某个窗体的尺寸： width, height = self.GetSize() 获取文本的宽度和高度 w, h = self.GetTextExtent(line) 如果是空行的话可以写为： w, h = self.GetTextExtent('M') 居中的定义 获取绘图区域的width，然后计算好你想要居中的对象的width（w），然后居中绘制起点x是： start_x = (width - w)/2 居右的定义 获取绘图区域的width，然后计算好你想要居右的对象的window（w）,然后居右的绘制起点x是： start_x = width -w dc.Clear TODO 我对这个理解还不是很深，只知道这个可以用来清空背景画刷。 brush = wx . Brush ( \"white\" ) dc . SetBackground ( brush ) dc . Clear () style管理 一般常数状态不用多说，下面说下wxpython的style是如何管理的，其首先定义一些常数，比如说 A = 0b1 B = 0b10 C = 0b100 然后假如说你定义了一个状态：style = A | B ， 则执行逻辑或操作即可。加入你想要测试style是否包含B态则 style & B 即可。由于每个style态只占一个二进制位，则其和目标style进行逻辑与操作，包含就返回非0值，返回0值则说明不包含目标style态。 参考资料 zetcode 的wxpython教程 wxpython官方参考文档 wxpython in action , Author by Harri Pasanen and Robin Dunn","tags":"wxpython","url":"articles/wxpython-drawing-custom-widget.html"},{"title":"websockets模块","text":"简介 python和websokets相关的模块在github得星差不多的大概有三个，一个autobahn在使用上更偏向twisted，而且个人使用的时候在连接上会报websocket upgrade error这样的错误，可能是我的问题，而另外一个更偏向javascript那边websocket的使用风格，因为个人没有使用过，不做点评，本文重点关注的是这个模块： https://github.com/aaugustin/websockets 这个模块使用还是很简单的，不过需要读者对asyncio那块异步编程要有所熟悉。 全局websocket 首先你的应用启动的时候和服务器建立websocket连接，最好让这个websocket成为一个全局变量，后续的发送和监听消息需求都根据这个websocket来。 和其他GUI框架的继承问题 这个websockets模块和GUI框架的继承问题更多的是在于该GUI框架如何和asyncio的事件循环集成起来。这个在目标GUI框架的时候会有所讨论，就不在这里讨论了。 简单来说就是asyncio的事件循环里面你将添加一个或者多个任务，在目标任务中，完成websoket的相关工作。 常驻监听模式 请读者看下面代码，下面建立了一种常驻监听模式，由于可能存在各种原因websocket服务器那边可能会强制把websocket连接关闭，所以你需要捕捉这个异常，然后试着重新建立一个全局websocket连接。 async def create_websocket ( self ): \"\"\" 主面板初始化新建一个全局的websocket 然后开始websocket监听 :return: \"\"\" ws_url = create_ws_url () while True : try : async with websockets . connect ( ws_url ) as websocket : g_var . websocket = websocket ws_message = await websocket . recv () logger . info ( f 'websoket got message {ws_message}' ) res = json . loads ( ws_message ) # 先将听到的信息放入Queue中，后续统一处理 g_var . ws_message_queue . put_nowait ( res ) except websockets . ConnectionClosed as e : logger . error ( 'websocket closed error' ) 这里我先把请到的消息放到一个队列里面，然后后续再慢慢处理队列里面的消息，这个并没有什么特别的考虑，只是觉得这样写逻辑会更清晰一些。 发送消息 发送消息就是简单的send，但你可能是在其他程序中，所以其他程序中更完整的表述是 在时间循环中添加一个任务，然后等着事件循环去完成目标任务。 import asyncio eventloop = asyncio . get_event_loop () eventloop . create_task ( hello ( 1 )) async def hello ( count ): websocket = g_var . websocket name = { 'name' : f 'wanze{count}' } name_obj = json . dumps ( name ) await websocket . send ( name_obj ) print ( f \"> {name}\" )","tags":"python好伙伴","url":"articles/websockets-module.html"},{"title":"机器学习第四谈","text":"前言 在前面第三谈中谈论的典型的二分类问题，多分类问题和回归问题在机器学习中都属于监督学习。此外还有无监督学习，自监督学习和强化学习。 无监督学习 无监督学习是数据分析的必备技能，在解决监督学习问题之前，为了更好地了解数据集，它通常是一个必要步骤。 降维 聚类 是常见的无监督学习方法。 自监督学习 自编码器 (autoencoder) 是有名的自监督学习例子。 强化学习 智能体接受环境的信息，为了某种奖励最大化而学习选择行为。 机器学习通用工作流程 定义问题，收集数据集 你的输入数据是什么？你要预测什么？ 你面对的是什么类型的问题？是二分类问题还是多分类问题等等。 选择衡量成功的指标 模型要优化什么，它应该直接和你的业务目标相关。 确定评估方法 留出验证集 数据量很大的时候采用 具体操作就是训练数据里面一部分作为训练集，剩下来的一部分作为验证集，然后用训练集训练，验证集评估当前模型的好坏。模型参数调节好训练好之后，记得最后用整个训练集从头训练一次，最后用另外的测试集数据测试下模型的实际效果。 K折交叉验证 重复的K折验证 准备数据 数据张量化 神经网络的所有输入和输出目标都必须是浮点数张量（某些情况下可以是整数张量）。无论面对的是声音，文本，图像还是视频，都必须先将其转换成为张量。 数据标准化 之前我们看到的数据标准化情况有： 图像0-255数据整除缩减到 0-1 数据区间 如果是多个特征的数据，那么推荐如前面提及的进行z-score的标准化处理 mean = train_data . mean ( axis = 0 ) train_data -= mean std = train_data . std ( axis = 0 ) train_data /= std 处理缺失值 对于神经网络来说，将缺失值设置为 0 是安全的。 特征工程 比如自然语言处理，根据自然语言处理学到的知识，选择二元模型对输入数据进行再处理。 良好的特征工程仍然可以让你用更少的资源更优雅地解决问题 良好的特征可以让你用更少的数据解决问题 开发比基准更好的模型 简单来说就是先随便开发一个小模型，要求不要太高，但至少要比随机乱猜准确率要高点的模型。 扩大模型规模，开发过拟合模型 一般是： 添加更多的层 让每一层变得更大 训练更多次数 要始终监控训练损失和验证损失，如果你发现模型随着训练次数增加在验证数据上性能下降了，那么就出现了过拟合。 模型正则化与调节超参数 这一步是最费时间的：你将不断调节模型，训练，验证，再调节模型... 。下面是一些你可能尝试的手段 添加Dropout层 Dropout层是深度学习之父Hinton和他的学生首次提出来的，它的原理很简单：对某一层使用dropout即该层在训练的时候会随机舍弃一些输出特征（也就是值变为0）。dropout比率是被设为0的特征所占的比例，一般设0.2~0.5之间。 添加Dropout层是最有效也最常用的正则化方法——正则化指降低过拟合。 尝试增加或者减少层 一般实践中开始会选择较少的层和节点数，然后逐渐增加之，直到这种增加对验证损失影响变得很小。 尝试L1 L2正则化 L1正则化和L2正则化都属于权重正则化，这是一种降低过拟合的方法，强制让模型权重只能取较小的值。 尝试不同的超参数 如每层的单元个数，优化器的学习率等。 参考资料 机器学习实战 Peter Harrington 著 李锐 李鹏等译 机器学习实战线上教程 python深度学习 弗朗索瓦·肖奈","tags":"机器学习","url":"articles/machine-learning-talk-four.html"},{"title":"机器学习第三谈","text":"前言 在上一文机器学习第二谈中，我们算是搭建了一个简单的神经网络，初步了解了一下大体情况。本文主要紧跟着对相关内容进行更细致的讨论。 relu激活函数 relu激活函数具体的数学运算公式很简单，就是： z = np.maximum(z, 0) 上面运算就是对z张量进行了relu运算了，按元素的，如果元素值大于0则为原元素的值，否则为0。 广播(broadcasting) 广播一种操作，shape较小的张量和shape较大的张量进行点对点运算时，需要对shape较小的张量进行广播操作，使其在运算上shape兼容。 广播具体操作规则是： shape较小的张量添加新的维度是的两个张量维度数相同 shape较小的张量在新的维度中的数据是重复的，相当于没有原维度的数据，即： y[1,j] = y[2,j] = y[3,j] =... y[j] 张量点积 矩阵乘法也就是这里的张量点积学过线性代数的对这个概念还是很清楚了，不过到更高的维度的张量的点积情况似乎有点复杂了。这里我们需要把张量点积的shape变化弄清楚，后面可能会有用的，具体实际张量运算可以交给函数去做。 $$ x \\cdot y = z $$ x shape (a, b) y shape (b,c) 输出 z的 shape(a, c) 高维的情况如下： (a, b, c ,d) · (d,) -> (a,b,c) (a, b, c ,d) · (d, e) -> (a,b,c, e) 张量变形 ndarray可以直接调用reshape方法来进行张量变形操作，变形后元素总个数应该不变，也就是各个维度容量乘积数不变。 张量的导数 张量的导数叫做梯度。 随机梯度下降(SGD) 小批量SGD过程如下： 抽取训练样本x和对应目标y组成数据批量 在x上运行网络，得到预测值y_pred 计算网络在这批数据上的损失，用于衡量y_pred和y之间的距离 计算损失相对于网络参数的梯度 将参数沿着梯度的反方向移动一点 W -= step * gradient ，从而使这批数据上的损失减小一点。这里的step即步长也叫学习率。 目前实践中的优化器optimizer都采用的是随机梯度下降，不同的是各自进行了某些优化，这些SGD变体有：带动量的SGD，Adagrad，RMSProp等。 二分类问题 imdb电影评论二分类问题，输出评论文字，然后得出评论积极还是消极。 准备数据 imdb电影评论的数据，其内部建立了一个字典索引，某个整数对应某个单词。 具体某一个评论是一个整数序列，下面有两种方法将这个整数序列张量化： 填充或截取，使得每个整数序列具有相同的长度，然后神经网络第一层必须是 Embedding 层。 对列表进行one-hot编码，比如说[3,5]在长度10的情况下编码为 [0,0,1,0,1,0,0,0,0,0] ，然后第一层使用Dense层，这个前面提到过了。 验证集 在model.fit 里面你可以通过 validation_data 参数来指定验证集，验证集和训练模型无关，是一个epoch之后来运算验证当前模型的效果，可以及时发现模型出现过拟合问题或者其他问题，从而决定是否终止训练模型。 你可以从训练集里面切一部分下来作为训练集，也可以直接使用测试集作为验证集【这里简单起见就直接用测试集做了验证集，正式的做法叫做留出验证集法，是应该操作如下：训练数据里面一部分作为训练集，剩下来的一部分作为验证集，然后用训练集训练，验证集评估当前模型的好坏。模型参数调节好训练好之后，记得最后用整个训练集从头训练一次，最后用另外的测试集数据测试下模型的实际效果】。 from keras.datasets import imdb import numpy as np ( train_data , train_labels ),( test_data , test_labels ) = imdb . load_data ( num_words = 10000 ) y_train = np . asarray ( train_labels ) . astype ( 'float32' ) y_test = np . asarray ( test_labels ) . astype ( 'float32' ) word_index = imdb.get_word_index() reversed_word_index = dict([value,key] for key,value in word_index.items()) decoded_review = ' '.join([reversed_word_index.get(i-3, '?') for i in train_data[0]]) decoded_review 这里采用的是one-hot编码，值得注意的是一句话如果有几个重复的单词，将是被忽略的，第一种方案填充截取方案会保留词语顺序，这个在自然语言处理中是很重要的一个因素。 import numpy as np def verctorize_sequences ( sequences , dimension = 10000 ): results = np . zeros (( len ( sequences ), dimension )) for i , sequence in enumerate ( sequences ): for d in sequence : results [ i , d ] = 1 return results x_train = verctorize_sequences(train_data) x_test = verctorize_sequences(test_data) from keras.models import Sequential from keras.layers import Dense , Dropout from keras.optimizers import RMSprop model = Sequential () model . add ( Dense ( 16 , activation = 'relu' , input_shape = ( 10000 ,))) model . add ( Dense ( 16 , activation = 'relu' )) model . add ( Dense ( 1 , activation = 'sigmoid' )) model . summary () model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy']) history = model.fit(x_train, y_train, epochs=4, batch_size=512, validation_data=(x_test, y_test)) history作图 keras出来的history并没提供作图函数，下面简单整理了一下： import matplotlib.pyplot as plt def plot_history_loss ( history ): acc = history . history [ 'acc' ] val_acc = history . history [ 'val_acc' ] loss = history . history [ 'loss' ] val_loss = history . history [ 'val_loss' ] epochs = range ( 1 , len ( acc ) + 1 ) # \"bo\" is for \"blue dot\" plt . plot ( epochs , loss , 'bo' , label = 'Training loss' ) # b is for \"solid blue line\" plt . plot ( epochs , val_loss , 'b' , label = 'Validation loss' ) plt . title ( 'Training and validation loss' ) plt . xlabel ( 'Epochs' ) plt . ylabel ( 'Loss' ) plt . legend () plt . show () plot_history_loss ( history ) def plot_history_acc ( history ): acc = history . history [ 'acc' ] val_acc = history . history [ 'val_acc' ] epochs = range ( 1 , len ( acc ) + 1 ) plt . plot ( epochs , acc , 'bo' , label = 'Training acc' ) plt . plot ( epochs , val_acc , 'b' , label = 'Validation acc' ) plt . title ( 'Training and validation accuracy' ) plt . xlabel ( 'Epochs' ) plt . ylabel ( 'Loss' ) plt . legend () plt . show () plot_history_acc ( history ) 这个基本上ephch超过2,3之后就开始过拟合了，但是精度没有超过90%的。Keras中的example相关看了一下，就算使用CNN提升也不是很明显，倒是用了数据预处理这块使用了二元模型，准确度稍微提升了一点，可见就imdb这个例子，必须加上自然语言处理相关的数据预处理步骤才能更好地提升准确度。 总结 使用验证集和绘图能够很好地观察过拟合现象，这个不能省，最后测试集环节省了验证集也不要省。 二分类问题最后一层激活函数推荐 sigmoid，损失函数推荐 binary_crossentorpy relu激活的Dense层堆叠，可以解决很多问题。 无论问题是什么，rmsprop优化器通常都是一个好的选择。 多分类问题 将某个数据点划分为某一个类别，但是有多个分类的问题是单标签多分类问题；如果某个数据点可以划分为多个分类，则为多标签多分类问题。 多分类问题在处理上和二分类问题很类似，除了一些细节上的差异： 标签数据张量化可以使用 to_categorical 来进行one-hot编码，然后损失函数需要选择 categorical_crossentropy 。或者标签数据直接作为整数标签转成ndarray对象送入，这时需要选择损失函数 sparse_categorical_crossentropy ，这两者只是接口差异，内部算法一样的。 多分类问题神经网络最后一层应该是对应N个分类的N个units的Dense层。 多分类问题神经网络应该避免使用太小的中间层，以免出现信息瓶颈。 回归问题 回归问题预测是连续的值而不是离散的标签。 取值范围差异很大的数据 取值范围差异很大的数据送入神经网络需要先进行标准化处理。这里指的标准化是正态分布那边的概念，也就是计算每个特征值的z-score标准分。即 每个特征值减去本特征的平均值然后除以本特征的标准差。 mean = train_data.mean(axis=0) 这是计算维度0的均值，或者说是计算每个特征列的均值。减去操作如下： train_data -= mean 这里往细上将还进行了mean的广播操作，所以才能按照元素点对点的执行了减法操作。 这是计算每个特征列的标准差： std = train_data.std(axis=0) 注意： 用于测试数据标准化的均值和标准差都是训练数据上的。在工作流程上，你不能从测试数据上计算得到任何结果。 K折验证 如果可用数据较少，可以使用K折验证来可靠地评估模型。 K折验证是将验证数据分成K分，重复K次，每次选取一个作为测试集，其他作为训练集。模型的最终验证分数等于K个验证分数的均值。 总结 回归问题神经网络最后一层没有激活函数，可以返回任意范围内的值。 回归问题常用损失函数：mse损失函数。MSE（mean squared error） 均方误差损失函数。 回归问题监控指标：平均绝对误差。MAS （mean absolute error）是预测值和目标值之差的绝对值。 如果可用的训练数据较少，最好使用隐藏层较少的小型网络，避免严重的过拟合 参考资料 机器学习实战 Peter Harrington 著 李锐 李鹏等译 机器学习实战线上教程 python深度学习 弗朗索瓦·肖奈 if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js','mhchem.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"机器学习","url":"articles/machine-learning-talk-three.html"},{"title":"机器学习第二谈之初识多层神经网络","text":"前言 本文先用tensorflow来实现单层神经网络处理mnist问题，然后用keras来写一个两层神经网络来解决mnist问题。最后试着用keras编写一个简单的深度学习模型，也就是多层神经网络来解决mnist问题。 本文代码主要参考了keras的examples代码库，同时本文也考虑了一些输入数据的预处理统一化过程。 数据预处理 首先我们利用keras来下载mnist相关数据并进行必要的预处理操作。 from keras.datasets import mnist ( train_images , train_labels ), ( test_images , test_labels ) = mnist . load_data () train_images.shape (60000, 28, 28) train_labels.shape (60000,) train_images 的shape第一维度是60000，说明有6万个图片，然后标签第一维度也是6万与之对应。 train_images = train_images . reshape (( 60000 , 784 )) train_images = train_images . astype ( 'float32' ) train_images = train_images / 255 第一步将第二维第三维数据合并到一维。 第二步是转换ndarray的dtype数据类型。 第三部是将数据0-255 归一化为 0- 1 。 类似的test_images也需要这样处理，这里就略过了。 标签数据需要进行one-hot编码处理： from keras.utils import to_categorical train_labels = to_categorical ( train_labels ) train_labels [ 0 ] array ([ 0. , 0. , 0. , 0. , 0. , 1. , 0. , 0. , 0. , 0. ], dtype = float32 ) one-hot编码的具体解释这里略过了，其他地方会讨论的。 感知器 感知器就是一层或者说单层神经网络。感知器类似于逻辑回归模型，只能做线性分类任务。 单层神经网络的编写用Keras非常的简单，但如果用tensorflow还是需要写一些代码的。不过作为一开始推荐还是用tensorflow来写一个简单的单层神经网络。因为Keras是基于tensorflow的更高层模块，这对于我们理解Keras具体做了什么工作很有帮助，也能帮助我们理解具体单层神经网络进行了那些数学运算。 x = tf . placeholder ( tf . float32 , [ None , 784 ]) W = tf . Variable ( tf . zeros ([ 784 , 10 ])) b = tf . Variable ( tf . zeros ([ 10 ])) y_true = tf . placeholder ( tf . float32 , [ None , 10 ]) y_logits = tf . matmul ( x , W ) + b y_pred = tf . nn . softmax ( y_logits ) 输入参数x第二维度784对应权重矩阵第一维度784，通常神经网络权重矩阵W的shape是(前一层节点数, 后一层节点数) 。这样输入参数矩阵x和权重矩阵W进行矩阵乘法【张量的点积，np.dot运算】之后得到第二维度等于权重矩阵第二维度的矩阵。输出的值数据送入 y_logits。这里 tf.matmul 就是进行的矩阵的乘法运算。 这里 tf.nn.softmax 是激活函数，具体softmax激活函数的讨论这里略过了。 交叉熵 tensorflow提供了专门的交叉熵计算函数，这里我们先用更原始的计算公式来看一下（参考了 这篇文章 ）： cross_entropy = - tf . reduce_sum ( y_true * tf . log ( y_pred )) 大体过程如下所示： $$ - \\sum (1,0,0) * log((0.5,0.4,0.1)) = -(1*log0.5 + 0*log0.4 + 0*log0.1) = 0.301 $$ 交叉熵越大那么预测值越偏离真实值，交叉熵越小那么预测值越接近真实值。 train_step = tf . train . GradientDescentOptimizer ( 0.01 ) . minimize ( cross_entropy ) # 0.01是学习速率 使用tensorflow自带的交叉熵方法 推荐使用tensorflow自带的softmax+交叉熵方法来计算交叉熵，参考了 这篇文章 ，说是计算会更稳定些。 现在让我们把到目前的代码整理一下： import tensorflow as tf from keras.datasets import mnist ( train_images , train_labels ), ( test_images , test_labels ) = mnist . load_data () train_images = train_images . reshape (( 60000 , 784 )) train_images = train_images . astype ( 'float32' ) train_images = train_images / 255 test_images = test_images . reshape (( 10000 , 784 )) test_images = test_images . astype ( 'float32' ) test_images = test_images / 255 from keras.utils import to_categorical train_labels = to_categorical ( train_labels ) test_labels = to_categorical ( test_labels ) x = tf . placeholder ( tf . float32 , [ None , 784 ]) W = tf . Variable ( tf . zeros ([ 784 , 10 ])) b = tf . Variable ( tf . zeros ([ 10 ])) y_true = tf . placeholder ( tf . float32 , [ None , 10 ]) y_logits = tf . matmul ( x , W ) + b y_pred = tf . nn . softmax ( y_logits ) cross_entropy = tf . reduce_sum ( tf . nn . softmax_cross_entropy_with_logits ( logits = y_logits , labels = y_true )) train_step = tf . train . GradientDescentOptimizer ( 0.01 ) . minimize ( cross_entropy ) 好了，我们的例子进入收尾阶段了： correct_mask = tf . equal ( tf . argmax ( y_pred , 1 ), tf . argmax ( y_true , 1 )) accuracy = tf . reduce_mean ( tf . cast ( correct_mask , tf . float32 )) with tf . Session () as sess : # Train sess . run ( tf . global_variables_initializer ()) count = 0 for _ in range ( 128 ): batch_xs = train_images [ count * 128 : 128 * ( count + 1 )] batch_ys = train_labels [ count * 128 : 128 * ( count + 1 )] sess . run ( train_step , feed_dict = { x : batch_xs , y_true : batch_ys }) count += 1 if count % 10 == 0 : ans = sess . run ( accuracy , feed_dict = { x : test_images , y_true : test_labels }) print ( \"Accuracy: {:.4}%\" . format ( ans * 100 )) # LAST ans = sess . run ( accuracy , feed_dict = { x : test_images , y_true : test_labels }) print ( \"Accuracy: {:.4}%\" . format ( ans * 100 )) 关于tf.argmax 函数请看下面的例子。不感兴趣的可以略过，其作用就是把标签解释出来，不是这里的重点。 import tensorflow as tf sess = tf . Session () m = sess . run ( tf . truncated_normal (( 5 , 10 ), stddev = 0.1 ) ) ----- array ([[ 0.0919205 , 0.06030607 , 0.01196606 , 0.03031359 , - 0.13546242 , - 0.12748787 , - 0.09680127 , 0.12220833 , 0.15264732 , 0.05449662 ], [ 0.01277541 , - 0.00535311 , 0.03589706 , 0.01658093 , - 0.16726552 , - 0.06979545 , - 0.14876817 , - 0.03735523 , - 0.0439501 , 0.15896702 ], [ - 0.05869294 , - 0.14986654 , - 0.17551927 , 0.08360171 , - 0.00648978 , - 0.03274798 , - 0.05770732 , 0.01505487 , 0.13726853 , - 0.01670119 ], [ - 0.02666636 , - 0.05316785 , - 0.05433881 , - 0.02210794 , 0.01175172 , - 0.0674843 , - 0.06402522 , 0.00812987 , - 0.17738222 , 0.01375954 ], [ - 0.01734987 , 0.01096244 , - 0.19889738 , 0.08350741 , - 0.00222254 , 0.05094135 , 0.06777989 , - 0.01986633 , - 0.1863249 , - 0.04648132 ]], dtype = float32 ) --- col_max = sess . run ( tf . argmax ( m , 0 ) ) ---- array ([ 0 , 0 , 1 , 2 , 3 , 4 , 4 , 0 , 0 , 1 ], dtype = int64 ) --- row_max = sess . run ( tf . argmax ( m , 1 ) ) --- array ([ 8 , 9 , 8 , 9 , 3 ], dtype = int64 ) --- 所以 tf.argmax 第二个参数是1，那么返回一行数值最大的那个index索引值。 tf.argmax(y_pred, 1) 返回的那个索引值在本例中比较简单，就是实际预测的数字值。 tf.reduce_mean 将所有维度的元素相加然后求平均值 这个例子最后就是调用tensorflow的作业流程，启动运算数据流。然后评估一下对于测试数据现在精度如何了。这些不是这里的重点。就单层神经网络来说mnist例子很难超过90%的。 多层感知器 多层感知器实际上就是两层全连接神经网络。理论上两层神经网络可以无限逼近任意连续的函数了。下面用Keras来实现一个多层感知器。 首先我们试着把上面单层神经网络用Keras写一遍，下面是准备数据过程，后面都一样的。 准备数据 import tensorflow as tf from keras.datasets import mnist ( train_images , train_labels ), ( test_images , test_labels ) = mnist . load_data () train_images = train_images . reshape (( 60000 , 784 )) train_images = train_images . astype ( 'float32' ) train_images = train_images / 255 test_images = test_images . reshape (( 10000 , 784 )) test_images = test_images . astype ( 'float32' ) test_images = test_images / 255 from keras.utils import to_categorical train_labels = to_categorical ( train_labels ) test_labels = to_categorical ( test_labels ) 建模 from keras.models import Sequential from keras.layers import Dense model = Sequential () model . add ( Dense ( 10 , activation = 'softmax' , input_shape = ( 784 ,))) model . compile ( optimizer = 'rmsprop' , loss = 'categorical_crossentropy' , metrics = [ 'accuracy' ]) model . fit ( train_images , train_labels , epochs = 5 , batch_size = 128 ) Epoch 1/5 60000/60000 [==============================] - 1s 13us/step - loss: 0.6063 - acc: 0.8482 Epoch 2/5 60000/60000 [==============================] - 1s 12us/step - loss: 0.3316 - acc: 0.9083 Epoch 3/5 60000/60000 [==============================] - 1s 12us/step - loss: 0.3025 - acc: 0.9159 Epoch 4/5 60000/60000 [==============================] - 1s 11us/step - loss: 0.2889 - acc: 0.9194 Epoch 5/5 60000/60000 [==============================] - 1s 12us/step - loss: 0.2806 - acc: 0.9219 score = model.evaluate(test_images, test_labels, verbose=0) print('Test loss:', score[0]) print('Test accuracy:', score[1]) Test loss: 0.2757013351589441 Test accuracy: 0.9232 结果大概也是差不多的。因为这个例子多运行几次epoch，但单层神经网络再怎么优化也只能到92%了。 上面的建模过程稍微加一行，我们就构建了一个多层感知器。一般多层神经网络前面的激活函数选relu会更好一些。也就多加了一层，最后输出节点数为10的神经网络。 from keras.models import Sequential from keras.layers import Dense model = Sequential () model . add ( Dense ( 512 , activation = 'relu' , input_shape = ( 784 ,))) model . add ( Dense ( 10 , activation = 'softmax' )) model . compile ( optimizer = 'rmsprop' , loss = 'categorical_crossentropy' , metrics = [ 'accuracy' ]) model . fit ( train_images , train_labels , epochs = 5 , batch_size = 128 ) Epoch 1/5 60000/60000 [==============================] - 5s 85us/step - loss: 0.2569 - acc: 0.9258 Epoch 2/5 60000/60000 [==============================] - 5s 84us/step - loss: 0.1037 - acc: 0.9688 Epoch 3/5 60000/60000 [==============================] - 5s 87us/step - loss: 0.0685 - acc: 0.9790 Epoch 4/5 60000/60000 [==============================] - 5s 85us/step - loss: 0.0508 - acc: 0.9848 Epoch 5/5 60000/60000 [==============================] - 5s 87us/step - loss: 0.0368 - acc: 0.9888 Test loss: 0.07560657636675751 Test accuracy: 0.9777 精度能够到97%了。 下面是Keras代码库examples里面的解决mnist问题的多层感知器，我根据上面的讨论将代码稍微调整下，建模过程如下： from keras.models import Sequential from keras.layers import Dense , Dropout from keras.optimizers import RMSprop model = Sequential () model . add ( Dense ( 512 , activation = 'relu' , input_shape = ( 784 ,))) model . add ( Dense ( 512 , activation = 'relu' )) model . add ( Dense ( 10 , activation = 'softmax' )) model . summary () 区别就是又加了一层神经网络。 Epoch 1/5 60000/60000 [==============================] - 8s 139us/step - loss: 0.2197 - acc: 0.9320 Epoch 2/5 60000/60000 [==============================] - 8s 140us/step - loss: 0.0815 - acc: 0.9750 Epoch 3/5 60000/60000 [==============================] - 9s 145us/step - loss: 0.0530 - acc: 0.9836 Epoch 4/5 60000/60000 [==============================] - 9s 151us/step - loss: 0.0374 - acc: 0.9886 Epoch 5/5 60000/60000 [==============================] - 9s 151us/step - loss: 0.0302 - acc: 0.9899 Test loss: 0.08149926771794035 Test accuracy: 0.9808 examples里面还新加入了Dropout层，这个是一种过拟合技术，我们加上之后会如何： from keras.models import Sequential from keras.layers import Dense , Dropout from keras.optimizers import RMSprop model = Sequential () model . add ( Dense ( 512 , activation = 'relu' , input_shape = ( 784 ,))) model . add ( Dropout ( 0.2 )) model . add ( Dense ( 512 , activation = 'relu' )) model . add ( Dropout ( 0.2 )) model . add ( Dense ( 10 , activation = 'softmax' )) model . summary () Epoch 1/5 60000/60000 [==============================] - 10s 162us/step - loss: 0.2439 - acc: 0.9253 Epoch 2/5 60000/60000 [==============================] - 10s 169us/step - loss: 0.1031 - acc: 0.9688 Epoch 3/5 60000/60000 [==============================] - 9s 151us/step - loss: 0.0760 - acc: 0.9771 Epoch 4/5 60000/60000 [==============================] - 10s 165us/step - loss: 0.0604 - acc: 0.9817 Epoch 5/5 60000/60000 [==============================] - 9s 155us/step - loss: 0.0512 - acc: 0.9846 Test loss: 0.07319687194137806 Test accuracy: 0.9814 区别其实不大，至少就mnist来说提升最大的是又新加入了一层神经网络，加入Dropout层没看出区别。 多层神经网络或者深度学习 卷积神经网络相关后面的讨论补上，这里我们主要来看下Keras代码库examples里面介绍的用CNN，深度学习神经网络来解决mnist问题效果如何。具体理解后面再说。 import tensorflow as tf from keras.datasets import mnist ( train_images , train_labels ), ( test_images , test_labels ) = mnist . load_data () from keras import backend as K if K . image_data_format () == 'channels_first' : train_images = train_images . reshape ( 60000 , 1 , 28 , 28 ) test_images = test_images . reshape ( 10000 , 1 , 28 , 28 ) input_shape = ( 1 , 28 , 28 ) else : train_images = train_images . reshape ( 60000 , 28 , 28 , 1 ) test_images = test_images . reshape ( 10000 , 28 , 28 , 1 ) input_shape = ( 28 , 28 , 1 ) 这里似乎涉及到不同backend的图形维度选择问题，这个后面再说。 train_images = train_images . astype ( 'float32' ) train_images = train_images / 255 test_images = test_images . astype ( 'float32' ) test_images = test_images / 255 from keras.utils import to_categorical train_labels = to_categorical ( train_labels ) test_labels = to_categorical ( test_labels ) 继续之前的数据预处理。 from keras.models import Sequential from keras.layers import Dense , Dropout , Flatten from keras.layers import Conv2D , MaxPooling2D from keras.optimizers import Adadelta model = Sequential () model . add ( Conv2D ( 32 , activation = 'relu' , input_shape = input_shape , kernel_size = ( 3 , 3 ))) model . add ( Conv2D ( 64 , ( 3 , 3 ), activation = 'relu' )) model . add ( MaxPooling2D ( pool_size = ( 2 , 2 ))) model . add ( Dropout ( 0.25 )) model . add ( Flatten ()) model . add ( Dense ( 128 , activation = 'relu' )) model . add ( Dropout ( 0.5 )) model . add ( Dense ( 10 , activation = 'softmax' )) model . summary () 本例子跑起来开始有点慢了。Dropout应该不算一层，Flatten我估计不算一层，那么上面例子大概有5层。 Epoch 1/5 60000/60000 [==============================] - ETA: 0s - loss: 0.2683 - acc: 0.917 - 119s 2ms/step - loss: 0.2683 - acc: 0.9173 Epoch 2/5 60000/60000 [==============================] - 120s 2ms/step - loss: 0.0891 - acc: 0.9734 Epoch 3/5 60000/60000 [==============================] - 115s 2ms/step - loss: 0.0655 - acc: 0.9804 Epoch 4/5 60000/60000 [==============================] - 111s 2ms/step - loss: 0.0555 - acc: 0.9833 Epoch 5/5 60000/60000 [==============================] - 114s 2ms/step - loss: 0.0466 - acc: 0.9856 Test loss: 0.031076731445921907 Test accuracy: 0.9898 例子报道说epochs=12的时候精度能够上升到99%。 为了公平起见，绝对多层感知器和CNN神经网络这两个例子都按照epochs=12再跑一次来对比一下看看。 多层感知器： Test loss: 0.08958661408673184 Test accuracy: 0.9821 和跑5次没有区别了。 CNN的看了一下个人PC CPU基本上跑满了，然后GPU没怎么用，tensorflow决定换成tensorflow-gpu 【PS：注意之前你用pip安装tensorflow了的，再安装个tensorflow-gpu即可，原来那个tensorflow包不能删的。】然后再看下。然后发现我这里显卡写着Intel UHD，似乎只有NAVID才能开启gpu，算了。 CNN神经网络： Test loss: 0.028602463609369078 Test accuracy: 0.992 精度提升到了99%，看来CNN多训练几次后续效果还能提升，别小看了这1%的提升啊！ 保存模型 一次训练有点费时了，那么如何保存训练好的模型呢？这个问题在keras文档FAQ里面有，算是很经典的一个问题了。 model.save('my_model.h5') 保存的数据有： 模型的结构，方便重新创造模型 模型训练得到的权重数据 训练损失和优化器配置 优化器状态，允许继续上一次训练 下次使用模型如下所示： import tensorflow as tf from keras.datasets import mnist ( train_images , train_labels ), ( test_images , test_labels ) = mnist . load_data () from keras import backend as K if K . image_data_format () == 'channels_first' : test_images = test_images . reshape ( 10000 , 1 , 28 , 28 ) input_shape = ( 1 , 28 , 28 ) else : test_images = test_images . reshape ( 10000 , 28 , 28 , 1 ) input_shape = ( 28 , 28 , 1 ) test_images = test_images . astype ( 'float32' ) test_images = test_images / 255 from keras.utils import to_categorical test_labels = to_categorical ( test_labels ) from keras.models import load_model model = load_model ( 'cnn_for_mnist_model.h5' ) score = model.evaluate(test_images, test_labels, verbose=0) print('Test loss:', score[0]) print('Test accuracy:', score[1]) Test loss: 0.028602463609369078 Test accuracy: 0.992 参考资料 机器学习实战 Peter Harrington 著 李锐 李鹏等译 机器学习实战线上教程 python深度学习 弗朗索瓦·肖奈 deep learning 中文版 机器学习 周志华著 这个文章介绍神经网络写的很好 if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js','mhchem.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"机器学习","url":"articles/machine-learning-talk-two.html"},{"title":"tensorflow模块","text":"前言 本文档记录关于tensorflow模块学习中的一些东西。 tensorflow是通用的数据流计算图框架，一般我们都会写上一个简单的hello world例子来简单了解一下目标框架： h = tf . constant ( 'hello' ) w = tf . constant ( ' world.' ) hw = h + w with tf . Session () as s : res = s . run ( hw ) print ( res ) tf.constant 表示一个常量，简单理解就相当于一个不断输出某个数值的节点。hw将两个常量相加，相当于连接两个节点执行了相加操作。tensorflow有个计算图的概念，在这个计算图中，具体计算只有在session回话实际 run 的时候才会执行： with tf . Session () as sess : do something 神经网络结构 神经元中的数据，或者是输入的，或者是常数，其后神经元的数据则是在数据流动中生成出来的。 神经元的连接用权重矩阵表示，某个节点神经元中的数据值 = 前输入层 * 权重矩阵，用数学公式表达可能更好： $$ data = \\begin{bmatrix} x1 & x2 & x3 \\end{bmatrix} \\begin{bmatrix} w1\\\\ w2\\\\ w3 \\end{bmatrix} $$ 第二个神经元的权重在第二列展开， 一层一层之间的连接用矩阵乘法表示，即 a = tf.matmul(x, w1) y = tf.matmul(a, w2) 前一层的输出就是后一层的第一个输入参数。 变量 用 tf.Variable 来定义一个变量，变量相当于一个节点其内数据值是变动的。我们可以用 tf.assign 来手动给某个变量赋值。 placeholder tf.placeholder 占位节点，和常量相比这个节点暂时还没有数据，是等后面在session 启动之后将通过 feed_dict 把数据塞进去。通常外面的数据流输入就输入到placeholder哪里。 tf.placeholder(dtype, [None, dim]) 这里None的意思是不确定要输入多少个数据，后面的dim指定具体输入数据的个数。 初始所有变量 with tf . Session () as sess : init_op = tf . global_variables_initializer () sess . run ( init_op ) if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js','mhchem.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"机器学习","url":"articles/tensorflow-module.html"},{"title":"机器学习第一谈","text":"前言 目前很火热的深度学习其本质仍然属于机器学习中比较厉害的一种技术，但不管是更好地理解这门技术和使用这门技术，都还是要打好机器学习这门学科的基本功。所以本分类机器学习除了包括传统机器学习的讨论外，还将包括神经网络和深度学习，以及相关的模块keras，tensorflow，可能还会包括matplotlib或者numpy等相关模块的讨论。 之所以这门技术不叫人工智能是很务实的态度，我很确信目前的深度学习等及其他技术将成为未来人工智能技术的基石，更确切来说是类似砖木一般的存在，但就目前机器学习的发展程度来说，还远远不足以称之为人工智能。因为目前机器学习的发展状态就是：对于人工智能领域最核心的一些问题，甚至连提出来的勇气都没有，更不要说解决他们了。 我接下来重点在学习理解深度学习上，传统机器学习和神经网络会有所谈论只是为了更好地理解深度学习相关概念。 机器学习能做什么 在开始讨论机器学习之前，我们程序员首先应该转变一种思维方式，机器学习并不是我们常见的那些算法，在那些算法里面，计算机该做什么，该处理什么数据，数据是什么含义都是程序员去定义的。而机器学习的意思是让机器自己去学习，去学习现实世界各个事物运行变化的规律，当然机器学习目前各个算法能力还是很有限的，但整个学科的发力方向就是这样，所以具体我们遇到某个问题的时候，程序员更多的不应该是去自己去分析研究对象的各个数据规律或者规则，而应该讲这些数据和答案（标签）送给机器学习算法，让机器自己总结出研究对象的规律或者规则。 这看上去很神奇，其实就是一些数据转换的工作，更多的是工程上的东西。 传统机器学习应用 传统机器学习可能应用领域如下： 电子邮件垃圾邮件过滤算法 搜索引擎根据你的点击记录来优化你的下次搜索结果 你在网上点击或者查看或者买了某个东西，网站记录你的这些活动，从而更好地为你推荐商品，或者推荐优惠券。 手写数字识别 你的一切金融活动，各大银行都上线了机器学习算法来判断你的贷款资格和贷款额度 深度学习应用领域 深度学习可能应用领域有： 将向量数据映射到向量数据 预测性医疗保健 分析患者的医疗保健数据 产品质量控制 将与某件产品制成品相关的一组属性映射到产品明年会坏掉的概率 将图像数据映射到向量数据 医生助手 将医学影像幻灯片映射到是否有肿瘤的判断 自动驾驶汽车 将车载摄像机的视频画面映射到方向盘角度控制命令 饮食助手 将食物照片映射到食物的卡路里数量 年龄预测 将自拍照片映射到人的年龄 将时间序列数据映射到向量数据 天气预报 将多个地点天气数据的时间序列映射到某地下周的天气数据 脑机接口 将脑磁图MEG数据的时间序列映射到计算机命令 行为定向 将网站上用户交互的时间序列映射到用户购买某件商品的概率 将文本映射到文本 智能回复 将电子邮件映射到合理的单行回复 回答问题 将常识问题映射到答案 生成摘要 将一篇文章映射到文章摘要 将图像映射到文本 图像描述 将图像映射到描述图像内容的简短说明 将文本映射到图像 图像生成 将简短的文字映射到与这段描述相匹配的图像 将图像映射到图像 超分辨率 将缩小的图像映射到相同图像的更高分辨率版本 理解神经网络 学习深度学习不一定要了解神经生物学，对于传统机器学习各个算法也不一定要面面俱到，但对于神经网络基本概念和具体里面矩阵，现在应该升级了，叫做张量运算还是应该有所了解的。 我们来看Keras的30s上手例子： from keras.models import Sequential model = Sequential () from keras.layers import Dense model . add ( Dense ( units = 64 , activation = 'relu' , input_dim = 100 )) model . add ( Dense ( units = 10 , activation = 'softmax' )) model . compile ( loss = 'categorical_crossentropy' , optimizer = 'sgd' , metrics = [ 'accuracy' ]) 首先我们需要建立一个模型，最常用的模型是 Sequential 顺序模型。这是最常用的模型。 神经网络现在的发展已经和大脑并无太多关系了，当然早期发展是吸收了一些灵感，所以人们也推荐神经网络应该叫做分层表示学习或者层级表示学习。 注意看上面 layer 就是层的意思，深度学习模型就是层的堆叠。 而上面的Dense 就是我们常说的全连接层。全连接层大概是这样的： 全连接层的意思是 本层的每个节点都和后一层的每个节点相连。 Dense的units参数是本层节点数的意思，其也还有一个意思，叫做本层的输出维度数。 每一层神经网络发生了 output = relu(dot(W, input) + b) 这样的数学运算。 其中 relu 是上面 Dense 指定的 activation 也就是激活函数。我觉得在这里去想神经网络原来那一套并不有助于我们的理解了，反倒是根据数学思维来更方便理解一些。每一层神经网络即这样一层数学运算层，能够对某一个数据集进行了某种线性变换，然后输出另外一个对应的数据集。就如同 弗朗索瓦·肖奈所打比方描述的： 一张纸被揉的皱巴巴的，我们可以通过一系列步骤的几何变换，每一步都只是简单的几何变换，但最终完成了某个展平动作，于是我们看到了这张纸上面写着的字。深度学习模型就是解开高纬数据复杂流形的数学机器。 我觉得弗朗索瓦·肖奈的另外一个比方也很好，很形象。可以把深度学习网络看做多级信息的蒸馏操作，信息穿越过滤器，然后纯度越来越高（对任务的帮助越来越大）。 上面公式中 W 是每一层的权重，深度学习训练的过程就是给每一次找到更好的权重参数，从而整个深度学习神经网络能够更好地帮助任务。 model.fit(x_train, y_train, epochs=5, batch_size=32) 训练的过程 x_train 是具体的数据， y_train 是对应的标签数据， epoch 是迭代次数，也就是对于某个训练数据的重复训练次数。batch_size 是一次训练所含样本数，参考了 这个网页 ，因为一次把所有样本训练完开销太大，而每训练一次就算一下损失函数震荡又大，所以现在通用的做法是： mini-batch gradient decent ，小批量数据的梯度下降。这里的batch_size 是一次训练所含的样本数，那么1个epoch就是把所有训练数据都训练完的训练次数是总样本数除以batch_size。 model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy']) 上面模型在compile的时候需要指定损失函数loss，损失函数是用来衡量模型得到的预测值和真实目标值之间的距离的，简单来说就是损失函数就是给目前模型打分的，来评价模型的效果好坏的。 根据打分来对模型的各个权重参数进行微调使用的是反向传播算法。 反向传播算法 反向传播算法（BP算法 backpropagation）。BP算法先将输入示例提供给输入层神经元，然后信号逐渐向前传递，直到产生输出层结果；然后计算输出层的误差，再将误差逆向传播直隐含层。最后根据隐含层神经元的误差来对连接权重和阈值进行调整的过程。改迭代过程循环进行，直到达到某个条件后停止。 反向传播算法进行调节由优化函数或者说优化器 optimizer来完成。 理解张量 标量 向量 矩阵 一般大家都有所接触了的，张量则是更多的维度的数据结构了。再谈到张量之后我发现之前那些图形几何上的理解的东西最好丢掉，而简单将张量理解为多个维度的数据结构。具体在python程序中就将张量看做numpy模块中的ndarray对象这是没有问题的。 张量的shape 首先看下矩阵方面的情况： (1,3） 这是一个行矢量， for example: [1,2,3] (3,1) 这是一个列矢量，for example： $$ \\begin{bmatrix} 1\\\\ 2\\\\ 3 \\end{bmatrix} $$ (2,3) 表示两行三列 小维度情况带上几何思维这没有问题，但到张量了比如说 shape (3,3,2,3) ，那么最好的理解是这个张量数据有四个维度，其中第一个维度的数据容量是3个，第二个维度的数据容量也是3个。 ndarray对象有这样的索引语法 ndarray[x, y , z] ，其中每一个维度也支持 ndarray[x1:x2, : , :] start:end 这样的语法。这样从维度来理解，就是第一个维度选择 x1:x2 之间，然后第二个维度选择所有，第三个维度选择组成的张量数据。总之在谈及张量的时候，即使是那些和空间关系很紧密的数据结构，我发现完全脱离几何思维，而只是单纯讨论维度会更方便些。 张量的dtype numpy的 ndarray对象，有一个 dtype参数 。表示目标张量数据结构所包含的数据类型。张量一般都包含的是数值型数据，也可能会有char型张量，但没有字符串型张量。不过我看到即使是单个字符，可能是处于字符编码问题考虑吧，但就算是纯英文的单个字符，我看到大家的通用做法还是建立字典，转成对应的数值型张量，估计计算速度也是一个考虑点吧。 样本维度 在深度学习领域，一般大家把第一个维度用作样本维度，所以我们看到MNIST例子中shape (60000,28,28)，第一个维度表示有60000个样本。 然后前面说到batch_size 是一次训练所含的样本数，所以实际一次训练模型送入的batch数据如下： batch_size = 128 batch = train_images[:128] # 第一个批次 batch = train_iamges[128:256] # 第二个批次 ... 参考资料 机器学习实战 Peter Harrington 著 李锐 李鹏等译 机器学习实战线上教程 python深度学习 弗朗索瓦·肖奈 deep learning 中文版 机器学习 周志华著 if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js','mhchem.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"机器学习","url":"articles/machine-learning-talk-one.html"},{"title":"wxpython第二谈","text":"动态多组件切换 用boxsizer来挂载一些面板，然后隐藏一些面板，并显示初始你想要显示的那个panel。Add, Show Hide 等方法来操作，最后注意Layout一下，这是基本功了。 这里值得一提的是，如果你只是本panel基本的Layout，那么多个panel切换父panel给那些子panel的size都是一致的，因为你的子panel各个size大小不同，如果你动态切换需要更好的效果，那么应该调用父panel的Layout。 某个子Panel的重写 一些参数的变化，你的子panel需要重写，这个时候推荐使用box的Replace方法： old_panel = self . category_sp2_panel new_panel = CategorySPInnerPanel ( self , data_list = value ) self . box . Replace ( old_panel , new_panel ) old_panel . Destroy () self . category_sp2_panel = new_panel 大体过程如上，实际切换推荐采用如下写法： 首先隐藏box所包含的所有子面板： def hide_all_panel(self): for panel in self.box.GetChildren(): self.box.Hide(panel.GetWindow()) 然后在决定显示那个子面板 self.box.Show(self.category_sp1_panel) 当然了最后记得要调用父面板级别的Layout一下。 全局捕捉异常 import sys import traceback import wx class Panel ( wx . Panel ): def __init__ ( self , parent ): super ( Panel , self ) . __init__ ( parent ) button = wx . Button ( self , label = '抛异常' ) button . Bind ( wx . EVT_BUTTON , self . OnButton ) def OnButton ( self , event ): 1 / 0 def MyExceptionHook ( etype , value , trace ): \"\"\" etype exception type value exception message trace traceback header :param etype: :param value: :param trace: :return: \"\"\" frame = wx . GetApp () . GetTopWindow () tmp = traceback . format_exception ( etype , value , trace ) exception = \"\" . join ( tmp ) print ( exception ) class DemoFrame ( wx . Frame ): def __init__ ( self ): super ( DemoFrame , self ) . __init__ ( None , - 1 , \"test capture all excepiton\" , size = ( 600 , 400 )) sys . excepthook = MyExceptionHook panel = Panel ( self ) if __name__ == '__main__' : app = wx . App () frame = DemoFrame () frame . Show () app . MainLoop () 实际过程很简单，就是把python的 sys.excepthook 重载为 MyExceptionHook 函数，一切异常交给它来处理。 验证器 验证器最开始是对于对话框的某些数据格式有限定要求，但后面发现验证器非常的有用，之前对话框管理 self.data 做的一些工作可以交给验证器来做，所以验证器这一块最好早接触。 一般使用验证器先自己定义一个验证器类，继承自 wx.Validator 。然后你自定义一个 Clone 方法，返回本验证器相同的副本。 验证器第一个功能是验证数据，你在本验证器类中定义的 Validate 方法就是做这个的。这个方法默认还将传递一个 win参数进来，这个win，比如说你的验证器类是挂载在某个TextCtrl上的，那么那个TextCtrl实例就是这个win，所以你可以方便引用这个win来获得数据。 如果 Validate 方法返回 True ，那么验证成功，如果返回 False，那么验证失败。再返回之前你还可以做一些其他的事情。 此外验证器类还需要定义 TransferToWindow 方法，表示验证器启动开始进行的动作；定义 TransferFromWindow 方法表示验证器验证结束后的动作。如果这两个函数都简单 return True ，那么将什么都不用做，此外你可以通过这两个方法一来一去来维护一个对话框维护的某个全局数据集。之前我还没接触验证器的时候，写了几十行代码为了维护一个类似的data数据集，而且是只要对话框各个控件稍有变动，就要触发一个事件进行数据同步动作。显然验证器的这种方案更加的优雅。 你的Dialog可能有几个控件，几个控件使用各自的validator是独立的，虽然你在写验证器类的时候可以统一为一个类，但实际运行时有好几个验证器各自起作用的。具体请看下面这个例子： import wx class CategorySPAddValidator ( wx . Validator ): def __init__ ( self , data , key ): super ( CategorySPAddValidator , self ) . __init__ () self . data = data self . key = key def Clone ( self ): return CategorySPAddValidator ( self . data , self . key ) def handle_targetCtrl_state ( self , targetCtrl , state ): \"\"\" 成功和失败的动作通用动作 :param state: :return: \"\"\" if state : targetCtrl . SetBackgroundColour ( wx . SystemSettings . GetColour ( wx . SYS_COLOUR_WINDOW )) targetCtrl . Refresh () else : targetCtrl . SetBackgroundColour ( \"pink\" ) targetCtrl . SetFocus () targetCtrl . Refresh () def Validate ( self , win ): targetCtrl = self . GetWindow () value = targetCtrl . GetValue () state = True if self . key == 'name' : if len ( value ) == 0 : dlg = wx . MessageDialog ( win , \"科目名称不能为空\" , '输入有误' ) dlg . ShowModal () state = False elif self . key == 'code' : if len ( value ) == 0 : dlg = wx . MessageDialog ( win , \"税收分类编码不能为空.\" , '输入有误' ) dlg . ShowModal () state = False elif len ( value ) != 19 : dlg = wx . MessageDialog ( win , \"税收分类编码必须是19位.\" , '输入有误' ) dlg . ShowModal () state = False elif self . key == 'unit' : pass elif self . key == 'price' : pass self . handle_targetCtrl_state ( targetCtrl , state ) return state def TransferToWindow ( self ): \"\"\" 对话框打开是，读取数据到窗体 :return: \"\"\" targetCtrl = self . GetWindow () state = True value = None if self . key == 'name' : value = self . data . get ( 'spmc' , '' ) elif self . key == 'code' : value = self . data . get ( 'spbm' , '' ) elif self . key == 'unit' : value = self . data . get ( 'jldw' , '' ) elif self . key == 'price' : value = self . data . get ( 'dj' , '' ) targetCtrl . SetValue ( value ) return state def TransferFromWindow ( self ): \"\"\" 对话框关闭 :return: \"\"\" targetCtrl = self . GetWindow () value = targetCtrl . GetValue () state = True if self . key == 'name' : self . data [ 'spmc' ] = value elif self . key == 'code' : self . data [ 'spbm' ] = value elif self . key == 'unit' : self . data [ 'jldw' ] = value elif self . key == 'price' : self . data [ 'dj' ] = value return state 这个例子我是跟着wxpython in action 一书上的例子进行了一些优化，一开始我以为书上的例子并没有很好地解决dialog那边数据传输问题，但最神奇的是，原对话框的 self.data 属性已经发生更改了，而且我确认 TransferFromWindow 哪里 self.data 指的的本验证器，当然。但问题是后面我调用dlg里面的data数据，没想到就是修改好的数据。所以现在的问题是，Why it works . 一个初步的猜测是wxpython的验证器非常聪明地将我之前传输 self.data 数据进来的时候就把它记住了，只能做这个解释。 经过试验发现上面如果面板层次稍微复杂点，上面的self.data直接操作风格就不行了，而如果你的验证器要管理多个数据也不能这样做的。总之关于验证器基本该了解的就是这么多了，具体数据传输，到母面板的哪里，或者从哪里提取数据，这些都是小细节了。 上面的代码只是一个演示功能，读者具体自己写代码还是不要寄托这些神奇的魔法，应该更加明晰的指定数据从哪里来，到哪里去。 wxpython和asyncio的集成 本小节主要参考了 这个代码文件 。我看了一下，空闲事件和Timer事件都彼此触发，重复得很明显，就选择一个Timer触发即可。 然后看了一下asyncio的相关文档，stop是不会让事件循环中的任务丢失的，所以总的效果就是asyncio 的事件循环一直在后台运行就是了。 self . timer = wx . Timer ( self ) self . timer . Start ( 1 ) self . Bind ( wx . EVT_TIMER , self . idle_handler ) self . eventloop = asyncio . get_event_loop () def idle_handler ( self , event ): \"\"\" Idle handler runs the asyncio event loop. \"\"\" self . eventloop . call_soon ( self . eventloop . stop ) self . eventloop . run_forever () 利用进程间通信来实现多次启动应用只有一个应用 前面已经讲了wxpython如何实现确保只有一个程序实例在运行，就是利用 wx.SingleInstanceChecker 这个类，具体使用很简单。 但我们如何实现那种效果，就是下一次点击应用图标，还是弹出的原窗体应用，而第二次启动应用尝试悄然结束即可。 仔细分析问题和查了一些资料之后发现，这实际上就是一个简单的进程间通信问题。第二次启动应用的进程，只要发送一个简单的消息给原应用就可以实现这种效果了。 了解进程间通信原理之后发现这块还挺复杂的，尤其是windows的那些win32 API操作，我非常的不熟悉，然后看到套接字也可以做进程间通信，这说白了就是你的应用开了一些小的server监听端口和client请求。这种实现方式兼容性是最好的，但一开始我总感觉是不是有点杀鸡用牛刀了，因为我就想发个简单的信号即可，然后了解到python的signal模块在windows这边兼容性不好，其他windows的win32操作麻烦还不一定是个好方案，就决定写个简单的套接字。 好在应用asyncio事件循环上面提及的，已经挂载在应用上了，也就是说我们只需要利用asyncio模块照着教程写个最简单的套接字发送一个简单的消息即可。 LOCAL_SOCKET_PORT = 10000 MSG_INSTANCE = 'instance' async def handle_local_socket_server ( reader , writer ): data = await reader . read () message = data . decode () if message == MSG_INSTANCE : logger . info ( 'another instance is calling.' ) mainFrame = get_mainFrame () mainFrame . taskBarIcon . max_show () async def handle_local_socket_client ( message , loop ): reader , writer = await asyncio . open_connection ( '127.0.0.1' , LOCAL_SOCKET_PORT , loop = loop ) writer . write ( message . encode ()) await writer . drain () writer . close () ..... if self . instance . IsAnotherRunning (): self . eventloop . run_until_complete ( handle_local_socket_client ( MSG_INSTANCE , loop = self . eventloop )) logger . warning ( '已经有一个潮生活发票助手程序在运行了！' ) return False else : local_socket_server = asyncio . start_server ( handle_local_socket_server , '127.0.0.1' , port = LOCAL_SOCKET_PORT , loop = self . eventloop ) self . eventloop . run_until_complete ( local_socket_server ) 大概代码如上所示，最后效果还挺不错的。 这里基本上只用到了asyncio套接字编程最基础的那些知识，这里有个问题，我这边还没有试探：那就是按照道理只需要 self.eventloop.create_task 把任务挂上去即可，而不需要 run_until_complete 的，可能是前面提及的wxpython和asyncio集成，要稍后面一些asyncio的事件循环才启动，因为那个计时器也才刚开始创建，这个我没试过，也可能不是。 程序触发事件 wxpython里面如何通过程序来触发某个事件呢，如下所示： homeButton = find_window_by_name ( 'homeButton' ) evt = wx . PyCommandEvent ( wx . EVT_BUTTON . typeId , homeButton . GetId ()) wx . PostEvent ( homeButton , evt ) 核心就是 wx.PostEvent 方法，值得一提的是，通过这种方法触发的事件不能调用 event.GetEventObject() 不过你可以通过 button = find_window_by_id(event.GetId()) 来找到那个目标button，也就是 GetId 方法还是可以用的。 参考资料 zetcode 的wxpython教程 wxpython官方参考文档 wxpython in action , Author by Harri Pasanen and Robin Dunn","tags":"wxpython","url":"articles/wxpython-talk-two.html"},{"title":"wxpython编码风格推荐","text":"基本建议 使用 import wx 不要使用 from what import * 这样的引入语法。 使用 size=(500,400)，不推荐使用 wx.Size ，这个提法是 这个网页 说的，可能会有点争议性，他说简单比复杂好。因为点就x, y两个值，所以就目前个人使用来说，确实直接用数组对会方便点，而且在编码的时候，具体size参数实际上已经指明了第一个参数是x，第二个参数是y了。 凡是面板都应该子类化，然后面板类的各个控件可以被面板管理。这个不是说要全部这样做，但这样做的好处很多。面板类的控件可管理，对你的后续管理操作编码带来很多便利，而面板的子类化是大型GUI程序的必然道路。 多个按钮推荐使用 StdDialogButtonSizer ， TODO ，后面我个人使用体验之后再讨论几句。 okButton = wx.Button(self, wx.ID_OK, \"&OK\") okButton.SetDefault() cancelButton = wx.Button(self, wx.ID_CANCEL, \"&Cancel\") btnSizer = wx.StdDialogButtonSizer() btnSizer.AddButton(okButton) btnSizer.AddButton(cancelButton) btnSizer.Realize() 代码重构：思考如何视图操作分离 本小节有些是自己思考的，但更多的是学习 这篇文章 提出的架构思路。 首先说一下整个编程世界公认的一些理念，比如DRY原则。 然后在具体编码中wxpython额外有些风格推荐。 按照DIY原则，我们有： 数据和代码分离，不管你的数据以何种方式加载进来的，这个都是后面完善的小细节，因为GUI编码的特殊性，从一开始就要考虑数据和代码的分离。 随着GUI程序编码的复杂度提高，请立刻开始重构你的代码，实现面向对象风格的写法，GUI程序内在和面向对象思想是很融洽的，只是一开始程序代码很简单不用考虑上面向对象，稍微写几天之后，就要考虑第一次重构了。请根据你的视图层结构特色，来对应编写你的gui模块的类的结构层次。 前面说到数据和代码分离，GUI有很多变量数据实际上是一些常量数据，建议所有后面不会发生变动的这些常量数据都另外再开个模块统一管理。一个不错的风格是这些常量数据包括你的所有变量数据和各种配置数据最终都在你的一个全局变量模块中汇总。既方便代码中的编写引用，也方便后续你写代码时候的debug模式编写，GUI程序运行时，只要写个简单的debug菜单，就可以将程序运行时所有的变量常量参数打印出来。 你的程序主要核心面板最好都给他们一个名字，这样后面事件处理的时候，可以直接调用对应的窗体，然后顺着这个窗体，调用目标窗体的子窗体来进行一些操作，但做的完善的，你的窗体应该提供各种方法来操控本窗体的子控件，而不是直接调用子控件。 而上面提到的那篇参考文章更进一步提出了MVC架构，这其中最关键的一点就是利用pypubsub模块，来实现你的程序内部的消息和发送和接收，从而实现视图层和模型层完全解耦。你的模型层只负责管理好本应用程序本地数据，你的控制层负责和模型层和视图层交互，通过控制层，你的视图层是完全不需要和模型层直接交互的。 具体哪个样例代码我就不贴了，而pypubsub模块的基本使用是很简洁的，这里面的关键在于理解MVC层各个层的分工和具体设计思路。仔细分析参考文章的样例代码，我们会发现这里面有一些设计很精妙的地方。首先请读者设想一个问题，这个问题在GUI程序编写或者其他类似的MVC架构中都会出现，那就是如果底层某个模型或者说某个数据或者更精确一点某个变量发生变化了，这种变化可能是内部计算得到的，也可能是从外部API获取到的数据，总之就是我们的GUI程序数据池里面已经有一些变动了，其中有一些数据是直接和视图层相关的，我们是希望视图层做出相应的调整。手工请求数据，再刷新页面的想法实在太愚蠢了，我们应该设计一个控制器，这个控制器负责进行内部某些运算或者从外部获取到某些数据，然后检测某些数据的变化，这些数据的变化首先送给本地模型层，做好变化记录，这时的样例程序是 changing 过程，然后本地模型层数据变化了，就应该改变视图层相应的显示，具体就是通过发送changed 信号来实现页面更新驱动的。 视图层 你之前写的GUI程序一开始就放在视图层，你的视图层的panel类等，本面板的子控件，主要是那些可变元素，挂在本面板上可以直接调用，后面根据你的业务和GUI显示需求，你需要些更好针对本面板的子控件的组合行为。 面板的属性，利用python的 @property 你将确定一些本面板的属性，通常你的面板的一些可变元素就是调用这些属性来的，而具体引用这些属性的方法，实际指向的是外部的可变内容，这样你的视图层内部代码每次引用 self.what ，都会实际调用你定义的属性的方法，也就是实时再计算一次，得到最新的信息。 然后视图层还有常数信息，按照前面讨论的编码风格推荐，也应该慢慢抽离出来，用某个const常数模块来统一管理之，一句话，努力做到数据和代码分离。 控制层 控制层的任务有如下： 接受本应用模型层，组织好本地常量变量数据 接受好视图层或者模型层发送的消息，针对这些消息进行对应的动作处理 如上所述，视图层引用可变数据的方法支持是控制层提供的 模型层 模型层不和视图层直接进行交互，如前面所说的，只负责管理好本地的数据和发送相应的信号，实际上模型层也没有引入控制层，其只是一个单纯简单的管理本地数据的接口罢了。 一般来说经常变动的一些和业务相关的数据应该进入模型层。 二次思考MVC架构 流行的web框架是以一种非常成熟的MVC架构风格，很多东西并没有引起我们太大的注意，加之GUI编程相对于web应用视图层和控制层不太好分离。随着GUI程序越来越复杂，我也确实感觉到有些东西有点杂乱，思路不够清晰，一会这里数据变动了，视图层忘记跟着变动，一会儿那边数据变动了，信号又忘记发送了。 目前我的处理方式，程序常量汇入全局变量池，除了本面板或者控件内自身的GUI要素，其他都汇入全局变量池，这给实际操作带来了很大的便利。然后全局变量池中某些变量进行了特殊的处理，由这种特殊的处理建立起了模型层。 在模型层中对于目标变量，只要发生了变化，就将发送一个对应的信号。 视图层对应监听目标信号，从而实时变动界面来体现数据的变化。 GUI层自身还有一些事件处理。 控制层还可能有其他的处理逻辑和模型层进行交互。 其实上面提到的这些都是正确的，关键在于都混在一起就有点杂乱了，再加上GUI自身的事件信号，让程序员思维有点混乱。 我试着进行如下约定，然后再试着重构整理下代码试试看。 常量，模型层变量，全局变量分离 程序涉及到的常量，模型层变量，全局变量分离，早期觉得都汇入全局变量挺方便的，但随着全局变量规模变得庞大，需要分离来减轻程序员头脑负担。 模型层和视图层分离 模型层里面不应该有视图层的东西，也就是面板之类的。 视图层里面不应该有模型层的东西，部分全局变量可以进入视图层（但主要要控制好这部分的量），除此之外的变量应该进入模型层。【视图层有时需要使用模型层的数据，推荐通过某个接口统一管理】 模型层不要向视图层发送的消息（name_changing）而只发送（name_changed），控制层直接修改模型层数据。视图层只负责监听 (name_changed) 的消息。控制层只监听(name_changing) 。 模型层信号规范 模型层是数据层，不管是业务逻辑也好还是视图层数据显示也好，只要其是数据依赖的，或者说数据驱动的，那么控制层或视图层就应该监听对应的数据模型。 监听信号名规范为： 变量名_changed 【模型层数据实际发生了变动，changed模式可被控制层或者视图层监听】 变量名_changing 【视图层数据发生变动，发射changing信号，本信号只被控制层监听，模型层不用管。】（这里再着重讨论下changing信号和changed信号各自的分工，changed信号的信息变动源更多的是外部，造成模型层数据变动，从而本程序内部视图层跟踪进行相应的变动，或者有时一些复杂的逻辑交给控制层中继处理；而changing信号更多的是本程序本地信息变动为驱动源，changing的第一任务是本GUI视图层内部各个不同面板组件之间信息同步，其次才是根据情况控制层决定是否监听从而更改模型层数据。简言之，changing第一任务是视图层内部的不同，changed第一任务是外部引起的数据变动视图层跟踪相应的变化，其次才是视需要控制层监听某些信号来编写更复杂的内部程序逻辑。） name_changing 和 name_changed 是只有值发生变法才发送消息，但某些情况下需要总是发送消息（可设置always_send选项） name_appending name_appended 某些情况下列表引入append模式会很方便 name_clearing name_cleared 某些情况下需要数据清空还原默认值操作 传递过去的value就是当前的数据值，除了append模式只传递附加的部分。 代码重构后感 按照上面的思路，模型层建立了一些通用模型，进行了代码重构，发现MVC架构在项目早期实际上还增加了很多额外的代码量，不过后期应该是会降低代码量的。 然后就是后面写代码的时候不仅要注意前面提及的规则，还需要额外再加上一条： 写的代码写完之后最好就可以放在一个地方供使用，然后其他时候就不用阅读了。 这不仅涉及到代码的可复用性，代码的良好设计，上面提及的MVC架构在努力实现模型层视图层的分离时也在努力去追求这一点。 TODO： pypubsub模块需要深入地学习如何debug，如何查看阅读那些信息发送了那些信息到那个函数里面被执行了。 三次思考MVC架构【PLUS】 前面二次思考MVC架构的内容基本是正确的，除了changing信号具体实现细节还有一些要补充的： 建立视图层变量，具体写法和建立方法类似于模型层变量的做法 视图层各个面板绑定好事件，内容发生变更则发送信号进行视图层相关面板数据同步工作。 视图层变量更多的和面板操作记录的临时变量相关，对于外部驱动发生的数据更改，之后驱动的方法我们应该优先选择面板的SetValue之类还会继续发送GUI Event的方法，如果没有这样的方法，则需要手工添加，好做到模型层初始化或者有变更则会自动触发视图层的变更。 注意事项 目前pypubsub 4.0版本已经确认如果有两个面板同时监听某个topic，那么各个面板对应的函数，参数格式应该一致。比如 def on_topic_test ( self , value ) pass 如果另外一个写为： def on_topic_test ( self , value = None ) pass 则pypubsub会抛异常，但如果两个都写作一样的，无论哪种形式，都没问题。 类变量和实例变量 这个算是python里面的基础知识了，在使用你自己写的可复用面板的时候，千万要记得： class ... a = 1 这里的变量每个实例都是相同的 def __init__ ()... b = 1 这里的变量每个实例都不同 也就是你在写一些方法和定义一些特别的本面板上的元素的时候，有些挂在类上问题不大，有些是一定要定义在初始化函数里面的，好让具体多个实例化后的面板有不同的子面板元素，这样行为才不会出错。 参考资料 zetcode 的wxpython教程 wxpython官方参考文档 wxpython in action , Author by Harri Pasanen and Robin Dunn","tags":"wxpython","url":"articles/wxpython-style-guide.html"},{"title":"算法复杂度","text":"一般讨论算法复杂度主要关注的是算法的时间复杂度，而真到了该思考算法的时间复杂度了，那么这时目标算法将应对的是一个输入规模n很大的情况。人们常说的大O表示法将一些细枝末节的东西都省略了的，因为输入规模n很大，还关心那多出来的几步是没有意义的。 所以我们更多的是专注于算法中的循环部分，而对于循环部分，若循环次数和输入规模无关，则记为O(1) 常数运行时间。 如果我们遇到了如下的循环： for i in range ( n ): print ( i ) 这个循环和输入规模n相关，我们记作 O(n) 线性运行时间。 假设一个算法里面又有上面提到的O(1) ，又有上面的O(n) ，那么我们应该将O(1) 项去掉： 如果运行时间是一个多项式的和，那么保留增长速度最快的项，去掉其他各项 那么上面提到的算法复杂度就可简单记为 O(n) 。 又假设有个算法，有两个这样的循环： for i in range ( n ): print ( i ) for i in range ( n ): print ( i ) 按照道理其算法复杂度应该是 2n ，大O表示法还有下面规则： 如果各个项是一个乘积，去掉所有的常数 也就是上面的算法复杂度是 O(2n) 最后简化为 O(n) ，这样整个算法仍然是线性运行时间。 如果是两个循环嵌套的情况： for i in range ( n ): for j in range ( n ): print ( i , j ) 其具体运行了n*n次，这个算法复杂度记为 \\(O(n&#94;2)\\) ，是二次多项式运行时间。此外可能会有其他情况，就是第二层循环会多运行几次或者少运行几次，这些都是细枝末节了，按照上面说的第一条规则：最后展开不管加减那些增长速度较慢的项将被去除，最后还是只剩下 \\(O(n&#94;2)\\) 。 递归的情况 以阶乘函数为例，递归函数的计算复杂度是递归函数最后展开为： $$ fac(n) * fac(n-1) ... fac(1) $$ 这个展开序列的长度也就是递归的次数就是计算复杂度 O(n) 。 对数复杂度 在考量对数复杂度的时候是不关心对数的底数的，因为上面提及的第二条规则乘积的常数项可以忽略。 while n > 0 : print ( 1 ) n = n // 10 上面的例子读者看的出来这个循环次数大约为输入规模n的对数次，也就是 O(logn) 。 二分查找算法的计算复杂度也是对数复杂度，其大致以2为底数逐步压缩查找空间。 对数线性复杂度 O(nlog(n)) 快速排序算法的计算复杂度就是对数线性复杂度。 def quick_sort ( seq ): \"\"\" 10000 的随机数列表排序： select_sort use time 3.0919713973999023 quick sort use time 0.024930477142333984 :param seq: :return: \"\"\" if len ( seq ) < 2 : return seq else : pivot = seq [ 0 ] less_part = [ i for i in seq [ 1 :] if i <= pivot ] greater_part = [ i for i in seq [ 1 :] if i > pivot ] return quick_sort ( less_part ) + [ pivot ] + quick_sort ( greater_part ) def selection_sort ( seq ): \"\"\" 两种写法速度都差不多的，那么优先写的直白点的。 :param seq: :return: \"\"\" def find_smallest_index ( seq ): smallest = seq [ 0 ] smallest_index = 0 for i in range ( 1 , len ( seq )): target = seq [ i ] if target < smallest : smallest = target smallest_index = i return smallest_index res = [] seq_copy = seq . copy () for i in range ( 0 , len ( seq )): smallest_index = find_smallest_index ( seq_copy ) res . append ( seq_copy . pop ( smallest_index )) return res 选择排序计算复杂度粗略估计是长度的 \\(O(n&#94;2)\\) ，非常直观的算法里面有个循环套循环。 选择排序和快速排序可以说非常直观地说明了计算复杂度等级不同，运算效率的提升有多明显。我测试的结果是： 10000 的随机数列表排序： select_sort use time 3.0919713973999023 quick sort use time 0.024930477142333984 是的，速度提升了100倍。 快速排序计算复杂度的估算里面有两部分： 小部分和大部分合计约n的比较判断操作 递归层级展开，大小部分按照2有点类似于二分查找一样进行了分割，比如一层之后8变成了4，所以递归层级是 \\(log_2n\\) 相乘快速排序计算复杂度就是 \\(O(n\\log(n))\\) 。 python里面用了更新的排序算法 蒂姆·彼得斯因不满python以前的排序算法（估计应该是类似于快速排序的存在），于2002年发明了timsort算法，其基本思路应该也是类似于快速排序，不过利用了数据集数据已经部分有序的情况，进行了优化。 python里面的list.sort或者sorted函数就是使用的timsort算法。 字典 字典里面查找key计算复杂度是O(1)，和字典长度无关，其内部使用的散列表算法。 我以前认为python的字典是基于红黑树或者二叉搜索树实现的，理解错了。python中的字典是基于hash table 散列表实现的，其 查 插入 删除 的计算复杂度都是 O(1) ，具体就是引入一个散列函数，将一个大规模输入空间映射到一个小的输出空间，将数量巨大的key转换成为数量较少的整数索引。 具体这块底层实现细节我也不是很懂： TODO if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js','mhchem.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"算法","url":"articles/suan-fa-fu-za-du.html"},{"title":"wxpython基础窗体一览","text":"简介 最基本的窗体 这些基本的窗体一般不会直接使用。 wx.Window wx.Control wx.ControlWithItem 顶层窗体 wx.PopupWindow wx.ScrolledWindow wx.Frame wx.MDIParentFrame wx.MDIChildFrame wx.Dialog 可以包含其他窗体的窗体 wx.ScrolledWindow wx.Panel wx.SplliterWindow wx.Notebook 一般动态窗体 动态窗体可被用户编辑。 wx.ToggleButton wx.CheckBox wx.TextCtrl wx.SpinCtrl .... 一般静态窗体 不可被用户编辑。 wx.StaticBox wx.StaticText wx.StaticLine wx.StaticBitmap wx.Gauge 其他窗体 wx.ToolBar wx.MenuBar wx.StatusBar 文本输入对话框 TextEntryDialog 一个小的弹出窗体，用户输入一行文本（其实也可以设为多行），然后程序获取用户输入的该行文本信息。 【图片】 ShowModal 弹出窗体 GetValue 获取文本内容 单选项对话框 SingleChoiceDialog 一个小的弹出窗体，用户进行一个单选动作。 ShowModal 弹出窗体 GetStringSelection 获取用户选择的字符串内容 GetSelection 获取用户选择的索引位置 文件对话框 FileDialog 选择打开或保存文件的对话 def OnOpen ( self , e ): \"\"\" Open a file\"\"\" self . dirname = '' dlg = wx . FileDialog ( self , \"Choose a file\" , self . dirname , \"\" , \"*.*\" , wx . FD_OPEN ) if dlg . ShowModal () == wx . ID_OK : self . filename = dlg . GetFilename () self . dirname = dlg . GetDirectory () f = open ( os . path . join ( self . dirname , self . filename ), 'r' ) self . control . SetValue ( f . read ()) f . close () dlg . Destroy () 简单的信息弹窗 dlg = wx.MessageDialog(self, \"A small text editor\", \"About Sample Editor\", wx.OK) dlg.ShowModal() dlg.Destroy() 颜色选择对话框 ColourDialog 简单的About弹窗 AboutBox 文件夹选择对话框 DirDialog 字体选择对话框 FontDialog 多选对话框 MultiChoiceDialog 打印页面设置对话框 PageSetupDialog 打印对话框 PrintDialog 启动画面 wx.adv.SplashScreen wx.adv.SplashScreen 添加菜单和菜单栏 filemenu = wx . Menu () aboutMenu = filemenu . Append ( wx . ID_ABOUT , \"&About\" , \" Information about this program\" ) filemenu . AppendSeparator () exitMenu = filemenu . Append ( wx . ID_EXIT , \"E&xit\" , \" Terminate the program\" ) menuBar = wx . MenuBar () menuBar . Append ( filemenu , \"&File\" ) self . SetMenuBar ( menuBar ) 你需要创建一个MenuBar对象，然后用Frame的 SetMenuBar 方法来设置，后面引用的时候可以使用 GetMenuBar 方法来获得对应的MenuBar对象 你需要创建一个 Menu 对象，然后MenuBar菜单栏把这个菜单 Append 上去。 具体某个菜单如上所示添加具体的一些选项 菜单的点击事件绑定语句如下： self . Bind ( wx . EVT_MENU , self . OnAbout , aboutMenu ) 静态文本 StaticTex 样式 wx.ALIGN_CENTER 静态文本于静态文本控件的中心 wx.ALIGN_LEFT 文本于控件中左对齐 默认 wx.ALIGN_RIGHT 文本于控件中右对齐 wx.ST_NO_AUTORESIZE 设置之后，通过SetLabel原来默认是要自动调整控件尺寸的，现在不调整了。 静态bitmap图片 StaticBitmap 文本输入 TextCtrl 样式 wx.TE_CENTER 控件中文本居中 wx.TE_LEFT 控件中文本左对齐 wx.TE_RIGHT 右对齐 wx.TE_PASSWORD 密码框 wx.TE_PROCESS_ENTER 默认不处理Enter按键事件，设置后处理 wx._TE_READONLY 只可读 wx.TE_MULTILINE 可多行输入 方法 Clear 输入文本重置为空字符串 AppendText(text) 附加文本 GetInsertionPoint SetInsertionPoint GetValue 获取输入文本 SetValue 设置输入文本 Remove 删除 Replace 替换 WriteText 在当前插入点插入某个文本 图片按钮 BitmapButton 图片按钮更改图片 调用图片按钮的 SetBitmapLabel 方法，这个目前文档里面没提及。 开关按钮 ToggleButton 通用按钮 wx.lib.buttons 里面有很多通用按钮创建方法，上面提到的一般按钮，开关按钮，图片按钮都有，相比较之前的一般按钮，通用按钮提供了更多的可定制性。 滑块 Slider 微调控件 SpinCtrl 进度条 Gauge 复选框 CheckBox 单选按钮 RadioBox wx.RB_GROUP 重要！定义了一组单选按钮的开始 列表框 ListBox 滚动文字信息栏 一行滚动文字的信息栏， from wx.lib.ticker import Ticker 状态栏 状态栏 self.statusbar = self.CreateStatusBar() 这里的self只能是Frame，类似的还有 CreateToolBar 。这个根据需要来，不一定要添加的。 参考资料 wxpython官方参考文档 wxpython in action , Author by Harri Pasanen and Robin Dunn","tags":"wxpython","url":"articles/wxpython-basic-window-gallery.html"},{"title":"python新的f-string","text":"现在python3版本迭代很快的，除了python3.4新加入的asyncio让我很是关心，最近还是接触一个新的f-string，是python3.6加入进来了。一开始对字符串前面加个f很是困惑，python2的时候字符串前面有u什么的，python3之后基本上字符串前面没什么东西了。但这次新加入的f-string，在初步使用之后就停不下来了，真的太好用了。 基本情况如下： python新的format字符串 f\"hello. {name}\" 等价于 \"hello. {name}\".format(name=name) 一个变量还好，多个变量的时候这种f-string的写法的好处就很明显了，当时环境下你前面已经定义好的变量名是可以直接使用的，我只能用一句话来形容，太好用了，用上了你就会停不下来。","tags":"python语言","url":"articles/python-the-new-f-string.html"},{"title":"logbook模块","text":"前言 logbook似乎是个不错的模块可以改进我们的日志功能，可以看做系统logging模块的第三方升级版，但还是有很多地方不同的。 一开始我接触的最大的不同就是logbook官方文档并不推荐将某个handler注册在某个logger的那种做法，logbook的handler可以注册在整个线程或者整个进程上。或者我们看到官方文档的第一个例子是这种写法： from logbook import warn , StreamHandler import sys StreamHandler ( sys . stdout ) . push_application () warn ( 'This is a warning' ) 或者写作： from logbook import warn , StreamHandler import sys log_handler = StreamHandler ( sys . stdout ) with log_handler . applicationbound (): warn ( 'This is too cool for stdlib' ) 这是单个注册在整个程序上的，此外还有 threadbound 是注册在整个线程上的。一般桌面GUI程序推荐注册在整个程序上，web应用推荐注册在整个线程上。 这并不是说你不需要定义logger了，你还是如同你以前习惯的这样定义和使用。 from logbook import Logger logger = Logger ( __name__ ) logger . info ( 'just log it.' ) logbook更多的配置如下所示，就是配置不同的handler： import os from logbook import NestedSetup , NullHandler , FileHandler , \\ MailHandler , Processor def inject_information ( record ): record . extra [ 'cwd' ] = os . getcwd () # a nested handler setup can be used to configure more complex setups setup = NestedSetup ([ # make sure we never bubble up to the stderr handler # if we run out of setup handling NullHandler (), # then write messages that are at least warnings to a logfile FileHandler ( 'application.log' , level = 'WARNING' ), # errors should then be delivered by mail and also be kept # in the application log, so we let them bubble up. MailHandler ( 'servererrors@example.com' , [ 'admin@example.com' ], level = 'ERROR' , bubble = True ), # while we're at it we can push a processor on its own stack to # record additional information. Because processors and handlers # go to different stacks it does not matter if the processor is # added here at the bottom or at the very beginning. Same would # be true for flags. Processor ( inject_information ) ]) 上面的Processor会自动在每条日志记录上打上额外的信息。logbook还提供了很强大的MailHandler等等。这些相关配置信息后面慢慢了解。 一些配置 level critical 导致程序终止的异常 error 还可以应付的error warning 一些情况可能不是error notice no-error 但你可能希望看见 info 信息你不想看见 debug 信息给debug用 handler StreamHandler 流handler，一般指 sys.stdout FileHandler RotatingFileHandler TimedRotatingHandler 用于输出到文件 MailHandler 用于输出到email bubble bubble参数默认是False，某个日志记录被某个handler处理了其他的handler就不会处理了，而设置bubble=True之后，其他handler同样也可以处理。 action_level 有了这个级别的记录才会输出日志，否则不输出。","tags":"python好伙伴","url":"articles/logbook-module.html"},{"title":"wxpython技巧大杂烩","text":"只有一个程序实例在运行 利用 wx.SingleInstanceChecker 很方便就可以做到这点，更多信息请参看文档的 这里 。下面的做法是确保了操作系统某个用户只有一个程序实例在运行。 import wx class SingleAppFrame ( wx . Frame ): def __init__ ( self , parent , title ): wx . Frame . __init__ ( self , parent , title = title , size = ( 300 , 300 )) self . Centre () class SingleApp ( wx . App ): def OnInit ( self ): self . name = \"SingleApp- %s \" % wx . GetUserId () self . instance = wx . SingleInstanceChecker ( self . name ) if self . instance . IsAnotherRunning (): wx . MessageBox ( \"Another instance is running\" , \"ERROR\" ) return False frame = SingleAppFrame ( None , \"SingleApp\" ) frame . Show () return True app = SingleApp ( redirect = False ) app . MainLoop () 欢迎页面 利用wx.adv.SplashScreen 就可以很方便地制作出一个欢迎页面，读者还可以看一下demo各个案例中提到的 wx.lib.agw.advancedsplash as AS ，和 SplashScreen 类比起来又多了一些可定制的选项。 from gui.mainFrame import ChaoShengHuo class ChaoShengHuoApp ( wx . App ): img_base = g_var . img_base def OnInit ( self ): self . name = \"SingleApp- %s \" % wx . GetUserId () self . instance = wx . SingleInstanceChecker ( self . name ) if self . instance . IsAnotherRunning (): wx . MessageBox ( \"已经有一个潮生活发票助手程序在运行了！\" , \"Do not Panic\" ) return False else : # 欢迎页面 bitmap = wx . Bitmap ( self . img_base + 'welcome.png' , wx . BITMAP_TYPE_PNG ) wx . adv . SplashScreen ( bitmap , wx . adv . SPLASH_CENTRE_ON_SCREEN | wx . adv . SPLASH_TIMEOUT , 3000 , None , - 1 , wx . DefaultPosition , wx . DefaultSize , wx . BORDER_SIMPLE | wx . STAY_ON_TOP ) wx . Yield () the_frame = ChaoShengHuo ( None , - 1 ) the_frame . Show ( True ) return True 程序最小化到托盘 主界面那边关闭事件是： def MinimizeWindow(self, event): self.Iconize(True) def CloseWindow(self, event): self.Hide() event.Skip() import wx import wx.adv class TaskBarIcon ( wx . adv . TaskBarIcon ): ID_About = wx . NewId () ID_Minshow = wx . NewId () ID_Maxshow = wx . NewId () ID_Closeshow = wx . NewId () def __init__ ( self , frame ): wx . adv . TaskBarIcon . __init__ ( self ) self . frame = frame self . SetIcon ( wx . Icon ( name = 'favicon.ico' , type = wx . BITMAP_TYPE_ICO ), '潮生活发票助手' ) self . Bind ( wx . adv . EVT_TASKBAR_LEFT_DCLICK , self . OnTaskBarLeftDClick ) # 定义左键双击 self . Bind ( wx . EVT_MENU , self . OnAbout , id = self . ID_About ) self . Bind ( wx . EVT_MENU , self . OnMinshow , id = self . ID_Minshow ) self . Bind ( wx . EVT_MENU , self . OnMaxshow , id = self . ID_Maxshow ) self . Bind ( wx . EVT_MENU , self . OnCloseshow , id = self . ID_Closeshow ) def OnTaskBarLeftDClick ( self , event ): if self . frame . IsIconized (): self . frame . Iconize ( False ) if not self . frame . IsShown (): self . frame . Show ( True ) self . frame . Raise () def OnAbout ( self , event ): wx . MessageBox ( '潮生活发票助手V3.0' , '关于' ) def OnMinshow ( self , event ): self . frame . Iconize ( True ) def OnMaxshow ( self , event ): if self . frame . IsIconized (): self . frame . Iconize ( False ) if not self . frame . IsShown (): self . frame . Show ( True ) self . frame . Raise () def OnCloseshow ( self , event ): self . RemoveIcon () self . Destroy () self . frame . Destroy () def CreatePopupMenu ( self ): menu = wx . Menu () menu . Append ( self . ID_Minshow , '最小化' ) menu . Append ( self . ID_Maxshow , '最大化' ) menu . Append ( self . ID_About , '关于' ) menu . Append ( self . ID_Closeshow , '退出' ) return menu 图片重画 一个抹去事件被发送，当窗体背景需要重画的时候。 An erase event is sent when a window's background needs to be repainted. dc = event.GetDC() wx.ClientDC：用于在一个窗口对象上绘画。当你想在窗口部件的主区域上（不包括 边框或别的装饰）绘画时使用它。主区域有时也称为客户区。wx.ClientDC类也应临 时创建。该类仅适用于wx.PaintEvent的处理之外。 参考网页 import wx class Frame ( wx . Frame ): def __init__ ( self ): wx . Frame . __init__ ( self , None , - 1 , \"My Frame\" , size = ( 400 , 300 ), style = wx . DEFAULT_FRAME_STYLE ) self . panel = wx . Panel ( self ) self . panel . Bind ( wx . EVT_ERASE_BACKGROUND , self . OnEraseBack ) def OnEraseBack ( self , event ): dc = event . GetDC () if not dc : dc = wx . ClientDC ( self ) rect = self . GetUpdateRegion () . GetBox () dc . SetClippingRect ( rect ) dc . Clear () bmp = wx . Bitmap ( \"background.jpg\" ) dc . DrawBitmap ( bmp , 0 , 0 ) if __name__ == '__main__' : app = wx . App () frame = Frame () frame . Show () app . MainLoop () 让窗体可以拖动 你想要的那部分窗体可以拖动，就将事件绑定一下，但拖动事件实际执行方法应该在主窗体上，然后主窗体应该也进行一次绑定。具体原因还不是很明白。 self . Bind ( wx . EVT_LEFT_DOWN , self . OnLeftDown ) # 左键点击按下 self . Bind ( wx . EVT_LEFT_UP , self . OnLeftUp ) # 左键释放 self . Bind ( wx . EVT_MOTION , self . OnMouseMove ) # 鼠标移动 # 拖动相关 def OnLeftDown ( self , event ): logger . debug ( f 'GUI事件: {event} - OnLeftDown' ) self . CaptureMouse () # 捕获鼠标 pos = self . ClientToScreen ( event . GetPosition ()) origin = self . GetPosition () self . delta = wx . Point ( pos . x - origin . x , pos . y - origin . y ) def OnLeftUp ( self , event ): logger . debug ( f 'GUI事件: {event} - OnLeftUp' ) if self . HasCapture (): self . ReleaseMouse () # 释放鼠标 def OnMouseMove ( self , event ): logger . debug ( f 'GUI事件: {event} - OnMouseMove' ) if event . Dragging () and event . LeftIsDown (): pos = self . ClientToScreen ( event . GetPosition ()) newPos = ( pos . x - self . delta . x , pos . y - self . delta . y ) self . Move ( newPos ) 扩充你的颜色定义 wxpython有自己内部一套颜色定义库，然后你还可以利用进一步扩充自己的颜色定义库： aquamarine：海蓝色 black：黑色 blue：蓝色 brown：褐色 coral：珊瑚色 cyan：青色 firebrick：火砖色 gold：金色 gray：灰色 green：绿色 khaki：土黄色 magenta：绛红色 maroon：栗色 navy：藏青色 orange：橙色 orchid：淡紫色 pink：粉红色 plum：梅红色 purple：紫色 red：红色 salmon：鲜肉色 sienna：红褐色 tan：浅棕色 thistle：蓟色 turquoise：青绿色 violet：紫罗兰色 wheat：浅黄色 white：白色 yellow：黄色 更多颜色请参看 demo 那边的 ColourDB 。 你需要在你的app OnInit 的时候加载你自己定义的颜色，请看官方代码的这个片段，这样你就知道自己该怎么做了： def updateColourDB (): \"\"\" Updates the :class:`wx.ColourDatabase` by adding new colour names and RGB values. \"\"\" global _haveUpdated if not _haveUpdated : import wx assert wx . GetApp () is not None , \"You must have a wx.App object before you can use the colour database.\" cl = getColourInfoList () for info in cl : name , colour = info [ 0 ], wx . Colour ( * info [ 1 :]) wx . TheColourDatabase . AddColour ( name , colour ) _haveUpdated = True","tags":"wxpython","url":"articles/wxpython-cookbooks.html"},{"title":"wxpython第一谈","text":"前言 本文假设读者已经熟悉某一种桌面图形开发了，比如说PyQt之类的，也就是基本的图形桌面开发概念读者是熟悉了，下面将言简意赅地就wxpython相关的特色核心概念说明之，然后后面就针对某些专门的问题专门讨论了。 首先说下安装，现在wxpython和pyqt5一样都已经进步了，都可以直接用pip安装了，而且linux下和windows都可以直接安装。 Sizer.Add参数详解 Sizer.Add(item, 0 , wx.ALIGN_RIGHT, 0) 右对齐布局，第一个参数proportion详细讨论在后面，第三个参数是设置border的宽度的。 Sizer.Add(item, 0, wx.ALIGN_CENTER, 0) 居中布局 Sizer.Add(item, 0, wx.EXPAND, 0) 扩展布局，（在vertical sizer里面水平扩展；在horizontal sizer里面垂直扩展） proportion参数 默认是0，0表示不缩放，我估计这样设置之后父窗体Layout，而子窗体将不会自动Layout。然后设置其他整数则是某种缩放比的意思。参考资料谈了一些缩放比的问题，暂时不是很关心这个。下面是讨论的原文： proportion参数是被wx.BoxSizer用作因数去决定当sizer的大小改变时，sizer应该如何调整它的孩子的尺寸。我们这里使用的是水平方向调整的sizer，stretch因数决定每个孩子的水平尺寸如何改变（坚直方向的改变由box sizer基于第三个参数来决定）。 一般的0表示不缩放，1表示随着父窗体缩放而缩放。 Flag参数 这块东西经常遇到，虽然Flag较多，还是建议沉下心来学一下，这些后面会频繁用到的： 控制那边有border wx.TOP wx.BOTTOM wx.LEFT wx.RIGHT wx.ALL 扩展 wx.EXPAND 周围有空间就扩展 wx.SHAPED 扩展同时保持宽高比 对齐 wx.ALIGN_CENTER or wx.ALIGN_CENTRE wx.ALIGN_LEFT wx.ALIGN_RIGHT wx.ALIGN_RIGHT wx.ALIGN_TOP wx.ALIGN_BOTTOM wx.ALIGN_CENTER_VERTICAL or wx.ALIGN_CENTRE_VERTICAL wx.ALIGN_CENTER_HORIZONTAL or wx.ALIGN_CENTRE_HORIZONTAL 下面举一些组合的例子： wx.EXPAND | wx.LEFT 有空间就扩展，border在左边，这样你会看到左边有空白 wx.EXPAND | wx.LEFT | wx.RIGHT 有空间就扩展，border在左边和右边，这样你会看到左边和右边有空白 wx.EXPAND | wx.ALL 有空间就扩展，上下左右border都有 Frame样式 wx.FRAME_NO_TASKBAR 没有任务栏 wx.FRAME_SHAPED 非矩形框架 wx.FRAME_TOOL_WINDOW wx.FRAME_FLOAT_ON_PARENT 框架将漂浮在父窗体之上 wx.STAY_ON_TOP 总在最上 wx.SIMPLE_BORDER 没有装饰的边框 布局的太布局的 一般手写布局代码的话，肯定是使用各个Sizer，其中BoxSizer最常用，对于不是特别复杂的布局BoxSizer，横竖拼接加上Add的参数调配，基本上都是调出来的。以至于每个panel类里面我现在都写上了一个 self.box 成为惯例了，虽然后面某些情况下会使用到其他Sizer，比如GridSizer等，但GridSizer是可以放在BoxSizer里面的，所以问题不大。这样形成惯例之后，后面引用该面板，想到主Sizer，就直接panel.box即可，这是题外话了。 FlexGridSizer FlexGridSizer布局将页面分成二维的表格，各个表格元素高度一定是一样的，但宽度可以不一样（GridSizer则要求一定一样）。 wx.FlexGridSizer(int rows=1, int cols=0, int vgap=0, int hgap=0) rows 多少行 cols 多少列 vgap 垂直向加点空间 hgap 水平向加点空间 wxpython里面的ID window identifiers 是一些整数 决定了窗体在系统中的唯一性，wxpython中可以如下定义窗体的ID： 窗体ID的定义 明确赋值一个正整数，不推荐 使用wx.NewID() 传递wx.ID_ANY 或 -1 给窗体构造器 frame = wx.Frame.__init__(None, -1) id = frame.GetId() 然后笔者强烈推荐读者使用名字来定义和定位窗体，这样你的代码具有更具有良好的可读性。 标准ID 官方文档标准ID列表 根据ID来查找窗体 1、wx.FindWindowById(id, parent=None) 2、wx.FindWindowByName(name, parent=None) 3、wx.FindWindowByLabel(label, parent=None) 如果在某个窗体内调用 self.FindWindowById 则是本窗体内查找，找到的第一个。 根据名字来查找窗体 笔者强烈推荐读者在写大型GUI程序的时候给几个核心窗体都定义好唯一的名字（具体大部分窗体都可以接受一个name可选参数的），然后如下来查找之。这对于你后面的编程会带来很大的便利。 import wx def find_window_by_name ( name ): \"\"\" 根据窗体的名字来返回窗体，推荐风格 :param name: :return: \"\"\" window = wx . FindWindowByName ( name ) return window def is_the_window_name ( window , name ): \"\"\" 根据名字来判断是否是这个窗体 :param window: :param name: :return: \"\"\" if window . SetName () == name : return True else : return False 深入理解wxpython中的事件 Bind(event, handler, source=None, id=wx.ID_ANY, id2=wx.ID_ANY) event 比如在wx.Button上鼠标单击一下将触发一个 wx.EVT_BUTTON 事件，event这里可以定义具体你想要绑定的事件。 handler 处理器 source 一般不需要指定，如果父窗口多个相同的触发源，比如说多个按钮，那么就需要指定下。 id 根据id定义事件触发源，在某些情况下根据id来会更方便些，然后id2同id可以确定一串连续的窗体。 wxpython事件处理过程 事件触发--> 获取事件触发对象 检查事件触发对象是否允许处理事件（可以通过 SetEvtHandlerEnabled(boolean) 来禁用窗体处理事件）【UI层面Disable Enable只是禁用了窗体和用户的交互，但它还是可以处理间接接受到的事件，比如通过PostEvent等】 event.Skip() 这个方法之前我以为是该事件的处理跳过了，理解错误了，更准确的说法是 本事件处理完成 了。 也就是如果在事件触发链中，没有看到这个方法，那么事件将会继续传播，否则事件处理终止。 如果目标事件允许 传播propagate ， 那么还会继续向上去触发父容器的事件，直到App，也就是最顶层结束传播。【默认情况，只有wx.CommandEvent及其子类的实例向上展开至容器级。其它的所有事件都不传播。】【Button单击属于CommandEvent，鼠标移动和浮动在上和离开都是MouseEvent】 习题1 请读者解释为什么是下面的写法，鼠标浮动在上和离开事件为什么只能定向self.button。 self.Bind(wx.EVT_BUTTON, self.OnButtonClick, self.button) #1 绑定按钮事件 self.button.Bind(wx.EVT_ENTER_WINDOW, self.OnEnterWindow) #2 绑定鼠标位于其上事件 self.button.Bind(wx.EVT_LEAVE_WINDOW, self.OnLeaveWindow) #3 绑定鼠标离开事件 按钮点击行为可以传播，其首先在本窗体上触发按钮事件，然后在本窗体上找对应的方法 OnButtonClick ，如果找到这个方法了，那么执行，执行过程中如果遇到Skip方法，那么本事件处理到此结束；如果没有，则会试着向上传播，直到顶层窗体。向上传播的过程就是传播事件，也就是本窗体的父窗体也将触发本按钮事件，然后试着实行对应的 OnButtonClick 方法。 鼠标移动行为是不可以传播事件，必须指明那个按钮绑定的。 self.button.Bind 过程就是直接执行你初始挂在的那个方法，找不到就抛出异常了。 大体是这样的，如果读者还有不明白了，请阅读 wxpython in action 这本书的第三章，关于这部分问题，这本书讲的很好。 习题2 如何一个按钮的点击事件会触发两个动作。 简单来说就是写两个 self.button.Bind() 语句绑定两个函数就可以了，按照前面说的，这两个函数每个都要跟上 event.Skip() 。 手动触发某个事件 有时直接手动触发一个事件会省下很多代码。 self.Close(True) 获取当前事件的触发对象 button = event.GetEventObject() print(button.GetName()) 常见的wx.Event子类 wx.CloseEvent frame框架关闭时触发 wx.CommandEvent 按钮单击 菜单选择 等 wx.KeyEvent 按键事件 wx.MouseEvent 鼠标事件 wx.PaintEvent 窗体需要重画时触发 wx.SizeEvent 窗体大小或布局改变时触发 wx.TimerEvent wx.Timer类创建的定时事件 按钮三事件 按钮在GUI设计中是使用频率非常高的一个组件，其绑定的最常用的三个事件有： self.Bind(wx.EVT_BUTTON, self.OnButtonClick, self.button) 绑定按钮事件 self.button.Bind(wx.EVT_ENTER_WINDOW, self.OnEnterWindow) 绑定鼠标位于其上事件 self.button.Bind(wx.EVT_LEAVE_WINDOW, self.OnLeaveWindow) 绑定鼠标离开事件 什么时候调用Layout方法 动态调整GUI的各个元素，我们会看到网上各个例子经常会看到调用了 Layout方法，然后有的时候我发现不调用似乎影响不大，有的时候发现不调用页面会变形，那么到底什么时候应该调用Layout方法呢。请参看 这篇文章 。 StaticText 进行 SetLable 操作之后，应该Layout下 通过sizer显示或隐藏某个面板元素之后应该Layout 下。 如果窗体触发了 EVT_SIZE 事件，wxpython会自动进行Layout重排。重排的时候父窗体的sizer会自动进行Layout，然后父窗体的子窗体也会相应的进行重排操作，但如果某个子窗体不需要重排，那么它就不会接受 EVT_SIZE 事件了，也就不会调用Layout方法了。比如StaticText 更改Layout，你调用其父窗体的Layout，StaticText是不会自动调整的。 按照 这个网页 的介绍，加上个人的一点实践经验，不推荐使用 SetSizerAndFit 方法了，个人的使用体验是使用 SetSizer 就能完成工作了，而加上Fit有的时候会给你的布局带来一些困扰，比如ScrolledPanel在Fit之后会发生截断问题。 总的原则经过试验确实是可行的： SetSizer 发现不对劲，Layout Layout之后还不对劲，这通常不是布局的问题了，某些情况下你更改了一些数据，可能需要Refresh TODO Layout 和 Refresh 的区别是什么 目前我已经遇到一个问题，只有Refresh之后才有正常的行为，那就是重画的透明组件再设置标签之后，似乎只有Refresh之后才会再次进行重画动作，这值得引起读者的注意。然后有的时候我们看到子面板Layout之后会自动Refresh。 ScrolledPanel 这里特别值得一提的是 ScrolledPanel 里面的内容在发生变动的时候，除了Layout之外还需要加上： self.SetupScrolling() 实践发现是内容变动之后都需要加上这句，否则侧边滚动条会丢失，下面的内容也会被隐藏。 设置背景颜色和字体颜色 wxpython的任何窗体对象（是的这两个方法是挂在wx.Window上的），可以用 SetBackgroundColour 来设置其背景颜色，用 SetForegroundColour 来设置前景颜色，前景颜色一般就是所谓的字体颜色吧。 如果你需要动态调成某个面板的背景颜色，那么记得调用Refresh方法来激活重画事件。 将图片转成python编码 首先是编写这样一个python脚本： #!/usr/bin/env python # -*-coding:utf-8-*- \"\"\" 将项目图片文件全部转成python文件，然后可以直接 import images 来引用图片了。 \"\"\" import sys from wx.tools import img2py command_lines = [ \" -F -i -n Favicon static/images/favicon.ico images.py\" , \"-a -F -n ApplyTaiKa static/images/apply_tai_ka.png images.py\" , \"-a -F -n Address static/images/address_img.png images.py\" , ] if __name__ == \"__main__\" : for line in command_lines : args = line . split () img2py . main ( args ) 其调用了wxpython提供的工具 img2py ，然后输出的images.py 里面的图片对象有如下方法： def GetBitmap(self): return wx.Bitmap(self.GetImage()) def GetData(self): data = self.data if self.isBase64: data = b64decode(self.data) return data def GetIcon(self): icon = wx.Icon() icon.CopyFromBitmap(self.GetBitmap()) return icon def GetImage(self): stream = BytesIO(self.GetData()) return wx.Image(stream) 最常用的是 GetBitmap 直接获取Bitmap图片对象。 后台任务 wxpython的后台任务推荐用 wx.CallAfter 或者 wx.CallLater 来调用。用python内置的多线程可能会让你的界面有时出现一些奇怪的问题。 wx.CallAfter(callable, *args, **kwargs) Timer wxpython里面的计时器某些任务挂上去还是很方便的。 self.timer = wx.Timer(self) self.timer.Start(1000) self.Bind(wx.EVT_TIMER, self.update, self.timer) 参考资料 zetcode 的wxpython教程 wxpython官方参考文档 wxpython in action , Author by Harri Pasanen and Robin Dunn","tags":"wxpython","url":"articles/wxpython-talk-one.html"},{"title":"贪婪算法","text":"任何问题总可以通过暴力穷举算法求解，当然有些问题组合数情况太多了，尤其是某些问题，没有快速算法，即NP完全问题。那么可以试着用一些近似算法来快速找到一个近似解。贪婪算法就是其中的一个近似解。 之前说的狄克斯特拉算法和广度优先算法就是这样的贪婪算法。 贪婪算法并不是某种具体的算法，更像是写算法时的一种思路参考。如果你要解决问题，而该问题可以分解为多个步骤，那么你可以通过寻找每步的局部最优解，来 近似 得到目标问题的全局最优解。（贪婪算法并不保证你得到的解一定是全局最优解，但一般这个解是很靠近全局最优解了。） 对于一个问题，如果贪婪算法是有效的，那么一般贪婪算法就是解决这个问题最好的算法。 背包问题 class Knapsack ( object ): def __init__ ( self , capacity , items = None ): self . capacity = capacity self . items = [] if items is None else items self . freespace = self . capacity def add_item ( self , item ): if self . freespace - item . weight >= 0 : self . freespace -= item . weight self . items . append ( item ) return True else : return False def all_items_value ( self ): value = 0 for item in self . items : value += item . value return value def __repr__ ( self ): return '<Knapsack: {0}>' . format ( self . items ) class Item ( object ): def __init__ ( self , name , value , weight ): self . value = value self . weight = weight self . name = name def __repr__ ( self ): return '<Item: {0}>' . format ( self . name ) def __eq__ ( self , other ): if self . name == other . name and self . value == other . value and self . weight == other . weight : return True else : return False def greedy_algorithm ( knapsack , items ): \"\"\" 贪婪法求解 :return: \"\"\" items_copy = items . copy () found = True while found : max_value = 0 choosed_item = None for item in items_copy : if item . value > max_value : choosed_item = item max_value = choosed_item . value if knapsack . add_item ( choosed_item ): found = True items_copy . remove ( choosed_item ) else : found = False return knapsack 参考资料 算法图解 Aditya Bhargava 著","tags":"算法","url":"articles/greedy-algorithm.html"},{"title":"bihu_query项目","text":"简介 实现了一个通用的根据输入的url，然后用户自己编写对应的url 正则匹配规则，然后编写相应的页面爬取规则，从而实现一个实时爬虫接口功能。 项目地址在 https://github.com/a358003542/bihu_query 。 功能简介 query 接口 /query/?url= 输入url参数，实时爬取目标页面，返回数据。 快速创建爬虫的图形操作界面 实现了一个快速创建爬虫的图形操作界面 更新说明 项目配置管理 本项目开发遵循12因素应用配置管理原则： .env 不进入版本库，控制整个项目的配置选择，目前选用了三个阶段： development testing production，分别对应于 本机早期开发， 实际上机测试 和 生产环境 .secrets.toml 里面放着一些私密的配置信息，不进入版本库 settings.toml 里面放着其他一些配置 使用请参看 dynaconf 模块。 版权申明 本模块版权归cdwanze所有，不可用于商业目的，若有需要请联系作者本人。","tags":"项目","url":"articles/bihu-query.html"},{"title":"python语言学习之-技巧大杂烩","text":"装饰器和装饰器的衍生装饰器 写一个装饰器现在很已经很简单通用了，有如下写法： from functools import wraps def test_decorator ( word ): def decorator ( f ): @wraps ( f ) def _decorator ( * args , ** kwargs ): print ( word ) return f ( * args , ** kwargs ) return _decorator return decorator 有的时候处于编程便捷的考虑，需要某些参数作为默认值另外再单独开出一个装饰器： bbb_decorator = test_decorator ( 'bbb' ) 这是可行的，然后还有种写法，实际上是一样的： def aaa_decorator ( f ): return test_decorator ( 'aaa' )( f ) 理解装饰器关键是理解： @aaa_decorator def hello2 (): print ( 'hello' ) 装饰器不仅仅是函数作为第一个函数这么简单，更进行了函数的命名重定义。 hello2 = aaa_decorator(hello2) 而可以传参数的装饰器其首先消化掉参数，然后decorator，也就是实际装饰函数的是内部的那个decorator函数，而 wraps 只是为了保留原函数头doc的优化。 在logging中使用pprint 参考了 这个网页 。 有的时候logging的输出我们希望调用pprint从而输出打印更加美观些，可以调用pformat函数来达到这个效果： from pprint import pprint , pformat ds = [{ 'hello' : 'there' }] logging . debug ( pformat ( ds )) and or not的运算优先级 一般是推荐用括号清晰表达，然后not我们知道优先级是最高的。我们再看下面这个例子: >>> True or True and False True 这个例子很好地说明了and和or的优先级顺序，具体就是 and的优先级比or的要高 。 all和any关键词 这是python语言里面的关键词函数，源码很简单，下面列出来，看一下就清楚了: def all(iterable): for element in iterable: if not element: return False return True def any(iterable): for element in iterable: if element: return True return False 如果用语言表述的话是: all，都是True，则返回True，否则返回False any，只要有一个True则返回True，否则返回False。 三元运算符 也就是类似这样的结构: loop = loop if loop is not None else get_event_loop() 通常我们在处理函数的入口参数实现默认值的情况的时候会用到，比如上面一般函数参数那里写着 loop=None ，用上面这种一行形式更简洁一些。而我们不直接在函数定义的那里采用默认值可能有两种情况，一是该默认值并不方便作为默认值，而最好默认为None；还有一种情况是默认值是需要通过某个函数等运算得到的。 __name__ 和 __file__ 这里所谓脚本被引入是指用import或者from语句被另外一个脚本引入进去，而这里所谓的脚本被执行是指直接如 python test.py 这样的形式执行该py脚本。 这两种形式很有一些区别，下面慢慢谈论: __name__ 的区别。这个大家应该很熟悉了。如果脚本是被引入的， __name__ 的值是该引入的脚本文件名，比如引入的是 test.py ，那么该脚本被引入，对于这个test.py文件来说，其内的 __name__ 的值就是 test ，也就是 模块名 ；而如果是作为脚本被执行，则该 __name__ 是 __main__ 。 __file__ 的区别。如果脚本是被执行的，假设该脚本文件是 hello.py ，那么在这个被执行脚本中， __file__ 的值是 hello.py ，也就是 文件名 。如果是被引用的，那么对于那个被引入的脚本来说， __file__ 的值是该被引入脚本相对系统来说的 完整文件名 ，比如是 /home/wanze/桌面/hello.py 。 如果我们要得知本脚本在系统中的绝对位置，可以使用os.path模块的abspath函数。 import os path = os . path . abspath ( '' ) 其将返回该脚本在系统所在的目录。 locals和globals python的 locals() 返回本函数内的局部变量字典值，而 globals() 则返回本模块文件的全局变量。 locals 是只读的，而 globals() 不是，我们可以利用 globals() 对脚本文件玩出一些新花样。 获取本模块对象 如下所示，可以获取本模块内的变量。 import sys current_module = sys . modules [ __name__ ] old_module_dict = copy ( current_module . __dict__ ) # for k, v in old_module_dict.items(): # if k == 'case_base': # pass # elif k.startswith('case_'): # if issubclass(v, case_base): # URL_CASES.append(v) 根据字符串获取模块对象 import importlib importlib . import_module ( 'what.what' ) 检查某个变量是不是模块对象 参考了 这个网页 >>> import os , types >>> isinstance ( os , types . ModuleType ) True assert语句 assert语句简单的理解就是 assert True ，正常刷过去，而 assert False 将抛出 AssertionError 。 属性管理的函数 hasattr，setattr，getattr，delattr，这些函数都属于关于python中各个对象的属性管理函数，其都是内置函数。 其中hasattr(object, name)检测某个对象有没有某个属性。 setattr(object, name, value)用于设置某个对象的某个属性为某个值， setattr(x,a,3) 对应 x.a = 3 这样的语法。 getattr(object, name[, default])用于取某个对象的某个属性的值，对应 object.name 这样的语法。 delattr(object,name)用于删除某个对象的某个属性，对应 del object.name 这样的语法。 可迭代对象flatten操作 a_list = [[1, 2], [3, 4], [5, 6]] print(list(itertools.chain.from_iterable(a_list))) # Output: [1, 2, 3, 4, 5, 6] # or print(list(itertools.chain(*a_list))) # Output: [1, 2, 3, 4, 5, 6] __missing__方法 对于字典或者字典的子类，你可以通过定义 __missing__ 方法来回避找不到键值而抛出的 KeyError ，参考了 这个网页 。如下所示: class NestedDict ( collections . UserDict ): ''' Implement this data structure: {\"section\":{}, } ''' def __init__ ( data = None ): super () . __init__ ( data ) def __missing__ ( self , key ): value = self [ key ] = dict () return value def update_in_section ( self , section , d ): self [ section ] . update ( d ) def get_in_section ( self , section , key ): return self [ section ] . get ( key ) def delete_in_section ( self , section , key ): del self [ section ][ key ] def set_in_section ( self , section , key , value ): self [ section ][ key ] = value 如果找不到该key，则该类会自动赋值一个新的 dict()并作为该key的值。你可能希望使用 type(self)() ，但这种风格对json的兼容性不太好，推荐还是都用dict类。 product函数 product函数在 itertools 模块里面，按照官方文档的说明是product(A, B)返回值等价于((x,y) for x in A for y in B)，也就是各种可能的组合情况（类似于笛卡尔积的概念）: >>> list(product(['a','b'],['c'])) [('a', 'c'), ('b', 'c')] 此外单一迭代加上 repeat 参数也会生成一些很有意思的结果: >>> list(product(['True','False'],repeat=len('abc'))) [('True', 'True', 'True'), ('True', 'True', 'False'), ('True', 'False', 'True'), ('True', 'False', 'False'), ('False', 'True', 'True'), ('False', 'True', 'False'), ('False', 'False', 'True'), ('False', 'False', 'False')] 这可以看作: >>> list(product(['True','False'],['True','False'],['True','False'])) [('True', 'True', 'True'), ('True', 'True', 'False'), ('True', 'False', 'True'), ('True', 'False', 'False'), ('False', 'True', 'True'), ('False', 'True', 'False'), ('False', 'False', 'True'), ('False', 'False', 'False')] deque结构 本小节主要参考了 这个网页 。 我想读者可能已经接触过queue结构了吧，queue结构是一端进data，然后另一端出data，这样形成了先进先出的数据流。而deque结构两端都可以进两端都可以出，这看上有点古怪，如果你只使用一端的话，那么其好像一个堆栈结构，是先进后出的；而如果一端只是进，另一端只是出，其又好像一个queue结构。那么其有什么优势呢？deque结构最大的优势，也就是我们需要使用它的原因是: 其两端插入元素和删除元素的时间复杂度是O(1)，是一个常数级，而列表开头插入或删除元素的时间复杂度是O(N)，所以如果我们需要一个类似列表的数据存储结构，而这个数据结构中，开头的几个元素和末尾的几个元素都比较重要，经常被访问，那么就应该使用deque结构。 上面的网页介绍了这么一个函数，用来返回一个文件最后的几行: from collections import deque def tail ( filename , n = 10 ): 'Return the last n lines of a file' with open ( filename ) as f : return deque ( f , n ) 其是利用了deque还有一个size定长的概念，输入的队列进入deque时较老的元素会被丢弃。我不太清楚这种做法效率如何，不过这种写法还是很优雅的。 查找多个最大最小元素的情况 如果只是想要获知某些数据的一个最大值或者一个最小值，那么当然用 max 或 min 方法就可以了。这里讨论的情况是如果你想要获知某些数据的多个最大值或多个最小值。一般想到的就是先对这些数据进行排序，然后进行切片操作。参考资料2的第一章第四节讨论的方法实际上是利用最小堆结构进行堆排序然后提出最大或最小的那个几个元素。 大体过程就是: lst = [ 1 , 8 , 2 , 23 , 7 , - 4 , 18 , 23 , 42 , 37 , 2 ] import heapq heapq . heapify ( lst ) heapq . nlargest ( 3 , lst ) heapq . nsmallest ( 3 , lst ) 获取一个月最后的一天 首先要说的是利用python的datetime和timedelta对于 days 的加减操作是能够很好地支持跨月问题的: >>> from datetime import datetime >>> d = datetime . now () >>> d datetime . datetime ( 2016 , 5 , 29 , 8 , 50 , 20 , 337204 ) >>> from datetime import timedelta >>> d - timedelta ( days = 29 ) datetime . datetime ( 2016 , 4 , 30 , 8 , 50 , 20 , 337204 ) >>> d - timedelta ( days = 28 ) datetime . datetime ( 2016 , 5 , 1 , 8 , 50 , 20 , 337204 ) 但是有的时候你就是需要直接获知某个月份的最后一天是30还是31等等，然后利用replace来获得一个月的最后一天。这个时候你需要利用 calendar 的 monthrange 函数。参考了 这个网页 。 >>> d.replace(year = 2016,month=4,day = monthrange(2016,4)[-1]) datetime.datetime(2016, 4, 30, 8, 50, 20, 337204) OrderedDict类 字典一般没有排序的需求吧，就是有也可以输出的时候再排序，再说OrderedDict和一般字典比较起来存储开销大了一倍，能不用就不用吧。不过在某些情况下，用这个类确实能带来一些便利。我第一次遇到这种情况大体是在bilibili的api对接那里，其计算密钥需要将所有参数排序然后urlencode为字符串然后再基于这个字符串进行一些计算。 params = OrderedDict(sorted(params.items(), key=lambda t: t[0])) string = urlencode(params) 大体在某些情况下，总是要求某个字典值变量按照某个顺序输出，那么用OrderedDict还是很便利的。其顺序就是按照其插入顺序来的，所以进入之前我们还是要做字典排序工作，所以我们可以看作这是一个自动进行了某种操作的便捷对象吧。 Counter类 Counter类是真有用，而且还不是一般的好用。下面的例子来自参考资料2，不多说，看看代码大体就了解了: words = [ 'look' , 'into' , 'my' , 'eyes' , 'look' , 'into' , 'my' , 'eyes' , 'the' , 'eyes' , 'the' , 'eyes' , 'the' , 'eyes' , 'not' , 'around' , 'the' , 'eyes' , \"don't\" , 'look' , 'around' , 'the' , 'eyes' , 'look' , 'into' , 'my' , 'eyes' , \"you're\" , 'under' ] from collections import Counter word_counts = Counter ( words ) # 出现频率最高的3个单词 top_three = word_counts . most_common ( 3 ) print ( top_three ) # Outputs [('eyes', 8), ('the', 5), ('look', 4)] Counter 对象是字典的子类，所以字典的一般方法它都有，下面就不赘述了。然后 update 方法我们应该理解为同key之间的加法， 此外还有 subtract 方法可以看作同key之间的减法。此外你还可以做: 这种加减运算和上面提及的 update 方法和 subtract 方法还是有点区别的，加法大体类似，主要是减法将会自动去掉计数小于等于零的项，而 subtract 方法不会。 >>> a = Counter(words) >>> b = Counter(morewords) >>> a Counter({'eyes': 8, 'the': 5, 'look': 4, 'into': 3, 'my': 3, 'around': 2, \"you're\": 1, \"don't\": 1, 'under': 1, 'not': 1}) >>> b Counter({'eyes': 1, 'looking': 1, 'are': 1, 'in': 1, 'not': 1, 'you': 1, 'my': 1, 'why': 1}) >>> # Combine counts >>> c = a + b >>> c Counter({'eyes': 9, 'the': 5, 'look': 4, 'my': 4, 'into': 3, 'not': 2, 'around': 2, \"you're\": 1, \"don't\": 1, 'in': 1, 'why': 1, 'looking': 1, 'are': 1, 'under': 1, 'you': 1}) >>> # Subtract counts >>> d = a - b >>> d Counter({'eyes': 7, 'the': 5, 'look': 4, 'into': 3, 'my': 2, 'around': 2, \"you're\": 1, \"don't\": 1, 'under': 1}) >>> 这个数据结构最为人们数值的统计频数了，通过调用 most_common(n) 方法，n是排行榜的前n名。 字符串比较大小 读者可以实验一下python中字符串之间是可以比较大小的： >>> 'abc' > 'ab' True >>> 'fabc' > 'abc' True >>> '3.04' > '3' True 这个特性有的时候很有用的，具体是如何比较大小的呢？按照python官方文档的描述，采用的是词典编纂顺序。具体描述信息如下： 序列之间比较大小是，首先两个序列各自的第一个元素开始比较，如果它们相同，则进行下一个比较，直到任何一个序列被穷尽。如果两个序列各自比较的类型都是相同的，那么整个过程将一直进行下去。如果两个序列是相等的则认为它们是相等的，如果某一个序列是另外一个序列的子序列，则那个短的序列认为比长的序列要小。具体到每一个元素的大小比较，是按照ASCII顺序对其进行比较的。 中文比较大小？ 读者这时会想到，既然python中字符串都默认是unicode编码（utf-8），那么中文应该也是能够比较大小的吧，事实确实如此： >>> '章' > '张' True >>> '章' < '张' False >>> ord('章') 31456 >>> ord('张') 24352 感兴趣的读者可以打开字符映射表看一下，'张'对应的unicode编号是U+5F20，你输入0x5f20，返回的正是24352。如果你输入hex(24352)，返回的就是'0x5f20'。 ord和chr函数 ord函数接受 一个 字符，然后返回其unicode编码，十进制的。chr函数是ord函数的反向，比如你输入24352这个十进制uniocde，就返回了对应的字符。 >>> chr(24352) '张' 所以我们可以总结到，python3的字符串比较大小，是基于utf-8编码的。 给某个对象动态加载一个方法 这里主要参考了 这个网页 。 具体原理还是很简单的，那就是构建一个函数对象，然后将这个对象赋值给某个对象。但这里的函数对象如果要接受self参数的话，其作为类的方法还是需要一些特殊的处理的。 class Test (): pass test = Test () def hello ( self ): print ( \"hello\" ) import types test . hello = types . MethodType ( hello , Test ) test . hello () 上面的types.MethodType是用来构建一个类的方法的，其第一个参数是具体的函数对象，第二个参数是对应的类或实例。 然后上面的例子继续优化就是如下的形式: import types class Test (): @classmethod def removeVariable ( cls , name ): return delattr ( cls , name ) @classmethod def addMethod ( cls , func ): return setattr ( cls , func . __name__ , types . MethodType ( func , cls )) def hello ( self ): print ( \"hello\" ) test = Test () Test . addMethod ( hello ) test . hello () 你看到了这里的addMethod是作用于本类的，当然你也可以选择作用于本实例: import types class Test (): @classmethod def removeVariable ( cls , name ): return delattr ( cls , name ) @classmethod def addMethod ( cls , func ): return setattr ( cls , func . __name__ , types . MethodType ( func , cls )) def addMethod2 ( self , func ): return setattr ( self , func . __name__ , types . MethodType ( func , self )) def hello ( self ): print ( \"hello\" ) test = Test () test . addMethod2 ( hello ) test . hello () 这样这个函数就只加在本实例上面了，这用处不太大。 configparse处理特殊字符 configparse对于某些特殊字符可能会报错，参考了 这个问题 ，推荐使用 RawConfigParser ，这样就可以解决问题。","tags":"python语言","url":"articles/python-cookbook.html"},{"title":"windows下的linux子系统","text":"WSL 在windows10里面是个新概念，大体可以看做mingw或者cygwin的替代吧。随着windows对WSL开发更新，发现这个东西在某些时候是可以解决某些程序在linux下能跑在windows下不能跑的问题。 WSL配置 首先需要用管理员方式运行powershell，然后运行： Enable-WindowsOptionalFeature -Online -FeatureName Microsoft-Windows-Subsystem-Linux 然后重启系统。这个必须做，否则wsl会提示错误。 然后进去了之后设置用户名和密码，这个没什么好说的，这里的用户名不一定是root。 然后在windows系统的 Settings -> Update and Security-> For develops 哪里打开 Devoloper Mode，不清楚为什么，但推荐做一下，参看的是 官方文档的这里 。 这样你在windows下输入bash就可以进入ubuntu系统了， ssh连接 NOTICE： 本小节可选项，可以不看。 主要就是修改 /etc/ssh/sshd_config 的一些配置，首先推荐把端口号改为 2222 或者什么的，因为windows系统现在外面可能还有个ssh服务会占用22端口，然后： UsePrivilegeSeparation no #因为wsl没有实现chroot PasswordAuthentication yes ListenAddress 127.0.0.1 # 安全考虑 然后会提示什么文件找不到错误，如下： sudo ssh-keygen -t rsa -f /etc/ssh/ssh_host_rsa_key sudo ssh-keygen -t ecdsa -f /etc/ssh/ssh_host_ecdsa_key sudo ssh-keygen -t ed25519 -f /etc/ssh/ssh_host_ed25519_key 在重启ssh服务，应该问题不大了： sudo service ssh --full-restart NOTICE: 如果你把ubuntu关闭了，那么ssh也就连不上了，网上有些解决方案说制作一个开机脚本后台启动的，觉得太麻烦了，就这个任务不愿意这么折腾，开发的时候注意打开ssh服务就是了。 额外的安装软件包 gcc g++ make cmake gdb这些软件包是需要在 WSL 里面安装的，推荐直接如下一并安装了： sudo apt update sudo apt upgrade sudo apt install build-esstial 这样应该c语言的开发环境就搭建起来了，WSL 还是给人一种怪怪的感觉，并不是很好用，不过也算是一种尝试吧。 参考资料 wsl官方文档 wsl的ssh配置","tags":"tools","url":"articles/wsl.html"},{"title":"bihu模块","text":"简介 一个通用目的的python模块，安装如下： pip install bihu 项目源码在 https://github.com/a358003542/bihu 功能简介 web 里面有获取随机user-agent函数等其他辅助函数。 workflow里面写了一个状态控制类，在airflow调度的时候，最小的任务执行仍然有状态记录。 database 里面放着很多便捷的对接数据库的通用操作模式。具体请读者用心体会。 utils里面有很多便捷的函数支持。 更新说明 项目配置管理 本项目开发遵循12因素应用配置管理原则： .env 不进入版本库，控制整个项目的配置选择，目前选用了三个阶段： development testing production，分别对应于 本机早期开发， 实际上机测试 和 生产环境 .secrets.toml 里面放着一些私密的配置信息，不进入版本库 settings.toml 里面放着其他一些配置 使用请参看 dynaconf 模块。 版权申明 本模块版权归cdwanze所有，不可用于商业目的，若有需要请联系作者本人。 API 下面介绍API只是简单介绍下，具体使用请参阅代码。 web get_random_user_agent 获取随机的user_agent to_absolute_url 将一个url转变成为绝对url download 在common下，下载文件便捷函数 etc... database mongodb 便捷连接操作和有去重逻辑的insert逻辑和upsert逻辑。 sqldb 利用sqlalchemy便捷连接sql database，utils里面定义了一些常见的操作，如 insert_or_ignore insert_or_update ，函数里面有去重判断，返回值选择和具体什么情况下才进行更新操作的函数钩子。 sqldb里面还有一个便捷的 SQLDataBase 类，其可以直接连接已经存在的数据库，从而获取到sqlalchemy 的 orm对象。 redis 简单的连接redis操作 utils date_utils 一些便捷的日期时间操作函数 path_utils 一些便捷的路径操作函数，如获取某个路径下所有的某个后缀的文件等。 workflow 提供了 StatusRecordHandler 类，可以很方便的对airflow操作流程具体某个时间片上的操作加上状态记录功能。","tags":"项目","url":"articles/bihu-module.html"},{"title":"bihu_spiderctl项目","text":"简介 本项目源于 https://github.com/DormyMo/SpiderKeeper 项目[MIT LICENSE]，进行了django化，这样方便数据库和以后的其他django项目数据库合并在一起，然后对界面进行了部分调整和简化。 项目地址在 https://github.com/a358003542/bihu_spiderctl 。 使用帮助 运行命令，进行project初始化： python manage.py init_data 用于初始化项目默认项目 default ，本项目简化去除了deploy和project等等概念，实际上一般使用并不需要考虑这些概念，分布式爬虫也不一定要用deploy那个命令行工具，实际上完全可以和运维工具git仓库控制结合起来，实现多台机器自动化代码更新。分布式也不是那么神秘，各个机器scrapyd服务开起来就可以了，具体命令让那里分发完全可以更高层的调度系统来控制。 这种处理和目前流行的 应用 单进程 ，然后 多进程由专门的工具如nginx 来实现有异曲同工的意图，那就是具体某个小的功能应用，不用太考虑系统架构上的事情，越小巧，越专注于本职工作就好。这样将大大降低单应用开发人员的思维复杂度，Again，让我们再重温一下Unix编程艺术里面的金句： KEEP IT STUPID AND SIMPLE. 周期性爬虫参数说明 所有 */n 每n 星期几 0-6 0表示周日 几号 1-31 几月 1-12 每周一 0 0 * * 1 版权声明 本项目同样遵循 MIT 协议。","tags":"项目","url":"articles/bihu-spiderctl.html"},{"title":"redis","text":"redis基础 redis简单来说就是一个基于内存的k-v存储数据库，当然具体内容还是很丰富的，这个后面再慢慢详细讨论之。 就作为python接口和基本的 get set操作都是很直观简单的，这个就不多说了，至于具体数据类型，先知道字符串型即可，哦，对了，redis存储数字1也会变成字符串\"1\"的。 一个简单的获取redis的连接函数如下所示： def get_redis_client ( db = 0 ): host = settings [ 'redis' ] . get ( 'host' , 'localhost' ) port = settings [ 'redis' ] . get ( 'port' , 6379 ) redis_client = redis . StrictRedis ( host = host , port = port , db = db , decode_responses = True ) return redis_client 注意看 decode_responses=True ，加上的目的就是让python那边接受字符串不是bytes型，也是字符串型，就大部分使用来说都会希望返回的是字符串型。 字典类型 确切的描述是 hash 表，大体对应于python那边的字典类型。 127.0.0.1:6379> hmset x a 1 OK 127.0.0.1:6379> hgetall x 1) \"a\" 2) \"1\" 127.0.0.1:6379> hmset x b 2 OK 127.0.0.1:6379> hgetall x 1) \"a\" 2) \"1\" 3) \"b\" 4) \"2\" 设置过期时间 设置某个key的过期时间， 请参看 expire 和 pexpire 命令。","tags":"数据库","url":"articles/redis.html"},{"title":"xpath","text":"前言 基本东西简单了解下即可，然后多看例子吧。 /what 基本路径表达，下个节点 //what 基本路径表达，任意位置的下个节点 这里 / 表示在下个节点中匹配， // 下个或所有子节点匹配。 //div[@id='what'] 根据id定位 //div[@id='what']/a[1] 根据id定位后找下面的第一个a标签 //div[@id='what']/a[*] 根据id定位后找下面的所有a标签 这里 * 表示所有的意思。 //div[@name] 找具有name属性的div标签 //div[@name='what'] 找name属性等于what的div标签 //*[contains(@class,'what')] 找某个标签class属性有 what NOTICE: 这里的意思是有，多个class属性也是可以匹配的 class=\"what what_what\" //div[@class='what'] 那个目标标签的class属性就是what，也就是匹配的是 class=\"what\" //*[@id=\"list\"]//dd[*]/a[@href and @title] 找id=list的标签下面的所有dd标签下面的a标签，a标签必须有href和title属性。 //title[@*] 选择title，随意属性，但title标签必须有属性 选择具体的内容 选择属性 //*[@id=\"list\"]//dd[*]/a[@href and @title]/@href 选择文本 //title/text() string 对于选择的节点（注意如果返回的是节点集 nodeset将只取第一个），将所有的节点（也就是包括子节点）的文本抽取出来并合并。 string(//div[@class=\"lemma-summary\"]) 参考资料 阮一峰写的xpath入门教程 w3school的xpath教程 一篇关于xpath写的不错的博文","tags":"python爬虫","url":"articles/xpath.html"},{"title":"setuptools和pip等相关","text":"setup.py配置 在上面模块那一章里对python模块包的知识还有python相关生态圈的知识几乎没有谈及，这里一并在本章中说明了。本章知识是我们理解前人编写的各个有用的模块包的基础，也是编写自己的模块包的基础。 请结合Github上的 pyskeleton项目 来阅读本章。 虽然官方内置distutils模块也能实现类似的功能，不过现在人们更常用的是第三方模块setuptools，其相当于distutils模块的加强版，初学者推荐就使用setuptools模块。更多内容请参看setuptools模块的 官方文档 。 安装就是先安装pip3： sudo apt-get install python3-pip 然后通过pip3来安装setuptools： sudo pip3 install setuptools 最简单的\"setup.py\"文件如下所示： from setuptools import setup , find_packages setup ( name = \"HelloWorld\" , version = \"0.1\" , packages = find_packages (), ) 第一行是从setuptools模块中引入setup函数和 find_packages 函数。 setup函数接受一系列的字典值，下面就setup函数的一些字典值的含义慢慢道来： name 本软件的名字 version 本软件的版本号 author 本软件的作者 author_email 本软件作者的邮箱 maintainer 本软件的维护者 maintainer_email 本软件维护者的邮箱 contact 本软件的联系人。可以不写，则是维护者的名字，如果没有则是作者的名字。 contact_email 本软件的联系人的邮箱，可以不写，则是维护者的邮箱，如果没有则是作者的邮箱。 license 本软件的license url 本软件项目主页地址 description 本软件的简要描述 long_description 本软件的完整描述，一般如下定义一行函数，然后读取本地目录下面README.md文件。 import codecs def long_description (): with codecs . open ( 'README.md' , encoding = 'utf-8' ) as f : return f . read () platforms 本软件经过测试可运行的平台 classifiers 本软件的分类，请参考 这个网页 给出一些值。是字符串的列表。 keywords 本软件在pypi上搜索的关键词，字符串的列表。 packages 你的软件依赖的模块。一般如下使用： packages = find_packages() 则文件夹下有 __init__.py 文件的，都将视作python模块包，其内的py文件都将加入进去。 除此之外你也可以直接手工输入你的模块名字，具体就是字符串的列表。 entry_point entry_points = { 'console_scripts' :[ 'zwc=zwc.zwc:main',], } 其中zwc是你的shell调用的名字，然后zwc是你的模块，另外一个zwc是你的主模块的子模块，然后main是其中的main函数。这就是你的shell调用程序的接口了。类似的还有gui_script可以控制你调用GUI图形的命令入口。 install_requires 接受字符串的列表值，将你依赖的可以通过pip安装的模块名放入进去，然后你的软件安装会自动检测并安装这些依赖模块。 setup_requires 和 install_requires 类似，所不同的是这个更加侧重于本 setup.py 所需要的依赖。然后注意 setup_requires 只是把依赖模块下载下来，还没有具体安装，因为 setup.py 具体还在执行。如果你希望某个依赖模块之于 setup.py 就可用，则需要将该依赖模块加入到 install_requires 和 setup_requires 中。 package_data 你的软件的模块额外附加的（除了py文件的）其他文件，具体设置类似这样 {\"skeleton\":['*.txt'],} 其中skeleton这里就是具体的你的软件的模块（对应的文件夹名），然后后面跟着的就是一系列的文件名列表，可以接受glob语法。注意这里只能包含你的模块文件夹也就是前面通过packages控制的文件夹下面的内容。 include_package_data 这个一般设置为True 其他不常用的属性值列在下面： scripts 不推荐使用，推荐通过entry_point来生成脚本。 py_modules 不推荐使用，推荐使用packages来管理模块。 data_files 前面的package_data是只能在你的模块文件夹里面的其他数据文件等，然后可能还有一些数据文件你需要包含的，用data_files来控制，具体后面跟着的参数格式如下面例子所示： data_files = [('icos',['icos/wise.ico'])], #这是添加的icos文件夹下面的wise.ico文件 data_files = [('',['skeleton.tar.gz'])], #这是添加的主目录下的skeleton.tar.gz文件 值得一提的是data_files不能接受glob语法。 data_files已经不推荐使用了，推荐用package_data来管理，可以方便用pkg_resources里面的方法来引用其中的资源文件。具体说明请看后面。 pip的develop模式 本小节参考了 这个问题 。 对于其他第三方包你不需要修改的，就直接 python setup.py install 就是了，而对于你自己写的包，可能需要频繁变动，最好是加载引用于本地某个文件夹，那么推荐是采用 python setup.py develop 命令来安装。 其对应于 pip install -e . 这个命令，或者直接安装本地文件夹不是develop模式 python install . 。 pipenv的 pipenv install -e . 也是这个develop模式，你修改的代码会实时生效。 pkg_resources模块来管理读取资源文件 如下所示： from pkg_resources import resource_filename resource_stream ( 'wise' , 'icos/Folder-Documents.ico' ) 第一个参数是模块名字，第二个参数是模块中的文件的相对路径表达。 上面的例子是resource_filename，返回的是引用的文件名。此外还有命令：resource_string，参数和resource_filename一样，除了它返回的是字节流。这个字节流可以赋值给某个变量从而直接使用，或者存储在某个文件里面。 在pypi上注册你的软件 具体很简单，就是 python3 setup.py register 你需要在pypi官网上注册一个帐号，然后你的软件不一定能够注册成功，因为很多好名字都被别人取了。。 在pypi上上传你的软件 python3 setup.py sdist upload 下载pypi上的软件源文件 参考了 这个网页 。 pip install --download=\"/pth/to/downloaded/files\" package_name python虚拟环境管理 Virtualenv模块的主要作用就是建立一个封闭独立的python开发环境，因为一个python项目的开发通常会涉及到多个模块，而你激活virtualenv环境之后，通过pip命令安装的模块是安装在本项目文件夹内的，这样就建立了单独的固定某个模块版本的开发环境。通过python虚拟环境，一方面控制了python的版本，另一方面控制了python模块的版本，同时使得整个项目类似于绿色安装版具有可移植性。 安装就是用pip来安装常规安装即可。 sudo pip install virtualenv 新建一个项目 新建一个项目就是使用virutalenv命令，然后后面跟一个文件夹名字，等下要新建的文件夹名字。 virutalenv [path] 这里的path就是你的项目的名字，等下会创建该名字的文件夹，你也可以设定为 \".\" ，这样就是在当前文件夹下创建。 然后常用的选项有： --python=python2 或者 --python=python3 如果不指定这个选项，虚拟环境会使用当前操作系统的默认python版本。 --system-site-packages ，如果加上这个选项，那么你的虚拟环境是可以使用安装到系统里去的那些python模块的。参考了 这个网页 ，这是个很值得一提的小技巧，那就是如果你之前设定是venv可以引用系统级的那些python模块，后面你又不想了，这个时候是不需要重新安装虚拟环境的，只需要在虚拟环境中创建一个这个空白文件即可： lib/python3.5/no-global-site-packages.txt 如果你又想引用系统级的那些python模块了，把这个文件删除即可。 激活本地虚拟环境 运行下面的命令即进入本地虚拟环境： cd venv source bin/activate 激活虚拟环境之后，使用python是使用的虚拟环境设定的python解释器，然后使用pip安装模块也是安装在虚拟环境之下。 退出本地虚拟环境 运行deactivate命令即可 deactivate pipenv模块 强烈推荐读者了解下pipenv模块。","tags":"python语言","url":"articles/python-setuptools-pip.html"},{"title":"django后台api编写之-模板","text":"模板基本概念 模板基本的样子如下，下面有模板继承，block ，循环，过滤，之类的。熟悉jinja2模板的同学稍微看下大致是个什么意思就已经清楚了。 {% extends \"base_generic.html\" %} {% block title %}{{ section.title }}{% endblock %} {% block content %} <h1> {{ section.title }} </h1> {% for story in story_list %} <h2> <a href=\" {{ story.get_absolute_url }} \"> {{ story.headline | upper }} </a> </h2> <p> {{ story.tease | truncatewords :\"100\" }} </p> {% endfor %} {% endblock %} django如何查找模板的 在django的settings.py哪里有： PROJECT_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__))) TEMPLATES=[ { 'BACKEND':'django.template.backends.django.DjangoTemplates', 'DIRS':[ os.path.join(PROJECT_DIR,'templates'), ], 默认是在每个app下的templates文件里都会递归遍历查找的，这里DIRS加上了另外一个文件夹，也就是现在settings.py所在的那个文件夹下如果有templates文件夹也会去遍历的。 模板文件最后都会合并的，所以就存在模板的覆盖机制了，为了避免无谓的覆盖，一般模板原则上推荐的结构是在templates下面，不管是那个app下面，都再新建一个目标app的名字，再新建模板文件。当然对于稍小的项目直接扔在templates下面问题不大。 比如你想覆盖django自带的admin界面，就要在templates下面新建一个admin文件夹，具体什么模板文件，你要研究下django的源码了。 django的变量怎么传给javascript NOTICE: 现在不推荐这种写法了，推荐走ajax通道传数据。 django的视图函数在render的时候通过context字典值，里面的各个字段的值将传给django的模板里的变量，这个我们是知道的了，那么django的变量怎么进而传递给javascript呢。本小节参考了 这个网页 。 首先要传递的字段建议如下json封装下： from django.core.serializers.json import DjangoJSONEncoder { what : json . dumps ( data [ 'content_images' ], cls = DjangoJSONEncoder ) } 然后在javascript那边： var what = JSON.parse(\" {{ what | safe | escapejs }} \") 注意 safe 和 escapejs 过滤器。","tags":"django","url":"articles/django-templates.html"},{"title":"sqlalchemy模块","text":"前言 老实说sqlalchemy这个模块特别难学，主要原因倒不是这个模块本身，阻碍我很好地学习这个模块的是这个心态，认为自己可以直接学习sqlalchemyORM封装就行了，不用学习SQL语句。这是错误的。要学好sqlalchemy必须先学习好SQL语句，要完全发挥出sqlalchemy的威力，也必须先学会SQL语句和对应的SQL实现。然后还有一个误区，我们在使用上也不一定要使用orm层的接口。实际上sqlalchemy这个模块里面内容是很丰富的，是很灵活的。它是可以完全取代sqlite3模块和psycopg2模块等初级的DB API，然后还提供了高级的ORM封装。 安装 sqlalchemy的安装简单用pip3命令安装之即可: sudo pip3 install sqlalchemy 引用惯例 在后面都默认有如下引用: from sqlalchemy import * 后面将不会再提及，也就是凡是 from sqlalchemy import what 的所有语句也都归于如上一条引用。 简介 通过sqlalchemy连接具体的某个数据库，前面有一些准备工作要做，参考 sqlalchemy architecture 一文的描述: 和数据库直接相连的是我们熟悉的那些DBAPI接口模块，比如: sqlite3, pymysql, psycopg2等，然后中间的核心层有Engine，连接池，方言，SQL表达语言和类型系统。core层很重要，实际上有些模块是完全建构在core层之上的，不一定要用ORM方法。 非ORM风格 创建一个Engine 创建一个 Engine 对象实际上对应的就是和数据库的连接操作。具体是通过 create_engine 函数创建的Engine对象，其一开始并没有实际连接数据库，只有具体要求某个操作的时候才会去连接。 连接sqlite3 连接sqlite3 in-memory engine = create_engine('sqlite://') 但是推荐采用如下写法: engine = create_engine('sqlite:///:memory:') 这样后面谈及的sqlalchmy_utils的 database_exists 函数也能正常工作。 连接sqlite3 on-disk engine = create_engine('sqlite:///sqlite3_learning_example.db') 上面的db文件是创建在命令行当前工作目录下的，也就是相对路径表达。此外还可以如下写上绝对路径表达: engine = create_engine('sqlite:////absolute/path/to/foo.db') 在三个斜杠线的基础上还需要加上一个斜杠线。作为这种形式的通用表达，前面必定有两个斜杠线，然后第二个斜杠线和第三个斜杠线之间是登录信息的描述，因为sqlite3没有这些信息，所以空了，如下所示: dialect://username:password@host:port/database 或者某个方言系统再加上某个驱动: dialect+driver://username:password@host:port/database 这里的方言可以有: sqlite: 默认的driver的官方的 sqlite3 模块，这个应该不需要改动。 mysql: 默认的dirver是 mysql-python ，但推荐使用 pymysql ，你需要用pip安装之。 engine = create_engine('mysql+pymysql://root@localhost/test') postgresql: 默认的driver是 psycopg2 ，这个还行。 oracle: 默认的driver是 cx_oracle 。 mssql: 默认的driver是 pyodbc 。 连接mysql engine = create_engine('mysql+pymysql://localhost/mysql_db') 确保你安装了pymysql: sudo pip3 install pymysql 连接postgresql engine = create_engine('postgres://rick:foo@localhost:5432/pg_db') MetaData对象 MetaData对象你可以看作比Table层更高一级的抽象，里面存放着Table对象的一些metadata描述信息。一个简单的理解是将一个MetaData对象看作sqlalchemy内部的database概念。 创建一个unbound MetaData对象 通过 MetaData() 默认创建的就是一个unbound MetaData对象。 metadata = MetaData() bind一个Engine对象 你可以如下将一个unbound MetaData对象具体 bind 一个Engine对象。 engine = create_engine('sqlite://') metadata = MetaData() metadata.bind = engine 或者在上面创建的时候就指定: engine = create_engine('sqlite://') metadata = MetaData(engine) 或者你还可以直接engine的URL表达来后台自动创建一个engine，于是有: metadata = MetaData('sqlite://') 对于初学者用的最多的还是 BoundMetaData ，通过上面谈及的方法创建了一个 BoundMetaData 对象之后，某个Table对象关联了该 BoundMetaData 对象，然后该Table对象就可以直接通过: table.create() 来创建自身了。 测试数据库是否存在 这里关于 sqlalchemy_utils 的想法来自 这个网页 。 from sqlalchemy import * from sqlalchemy_utils import database_exists , create_database def init_sqlalchemy ( dburl , echo = True ): engine = create_engine ( dburl , echo = echo ) if not database_exists ( engine . url ): ###确保目标数据库是存在的。 create_database ( engine . url ) metadata = MetaData ( bind = engine ) return metadata metadata = init_sqlalchemy ( 'sqlite:///test.db' ) 这里的 sqlalchemy_utils 需要额外安装，在这里主要是利用其 database_exists 函数来检测某个数据库是否存在，然后如果不存在的话则用 create_database 函数创建之。 上面的 init_sqlalchemy 函数最重要的一个参数就是那个 dburl ，具体其细节前面已有所叙述，正是照它来创建的Engine，并基于这个Engine对象来创建的MetaData对象，一般将这个MetaData对象bind之前的那个engine，然后返回该metadata即可，后面主要需要使用这个metadata。 然后后面实际操作就以创建一个Table对象开始了，其他database的操作，建议如同上面处理的一样，都提到顶层用sqlalchemy_utils模块来处理之。类似的还有 drop_database : 删除database，参数如create_database也是某个Engine对象的url。 创建一个Table对象 下面是一个完整的例子，最后创建了一个Table表格。这里的 db 也就是前面谈及的MetaData对象，我们看到在创建Table对象的时候第一个参数是具体创建的SQL表格的名字，第二个就是该表格bind的某个MetaData对象，也可以简单理解为该表格对象存入该MetaData对象代表的database中。然后后面调用 db.create_all() ，所有这些bind到该db上的表格都将创建。你还可以用 users.create() 来单独创建某个表格。 from sqlalchemy import * from sqlalchemy_utils import database_exists , create_database def init_sqlalchemy ( dburl , echo = True ): engine = create_engine ( dburl , echo = echo ) if not database_exists ( engine . url ): ###确保目标数据库是存在的。 create_database ( engine . url ) metadata = MetaData ( bind = engine ) return metadata db = init_sqlalchemy ( 'sqlite:///test.db' ) users = Table ( 'users' , db , Column ( 'user_id' , Integer , primary_key = True ), Column ( 'name' , String ( 40 )), Column ( 'age' , Integer ), Column ( 'password' , String ), ) db . create_all () 利用已存在的Table 如果某个数据库的某个Table已经存在了，那么你就没有必要如上去创建一个Table对象了，只需要如下做就可以获得该Table对象了: users = Table('users',db,autoload=True) 具体就是将 autoload 设置为True即可。这里的db就是所谓的metadata，然后这里必须是bind了的metadata对象，若还未bind，则还需要加上autoload_with参数。 实际在数据库中创建表格 具体可以整个metadata对象，调用 create_all 方法来创建所有表格（其也有 checkfirst 参数。）: db.create_all() 或者该Table对象具体调用 create 方法来自我创建之。在应用推荐加上 checkfirst=True 设置，这样就算数据库中该表格已经存在也不会报错。如下所示: users.create(checkfirst=True) 类似的还有如下用法用于安装删除某个表格，即使该表格不存在也不会报错: users.drop(checkfirst=True) 这里代码改成了这个样子了: try : users = Table ( 'users' , db , autoload = True ) except sqlalchemy . exc . NoSuchTableError : users = Table ( 'users' , db , Column ( 'user_id' , Integer , primary_key = True ), Column ( 'name' , String ( 40 )), Column ( 'age' , Integer ), Column ( 'password' , String ), ) 注意这个 NoSuchTableError ，如果通过 autoload=True 来获取该Table对象而其在数据库中并不存在，则将抛出这个异常。 列的属性设置 创建表格对象后面一系列的参数就是具体各个列Column对象，其第一个参数是具体列的名字，然后第二个参数该列所存储的值的类型，后面还可以跟其他一些可选项作为属性的进一步修饰。具体如下所示: primary_key: 设置该列为主键列或者称之为主键约束 unique: 该列加上唯一约束，即该列的值不可重复。主键约束是一种特殊的唯一约束。 nullable: 该列可不可为空 default: 该列的默认值设置 index: 该列是否加入索引 auto_increment: Integer的列数值自动递增 ForeignKey('brand.id'): 设置外键约束 CheckConstraint('amount > 0'): 设置Check约束 onupdate: 最常见的用法如下: onupdate=datetime.utcnow 应该意思是若update了则调用某个callable对象吧。 列的数据类型声明 下面对各个列存储的值的可能类型描述详细介绍之，更多信息请参看文档查看之。 Class name Python Type SQL Type (for SQLitedriver) Arguments String string TEXT or VARCHAR length Integer int INTEGER none SmallInteger int SMALLINT none Numeric float,Decimal NUMERIC precision=10, length=2 Float float NUMERIC precision=10 DateTime datetime.datetime TIMESTAMP none time datetime.time TIME none Date datetime.date DATE none Binary byte string BLOB length Boolean bool BOOLEAN none Unicode unicode TEXT or VARCHAR length 大致就这些，然后sqlalchemy还有一些类名大致和上面的某个等同，只是多了一个使用上的名字。 FLOAT: 等同于 Numeric TEXT: 等同于 String DECIMAL: 等同于 Numeric INT: 等同于 Integer INTEGER: 等同于 Integer TIMESTAMP: 等同于 DateTime DATETIME: 等同于 DateTime CLOB: 等同于 String VARCHAR: 等同于 String CHAR: 等同于 String NCHAR: 等同于 Unicode BLOB: 等同于 Binary BOOLEAN: 等同于 Boolean mysql方言的额外类型 Class name Python type SQL type Arguments MSEnum string ENUM values MSTinyInteger int TINYINT length MSBigInteger int BIGINT length MSDouble float DOUBLE length=10,precision=2 MSTinyText string TINYTEXT none MSMediumText string MEDIUMTEXT none MSLongText string LONGTEXT none MSNVarChar unicode NATIONAL VARCHAR length MSTinyBlob byte string TINYBLOB none MSMediumBlob byte string MEDIUMBLOB none MSLongBlob byte string LONGBLOB none MSBinary byte string BINARY length MSVarBinary byte string VARBINARY length MSSet set SET set values MSYear int YEAR length MSBit long BIT length postgresql额外的类型 Class name Python type SQL type Arguments PGArray any TypeEngine type engine[] TypeEngine PGBigInteger int,long BIGINT none PGInet none INET none PGInterval none INTERVAL none Oracle额外的类型 Class name Python type SQL type Arguments Oracle byte string RAW length JSON支持 这个现在特别值得提一下，现在主流数据库已经都开始支持JSON数据了。sqlalchemy有JSON这个字段类型了，然后postgresql很早就支持了，mysql版本 > 5.7.5 也是支持的了，现在估计大多已经超过这个版本了。 很是好用，强烈推荐读者去了解下，后面有时间补上具体的使用技巧： TODO insert语句 上面谈及的Table对象调用 insert 方法即可产生一个临时表达语句对象（大概类似的东西，这个词是我杜撰的。），比如在执行 i = users.insert() 之后: >>> type(i) <class 'sqlalchemy.sql.dml.Insert'> >>> str(i) 'INSERT INTO users (user_id, name, age, password) VALUES (?, ?, ?, ?)' >>> 这个i临时表达语句对象有 execute 方法，其可以接受一些参数，比如如下所示: i = users.insert() i.execute(name='Mary', age=30, password='secret') 这个语句执行之后，该数据就被插入进数据库了。你还可以用execute方法来插入多个值，如下所示: i.execute({'name': 'John', 'age': 42}, {'name': 'Susan', 'age': 57}, {'name': 'Carl', 'age': 33}) 然后如果我们需要使用 insert ignore 这样的语句，则需要这样处理: i = users.insert().prefix_with('or ignore') 'INSERT or ignore INTO users (user_id, name, age, password) VALUES (?, ?, ?, ?)' >>> 上面的例子是sqlite的情况，mysql那边则需要写成 .prefix_with('ignore') 这样的形式。 然后额外值得一提的是: 要真正做到重复刷，primary_key，也就是这里的 user_id 需要具体指定为多少，因为这里的ignore的逻辑就是基于主键列不重复的。 delete语句 delete语句的使用也类似上面insert语句所谈及的，除了根据SQL delete语句的实际情况，其为第一个可选参数为where过滤字句，如下所示: d = users.delete(users.c.password == None) >>> str(d) 'DELETE FROM users WHERE users.password IS NULL' 我们注意到上面 users.c.password 的用法，这里的细节后面再讨论，大体意思就是users这个表格的password这一列其值等于None（对应NULL），然后python中的 is None 这种写法试了一下并不行。 上面的delete语句是将users表格中password为空的行都删除，然后如果在构建delete语句时，不填任何where语句，则是表格所有记录都将被删除。 d = users.delete() update语句 然后是update语句，下面来更新那几个user的password。 update 语句的参数设置如下: update(whereclause=None, values=None, inline=False, **kwargs) 我们可以看到其第一个可选参数和delete一样是 whereclause where过滤字句，然后第二个values要跟一个字典值，用来表示具体设置的某些值。下面演示逐步构建update语句的风格，这种风格同样适用于 insert , update , select 语句的构建。 u1 = users.update() u2 = u1.where(users.c.name == 'John').values(password='123456') >>> str(u1) 'UPDATE users SET user_id=?, name=?, age=?, password=?' >>> str(u2) 'UPDATE users SET password=? WHERE users.name = ?' 这里str显示参数并没有给打进去，我们 u2.execute() 执行的话就会看到实际效果了。 select语句 select语句和前面谈论的 insert 等语句的构建过程类似，只是因为SQL中select语句情况较为复杂，然后select语句还需要考虑具体查询的返回值问题，所以东西很多。 首先我们看下面这个函数: def show_squery ( squery ): res = squery . execute () for r in res : print ( r ) select语句执行之后的返回结果叫做什么 ResultProxy 对象，其可以直接用for语句来迭代。不带任何参数的select语句返回Table的所有行: >>> show_squery(users.select()) (1, 'Mary', 30, 'secret') (2, 'John', 42, '123456') (3, 'Susan', 57, None) (4, 'Carl', 33, None) 或者: >>> show_squery(users.select(users.c.name=='John')) (2, 'John', 42, '123456') 这是 and_ 或 & 的用法: >>> show_squery(users.select(and_(users.c.age < 40 , users.c.name != 'Mary'))) (4, 'Carl', 33, None) >>> show_squery(users.select((users.c.age < 40) & (users.c.name != 'Mary'))) (4, 'Carl', 33, None) 类似的还有 or_ 或 | 做逻辑或的意思 ; 或者 not_ 或 \"~\" 做逻辑非的意思。 此外还有 startswith , like , endswith users.select(users.c.name.startswith('M')) 还有 between , in_ : users.select(users.c.age.between(30,39)) users.select(users.c.name.in_('Mary', 'Susan')) ResultProxy对象 select语句执行后返回的ResultProxy对象除了可以直接迭代外还有如下这些方法。 fetchone: 取一行，具体是所谓的 RowProxy 对象，其可用api后面会描述之。 fetchmany: 取多行，具体返回的是一个列表，其内装着 RowProxy 对象。 fetchall: 取所有行，如果fetchmany不指定size则等同于取所有行，返回的是一个列表，其内装着 RowProxy 对象。 scalar: keys: rowcount: close: RowProxy对象 对ResultProxy对象进行迭代，或者fetchone，fetchmany，fetchall方法，就可以获得RowProxy对象，其对应的就是数据库的一行记录。该对象api操作很是灵活，具体你可以像操作一个字典来操作它，也可以类似操作namedtuple般的来操作它，还可以如同列表一般用这样 [0] 的索引方法提取某一列，如下所示: s = users.select() rs = s.execute() row = rs.fetchone() >>> row[0] 1 >>> row.name 'Mary' >>> row['password'] 'secret' 多表连接 现在代码情况如下所示: import sqlalchemy from sqlalchemy import * from sqlalchemy_utils import database_exists , create_database def init_sqlalchemy ( dburl , echo = True ): engine = create_engine ( dburl , echo = echo ) if not database_exists ( engine . url ): ###确保目标数据库是存在的。 create_database ( engine . url ) metadata = MetaData ( bind = engine ) return engine , metadata engine , db = init_sqlalchemy ( 'sqlite:///test.db' ) try : users = Table ( 'users' , db , autoload = True ) except sqlalchemy . exc . NoSuchTableError : users = Table ( 'users' , db , Column ( 'id' , Integer , primary_key = True ), Column ( 'name' , String ( 40 )), Column ( 'age' , Integer ), Column ( 'password' , String ), ) users . create ( checkfirst = True ) insert_query = users . insert () . prefix_with ( 'or ignore' ) insert_query . execute ( id = 1 , name = 'Mary' , age = 30 , password = 'secret' ) insert_query . execute ({ 'id' : 2 , 'name' : 'John' , 'age' : 42 }, { 'id' : 3 , 'name' : 'Susan' , 'age' : 57 }, { 'id' : 4 , 'name' : 'Carl' , 'age' : 33 }) delete_query = users . delete () update_query = users . update () update_query = update_query . where ( users . c . name == 'John' ) . values ( password = '123456' ) update_query . execute () def run ( query ): query . execute () def show_squery ( squery ): res = squery . execute () for r in res : print ( r ) try : emails = Table ( 'emails' , db , autoload = True ) except sqlalchemy . exc . NoSuchTableError : emails = Table ( 'emails' , db , Column ( 'id' , Integer , primary_key = True ), Column ( 'address' , String ), Column ( 'user_id' , Integer , ForeignKey ( 'users.id' )), ) emails . create ( checkfirst = True ) insert_query = emails . insert () . prefix_with ( 'or ignore' ) insert_query . execute ( { 'address' : 'mary@example.com' , 'user_id' : 1 }, { 'address' : 'john@nowhere.net' , 'user_id' : 2 }, { 'address' : 'john@example.org' , 'user_id' : 2 }, { 'address' : 'carl@nospam.net' , 'user_id' : 4 }, ) 交叉连接或笛卡尔积 下面是交叉连接的情况: >>> show_squery(select([users,emails])) 2015-10-28 20:27:21,721 INFO sqlalchemy.engine.base.Engine SELECT users.id, users.name, users.age, users.password, emails.id, emails.address, emails.user_id FROM users, emails 2015-10-28 20:27:21,721 INFO sqlalchemy.engine.base.Engine () (1, 'Mary', 30, 'secret', 1, 'mary@example.com', 1) (1, 'Mary', 30, 'secret', 2, 'john@nowhere.net', 2) (1, 'Mary', 30, 'secret', 3, 'john@example.org', 2) (1, 'Mary', 30, 'secret', 4, 'carl@nospam.net', 4) (2, 'John', 42, '123456', 1, 'mary@example.com', 1) (2, 'John', 42, '123456', 2, 'john@nowhere.net', 2) (2, 'John', 42, '123456', 3, 'john@example.org', 2) (2, 'John', 42, '123456', 4, 'carl@nospam.net', 4) (3, 'Susan', 57, None, 1, 'mary@example.com', 1) (3, 'Susan', 57, None, 2, 'john@nowhere.net', 2) (3, 'Susan', 57, None, 3, 'john@example.org', 2) (3, 'Susan', 57, None, 4, 'carl@nospam.net', 4) (4, 'Carl', 33, None, 1, 'mary@example.com', 1) (4, 'Carl', 33, None, 2, 'john@nowhere.net', 2) (4, 'Carl', 33, None, 3, 'john@example.org', 2) (4, 'Carl', 33, None, 4, 'carl@nospam.net', 4) 内连接 下面是内连接的情况: >>> show_squery(select([users,emails],users.c.id == emails.c.user_id)) 2015-10-28 20:39:09,173 INFO sqlalchemy.engine.base.Engine SELECT users.id, users.name, users.age, users.password, emails.id, emails.address, emails.user_id FROM users, emails WHERE users.id = emails.user_id 2015-10-28 20:39:09,173 INFO sqlalchemy.engine.base.Engine () (1, 'Mary', 30, 'secret', 1, 'mary@example.com', 1) (2, 'John', 42, '123456', 2, 'john@nowhere.net', 2) (2, 'John', 42, '123456', 3, 'john@example.org', 2) (4, 'Carl', 33, None, 4, 'carl@nospam.net', 4) sqlalchemy还有一种更智能的内连接用法: >>> show_squery(join(users, emails).select()) 2015-10-28 20:40:17,502 INFO sqlalchemy.engine.base.Engine SELECT users.id, users.name, users.age, users.password, emails.id, emails.address, emails.user_id FROM users JOIN emails ON users.id = emails.user_id 2015-10-28 20:40:17,502 INFO sqlalchemy.engine.base.Engine () (1, 'Mary', 30, 'secret', 1, 'mary@example.com', 1) (2, 'John', 42, '123456', 2, 'john@nowhere.net', 2) (2, 'John', 42, '123456', 3, 'john@example.org', 2) (4, 'Carl', 33, None, 4, 'carl@nospam.net', 4) 外连接 外连接如下所示，和写入顺序有关。具体是第一个连接第二个，满足过滤条件的则data收进来，没有的则用NULL填充。 >>> show_squery(outerjoin(users, emails).select()) 2015-10-28 20:41:16,610 INFO sqlalchemy.engine.base.Engine SELECT users.id, users.name, users.age, users.password, emails.id, emails.address, emails.user_id FROM users LEFT OUTER JOIN emails ON users.id = emails.user_id 2015-10-28 20:41:16,610 INFO sqlalchemy.engine.base.Engine () (1, 'Mary', 30, 'secret', 1, 'mary@example.com', 1) (2, 'John', 42, '123456', 3, 'john@example.org', 2) (2, 'John', 42, '123456', 2, 'john@nowhere.net', 2) (3, 'Susan', 57, None, None, None, None) (4, 'Carl', 33, None, 4, 'carl@nospam.net', 4) >>> show_squery(outerjoin(emails, users).select()) 2015-10-28 20:43:56,590 INFO sqlalchemy.engine.base.Engine SELECT emails.id, emails.address, emails.user_id, users.id, users.name, users.age, users.password FROM emails LEFT OUTER JOIN users ON users.id = emails.user_id 2015-10-28 20:43:56,590 INFO sqlalchemy.engine.base.Engine () (1, 'mary@example.com', 1, 1, 'Mary', 30, 'secret') (2, 'john@nowhere.net', 2, 2, 'John', 42, '123456') (3, 'john@example.org', 2, 2, 'John', 42, '123456') (4, 'carl@nospam.net', 4, 4, 'Carl', 33, None) ORM风格 sqlalchemy模块的面向对象封装部分改动较大，参考资料1和2里面的内容很多都过时了，没办法只好看嚼官方文档了。 首先我们看到下面这段代码: import sqlalchemy from sqlalchemy import * from sqlalchemy_utils import database_exists , create_database from sqlalchemy.ext.declarative import declarative_base engine = create_engine ( 'sqlite:///:memory:' , echo = True ) if not database_exists ( engine . url ): ###确保目标数据库是存在的。 create_database ( engine . url ) metadata = MetaData ( bind = engine ) Base = declarative_base ( bind = engine ) class User ( Base ): __tablename__ = 'users' id = Column ( Integer , primary_key = True ) name = Column ( String ) fullname = Column ( String ) password = Column ( String ) def __init__ ( self , name , fullname , password ): self . name = name self . fullname = fullname self . password = password def __repr__ ( self ): return '<User {}>' . format ( self . name ) 我们调用 User 类的 __table__ ，其实质就是前面no-orm风格提及的Table对象。 >>> User.__table__ Table('users', MetaData(bind=Engine(sqlite:///:memory:)), Column('id', Integer(), table=<users>, primary_key=True, nullable=False), Column('name', String(), table=<users>), Column('fullname', String(), table=<users>), Column('password', String(), table=<users>), schema=None) >>> ORM层是通过Session对象来和数据库进行会话的: from sqlalchemy.orm import * Session = sessionmaker ( bind = engine ) session = Session () 下面先将如何通过session进行数据库的CRUD（CREATE RETRIEVE UPDATE DELETE）操作分别说明一下: 通过orm层创建数据库 或者引入orm对象之后，调用其 __table__ Table对象，然后像之前的调用 create 方法即可。 UserInfo.__table__.create(bind =engine) Warning: 单表这样创建必须没有外键关系，有则会失败。 或者如官方教程推荐的： Base.metadata.create_all(engine) 增加记录 如下来给某个表格增加一条记录: admin = User('admin','administor','admin') session.add(admin) # 此外还有 add_all 方法可以一次性添加多个orm对象 session.commit() 当session add 了某一条记录，这种更改称之为on-fly更改，后面谈及的其他基于python对象的操作从而对具体某个记录的某个属性的更改也是如此，都是on-fly模式。也就是只有在执行了 session.commit() 之后，所有的更改才会实际刷入数据库，而之前的更改虽然没有实际刷入数据库，但后面代码的查询等等操作都是基于这种改动之后新的（可以看作以某种形式的基于内存的）数据库的。 如果你了解SQL的transaction的概念，就清楚SQL数据库的实现通过transaction来实现数据提交的安全保障——如果一次transaction提交失败，那么将会rollback回滚之，从而保证SQL数据库不会mess up。session有 rollback 方法可以主动回滚，这样on-fly的没有commit的所有transaction都会被丢弃。当session commit 之后，这次的transaction成功提交了就完成了，下次又是另外一个新的transaction。 查询记录 同之前谈及的no-orm风格中提到的select语句查询不同，orm风格的查询语句更加的精简了，但仍然没有脱离select语句查询的本质，熟悉SQL的select语句能够帮助我们更好地学习下面的查询语句。 查询的起步是: session.query(User) 其返回的是orm子模块里面的Query对象。User是具体要查询的某个类（对应某个表格）。简单的理解是将这个 query 方法看作select操作的 select * from User 。 这个Query对象是个可迭代对象，迭代过程中上面返回的就是 User 对象。 若写成这样的形式: session.query(User.name, User.fullname) 则大致对应的是 select name,fullname from User 。 具体如下所示: >>> for i in session.query(User): ... print(i) ... <User admin> >>> guest = User('guest','guest','123456') >>> session.add(guest) >>> for name,fullname in session.query(User.name,User.fullname): ... print(name,fullname) ... admin administor guest guest 在学习SQL的select语句的时候我们学到在 select what from what 语句之后还可以跟上where字句，order by字句等等。sqlalchemy的orm封装同样支持这样的额外操作，具体就是在上面的query语句的基础上进一步操作。经过这些额外的操作返回的同样还是Query对象，也就是你可以写上 session.query(User).filter_by(what).filter(what).order_by(what) 。这样看上去有点长的语句，只要你熟悉SQL语句，并知道在做些什么，那么是完全没有问题的。 过滤排序等操作 filter方法: filter方法对应select语句的where字句。下面是官方文档的一些例子，复制到这里看看熟悉一下即可，大多是什么含义一般都是清楚的: query.filter(User.name == 'ed') query.filter(User.name != 'ed') query.filter(User.name.like('%ed%')) query.filter(User.name.in_(['ed', 'wendy', 'jack'])) query.filter(~User.name.in_(['ed', 'wendy', 'jack']))#not in query.filter(User.name == None) query.filter(User.name != None) query.filter(and_(User.name == 'ed', User.fullname == 'Ed Jones')) query.filter(or_(User.name == 'ed', User.name == 'wendy')) filter_by方法: filter_by方法类似filter方法，除了如上面的User.name要写成name，也就是直接引用表格的列名。 query.filter_by(name = 'ed') order_by方法: 对应select语句的order by字句。 order_by(User.id)[1:3] 然后上面还揭示了 Query 对象很重要的一个特性，其支持python的切片操作。 返回结果 Query对象还可以通过下面这些方法还获得返回结果: all(): 返回一个列表，包含所有的结果。 first(): 返回第一个结果。 one(): 严格只有一个结果，如果有多个结果，将抛出 MultipleResultsFound 异常，如果没有结果，将抛出 NoResultFound 异常。 scalar(): 参考了 这个网页第五条 ，执行查询，如果有多条记录命中，则抛出MultipleResultsFound 异常，如果没有命中，则返回None，如果命中数为一条记录，则返回该记录的 第一列 的值。 count(): 返回命中记录数。 更多的查询例子 你懂得，我们需要更多的查询例子 TODO ： session.query(Game).filter(Game.release_date >= '1999-01-01') text函数 text函数用于支持 filter 和 order_by 方法支持原生的SQL语句表达。大致如下所示，了解下即可: from sqlalchemy import text session . query ( User ) . filter ( text ( \"id<224\" )) . order_by ( text ( \"id\" )) 更改记录 更改记录经过ORM封装之后变得很简单了，就是查询之后获得对应的python对象，然后直接修改即可。 game = session.query(Game).get(1) game.name = 'Super Mario Brothers' session.commit() 删除记录 session.delete(jack) 批量修改或删除 session.query(Game).filter_by(category=\"RPG\").update({\"category\": \"ARPG\"}) session.query(Game).filter_by(category=\"ARPG\").delete() ORM层的关系 SQL表格有四种关系，one-to-one, one-to-many, many-to-one, many-to-many，它们实际上都是基于SQL的外键约束和join查询。其中one-to-many和many-to-one是最需要了解清楚的关系模型，在这之上many-to-many，三个SQL表格搭建起来的关系模型也就很好理解了。推荐读者阅读 这篇文章 来更好地理解SQL表格的这四种关系模型。因为one-to-one实际上是one-to-many的特殊情形，而many-to-one实际上是one-to-many模型的反向，所以我们首先需要重点了解one-to-many模型。 one-to-many模型 sqlalchemy的orm层对one-to-many关系进行了高度封装，使得你不需要考虑SQL的join连接语法细节，只需要声明好外键约束和关系约束（可以看作sqlalchemy新加入了关系约束），然后就可以神奇的使用SQL表格one-to-many的全部特性了。 首先让我们用ORM层的join方法来暂时SQL表格的这些relationship的建立细节，然后再来具体讨论更实用的ORM层的relationship建立的写法。 这是示例代码: import sqlalchemy from sqlalchemy import * from sqlalchemy_utils import database_exists , create_database from sqlalchemy.ext.declarative import declarative_base engine = create_engine ( 'sqlite:///test.db' , echo = True ) if not database_exists ( engine . url ): print ( 'create new database' ) create_database ( engine . url ) metadata = MetaData ( bind = engine ) Base = declarative_base ( bind = engine ) class User ( Base ): __tablename__ = 'users' id = Column ( Integer , primary_key = True ) name = Column ( String ) password = Column ( String ) def __init__ ( self , name , password ): self . name = name self . password = password def __repr__ ( self ): return '&lt;User {}&gt;' . format ( self . name ) class Email ( Base ): __tablename__ = 'emails' id = Column ( Integer , primary_key = True ) email = Column ( String ) user = Column ( Integer , ForeignKey ( 'users.id' )) def __init__ ( self , email , user ): self . email = email self . user = user def __repr__ ( self ): return '&lt;Email {}&gt;' . format ( self . email ) Base . metadata . create_all ( checkfirst = True ) ### create table from sqlalchemy.orm import * Session = sessionmaker ( bind = engine ) session = Session () admin = User ( 'admin' , 'admin' ) session . add ( admin ) session . add_all ([ User ( 'Mary' , 'secret' ), User ( 'John' , '123456' ), User ( 'Susan' , '123456' ), User ( 'Carl' , '123456' )]) session . add_all ([ Email ( 'mary@example.com' , 2 ), Email ( 'john@nowhere.net' , 3 ), Email ( 'john@example.org' , 3 ), Email ( 'carl@nospam.net' , 4 )]) session . commit () 然后用sqliteman观察数据库情况如下: session.query(User,Email) 返回的是笛卡尔积的形式: >>> session.query(User,Email).all() [(<User admin>, <Email mary@example.com>), (<User admin>, <Email john@nowhere.net>), (<User admin>, <Email john@example.org>), (<User admin>, <Email carl@nospam.net>), (<User Mary>, <Email mary@example.com>), (<User Mary>, <Email john@nowhere.net>), (<User Mary>, <Email john@example.org>), (<User Mary>, <Email carl@nospam.net>), (<User John>, <Email mary@example.com>), (<User John>, <Email john@nowhere.net>), (<User John>, <Email john@example.org>), (<User John>, <Email carl@nospam.net>), (<User Susan>, <Email mary@example.com>), (<User Susan>, <Email john@nowhere.net>), (<User Susan>, <Email john@example.org>), (<User Susan>, <Email carl@nospam.net>), (<User Carl>, <Email mary@example.com>), (<User Carl>, <Email john@nowhere.net>), (<User Carl>, <Email john@example.org>), (<User Carl>, <Email carl@nospam.net>)] 然后调用Query对象的 join 方法执行了内连接: >>> session.query(User,Email).join(Email).all() [(<User Mary>, <Email mary@example.com>), (<User John>, <Email john@nowhere.net>), (<User John>, <Email john@example.org>), (<User Susan>, <Email carl@nospam.net>)] >>> 从这里我们就可以看出一点one-to-many的影子了，注意John对应了两个Email对象。 然后我们稍加过滤条件: >>> session.query(User,Email).join(Email).filter(User.name == 'John').all() [(<User John>, <Email john@nowhere.net>), (<User John>, <Email john@example.org>)] 或者更明确的查询email: >>> session.query(User,Email.email).join(Email).filter(User.name == 'John').all() [(<User John>, 'john@nowhere.net'), (<User John>, 'john@example.org')] 此外还有这种形式: >>> session.query(Email,User).join(User).all() [(<Email mary@example.com>, <User Mary>), (<Email john@nowhere.net>, <User John>), (<Email john@example.org>, <User John>), (<Email carl@nospam.net>, <User Susan>)] >>> session.query(Email,User).join(User).filter(User.name == 'John').all() [(<Email john@nowhere.net>, <User John>), (<Email john@example.org>, <User John>)] 由于内连接虽然输出一行具体输出内容根据你的 select what 不同而不同，但具体行数和对于内容的描述上实际上就是一回事。上面是另外一种内连接顺序。然后我们利用这个反向查询某个邮箱的User也是可以的，这就是many-to-one数据模型了。 此外Query对象当然还有 outerjoin 方法，因为这里是要描述各关系模型，就略过了。下面介绍ORM层更实用的关系定义方法: import sqlalchemy from sqlalchemy import * from sqlalchemy.orm import * from sqlalchemy_utils import database_exists , create_database from sqlalchemy.ext.declarative import declarative_base engine = create_engine ( 'sqlite:///test.db' , echo = True ) if not database_exists ( engine . url ): print ( 'create new database' ) create_database ( engine . url ) metadata = MetaData ( bind = engine ) Base = declarative_base ( bind = engine ) class User ( Base ): __tablename__ = 'users' id = Column ( Integer , primary_key = True ) name = Column ( String ) password = Column ( String ) email = relationship ( \"Email\" , backref = backref ( 'user' )) def __init__ ( self , name , password ): self . name = name self . password = password def __repr__ ( self ): return '&lt;User {}&gt;' . format ( self . name ) class Email ( Base ): __tablename__ = 'emails' id = Column ( Integer , primary_key = True ) email = Column ( String ) user_id = Column ( Integer , ForeignKey ( 'users.id' )) def __init__ ( self , email , user_id ): self . email = email self . user_id = user_id def __repr__ ( self ): return '&lt;Email {}&gt;' . format ( self . email ) Base . metadata . create_all ( checkfirst = True ) ### create table Session = sessionmaker ( bind = engine ) session = Session () admin = User ( 'admin' , 'admin' ) session . add ( admin ) session . add_all ([ User ( 'Mary' , 'secret' ), User ( 'John' , '123456' ), User ( 'Susan' , '123456' ), User ( 'Carl' , '123456' )]) session . add_all ([ Email ( 'mary@example.com' , 2 ), Email ( 'john@nowhere.net' , 3 ), Email ( 'john@example.org' , 3 ), Email ( 'carl@nospam.net' , 4 )]) john = session . query ( User ) . filter ( User . name == 'John' ) . one () e1 = session . query ( Email ) . filter ( Email . email == 'john@example.org' ) . one () 然后我们就可以这样使用了: >>> john.email [<Email john@nowhere.net>, <Email john@example.org>] >>> e1.user <User John> 这确实很好用，而这里具体的模型就是one（user）对应many（email）的one-to-many模型。 下面重点介绍一下 relationship 这一行具体干了些什么: email = relationship(\"Email\",backref=backref('user')) 给User email属性，如上你可以这样 john.email 这样调用了。 指定Email对应（many）端（可以理解为这里针对Email执行了内连接操作，当然sqlalchemy具体如何处理的内部细节我还不清楚，但应该差不多就是这个过程。），这样的话具体User.email的值就通过某种机制大概如下所示 >>> session.query(User,Email).join(Email).filter(User.name == 'John').all() >>> [(<User John>, <Email john@nowhere.net>), (<User John>, <Email john@example.org>)] 这样获得了User John所回应的几个Email对象。具体过程不清楚，但用上面这样的语句来理解应该已经八九不离十了。 one-to-one模型 one-to-one模型就是one-to-many模型的特例，所以这里先讲了，和上面比较起来区别很小的。 class User ( Base ) : __tablename__ = 'users' id = Column ( Integer , primary_key = True ) name = Column ( String ) password = Column ( String ) email = relationship ( \"Email\" , backref = backref ( 'user' ), uselist = False ) def __init__ ( self , name , password ) : self . name = name self . password = password def __repr__ ( self ) : return '<User {}>' . format ( self . name ) class Email ( Base ) : __tablename__ = 'emails' id = Column ( Integer , primary_key = True ) email = Column ( String ) user_id = Column ( Integer , ForeignKey ( 'users.id' )) def __init__ ( self , email , user_id ) : self . email = email self . user_id = user_id def __repr__ ( self ) : return '<Email {}>' . format ( self . email ) 就加上了 uselist=False) 这一句，这样将直接返回某个Email对象。 many-to-one模型 many-to-one模型实际上和one-to-many模型就是一回事，而且如果我们如同上面的把 backref 设置好，针对多个Email对象实际上就可以直接找到某个User对象了，所以为了简单起见，我们可以就直接用one-to-many模型来理解之。 many-to-many模型 many-to-many模型有点复杂和难于理解，这是因为其还要求有一个额外的Table来管理原两个表格之间的元素的映射关系，幸好sqlalchemy官方文档专门有一小节对这个做出了一些说明。其描述的一个应用场景就是一篇博文有多个标签，然后一个标签有多篇博文（我们可以简单构建出这样一个功能，单击一个标签按钮，然后弹出所有有这些标签的文章出来）。一个博文有多个标签这很简单，一个one-to-many模型就解决了，大概就是 blog.tags ，就弹出一个list，里面装着一些标签对象。所以关键性的问题是如何实现出 tag.blogs ，就弹出一个list，里面装着一些博文对象。而在 这篇文章 的这幅图片中: ![img]({filename}/images/python/many_to_many.png \"\"many-to-many模型\") 于是现在的情况变成这样的了，blog one-to-many，但to many的是一个中间表格，而tag one-to-many，这个many也是一个中间表格。我们知道所谓的many一方存储着外键约束值，所以这个中间表格就两列，左列外键引用blog，右列外键引用tag，具体每一个映射关系都要写一条记录上去。不管怎么说，看下面这个例子吧: #!/usr/bin/env python3 # -*- coding: utf-8 -*- import sqlalchemy from sqlalchemy import * from sqlalchemy.orm import * from sqlalchemy_utils import database_exists , create_database from sqlalchemy.ext.declarative import declarative_base engine = create_engine ( 'sqlite:///test2.db' , echo = True ) if not database_exists ( engine . url ): print ( 'create new database' ) create_database ( engine . url ) metadata = MetaData ( bind = engine ) Base = declarative_base ( bind = engine ) blog_tags = Table ( 'blog_tags' , Base . metadata , Column ( 'blog_id' , Integer , ForeignKey ( 'blogs.id' )), Column ( 'tag_id' , Integer , ForeignKey ( 'tags.id' ))) class Blog ( Base ): __tablename__ = 'blogs' id = Column ( Integer , primary_key = True ) title = Column ( String ) body = Column ( String ) tags = relationship ( \"Tag\" , secondary = blog_tags , backref = backref ( 'blogs' )) def __init__ ( self , title , body ): self . title = title self . body = body def __repr__ ( self ): return '&lt;BLog {}&gt;' . format ( self . title ) class Tag ( Base ): __tablename__ = 'tags' id = Column ( Integer , primary_key = True ) tag = Column ( String ) def __init__ ( self , tag ): self . tag = tag def __repr__ ( self ): return '&lt;Tag {}&gt;' . format ( self . tag ) Base . metadata . create_all ( checkfirst = True ) ### create table Session = sessionmaker ( bind = engine ) session = Session () blog1 = Blog ( 'learning mysql' , 'how to learning mysql' ) tag1 = Tag ( 'python' ) blog2 = Blog ( 'learning sqlalchemy' , 'how to learning sqlalchemy' ) tag2 = Tag ( 'sql' ) tag3 = Tag ( 'sqlalchemy' ) tag4 = Tag ( 'mysql' ) blog1 . tags . append ( tag2 ) blog1 . tags . append ( tag4 ) blog2 . tags . append ( tag1 ) blog2 . tags . append ( tag2 ) blog2 . tags . append ( tag3 ) session . add_all ([ blog1 , blog2 , tag1 , tag2 , tag3 , tag4 ]) session . commit () 然后生成的表格如下所示: 然后执行结果如下: >>> blog1 <BLog learning mysql> >>> blog1.tags [<Tag sql>, <Tag mysql>] >>> blog2 <BLog learning sqlalchemy> >>> blog2.tags [<Tag python>, <Tag sql>, <Tag sqlalchemy>] >>> tag1 <Tag python> >>> tag1.blogs [<BLog learning sqlalchemy>] >>> tag2.blogs [<BLog learning mysql>, <BLog learning sqlalchemy>] 这里的关键就是建立这样一个中间表格: blog_tags = Table('blog_tags',Base.metadata, Column('blog_id',Integer,ForeignKey('blogs.id')), Column('tag_id',Integer,ForeignKey('tags.id'))) 然后建立一个这样的relationship: tags = relationship(\"Tag\",secondary=blog_tags,backref=backref('blogs')) 其中 secondary 参数指定你新建的那个中间表格，然后这个中间表格任何数据都不需要你操心了，只需要如上直接对 blog1.tags 这个属性（应该是一个列表）操作就行了。 具体利用ORM层来实现很简单，但我不敢想像sqlalchemy底层到底做了多少工作，不得不承认，这真是sqlalchemy Great的地方。然后值得一提的地方是原来的两个表格都没有外键约束了，可以说这个关系连接的工作完全抽象成为一个表格了。 总之，类似one-to-many一样，在one那里管理某个many方的表格，然后回引backref让many方那个对象也可以使用某个属性，然后定义一个中间表格就行了。many-to-many数据模型还是很有用的。 高级议题 cascade 定义基于关系的删除行为 items = relationship(\"Item\", cascade=\"all, delete-orphan\") 默认值是 save-update merge save-update 指一个对象 Session.add() 进入之后，和它有关的其他对象都应加进去。 merge 和Session.merge行为有关 此外用的最多的是 all 和 delete-orphan all 指 save-update merge refresh-expire expunge delete delete 和Session.delete行为有关，默认没加delete，则子对象只是parent_id那里只是赋空值，加了之后子对象也将删除。 delete-orphan 增加delete 的删除行为，不仅子对象将被删除，而且子对象也将执行Session delete标记，也就是后面的子子对象也将删除如何和delete一起配合使用的话。 自我引用表达树状结构 用一个SQL表格就可以表达出这样的树状层级结构的（这在很大程度上弥补了python语言对于这样的树状结构的应付能力不足）: root --+---> child1 +---> child2 --+--> subchild1 | +--> subchild2 +---> child3 具体写法如下所示: class Folder ( db . Model ): __tablename__ = 'folders' id = db . Column ( db . Integer , primary_key = True ) name = db . Column ( db . String ( 400 ), nullable = False ) description = db . Column ( db . String ( 800 )) parent_id = db . Column ( db . Integer , db . ForeignKey ( 'folders.id' )) children = db . relationship ( \"Folder\" , backref = db . backref ( 'parent' , remote_side = [ id ])) 具体就是认为 parent_id 是NULL的认为是最高级节点，然后每一个子节点都需要描述自己的 parent_id 是谁。这里的children是引用的自己，大体类似 one-to-many 的写法，也就是一个节点有多个子节点，这个前面将过来。唯一的区别就是设置 remote_side=[id] ，似乎这种写法也是可以的 remote_side=id ，意思是parent_id是本地local端的，然后id列是remote端的。更多信息请参看 官方文档的这里 。 面向ORM的内省机制 如果原数据库表格已经存在，在前面提及可以如下: users = Table('users',db,autoload=True) 来自动内省某个表格，而在面向ORM写法中，也是可以的。具体请参看 官方文档的这里 。其中最核心的代码是: engine = create_engine ( 'sqlite:///session.db' ) from sqlalchemy.ext.automap import automap_base AutoBase = automap_base ( bind = engine ) class OldTable ( AutoBase ): __tablename__ = NewTable . __tablename__ 但是具体schema并不是可以任意改动的，一般是继续扩展SQL数据库，然后搭建各种关系，实在有改动schema的必要，推荐采用migrate机制。下面是我写的一个简单的migrate脚本: #!/usr/bin/env python3 # -*- coding: utf-8 -*- from __future__ import print_function from __future__ import unicode_literals import sqlalchemy from sqlalchemy import * from sqlalchemy.orm import * from sqlalchemy_utils import database_exists , create_database from sqlalchemy.ext.automap import automap_base from sqlalchemy.ext.declarative import declarative_base new_engine = create_engine ( 'sqlite:///new_session.db' ) Base = declarative_base ( bind = new_engine ) old_engine = create_engine ( 'sqlite:///session.db' ) class User ( Base ): __tablename__ = 'user' id = Column ( Integer , primary_key = True ) username = Column ( String ( 80 ), unique = True ) password = Column ( String ( 80 )) def __init__ ( self , username , password , ** kwargs ): '''kwargs用于收集其他废参数''' self . username = username self . password = password def __repr__ ( self ): return '&lt;User {}&gt;' . format ( self . username ) def migrate_database ( NewTable , fromdb , todb ): if not database_exists ( fromdb . url ): raise Exception else : NewTable . __table__ . create ( checkfirst = True ) ### create table AutoBase = automap_base ( bind = fromdb ) class OldTable ( AutoBase ): __tablename__ = NewTable . __tablename__ AutoBase . prepare ( fromdb , reflect = True ) Session = sessionmaker ( bind = fromdb ) old_session = Session () Session = sessionmaker ( bind = todb ) new_session = Session () for q in old_session . query ( OldTable ) . all (): add_one = NewTable ( ** q . __dict__ ) new_session . add ( add_one ) new_session . commit () print ( 'done' ) if __name__ == '__main__' : migrate_database ( User , old_engine , new_engine ) 但是如果有多个表格加上关系之后情况变得更复杂了，上面的脚本 AutoBase.prepare(fromdb, reflect=True) 就是建立内省的模型和关系的，所以如果多个表格的话，这句话应该再放到后面些。然后后面添加新的数据因为sqlalchemy有自动处理相关关系对象的功能，这里倒问题不大，但也可能会有问题。也有其他一些模块是专门处理这个迁移数据库的问题的，但也绝不是一件轻松的事。总之SQL表格尽量设计好和可扩展性好，将自己的太多精力花在这上面是很浪费的。 面向ORM的数据继承机制 有时间补上。 额外的属性支持 所谓的额外的属性并不是基于SQL表格的某一列的属性，而是在ORM之上建立起来的额外的属性，其一般是基于SQL表格的某一列或某些列的，是ORM封装之上提供的更加便利的属性接口。 class EmailAddress ( Base ): __tablename__ = 'email_address' id = Column ( Integer , primary_key = True ) _email = Column ( \"email\" , String ) @hybrid_property def email ( self ): \"\"\"Return the value of _email up until the last twelve characters.\"\"\" return self . _email [: - 12 ] @email.setter def email ( self , email ): \"\"\"Set the value of _email, tacking on the twelve character value @example.com.\"\"\" self . _email = email + \"@example.com\" 某一列的额外的别名 这里所谓的某一列额外的别名指并没有创建额外的列，而是在ORM层针对某一列可以用额外的别名来做类似的操作。 from sqlalchemy.ext.declarative import synonym_for class MyClass ( Base ): __tablename__ = 'my_table' id = Column ( Integer , primary_key = True ) status = Column ( String ( 50 )) @synonym_for ( \"status\" ) @property def job_status ( self ): return \"Status: \" + self . status 其等于: class MyClass ( Base ): __tablename__ = 'my_table' id = Column ( Integer , primary_key = True ) status = Column ( String ( 50 )) @property def job_status ( self ): return \"Status: \" + self . status job_status = synonym ( \"status\" , descriptor = job_status ) 也就是具体该列在ORM层可以通过 status 或者 job_status 来操作。具体参考 这里 。 多列组合唯一性约束 请参看 这个网页 。 如果是ORM层，则是: class Location ( Base ) : __tablename__ = 'locations' id = Column ( Integer , primary_key = True ) customer_id = Column ( Integer , ForeignKey ( 'customers.customer_id' ), nullable = False ) location_code = Column ( Unicode ( 10 ), nullable = False ) __table_args__ = ( UniqueConstraint ( 'customer_id' , 'location_code' , name = '_customer_location_uc' ), ) 上面flask_sqlalchemy的话可以使用 db.UniqueConstraint 。 比如: __table_args__ = ( db.UniqueConstraint(\"main_directory\", \"sub_directory\",\"filename\", \"filext\"), ) 如果是Core层，则是: mytable = Table('mytable', meta, # ... Column('customer_id', Integer, ForeignKey('customers.customer_id')), Column('location_code', Unicode(10)), UniqueConstraint('customer_id', 'location_code', name='uix_1') ) ORM层的内省 Table层直接利用已经存在的数据库表格就是 reflect 的概念，因为ORM层多了很多额外的东西，其中最关键的是 relationship 的概念，而sqlalchemy的Automap这一章主要就是解决ORM层内省这个问题的。更详细的讨论请参看 官方文档 。 最基本的应用就是 建立一个 automap_base 对象: from sqlalchemy.ext.automap import automap_base Base = automap_base () 然后运行其 prepare 方法进行内省: Base.prepare(engine, reflect=True) 然后对应的sqlalchemy ORM层的那些类就可以如下获得了: User = Base.classes.user #或 Base.classes.get('user') 对于一般的属性引用，这是没有问题的。就是relationship可能还是有问题，那么我们可以预先定义一些属性，在 prepare 之前，那么预先定义的那些东西也将覆盖后面的自动reflect那部分定义，这可以起到矫正的作用。然后预先定义的那个类就是后面要使用的类了，就不要用 Base.classes.what 这种风格再获取了。 分表策略 当某个表格数据量过大的时候，那么就需要建立分表策略，具体是根据某个值取模来确定表名，先看例子吧，本例子参考了 这个网页 。 class NovelChapter ( object ): _mapper = {} @staticmethod def model ( book_id ): table_index = book_id % 100 class_name = 'NovelChapter_{0}' . format ( table_index ) ModelClass = NovelChapter . _mapper . get ( class_name , None ) if ModelClass is None : ModelClass = type ( class_name , ( Base ,), { '__module__' : __name__ , '__name__' : class_name , '__tablename__' : 'bh_novel_chapter_{0}' . format ( table_index ), 'id' : Column ( Integer , primary_key = True ), # 这里继续填写目标Model的字段定义 }) NovelChapter . _mapper [ class_name ] = ModelClass return ModelClass 上面提供了 .model 方法，核心就是利用type函数来生成一个类，也就是人们说的元类编程，具体参数如下： class = type ( classname , superclasses , attributedict ) 至于 _mapper 不过是本对象的一个类对象的缓存罢了，免得重复创建。 本例子中最关键的是 __tablename__ 的差异化定制。 附录 datetime数据类型 sqlalchemy中DateTime 数据类型的默认值可以跟着 datetime.datetime.utcnow 如下所示: created_date = Column(DateTime, default=datetime.datetime.utcnow) 参考网页 如何测试 参考网页 参考资料 essential sqlalchemy ; author: Rick copeland ;press:O'REILLY a step by step sqlalchemy tutorial sqlalchemy-essential-tutorial-and-techniques 面向django orm用户的sqlalchemy教程","tags":"数据库","url":"articles/sqlalchemy-module.html"},{"title":"alembic模块","text":"alembic模块有什么，如果读者熟悉django的话，那么可以将其类比为django里面的makemigrations和migrate相关的命令，简单来说，其管理数据库版本，进行数据库迁移工作。随着我们对于数据库操作的使用频繁，我相信读者就会开始慢慢感受到数据库迁移管理的必要性，实际上我相信读者会从一开始不愿意将这些东西加入代码版本控制，到后来开始主动要将其加入代码版本控制。 更多关于alembic的使用请参看官方文档，下面就一些基本的使用概念说一下。 基本使用 初始化alembic项目 alembic init alembic 然后当前目录下会多一个 alembic.ini 文件，这个配置文件里面有很多重要的配置，其中 sqlalchemy.url 是必配的。 根据models.py来 类似于django的 models.py 文件里面定义一些模型，我们利用sqlalchemy模块也可以定义一些模型文件，然后根据这个模型文件的定义，我们可以利用alembic来自动根据你的数据库的一些更改： alembic revision --autogenerate -m \"add_some_key\" 你需要定义好 alembic 文件下的 env.py 里面的 target_metadata 这个变量： from myapp.models import Base target_metadata = Base . metadata 然后其会自动生成一些版本控制的py文件，有 upgrade 和 downgrade 操作。 升级 alembic upgrade head # head是最新的版本，你也可以指定版本号 你也可以管理多个模型文件，多个表格对象，更多细节请参看官方文档，后面有时间本文也会详细补充之。 TODO。","tags":"数据库","url":"articles/alembic-module.html"},{"title":"pandas模块","text":"本文对pandas模块的一些核心概念进行说明。 基本入门 pandas最核心的两个数据结构就是 Series 类和 DataFrame 类。其中DataFrame可能会用的偏多一点，Series相当于一维情况下较简单的DataFrame，有的时候会用到。本文重点讨论DataFrame类。 DataFrame之所以很常用是因为这种数据结构太常见了，在excel中，在csv中，在sql中，等等来源的数据都可以汇总成为DataFrame数据结构，然后进行一些后面必要的数据处理，包括送入机器学习或者深度学习的模型中去。 pandas的io子模块写得很便捷，实际上我经常看到有些python程序员并不是在做数据处理，有时都会调用下pandas的io来做一些读写操作。 其大体有这些函数： read_csv to_csv read_json to_json read_html to_html read_excel to_excel read_sql to_sql 这其中，html的读写在网络抓取上有时可能有用，但不是很强大，还是推荐用专门的工具来做，sql的操作简单点可以用pandas那边的接口，但如果稍微复杂点还是推荐用sqlalchemy来做，这样写出来的代码可读性更好一些，orm层接口也更便捷写，代码里面全是一大堆sql语句，总不是太好的。 读txt文件 实际上我们可能更常遇到的是txt文件，还是用 read_csv 函数来读，只是需要做一些额外的配置，比如 这个问题 里面的例子是这样的： data = pd.read_csv('output_list.txt', sep=\" \", header=None) sep 设置读取csv时每个字段的分隔，默认是逗号，我遇到过是 \\t 作为分隔符的情况 header 默认取csv的第一行作为df数据的作为各个列的列名，如果设置了 names ，也就是手动指定列名，那么header相当于设置了None，如果header设置了None，将不会读取第一行作为列名。 read_csv 有很多选项，应付初步加载csv数据进入df内是绝对没问题的了。 读excel文件 利用pd.read_excel来读excel文件里面的数据，这个功能需要按照xlrdpython第三方模块支持。 直接加载python对象 这里支持的python对象有字典，或者已经是DataFrame了。 data = { 'state' : [ 'Ohio' , 'Ohio' , 'Ohio' , 'Nevada' , 'Nevada' , 'Nevada' ], 'year' : [ 2000 , 2001 , 2002 , 2001 , 2002 , 2003 ], 'pop' : [ 1.5 , 1.7 , 3.6 , 2.4 , 2.9 , 3.2 ]} frame = pd . DataFrame ( data ) frame 实际上有些情况，可能利用python的其他模块进行数据源加载，然后整合为python字典之类，再存入DataFrame中会更方便一些，这个要根据具体情况来了。 执行某个sql查询语句 使用pd.read_sql 来从某个sql查询语句中获取数据，其有第二个必填参数conn，可以利用sqlalchemy如下获得： import sqlalchemy data_source = sqlalchemy . create_engine ( 'sqlite:///mydata.sqlite' ) 上面的讨论我们可以汇总成为一个DataHandler对象，某些算法可以直接继承自这个类，直接加载数据，算法内部自动进行一些输出预处理，分类，测试，打标签，相应的算法计算等等。 import os import pandas as pd class MissingSQLStatementError ( Exception ): pass class DataHandler ( object ): \"\"\" read data source from - file - python DataFrame dict ... - sql \"\"\" def __init__ ( self , data_source = None , data_source_type = 'file' , sql_query = None , read_data_kwargs = None ): self . data_source = data_source self . read_data_kwargs = read_data_kwargs if read_data_kwargs is not None else {} self . df = None if data_source_type == 'file' : _ , ext = os . path . splitext ( self . data_source ) ext = ext . lower ()[ 1 :] if ext in [ 'csv' , 'txt' ]: self . df = pd . read_csv ( self . data_source , ** self . read_data_kwargs ) elif ext in [ 'xlsx' ]: # sheet_name self . df = pd . read_excel ( self . data_source , ** self . read_data_kwargs ) elif data_source_type == 'python' : self . df = pd . DataFrame ( self . data_source ) elif data_source_type == 'sql' : if sql_query is None : raise MissingSQLStatementError else : self . df = pd . read_sql ( sql_query , self . data_source , ** self . read_data_kwargs ) 新建一个随机数填充的DataFrame 新建一个DataFrame对象，随机数填充6行4列，列名分别为 ['a','b','c','d'] 。 df = pd.DataFrame(np.random.randn(6,4), columns=['a','b','c','d']) 在实践中行row的名字也是可以定制的，但我们先重点看一下列名这个概念。上面 columns 参数是设置列名的，而上面提到的通用数据源加载类中，并没有提到columns这个概念，是因为，你的DataFrame创建之后，列名是可以随时修改定制的： def set_columns ( self , columns ): self . df . columns = columns def rename_column ( self , origin_column_name , column_name ): \"\"\" 默认的column 可用 0 1 2 来引用 :param origin_column_name: :param column_name: :return: \"\"\" d = {} d [ origin_column_name ] = column_name self . df . rename ( columns = d , inplace = True ) def rename_columns ( self , columns ): self . df . rename ( columns = columns , inplace = True ) 首先我们看到第一个方法 set_columns ，其直接设置列名。 然后我们看到 rename_column 方法，如果你一开始不管列名这个问题，那么你新建的df默认的column就是 0,1,2... （是数值型不是字符串型），然后如上你可以定制那个列名，然后重命名之。 DataFrame转numpy数据类型 如上pandas有很好的io接口，获取数据之后，然后我们就有了相应的dataframe对象了，但有的时候我们进行计算是希望以ndarray（numpy）的形式来进行的（我们引入DataFrame是因为其有label等等让各个列数据有含义的功能，而到了实际底层算法，可能就是特征1234了，我们不再关心具体特征的名字，这个时候将某部分数据退化为numpy的ndarray数据类型就很必要了，一方面底层算法层不在意这些，第二就是numpy的ndarray对象可以和以前我们常见的那些算法包括新出来的tensorflow很容易对接起来。） 实际转变如下，非常简单： nd = df.values 参考了 这个网页 。 索引 按照列名选择 如果你已经定义列名了，那么选择一列按照列名是最直观的了： df[column_name] 返回的是Series对象，原DataFrame对象的index部分继续保留，也就是原来你的DataFrame的index是有名字的，那么可以继续使用这些索引名字。 这种引用也可以用于添加某一列或者删除某一列： del df[column_name] df[column_name] = series 按照列名选择多个列 df [[ 'a' , 'b' , 'c' ]] 这样得到的将是一个copy！ iloc方法 因为我是比较喜欢矩阵那种几行几列对于某一具体单元格的描述的，所以我很喜欢用 df.iloc[i][j] 这种形式来索引具体某个单元格的数据，就是i行j列，然后注意如果你的column是指定的数字，不是从0开始的，那么引用0就会出现索引异常【如果你的列名不是数字类型那么没有这个问题】。 唯一要注意的是就是和线性代数里面行列式下标有所不同，这里的索引都是从0开始计数的。 按照索引选择多个列 选择多个列【切片式】 df.iloc[:,0:2] 此外还有种写法【列举式】： df.iloc[:, [0,2]] DataFrame 对某一特征列进行某个运算 利用pandas的DataFrame的apply方法将某个函数应用到某个特征列，然后赋值给新的一列。 df [ 'commas' ] = df [ 'text' ] . apply ( lambda x : x . count ( ',' )) 搜索语句 DataFrame可以通过如下的搜索语句来对针对某些特征列的值进行判断，从而过滤掉某些行。 df[df['col1']==1] df[(df['col1']==1)|(df['col2']==1)] df[(df['col1']==0) & (df['col2']==0)] 按照行排序 df.sort_index(axis=1, ascending=False 按照列排序 df.sort_values(by='B') 绘图相关 绘制散点图 DataFrame.plot.scatter(x, y, s=None, c=None, **kwds) 根据数据记录 x 列（由x参数指定）和 y 列（由y参数指定）的一一对应的数据，来绘制散点图。","tags":"机器学习","url":"articles/pandasmo-kuai.html"},{"title":"airflow模块","text":"前言 airflow和luigi模块相比有以下优点： 通用的DAG概念来描述工作流，更专业点。 集成系统的crontab从而支持周期性任务，这样airflow就只能在linux系统下运行了。 图形界面很美观，功能更强大。 老实说我不喜欢crontab，如果只是简单调度，用apscheduler或者之类的工具简单写下就能集成到你的软件系统中去，而再复杂点的工作流，任务流程等等管理，都推荐使用airflow这样的框架来管理。 而至于说到大数据上的那些流式数据处理工具，实际上只有百分之几的公司因为业务需要必须上大数据，大部分公司是没必要上大数据的，因为大数据引入了太多的复杂度了，如果没有必要，而仅仅追求时髦去玩大数据，那显然是违背我们程序界公认的KISS原则的【Keep it simple and stupid.】。 安装airflow pip install apache-airflow 推荐起步 推荐 项目工作目录下 .env 文件下写上： export AIRFLOW_HOME=. 这样使用pipenv或者其他工具在当前目录激活工作环境的时候，也自动激活了airflow在当前目录下工作的配置。这样我们airflow相关works配置的相关代码都放在这里。 激活虚拟环境后，然后我们有如下操作： 初始化数据库 airflow initdb 启动webserver airflow webserver 使用其他数据库 刚开始玩下sqlite3数据库，后面正式运行还是要上正式的数据库，sqlalchemy支持的数据库airflow都支持。然后 sqlite3数据库是不支持 LocalExecutor 的，但是一开始搭建项目和大概项目百分之八九十代码还没确定下来和测试好，还是推荐使用sqlite3数据库。LocalExecutor相比较默认的 SequentialExecutor 其一次只能运行一个任务的，而LocalExecutor 是支持多进程运行任务的，这在后面还是很有用的。 所有的任务运行情况在数据库中都做好记录： pipenv install apache-airflow[postgres] 然后 airflow.cfg 哪里配好这些配置： sql_alchemy_conn 正式运行必做的配置 正式运行很多配置都要想好，配置好，其中有些配置是必做修改的： executor 正式运行，推荐切换为 LocalExecutor 这样支持多进程运行，分布式可以考虑 CeleryExecutor 请启用 airflow scheduler 好让你配置的任务能够自动周期运行。 请参看 airflow github仓库源码 的scripts文件夹的systemd或者upstart来配置你的服务脚本。 实际编写dags \"\"\" Code that goes along with the Airflow tutorial located at: https://github.com/airbnb/airflow/blob/master/airflow/example_dags/tutorial.py \"\"\" from airflow import DAG from airflow.operators.bash_operator import BashOperator from datetime import datetime , timedelta default_args = { 'owner' : 'airflow' , 'depends_on_past' : False , 'start_date' : datetime ( 2015 , 6 , 1 ), 'email' : [ 'airflow@example.com' ], 'email_on_failure' : False , 'email_on_retry' : False , 'retries' : 1 , 'retry_delay' : timedelta ( minutes = 5 ), # 'queue': 'bash_queue', # 'pool': 'backfill', # 'priority_weight': 10, # 'end_date': datetime(2016, 1, 1), } dag = DAG ( 'tutorial' , default_args = default_args ) # t1, t2 and t3 are examples of tasks created by instantiating operators t1 = BashOperator ( task_id = 'print_date' , bash_command = 'date' , dag = dag ) t2 = BashOperator ( task_id = 'sleep' , bash_command = 'sleep 5' , retries = 3 , dag = dag ) templated_command = \"\"\" { % f or i in range(5) %} echo \"{{ ds }}\" echo \"{{ macros.ds_add(ds, 7)}}\" echo \"{{ params.my_param }}\" { % e ndfor %} \"\"\" t3 = BashOperator ( task_id = 'templated' , bash_command = templated_command , params = { 'my_param' : 'Parameter I passed in' }, dag = dag ) t2 . set_upstream ( t1 ) t3 . set_upstream ( t1 ) 配置DAG的参数： owner 任务所有者 depends_on_past start_date email email_on_failure email_on_retry retries retry_delay BashOperator 调用bash命令： task_id 任务名字 bash_command 实际bash命令 我们看到它还支持jinja2的模板语法，当然最后输出和执行的还是bash命令 retries 重试次数 整个脚本实际上就是一个 DAG 结构配置描述文件，具体你的其他python代码写在其他地方都是可以的。我们看到这里： t2.set_upstream(t1) t3.set_upstream(t1) 每个任务在一个目标dag里面就是一个节点，这里设置节点t2的上一个节点是t1，t3的上一个节点是t1。 PythonOperator 我是个深度python爱好者，所以让我们进一步讨论下PythonOperator吧： from airflow.operators import PythonOperator 在这里重点强调一点： dags只是一些有关任务的配置文件，其他一切python函数之类的都移到其他地方，作为python模块引入，强烈推荐 pipenv 的 -e 风格。 task = PythonOperator( task_id = '这里是任务的名字' , python_callable = func, provide_context=True, dag = dag ) 你看到上面还有一个参数 provide_context=True ，默认是False，如果设置为True，那么你的函数将接受额外的两个参数： def func(ds, **kwargs): 其中ds是当前的执行时间，然后kwargs里面还有更多的参数，具体请参看官方文档的API的 Macors 哪里。 测试某个任务 airflow test dag_id task_id date 这样测试某个任务是不会在数据库中有记录的。 调度的时间控制 scheduler调度的时间控制说的非常清楚： 首先调度会从 start_date 开始计算，但是如果的dag设置了 catchup = False ，那么将只会从最新的dag间隔序列算起。 其次调度的间隔序列基于你设置的 schedule_interval 属性，将时间分成一个一个片段，目标dag被运行是在目标间隔时间过完之后。 clear某个dag 有的时候某个时间片的dag你想要再重新运行一次，那么你可以在UI上点击那个时间片的dag，然后点击 Clear 。 如果时间片较多的话可以运行命令： airflow clear -s start_dt -e end_dt dag_id backfill某个dag backfill和test的不同是运行状态会进入数据库并记录下来，有的时候你会更改临时更改 start_date ，这个时候一般之前的那些 scheduler不会照顾到，我重启来 scheduler也没有照顾到。通过backfill可以设定一个时间片段，然后执行目标dag airflow backfill dag_id -s start_dt -e end_dt 杂谈 关于大数据处理这块，之前写过一篇小文章谈过一点，一个核心的点就是 处理任务碎片化 ，airflow给我们提供的框架就是一种基于 时间片的过程 让大数据的 处理任务碎片化，从而每个处理小片段的状态都记录好然后可回溯。 比如说你的程序在某个时间片上抛出一个异常，有意或者无意的 raise Exception ，那么airflow记录的这个小处理片段就会标记为failed失败状态，而如果你点击它，然后clear清楚这个状态，那么这个任务在scheduler的调度下，过一会又会启动这个任务。 而你的任务运行没有问题的话，那么这个任务运行完之后就会标记 sucess ，那么这个小时间片下的数据以后就不会处理了。 一个好的建议是设置好数据库的 updated_time ，然后根据 updated_time 来切分数据时间片，当然某些情况写 插入时间的切分就够用了，必须要额外的记录更新时间。 参考资料 airflow官方文档 airflow tutorial etl with airflow","tags":"python好伙伴","url":"articles/airflow-module.html"},{"title":"sql数据库基础","text":"本小节主要结合sqlite3来简要说明sql数据库的一些基本理论知识。至于其他SQL数据库比如mysql，postgresql等具体实现的相关知识本文不会讨论。 基本术语 数据库（database）简单的理解就是一个文件柜。然后DBMS（database management system）是数据库管理系统。而所谓的 table 表你可以将其看作文件柜里的一个结构化了的文件。在表格里面的数据都是 按行存储 的，这个要在头脑中牢记。然后一行数据称之为一个 记录 。SQL（Structured Query Language）的意思是结构化查询语言。 sqlite3的安装就不罗嗦了，若有问题请从网络查阅之。 第一个例子 sqlite3和postgresql不同，其没有客户端/服务器的概念，就是直接的文件管理，sqlite3的数据库就是一个文件，然后如果连接到某个不存在的文件，就会自动创建对应的数据库文件。删除数据库当然就是删除数据库文件即可，这一块sqlite3很简单。 现在我们往这个数据库里面加入一点东西: wanze@wanze-ubuntu64:~/桌面$ sqlite3 mydb SQLite version 3.8.2 2013-12-06 14:53:30 Enter \".help\" for instructions Enter SQL statements terminated with a \";\" sqlite> create table mytable(id integer primary key, name text); sqlite> insert into mytable(id,name) values(1,\"Micheal\"); sqlite> select * from mytable; 1|Micheal sqlite> .table mytable sqlite> .database seq name file --- --------------- ---------------------------------------------------------- 0 main /home/wanze/桌面/mydb sqlite> .header on sqlite> select * from mytable; id|name 1|Micheal 这个例子首先连接之前创建的mydb数据库，然后通过CREATE TABLE语句来创建database数据库里面的一个表，接下来用INSERT INTO语句来给某个表插入一些数据，然后用SELECT语句来查看这些数据。 然后 .database 列出当前连接的数据库信息 .table 列出当前表格的信息 .header on 显示SQL表格头 .quit 退出sqlite3命令行 你还可以通过 .help 来查看更多相关信息。 CREATE TABLE 如下所示就是创建表格的命令格式: CREATE TABLE mytable( id INTEGER PRIMARY KEY, name TEXT); 这里的mytable就是具体创建的表格名字，然后接下来每一行定义了具体表格的某一个字段或者说某一列。第一个是字段的名字，第二个是字段的数据类型定义，后面可选的还可以跟上其他一些约束词。下面先就字段的数据类型做出一些说明。 字段数据类型 按照 sqlite3官方文档 的介绍 ，其就支持五种数据类型： NULL 空值 INTEGER 整型 REAL 浮点型 TEXT 字符串型 BLOB 字节流型 然后sqlite3关于你的类型声明字符串还建立了一套语法糖规则，具体语法糖规则如下所示: 如果没有类型声明，则视为none affinity; 如果在声明字符串中看到\"int\"（不区分大小写）这个子字符串，那么就视为integer affinity； 继续，接下来如果找到\"char\"或者\"clob\"或者\"text\"，则视为text affinity；所以varchar(80)会被简单视为text affinity; 继续，接下来如果找到\"blob\"，则视为blob，如果没数据类型声明，则视为none affinity; 继续，接下来如果找到\"real\"或者\"floa\"或者\"doub\"，则视为float affinity; 然后其他的都视为numeric affinity。 这里什么affinity是sqlite特有的概念，比如text affinity和前面的内置TEXT字符串型是不同的，其可能对应的是NULL，TEXT或BLOB。然后如果输入的数值则会自动将其转换成为字符串型。然后NUMERIC会自动分配成为INTEGER或REAL型，如果输入的字符串还负责转化。等等，总之我们在心里知道sqlite3在类型声明上是很灵活的就行了，具体使用还是严格按照自己喜欢的一套类型声明即可，比如这五个: null int float text blob 或者 null integer float varchar blob 等等。 字段约束词 请看下面这个例子: sqlite> CREATE TABLE products( ...> id int PRIMARY KEY, ...> name text NOT NULL, ...> quantity int NOT NULL DEFAULT 1, ...> price real NOT NULL); PRIMARY KEY 一个表格只能有一个PRIMARY KEY，被PRIMARY KEY约束的字段值必须唯一且不为空，从而使其能够成为本表格中各个记录的唯一标识。表格中可以有一个列或者几个列被选定为primary key。值得一提的是 integer primary key 自动有了自动分配的属性，也就是大家清楚的id那一列，即使不赋值，也会自动添加。 NOT NULL 约束该字段不可取空值，也就是该字段必须赋值的意思。 DEFAULT 指定该字段的默认值。 创建表格如果表格不存在 create table if not exists department (dept_id int primary key, name varchar not null ); 更改表格属性 sqlite3更改表格属性的功能是很有限的，就只有两个，一个是更改表格名字，还一个是新建一个字段。所以sqlite3主要还是靠CREATE TABLE的时候就把各个字段属性设置好（因为后面有迁移需要则需要单独写脚本）。具体使用就是使用 ALTER TABLE 语句，如下所示: ALTER TABLE tablename RENAME TO new_tablename; ALTER TABLE tablename ADD COLUMN column_name column_datatype; 删除表格 删除前请慎重。 DROP TABLE tablename; 插入记录 插入一条记录如前所示使用 INSERT INTO 语句，具体如下所示： INSERT INTO products (product_no, name, price) VALUES (1, 'Cheese', 9.99); 这是推荐的风格，后面圆括号跟着的列名不一定是按照顺序来，只是和后面的值一一对应，而且一条记录里面的所有列也不需要都列出来，不写的会按照默认值来处理。INSERT INTO语句是通用的。 如果只是需要简单插入新的一行的数据那么可以直接使用之前的insert into语句。 sqlite> insert into mytable(age) values(6); sqlite> select * from mytable; id name age ---------- ---------- ---------- 1 Alice 2 Betty 3 Cassie 4 Doris 5 Emily 6 Abby 7 Bella 8 6 不重复插入 只有主键值不重复才插入： insert or ignore into department (dept_id, name) values (1, 'Operations'); insert or ignore into department (dept_id, name) values (2, 'Loans'); insert or ignore into department (dept_id, name) values (3, 'Administration'); 更新记录 下面的语句用于更新某个特定的表格的数据： sqlite> update mytable set age=18 where id =1; sqlite> select * from mytable; id name age ---------- ---------- ---------- 1 Alice 18 2 Betty 3 Cassie 4 Doris 5 Emily 6 Abby 7 Bella 8 6 删除记录 DELETE FROM products WHERE price = 10; DELETE FROM products; 注意：第二个语句表内所有记录都将被删除！ DELETE FROM 语句是通用的。 查询记录 为了后面讲解方便，这里根据前面的第一个例子简单创建一个数据库，具体代码如下： ~$ sqlite3 test.db sqlite> CREATE TABLE mytable(id INTEGER PRIMARY KEY, name TEXT); sqlite> INSERT INTO mytable(id,name) values(1,'Alice'); sqlite> INSERT INTO mytable(id,name) values(2,'Betty'); sqlite> INSERT INTO mytable(id,name) values(3,'Cassie'); sqlite> INSERT INTO mytable(id,name) values(4,'Doris'); sqlite> INSERT INTO mytable(id,name) values(5,'Emily'); sqlite> .header on sqlite> .mode column sqlite> SELECT * FROM mytable; id name ---------- ---------- 1 Alice 2 Betty 3 Cassie 4 Doris 5 Emilyv 检索的基本语法如下： sqlite> SELECT id FROM mytable; 想要显示多个列则写上多个列名，列名之间用逗号隔开。检索所有列就是列名处用通配符 \\verb+*+ 来匹配所有列。 排序 用SELECT语句默认情况是没有排序的，如果需要排序则需要使用ORDER BY字句。现在又插入几个新名字： sqlite> INSERT INTO mytable(id,name) values(6,'Abby'); sqlite> INSERT INTO mytable(id,name) values(7,'Bella'); 如果我们需要输入结果按照name来排序则： sqlite> SELECT id,name FROM mytable ORDER BY name; id name ---------- ---------- 6 Abby 1 Alice 7 Bella 2 Betty 3 Cassie 4 Doris 5 Emily 按多个列排序 首先更新之前的表格的一些数据。 sqlite> ALTER TABLE mytable ADD COLUMN age int; sqlite> UPDATE mytable set age=18 WHERE id=1; sqlite> update mytable set age=20 where id =2; sqlite> update mytable set age=6 where id =3; sqlite> update mytable set age=25 where id =4; sqlite> update mytable set age=30 where id =5; sqlite> update mytable set age=66 where id =6; sqlite> update mytable set age=20 where id =7; sqlite> INSERT INTO mytable(id,name,age) values(8,'Alice',20); sqlite> SELECT * FROM mytable; id name age ---------- ---------- ---------- 1 Alice 18 2 Betty 20 3 Cassie 6 4 Doris 25 5 Emily 30 6 Abby 66 7 Bella 20 8 Alice 20 现在开始按多个列排序： sqlite> SELECT * FROM mytable ORDER BY name , age; id name age ---------- ---------- ---------- 6 Abby 66 1 Alice 18 8 Alice 20 7 Bella 20 2 Betty 20 3 Cassie 6 4 Doris 25 5 Emily 30 我们看到首先按name排序，如果名字相同则按age排序。 降序排序 ORDER BY字句默认排序是升序，如果想要其为降序则使用DESC关键词，如下所示: sqlite> SELECT * FROM mytable ORDER BY name , age DESC; id name age ---------- ---------- ---------- 6 Abby 66 8 Alice 20 1 Alice 18 7 Bella 20 2 Betty 20 3 Cassie 6 4 Doris 25 5 Emily 30 DESC关键词要放在想要降序排序的列的后面。如果想要多个列降序排序，则那些列 \\uline{都要加上DESC关键词} 。 过滤数据 SQL用WHERE字句来达到查询时过滤数据的功能，如果同时有WHERE字句和ORDER BY字句，则ORDER BY字句要放在后面。 一个简单的例子如下所示: sqlite> SELECT * FROM mytable WHERE age < 30; id name age ---------- ---------- ---------- 1 Alice 18 2 Betty 20 3 Cassie 6 4 Doris 25 7 Bella 20 8 Alice 20 如果后面的值是字符串则需要加上单引号，如: 'string' ，这些比较符号的含义都是一目了然的，如: = , <> , != , < , <= , !< , > , >= ,!> 。此外还有 BETWEEN 在两个值之间， IS NULL 判断是否为NULL值。 BETWEEN的使用如下: SELECT prod_name, prod_price FROM Products WHERE prod_price BETWEEN 5 AND 10; NULL 无值，它与字段包含0，空字符串等不同。 IS NULL 用法如下: SELECT prod_name FROM Products WHERE prod_price IS NULL; 外键引用 外键引用在sqlite3中必须加上这一行设置: PRAGMA foreign_keys = ON; 然后后面加入外键引用的语法和mysql有点类似，除了没有 constraint pk_product_type 这一描述外。然后sqlite3里面并没有 \\textbf{date} 类型的，其内部会自动处理为text,int或real等类型。但我们在声明的时候还是可以这样写的，然后值得一提的是sqlite3里面有一些date相关函数支持。 关于外键引用更多信息请参看 官方文档的这里 。 PRAGMA foreign_keys = ON; create table if not exists employee (emp_id int primary key, fname varchar not null, lname varchar not null, start_date date not null, end_date date, superior_emp_id int , dept_id int , title varchar, assigned_branch_id int , foreign key (superior_emp_id) references employee (emp_id), foreign key (dept_id) references department (dept_id), foreign key (assigned_branch_id) references branch (branch_id) ); SQL关系模型浅谈 内部联接 关于联接的抽象理论讨论还是很有必要的，这里我也谈论一些，但具体还是需要读者自己沉思。我们把一个SQL表格看作一个对应外部世界的模型，你可以将其看作柏拉图所谈论的理念。然后就作为外部世界各个模型来说，彼此之间有两种关系: 第一种是继承关系，第二种是组合关系。所谓继承关系是指对于每一个苹果实体来说，它有各种各样的属性，我们不可能将其装入一个数据库中，比如说本苹果实体的供应商信息，本苹果的重量颜色信息等等。更合理的做法是我们将描述苹果（或者所有产品）供应商信息单独放入一个模型，然后将描述苹果重量颜色等信息也单独放入一个模型，除此之外还有水果店信息等等。我们在实际处理的时候，常常各个衍生模型都有一个 parent_id 类似这样的字段属性来描述本衍生模型的该记录所对应的实际母体parent是谁，从而将多个衍生模型在一个实体对象上统一起来，从而形成表的联接。你可以看作表的联接的最终成果就是你心目中所想的那个超大型SQL表格，对应的是苹果这个模型，里面存放着所有一切和该苹果相关的属性信息。然后你用SELECT语句查一下即可。 第二个组合关系就是苹果由苹果皮和苹果肉等部分组成，各子部分和母体一样具有某种实体性，这个时候我们应该在苹果这个模型上加入如同 pingguopi_id 和 pingguorou_id 这样的字段属性，然后约定其他以 _id 结尾的都视作本苹果的组成部分，不是的都视作非其他组成部分独独为我苹果模型所有的属性。这个组合关系也很重要，在后面再谈及，下面主要谈论表格的联接，而这里表格的联接主要在描述模型之间的继承关系。 具体语法如下所示: SELECT name,price,weight FROM Supplier,Info WHERE Supplier.parent_id = Info.parent_id 这里我们约定Supplier和Info这两个衍生模型内存储的 parent_id 具体就应该Pingguo这个模型中的记录号。然后记录号相等就代表着同一个苹果实体。然后将这同一个苹果实体的name, price, weight 等属性列出来。 如果不使用WHERE字句会执行笛卡尔乘积操作，各个字段属性随意组合，没有任何现实意义了。 按照SQL规范，已经不推荐使用这样的WHERE字句表达了，上面的内部联接（INNER JOIN）语句更推荐的是写成这样的形式: SELECT name,price,weight FROM Supplier INNER JOIN Info ON Supplier.parent_id = Info.parent_id SQL语法里面有一个专门的术语来形容上面的这个SELECT语句，叫做内部联接。注意WHERE变成了ON，然后使用关键词INNER JOIN。SQL联接默认方式就是内部联接。 视图 视图是虚拟的表，其自身并不包含数据，更确切来说只是一种检索手段。视图可以嵌套视图，但需要注意的是视图因为不包含数据，依赖于检索，所以过多使用视图会很降低性能。","tags":"基础","url":"articles/sqlshu-ju-ku-ji-chu.html"},{"title":"makefile你不来一发吗","text":"简单了解下makefile makefile一般只能在Linux环境下运行，更确切来说要有gnu make这个工具去运行Makefile这个文件。 makefile里面内容其实很丰富的，实际上甚至有点过于复杂了。不过有的时候只是简单使用其基本功能还是很便利的。 project = helloworld cflags = -g -Wall ${ CCFLAGS } ${project} : ${ CC } helloworld.c -o $@ ${ cflags } clean : rm ${ project } install : cp ${ project } /usr/local/bin uninstall : rm /usr/local/bin/ ${ project } .PHONY : clean uninstall install 为了便于理解，上面这个makefile我有意采用了一种和bash shell接近的风格。前面 project= 就是一个定义变量的行为。这个project变量就是本脚本的名字。然后makefile下面的主体部分格式如下: target : prerequisites the command 具体意思就是要生成target这个文件，首先要确保prerequisites这些依赖文件都在而且是最新的，不在或者不是最新的那么查找对应的目标生成规则继续生成。而对于这个target的生成就是执行下面的bash命令。下面是关于上面例子的一些讲解信息: 特别要强调，命令前面请用 Tab键 隔开 。 关于变量的使用读者看到上面的例子，我有意采用了类似bash脚本的语法。这么写也是支持的。 $@ 这个特殊的符号并不是什么神秘东西，其意思就是当前目标的文件名，上面例子中当前目标是 ${target} ，也就是helloworld，所以这里 $@ 就是 \"helloworld\" 。 .PHONY 这后面跟着一些生成目标，具体意思就是这些生成目标是伪目标，或者说其并没有生成文件，只是执行了某个命令。 我们注意到上面的 ${CC} 和 ${CCFLAGS} 并没有为用户定义，其是make命令的一些默认变量。 $(CC) 就是调用系统默认的c编译器，一般为gcc。 make 命令不输入任何子命令时，默认执行输出第一个目标命令，一般是本项目目标。 makefile的每个命令都有一个独立的终端，也就是不同的终端不共享变量，所以最好多个命令连接成为一个命令，这样好在一个shell里面执行和共享变量。（export是可以共享的？） makefile扫描两边，第一遍变量替换，第二遍依赖关系。变量声明最好跟着对应的规则，还有要保证不能被后面的变量声明改变。 强制某个目标更新 参考了 这个网页 。 大致如下面所示，设置一个 FORCE 目标，凡是依赖FORCE目标的都将强制没一次都再更新一遍，而原因就是因为这个FORCE目标不不依赖任何目标，这样makefile认为目标不存在，而每次都会再更新生成一遍。 ${project}.org : FORCE python3 make_ ${ project } org.py FORCE :","tags":"linux","url":"articles/makefileni-bu-lai-yi-fa-ma.html"},{"title":"python2和python3的兼容性","text":"2to3内置模块 python有个 2to3 内置模块可以自动进行python2脚本到python3脚本的移植工作，不过我感觉最好是不要过分依赖这个工具，这只是适合初学者的。因为python2和python3很多地方不一样了。如果你对这个模块有很深的了解，可能自己手工进行修改会更合适一些（其中可能会涉及到新的编写思路）。具体模块的使用请参看官方文档。 // 和 / 在python2中，两个整数相除会返回一个整数，也就是python3的 // 。 >>> 5/2 2 兼容方案 在文件头上加上一行： from __future__ import division 这样就都是使用python3的语法规则，即: / 表示常规除法， // 表示整除——返回商。 print函数 这是最常见的错误了，推荐第一步就在文档里面进行find print这个字符串操作，然后将所有： print ... 这样的形式都换成： print(...) 这是目前python2和python3都兼容的形式了，所以没有什么好犹豫的，大胆的修改就是了。 其中python2 print 1, 2, 似乎还有点小复杂，简单的理解就是对应到python3的 print(1, 2, end=' ') 然后python2支持这样的重定向语法 print >>sys.stderr, 1, 2, 3 其对应python3的就是file选项： print(1, 2, 3, file=sys.stderr) 兼容性方案 目前推荐在模块最上面写上: from __future__ import print_function 然后使用python3的语法来使用print函数。这样python2里面也能正常运行。 unicode字符串问题 首先说一下Unicode字符串问题的历史由来，因为python2诞生的比Unicode字符串（宽字符解决编码方案的统称）要早，所以python2早期是基于ASCII编码的，ASCII编码是8位值编码，那个时候比较单纯，python2就是一个str类型既表示8位字符又表示二进制数据。后来python2才引入unicode字符类型，其就是对应的宽字符文本。 后来python2为了兼容python3也引入了bytes类似和bytearray类型。但只是为了兼容性考虑。目前python2和python3代码兼容上最大的一个坑就是python2的str类型是8位文本和二进制数据的统称，也就是在某些默认是ASCII编码的情况下，可能不知不觉，比如系统的默认编码默认是ASCII，然后这些8位值数据你不知道其到底是不是文本。（python3的str是默认的UTF-8编码，其既支持8位文本也支持宽字符文本，这样其就真的是文本的含义了。） 首先我们要看到大家都同意python3的新分类是很好的： str 文本， bytes 字节流。后面的编程都应该一律采用这种思维。 然后我们现在写python2代码都推荐在文件头上写上： from __future__ import unicode_literals 如上面写了之后python2中随便定义的字符串 >>>\"test\" u'test' 返回的将是unicode类型，可以对应于python3的str类型。程序员在 （\\cite{高质量python代码}） 编码时应该更多地考虑业务逻辑而不是考虑具体字符是什么编码什么二进制形式存放的。 简单起见字符串都只是简单认为是字符串（或者说文本），然后程序员一般也不会考虑编码问题，只是确实到了某个点，需要直接操作字符的bytes形式，确实有需要，然后再考虑进行转换操作。 具体的转换： # python2 def to_unicode(unicode_or_str): if isinstance(unicode_or_str, str): value = unicode_or_str.decode('utf-8') else: value = unicode_or_str return value def to_str(unicode_or_str): if isinstance(unicode_or_str, unicode): value = unicode_or_str.encode('utf-8') else: value = unicode_or_str return value 而对于那些历史遗留的代码，非常遗憾，考虑到python2和python3在这一块如此巨大的裂痕，更加详细的阅读和修改甚至重写代码恐怕是避免不了的了。 input和raw_input 在python2中的raw_input函数对应的就是python3的input函数。然后python2还有一个input函数，具体在python3中对应的是eval(input())，这个函数推荐被废弃掉。 兼容方案 from builtins import input name = input ( 'What is your name? ' ) 所有的类都继承自object python3中所有的类都默认是object的子类。 兼容方案 兼容方案是引入从builtns引入object，然后都明确指明继承自object。 from builtins import object class Upper ( object ): def __init__ ( self , iterable ): self . _iter = iter ( iterable ) def __next__ ( self ): # Py3-style iterator interface return next ( self . _iter ) . upper () # builtin next() function calls def __iter__ ( self ): return self execfile函数 在python2中execfile是个内置函数，可以直接运行，用来执行某个python脚本。 execfile(join(dirname(__file__), 'openerp', 'release.py')) # Load release variables lib_name = 'openerp' exec(compile(open(join(dirname(__file__), 'openerp', 'release.py')).read(), join(dirname(__file__), 'openerp', 'release.py'), 'exec')) lib_name = 'openerp' 兼容方案 exec(compile(open('myfile.py').read())) <>替换为 != 不等于号<>被废弃了，推荐用!=，这样python2和python3都是兼容的。 模块包的导入问题 python2到python3模块包的结构很多地方也发生了变动，实际上即使是python3，随着版本升级，内置模块包内部也在发生着变动，比如新加入的函数类等等。这是不可避免的，同时python2一些模块包已经被官方提醒要被废弃了，这也是值得引起我们的注意的。这一块，当然还是自己平时多阅读官方文档（通常这些变动官方文档都会有所说明的）。","tags":"python语言","url":"articles/python2he-python3de-jian-rong-xing.html"},{"title":"计算机网络基础","text":"先找到目标计算机 首先让我们简单回顾一下在学习Linux系统时接触到的网络知识，Internet源起于美国的ARPAnet项目，其有个基本的知识点就是 只有两个位于同一网域的计算机才可以直接进行文件交互 。那么读者就会问了什么是网域，所谓网域说白了就是把一个大的互联网分割分割再分割的一个产物。而分割手段就是 子网掩码 ，怎么判断两个计算机是同一网域呢？就是把这个计算机的IP地址和子网掩码相加，结果相同我们就说他们位于同一网域。 现在我们说一台计算机要对另外一台计算机发送一个信息包，首先这个计算机会分析自己的路由表，如果发现目标机器和自己在同一网域，那么就直接发送信息了。如果不在同一网域，那么这个计算机就要根据路由表将这个信息包发送给默认的路由器（gateway）。路由器或者交换机在网络世界里扮演着一个特殊的角色，那就是它们不具体处理数据，只负责数据分发。具体过程实际上就是上面描述的过程的不断迭代重复，也就是路由器也有一个自己的路由表，然后看看目标机器是不是和自己在同一网域等等，如果不则将信息包发送给另外一个默认的路由器或交换机之类的等等，直到最终目标机器和自己位于同一网域，然后将信息包发送给目标机器。 通信协议 计算机找到目标计算机了就可以开口说话了，但是不能随便说话也就是发送一堆乱码过去，那样目标机器是看不懂的。这个时候我们就需要制定计算机之间的通信协议。那么什么是计算机之间的通信协议？简单来说就好比两个人之间对话的某种规范，或者两个国家进行外交协商的某种特定交互流程。比如一个人对另外一个人说\"你好\"，另外一个人收到则回应\"你好\"，表明我已经收到了，然后第一个如果收到这个回应，则表明协议牵手成功，然后继续进行其他会话，比如\"今天星期几\"，发送过去，然后另外一个人收到之后回应\"今天星期一\"……就是类似这样的交互方式。有的连接是双向的，连接为持续存在，一般最后需要发送goodbye来关闭协议，而有的协议是单向的，也叫做无状态协议，比如HTTP协议，信息发送了完了连接就算自动关闭了。 上面的描述还遗漏了一点那就是不仅交互的流程上有规范，而且发送的信息包的格式也是有规范的，或者说有一定的格式的。 应用程序体系结构 网络世界里目前有两种应用程序体系结构：一种是client/server体系结构；另一种peer to peer，也就是P2P体系结构。 选择客户机/服务器体系结构，你的应用程序会有两个命令两种工作模式，一个启动本地客户机进程，一个启动服务器进程，很多应用程序都是这样的。P2P目前主要是BitTorrent下载软件为大家熟知。 下面主要讨论应用最普遍的client/server体系结构。 什么是套接字 程序之间具体是进程和进程之间进行通信，一般是一个是客户机进程，另一个是服务器进程，这两个进程之间进行通信。前面谈到的P2P体系结构，也可以这样理解，只是具体某一个进程其既可以是客户机也可以是服务器。我们有如下定义: 在给定的一对进程之间进行通信，我们称发起通信的进程为客户机进程，在会话中等待联系的进程是服务器进程。（也可以理解为被动等待通信信号） 两个进程之间具体是用 \\textbf{套接字} (socket)来发送和接受报文的。套接字是一个主机内应用层和传输层之间的接口，应用程序开发者可以控制套接字在应用层面上的所有东西，而对于套接字在传输层可以控制的东西非常有限，就仅限于: 选择传输层协议和设定几个传输层参数（如最大缓存最大报文长度等）。 目前TCP/IP网络上的应用就使用了两个传输协议: UDP协议和TCP协议。软件开发者在创建新的应用程序时，首先应该决定传输层是用TCP协议还是UDP协议。 TCP协议 TCP协议是面向连接的和可靠数据传输的。所谓的面向连接是指客户机和服务器之间一开始要进行握手过程好建立TCP连接，然后结束之后需要拆除连接。所谓的可靠数据传输是指TCP协议保证数据是无差错的按顺序交付发送的。此外TCP协议还具有拥塞控制机制。SMTP（电子邮件）协议，Telnet协议，HTTP协议，FTP协议多用TCP协议实现。 UDP协议 UDP是一种不提供不必要服务的轻量级传输层协议，它仅提供最小的服务。UDP是无连接的，两个进程之间没有握手过程。UDP协议并不保证报文能够被接受进程收到，也不保证数据是按顺序到达的。UDP也没有拥塞控制机制。因特网电话和流媒体多用UDP协议实现。 HTTP协议 HTTP（HyperText Transfer Protocol）超文本传输协议是网络世界一个为大家熟知的协议，其属于应用层，为应用层协议。HTTP定义了两个端系统，一个客户机，一个服务器，两个之间如何进行报文交换和这些报文的格式。Web浏览器就是HTTP协议的客户机端，Web服务器就是HTTP协议的服务器端。 HTTP协议使用TCP协议作为其传输层的协议，当用户请求一个Web页面时，浏览器或其他HTTP客户机将首先和服务器建立起一个TCP连接，等连接建立之后，浏览器和服务器就可以通过套接字来交流了。然后客户机经由其套接字向服务器发送一个HTTP请求报文，随后服务器接受到了这个HTTP请求报文，其内部经过某些处理，比如找到html文件即其他资源文件或者其他数据运算之后，也经由套接字回应了一个HTTP响应报文给客户机。然后HTTP服务器进程通知TCP可以断开TCP连接了，然后TCP那边大概等到客户机完整接受这个HTTP响应报文之后，TCP连接就真正断开了。HTTP客户机那边接受到HTTP响应报文，TCP连接断开了，这一次HTTP请求算是完了。 然后这个Web页面还包含有其他图片引用或者javascript引用，每一个引用浏览器客户机那边都将产生一个HTTP请求，类似上面的继续处理。因此基于HTTP协议的TCP协议只进行了一个请求报文和一个响应报文的传输，一个Web页面，可能要发送十几个HTTP请求，那么就要建立十几个TCP连接。（整个过程大抵如此，而现在客户机一般都会打开5-10个并行的TCP连接。） 上面描述的是HTTP协议初始版本的情况，自HTTP/ 1.1起HTTP协议加入了持久连接特性，而且默认就采用持久连接的方式。持久连接可以减少新开TCP连接的消耗，现在HTTP不会每送一个报文就请求断开TCP连接了，而是如果该连接长时间未使用，HTTP服务器才关闭该连接。 然后我们说HTTP协议本身是无状态的，因为HTTP服务器并没有记忆关于客户机的任何信息，但现在有cookie和session，cookie是客户机保存状态信息，session是服务器保存状态信息，这个后面再说。 HTTP报文格式 HTTP报文就分为两种，一种是请求报文，一种是响应报文。 比如下面就是一个HTTP请求 GET / HTTP / 1 . 1 Host : www . google . com User-Agent : Mozilla / 5 . 0 ( X11 ; Ubuntu ; Linux x86_64 ; rv : 40 . 0 ) Gecko / 20100101 Firefox / 40 . 0 Accept : text / html , application / xhtml + xml , application / xml ; q = 0 . 9 ,*/*; q = 0 . 8 Accept-Language : zh-CN , zh ; q = 0 . 8 , en-US ; q = 0 . 5 , en ; q = 0 . 3 Accept-Encoding : gzip , deflate Connection : keep-alive 第一个是方法字段，HTTP有GET、POST、PUT、DELETE等方法，然后HOST是请求的主机名字，然后User-Agent是用户使用的浏览器，然后Connection这里设置为keep-alive正是前面说的建立持久连接。 然后响应如下: HTTP / 1 . 1 200 OK Cache-Control : private Content-Length : 231 Content-Type : text / html ; charset = UTF-8 Date : Wed , 02 Sep 2015 08 : 47 : 52 GMT Location : https :// www . google . com /? gws_rd = ssl ......... 这个响应的那个200就是大家熟知的HTTP响应状态码。关于HTTP协议更多内容将在html5学习中讨论。 cookie技术 cookie的作用原理如下，用户首先登录一个网站，然后该网站的服务器返回一个HTTP响应，其中有一行 Set-cookie: whatwhatwhat 这个HTTP响应被用户的浏览器接受之后，其将在特定的cookie文件中添加一行，其中有该服务器的名字（HOST）和这个Set-cookie还有后面的标识码信息。然后以后浏览器再访问这个网站的时候，其将自动在HTTP请求上加上这么一行: Cookie: whatwhatwhat 那个网站的服务器看到HTTP请求的这么一行之后，就说，唉，张三又回来了。然后之后该用户在这个网站上的操作记录都被这个网站的数据库统一管理起来了，什么张三点击了那个页面，什么张三买了什么东西等等。 web缓存器 web缓存器又叫代理服务器，其能够代表初始服务器来满足用户的HTTP请求。其过程如下: 首先是用户那边的浏览器与we缓存器建立TCP连接，然后对其发送一个HTTP请求。 web缓存器会检查自己本地是否缓存了目标对象的备份，如果有，则web缓存器用HTTP响应回应用户浏览器。 如果web缓存器没有该目标对象的缓存，则其就会向初始服务器打开一个TCP连接，发送一个HTTP请求，获得该目标对象，并将该对象缓存在自己本地，当然还有向用户浏览器回应一个HTTP响应好把新获得的对象也发给用户浏览器。 web缓存器本地虽然可能有目标对象缓存了，但可能这个缓存过于陈旧了。缓存器必须证实本地的缓存内容是最新的，其利用的是HTTP协议的 \\verb+If-modified-since+ 这一行。web缓存器将发送一个非常短小的HTTP请求，其中就包含这样一行: If-modified-sine: Wed, 4 Jul 2007 09:23:24 这个日期是web缓存器存储上一次该缓存对象是获得的HTTP响应头上就有的 Last-Modified 这一行。 然后Web服务器会回应一个很短小的HTTP响应，就是最简短的HTTP状态码和其他几个必要的信息，比如304,Not Modified。 DNS协议 DNS协议虽然和计算机网络最底层的找到目标计算机操作相关，但其是属于应用层的。 当你输入域名 www.example.com 的时候，计算机是不认识的，计算机首先要将其转化成为IP地址才行，那么计算机怎么转化了，在互联网世界，有很多的DNS服务器，计算机通过查询DNS服务器，然后就获取了这个域名对应的IP地址。","tags":"基础","url":"articles/ji-suan-ji-wang-luo-ji-chu.html"},{"title":"python语言学习之-学习资料整理","text":"python入门教程，python官网上的tutorial。原作者：Guido van Rossum Fred L. Drake ；中文翻译：刘鑫等；版本：2013-10-28；pdf下载链接： python入门教程 。 learning python，主要python语言参考，我主要参看了python学习手册（第四版）。原作者：Mark Lutz，中文翻译：李军，刘红伟等。 programming python，作者Mark Lutz对python编程的进阶讨论；版本：第四版。 python 官网上的资料 。 第三方模块参考手册，如numpy, scipy, matplotlib等等第三方模块官网上发布的官方参考手册。 dive into python3 english version , 这是 中文版 。 A Guide to Python's Magic Methods，作者：Rafe Kettler ,版本：2014-01-04， Github 地址 . Foundations of Python Network Programming ，python网络编程基础，[美] John Goerzen 著，莫迟等译 。 这是 中文在线阅读网页 ，这是 english version 。 Unix网络编程卷1: 套接字联网API , Author: W. R. Stevens , Bill Fenner 等著 , version: 第三版 python 3 cookbook Effective Python 编写高质量Python代码的59个有效方法，[美] Brett Slatkin 著， 爱飞翔译。 计算机网络自顶向下方法 , Author: James F. Kurose , Keith W. Ross ,陈鸣译 。这本书作为入门了解有关计算机网络相关知识还是很不错的。 SQL必知必会 [英] Ben Forta 著， 钟鸣 刘晓霞等译。","tags":"python语言","url":"articles/pythonyu-yan-xue-xi-zhi-xue-xi-zi-liao-zheng-li.html"},{"title":"docker入门","text":"前言 关于docker是什么请参看 这个网页 ，说docker将改变软件生态确实是不为过的。老实说在接触docker之后感觉之前学到的很多东西，比如linux系统相关的一些，ansible等等部署工具相关的一些，virtualbox和 vagrant相关的一些，都在慢慢过时和淘汰了。当然那些工具还是很有用的，说他们被淘汰了是有点过了，更确切来说，对于一般玩家来说，可以节省更多的精力和时间，而不需要折腾那些工具那些配置学习折腾个老半天了。 That‘s why we love docker. 但实际上docker带来的变化远远不止于只是一个可以节省开发者做某些事情的时间的一个不错的工具那么简单，其伴随着SPPS，软件即服务，更确切来说整个互联网的大背景下，应运而生的。与之相应的，开发者们顺应这个时代，在编码，软件应用的很多方面，都需要做出改变。请读者进一步阅读 https://12factor.net/zh_cn/ 里面的讨论。 实际上之前我折腾vagrant的时候，就很是认同这个理念： 那就是开发，测试，生产一致的环境，彻底解决，在这里可以运行，在这里就不行了的问题。而vagrant的控制virtualbox创建虚拟机的方式，在我看来显得略微笨拙了点，配置的繁琐，似乎并没有很好地解决这个问题；而docker除了很好地解决了上述问题之外，他的虚拟化方案更轻量级，更接近原生。 docker包括三个核心概念： 镜像image，容器container，仓库 image 镜像 一个特殊的文件系统，和一般操作系统相比做了很多精简。 container 容器，可以看做镜像生成的一个实例 安装 windows下安装如果你的操作系统不是专业版或者企业版，那么只能用 docker tool box 来安装。然后记得把 window10 的开发者模式打开。 如果你的windows10事企业版或者专业版，我没试过，我想按照官网哪个，直接就能安装成功吧。 kitematic 是docker 镜像的管理工具，推荐使用，这个工具的介绍就不做过多说明了，下面主要也是就一些命令行用法做一些说明。 centos安装 yum install -y yum-utils yum install -y device-mapper-persistent-data yum install -y lvm2 yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo yum install docker-ce 镜像 从网上拉取镜像 docker pull 罗列镜像 docker image ls 删除镜像 docker image rm <id> 自建镜像 docker build -t image_name where_foler 容器 罗列容器 docker container ls 删除容器 docker container rm <id> 启动容器 docker container start <id> 重启容器 docker container restart <id> 运行镜像 docker run -p 4000:80 helloworld 具体有很多参数： -p 如上面所示，前面的宿主机的端口号，后面是容器内app的端口号。 只要docker 服务还在，哪些docker运行的容器都会在后台运行的额， 进入docker shell docker exec -it \"id of running container\" bash sqlite数据库丢失问题 docker容器删除了，再从镜像启动一个容器，里面的sqlite或者说其他文件存储的数据都将丢失，可以在镜像制作的时候设置valume，但我总感觉这种做法不太优雅。 Dockerfile 的编写 Dockerfile 文件就是定义了具体你的镜像从继承何者镜像，到你做了哪些修改等等的相关配置文件。 ​ 参考资料 http://www.ruanyifeng.com/blog/2018/02/docker-tutorial.html https://docker_practice.gitee.io https://docs.docker.com/","tags":"tools","url":"articles/docker.html"},{"title":"python-dateutil模块","text":"一般能够使用python的内置模块datetime解决的问题或者简单写几个辅助函数就能解决的问题是没必要上 python-dateutil 模块的，但有的时候某些问题，上python-dateutil模块会非常的方便，然后我发现好多有名的模块都默认安装这个模块了。 relativedelta 某些问题，用datetime的replace将某个值设为0或者什么值，或者用timedelta来减去什么值，大部分都能解决，但有的时候，比如跨月份涉及到要考虑天数不等或者其他等等问题，用relativedelta还是很方便的。 总的说来涉及到datetime的某个跨度的计算问题，还是推荐使用 relativedelta函数。 from dateutil.relativedelta import relativedelta now = datetime . utcnow () sdt = now - relativedelta ( months = months ) rrule 虽然没有lrule，但根据上面的relativedelta配置的起始时间，然后指定结束时间，通过rrule函数来生成一个时间区间，有时是很方便的。 from dateutil.rrule import rrule , MONTHLY list ( rrule ( freq = MONTHLY , dtstart = sdt , until = now )) parse dateutil 的 parse函数根据输入日期时间字符串来获得datetime object还是很方便的，不过在某些简单的情况下，可能使用datetime的 strftime 函数就够用了。","tags":"python好伙伴","url":"articles/python-dateutilmo-kuai.html"},{"title":"python爬虫之-表单和登陆等相关","text":"表单简单来说就是一个前端友好的界面，其实质就是发送了 一个 POST 请求。 关键是要理解前端的表单界面，具体POST了哪些参量。 <form method= \"POST\" action= \"???\" <input type= ... name= \"firstname\" ... > <input type ... submit </form > input 的 name 就是具体 POST 的参量，然后就是action那边就是你要 POST 的目的地。 类似的表单还有很多其他元素，比如checkbox之类的，其都不过是为了让用户快速地设置某个参量罢了。 登录的cookies问题 因为http无状态，所以有cookies 和 session ，服务端数据库记录session，cookies就是客户端。爬虫要正常登录，记得保留好登录成功之后的cookies。 多次请求的时候，用requests的cookies保存和设置就不好用了。记得使用requests的session机制。 import requests session = requests . Session () data = { 'username' : 'user' , 'password' : '123456' } s = session . post ( 'login.html' , data ) ##### 继续用这个session来请求，没有任何问题 s . get ( 'profile.html' )","tags":"python爬虫","url":"articles/pythonpa-chong-zhi-biao-dan-he-deng-lu-deng-xiang-guan.html"},{"title":"python爬虫之-防止被封的策略","text":"防止被封的首要策略就是尽量的为别人的服务器多考虑下，让自己写的爬虫少请求，每次请求都是有效的核心请求获取最核心的数据，不管是刷页面还是刷ajax，多次请求之间应该设置一个停顿时间。 time.sleep(3) 在上面的首要原则的基础上，下面介绍的很多实战技巧，其实都符合一个大的原则：尽可能地让你的爬虫和人浏览网页没有区别。 http请求头调整 user-agent 设置，而且时不时的切换下。 虽然目前还没有遇到，不过我推测可能 Referrer 这个header在某些场景下是有些文章的。 还有 Accept-Language 也可能有用。 Cookies 有些情况下cookies的正常获取需要javascript的支持。cookies总的原则是第一次请求获取到cookies，然后后面的很多次请求都使用这个cookies即可。 不过反爬虫cookies一般都会有个时间限制，一个简单的做法就是这边也设置个时间，定时获取最新的cookies或者，一定请求量之后再获取一个新的cookies。 具体使用 scrapy-splash 了解下。 表单陷阱 有的表单里面有： <input type=\"hidden\" ... 我们要记住人如果在页面上点击，这个没有显示的字段的值也会一并送过去，而他们服务器那边会根据这个值可能是个加密的某个值来判断这个请求是人点的还是爬虫行为。 最好的策略是先把整个表单内容爬过来，收集好之后再发送表单请求。 和上面的情况相反，还有一种情况，页面表单发送可能有特别的处理，某些表单字段，不管用户看得见看不见，你都不能发送过去，只要发送过去就会被毙掉。 继续上面的表单陷阱，某些css也会动态将某个input 属于hidden属性，这个需要好好分析下。 403 forbidden 这极有可能是你的爬虫被封了。 参考资料 web scraping with python writing by Ryan Mitchell","tags":"python爬虫","url":"articles/pythonpa-chong-zhi-fang-zhi-bei-feng-de-ce-lue.html"},{"title":"python爬虫之-自然语言处理相关","text":"网页里面的内容大部分是文本，所以爬虫继续深入不可避免要研究自然语言处理的。 爬虫越学到后面就会明白，漫无目的的爬虫真的只是入门阶段，而爬虫进阶很多时候就要在这个爬虫定向上下功夫。 本文不是介绍自然语言处理相关知识的，只是就和爬虫相关做一些讨论和思考。 比如分析文章得到热门词，然后根据热门词进一步定向搜索定向爬取。 但在这里我们说得更加抽象一点，而这就是爬虫进阶和自然语言处理结合的理想状态，简言之就是： 好像一个人在阅读一篇文章，然后真的理解了里面的文章和里面的词语，然后他自己去决定哪个url该点，哪个关键词该收集，那篇文章有价值，那篇文章该分到哪一类等等。 下面列出一些自然语言处理的基本功，想要爬虫进阶深造的可能就要开始把这些基本功打扎实了： 分词 词频统计 ngram模型等分析词语之间的关系","tags":"python爬虫","url":"articles/pythonpa-chong-zhi-zi-ran-yu-yan-chu-li-xiang-guan.html"},{"title":"python爬虫之-字体反爬虫","text":"在爬虫的时候，你分析网页会看到，某些东西看上去是乱码，其css设置了一种额外的字体。怎么破解里面的内容呢？ 首先你需要把目标字体下载下来，通常这种字体有各种各样的名字，里面的具体字体codepoint也是随机的... 如果你下载一个fontcreator会看到具体哪个字对应哪个codepoint，而爬虫这边编码，我们需要使用python的 fonttools库来加载字体。 首先你需要下载好字体，保存好字体做好缓存工作。 见本文的参考资料2，然后就是利用 fonttools 模块加载目标字体。 font = TTFont(font_filename) 然后就是分析这个字体的cmap tables的cmap数据，不同的字体似乎情况不同，这个要实际分析，由于fonttools这个模块文档较少，加上我对字体知识不太多，所以只能简单摸索下了。 font_mapping = font['cmap'].tables[?].cmap 如果你找到 font_mapping 了，字符 用python的 ord 函数处理下，就能得到目标字符的 unicode code point，也就是我们上面说的字体的code point，在这个 font_mapping 里面你会看到的，然后具体什么内容就出来了。 参考资料 https://zhuanlan.zhihu.com/p/32087297 how to find out which codepoint in ttf file","tags":"python爬虫","url":"articles/pythonpa-chong-zhi-zi-ti-fan-pa-chong.html"},{"title":"python中的位操作","text":"位操作似乎用c语言会更方便，不过我们可以先把这块概念弄清楚，然后迁移到c代码是很方便的。 问题1，如何表示任意长度的基于字节的 位向量 比如说我想表达 01010101010101 答： 0b01010101010101 问题2 上面任意长度的位向量，我如何实现遍历逻辑 是的，我是看编程珠玑确定这些问题的，然后发现python，当然，已经有类似的实现库了： https://github.com/ilanschnell/bitarray 下面好好研究下这个项目的源码。 问题4 如何建立位图映射 比如 0b1010101010 -> 对应的是 数字集合 {1,3,5,7,9} 问题5 有没有可能建立其他位图映射 问题3 常规的位操作运算符，你帮我说说吧 按位与 x = 0b111101010 y = 0b101010101 print(bin(x)) print(bin(y)) print(bin(x & y)) --- 0b111101010 0b101010101 0b101000000 按位或 按位异或 按位取反 按位左移 按位右移","tags":"python语言","url":"articles/pythonzhong-de-wei-cao-zuo.html"},{"title":"使用cython来加速python","text":"找到性能瓶颈所在 首先需要确认脚本或者某个函数具体到底是哪里出现了性能瓶颈： python -m cProfile test.py 或者使用jupyter notebook 的timeit 功能，或者自己写 time计时。 目前我知道的循环结构提速很明显，然后指定静态类型会提速。 一般的python代码cython都是支持的，但一般我们是重点去开发那个限速的目标函数，而不会到处优化的。 参考资料1的例子，没有加速，N设置为3000，用时 53.301s，加速之后，用时4.186s。然后没有加速的那个exp运算了很多很多次，大概花了一两秒的样子，所以我们看到原始python代码在循环操作上开销很大。某些关键计算如果循环次数太多，那么就要考虑上c扩展优化了。 在做性能测试的时候有一类耗时较多的操作是不用考虑c代码优化的，这类耗时多的操作就是IO等待型操作，有的是等待数据库IO操作，有的是等待文件读写IO操作，有的是等待网络IO请求等等。这些请求很多都和socket套接字请求相关。 pyx文件 关于pyx文件的更多请查看cython的官方手册。 下面重点讲一下 python模块包的管理方案，推荐是利用 setuptools 来， from setuptools import setup , find_packages , Extension ext1 = Extension ( \"expython.common\" , [ \"expython/common.pyx\" ]) EXTENSIONS = [ ext1 ] setup ( zip_safe = False , ext_modules = EXTENSIONS , ) 这里Extension类： 第一个参数name就是你想让这个目标加速模块（python文件就叫模块，多个带__init__.py的叫包）在总模块中叫什么名字，支持点标记。 第二个参数 sources，一个列表，把一些文件路径写上就是了。 集成原始c代码 有的时候你会写一些原始的c代码，那么怎么利用cython集成进来呢。 from setuptools import setup , find_packages , Extension from Cython.Distutils import build_ext ext1 = Extension ( name = \"expython.wrapped\" , sources = [ \"expython/clib/cgfun.c\" , \"expython/clib/wrapped.pyx\" ], libraries = [], include_dirs = []) EXTENSIONS = [ ext1 ] setup ( name = '...' , ... packages = find_packages ( exclude = [ 'ez_setup' , 'examples' , 'tests' ]), zip_safe = False , cmdclass = { \"build_ext\" : build_ext }, ext_modules = EXTENSIONS , ) setup.py 里面的核心代码如上所示，具体有几个文件: cgfun.c cgfun.h wrapped.pyx 的内容如下所示，然后实际引用的时候你可以在 clib的 __init__.py 哪里写上： from expython.wrapped import is_prime , fibonacci , factorial 这样你就可以： from expython.clib import is_prime , fibonacci , factorial cgfun.c 的内容如下： int cgcd(int x, int y) { int g = y; while (x > 0) { g = x; x = y % x; y = g; } return g; } long cfib(long n){ long i; long a=0; long b=1; long tmp; for (i=0; i<n; ++i){ tmp = b; b = a + b; a = tmp; } return a; } cgfun.h 的内容如下： #ifndef __CGFUN_H__ #define __CGFUN_H__ int cgcd ( int a , int b ); long cfib ( long n ); #endif wrapped.pyx的内容如下： cimport cython cdef extern from \"cgfun.h\" : int cgcd ( int a , int b ) long cfib ( long n ) def gcd ( a , b ): return cgcd ( a , b ) def fibonacci ( n ): return cfib ( n - 1 ) def factorial ( int x ): \"\"\" cython language \"\"\" cdef int m = x cdef int i if x <= 1 : return 1 else : for i in range ( 1 , x ): m = m * i return m @cython.boundscheck ( False ) @cython.cdivision ( True ) def is_prime ( int n ): '''test input integer n is a prime. >>> is_prime(0) False >>> is_prime(-5) False >>> is_prime(5) True >>> is_prime(123) False ''' if n == 2 : return True elif n < 2 or ( not n & 1 ): return False cdef int x for x in range ( 3 , int ( n ** 0.5 ) + 1 , 2 ): if n % x == 0 : return False return True 更多高级只是比如集成numpy等等，就需要查看cython官方文档了。 参考资料 Cython 入门教程 github上一个简单的cython样例 python3 cookbook相关讨论","tags":"python好伙伴","url":"articles/shi-yong-cythonlai-jia-su-python.html"},{"title":"软件即服务的12因素方法论","text":"本文主要学习 这个网站 ，这个网站提出了软件即服务架构的12因素方法论。在目前软件开发，部署docker化，微服务，云服务，分布式架构等大趋势下，软件即对外提供一种http api服务的定位是很具有普遍性的。本文的一些讨论是很值得我们细细去思考的。 前言 Adam Wiggins 研究了数以百计的应用程序的开发和部署，并在Heroku平台上数十万应用程序的开发运作和扩展过程，写作了这个博客： https://12factor.net/zh_cn/ 。 在互联网Internet的大背景下，软件作为一种服务，更确切来说作为一种api服务而存在是一种具有普适性的架构模式，不管软件自身功能如何，但软件本身只是一个提供了一些对外api接口的工具的定位，无疑是面向整个互联网和面向未来的。 同时这里的讨论不光涉及到部署和运维，实际上，在软件开始编写时的架构设计和具体编码部分内部细节，编码者的思路也需要作出相应的调整。 总的原则 使用 标准化 流程自动配置，从而使新的开发者花费最少的学习成本加入这个项目。 和操作系统之间尽可能的 划清界限 ，在各个系统中提供 最大的可移植性 。 适合 部署 在现代的 云计算平台 ，从而在服务器和系统管理方面节省资源。 将开发环境和生产环境的 差异降至最低 ，并使用 持续交付 实施敏捷开发。 可以在工具、架构和开发流程不发生明显变化的前提下实现 扩展 。 这套理论适用于任意语言和后端服务（数据库、消息队列、缓存等）开发的应用程序。 一套基准代码多份部署 我看到人们经常对于 development testting 或者 production 等状态采用的是git不同版本号来控制的，这种做法不是很优雅，通常软件开发的不同状态是由软件的相关配置决定的，而这正是下面要讨论关于配置管理要讨论的问题。 我们在git代码管理的时候应该做到一个应用，一个对外api接口，一个git仓库，一个docker部署。具体多份部署无非是修改项目根目录下某个没进入git管理的文件环境变量。 在环境中存储配置 程序编码者在一开始编码的时候就应该做到，软件立刻开源，是不会泄露任何敏感信息的。而对于不同的部署的某些无差异配置，是可以写入代码的，这是没有问题的。 目前推荐的做法是将应用的相关核心配置存储于环境变量中。下面以python生态圈来讨论之。 在项目根目录下写一个 .env 文件，一般只需要写上一个核心环境配置变量即可： ENV_FOR_DYNACONF=development 在项目根目录下写上一个 .secrets.toml 文件，toml配置文件很好用，也很简单，是dynaconf模块推荐使用的，读者简单了解下即可。里面如下格式写上一些私密信息: [default] [development] MONGODB_USERNAME = '' MONGODB_PASSWORD = '' [testing] MONGODB_USERNAME = '' MONGODB_PASSWORD = '' [production] MONGODB_USERNAME = '' MONGODB_PASSWORD = '' 这两个文件不进入版本控制。 在项目根目录下写上 settings.toml 文件，这个配置文件格式如上，写上一些不太私密的配置信息，这些文件将进入版本控制。 实际使用时修改 .env 即改变了整个项目的环境变量状态。实际python编码如下： from dynaconf import settings 然后这个settings里面就可以取各种配置变量值了。而dynaconf稍作配置，就可以集成django或者flask的配置。更多信息请参看 dynaconf 官方文档。 在实际使用的时候，使用pipenv工具的 pipenv shell 或者 pipenv run 或者pycharm等等很多工具，他们都会默认加载 .env 这个环境变量配置文件的。 显式声明依赖关系 python生态圈有很多依赖关系管理工具，推荐使用pipenv，pipenv会输出一个lock文件，这个lock并不一定要进入版本库，按照官方文档的介绍，如果你的不同部署python版本号不太一致，那么最好不要将这个lock文件写入版本库。然后 requirments.txt 也可以输出一份。这个随个人喜好了，总之软件项目的这些依赖关系对软件部署是非常友好的，强烈推荐具体使用和Dockerfile集成起来。 其他语言也有其他相对应的依赖关系，这些都要声明好。 通过端口绑定提供服务 把其他后端服务作为附加资源 上面这两条是一起的，在实际编写软件即服务架构时，本地的服务，第三方提供的服务和本软件应用提供的服务是不区分的。 这些服务包括：一般服务，数据库服务，消息队列服务，缓存服务等等。 在使用docker部署的时候，其他后端附加资源服务，推荐完全集成进去。 严格分离构建、发布和运行 构建是将代码仓库转化成为可执行包的过程。 发布时将构建的结果和相应配置结合的过程。 运行是针对发布的版本实际启动运行进程的过程。 应该严格分离构建、发布和运行这三个过程。 实践中针对互联网应用，构建指的可能不是发布一个exe文件，而是一个docker的image文件，然后运行image的时候配置一些环境变量，然后运行。 进程和并发 把进程作为第一等公民，实际以一个无状态进程来启动应用，具体和简单运行 python script.py 没有任何区别。 用专门的工具来实现进程并发，比如gunicorn等，比如就是一个进程，多个worker模型。实际进程不推荐使用supervisor这样的守护进程，而推荐和操作系统的进程管理或者说服务比如systemd集成起来。 快速启动，优雅终止 尽可能开发环境和线上环境相同 这两点应用docker化之后不存在任何问题。 日志 不用太在意日志，目前互联网应用开发都是快速开发，快速迭代，线上修改风格。所有如果需要监控软件应用运行情况，应该优先的终端输出流。这样开发人员在开发的时候就可以实时查看应用运行情况。 在确定需要某些存放在文件里面的日志信息时，推荐发送给某个日志管理工具来统一管理。 零碎的一次性任务提供命令行接口 比如django的迁移数据库操作 python manage.py migrate 等，有零碎的一次性任务应该编写相应的命令行接口。","tags":"设计","url":"articles/12factor-app-talk.html"},{"title":"python语言之-单例模式","text":"某些情况下你需要确保某个类只有一个实例，这叫做单例模式。 python中的对象有 __new__ 方法 和 __init__ 方法，其中 __new__ 方法会返回你的类具体创建的实例，而 __init__ 方法仅仅和你的实例化初始化之后的一些额外动作相关。 于是我们有： class SingleInstance ( object ): def __new__ ( cls , * args , ** kwargs ): if not hasattr ( cls , '_instance' ): cls . _instance = super ( SingleInstance , cls ) . __new__ ( cls , * args , ** kwargs ) return cls . _instance","tags":"python语言","url":"articles/pythonyu-yan-zhi-dan-li-mo-shi.html"},{"title":"python语言之-format函数","text":"format函数或者说字符串的format方法，一般的使用还是很简单的，但是有的时候有些特殊的高级需求，下面渐渐收集之。 等宽数字 {:0>2d} 目标数字宽度为两位，左边填充0 ， > 表示左边填充， 0> 表示左边填充0，此外还有 > 表示右边填充。","tags":"python语言","url":"articles/pythonyu-yan-zhi-formathan-shu.html"},{"title":"python语言之-int函数","text":"我没想到学python这么久了，竟然还要再来介绍int函数。 int函数用于强制类型转换的时候，可以将一个类数值字符串变成integer，但这个函数还隐藏了一个强大的功能，那就是其还有第二个可选参数，进位制。 >>> int ( 'a' , base = 16 ) 10 >>> int ( '0xa' , base = 16 ) 10 上面的效果就是将一个十六进制的字符按照十六进制输出一个十进制的数值。有相同需求的地方别用eval了。","tags":"python语言","url":"articles/pythonyu-yan-zhi-inthan-shu.html"},{"title":"500lines-一个简单的web服务器","text":"前言 本文主要是对 500lines 项目的这篇文章的学习和讨论，这篇文章写得是极好的，除了对如何编码有一些很好的借鉴参考价值，还主要能让读者对http web server 做的事情有了一个清楚的认识。这篇文章弄清楚了，对django或者flask在做一些什么事，就很胸有成竹了，甚至包括nginx等服务器在做一些什么事也有一个大致的了解了。 因为作者后端出身，所以对这篇文章的质量和价值是清楚的，以至于作者在强烈呼唤出现这样一篇类似的描述前端框架的文章，目前我对前端框架整个过程还没有一个很好的认识。 关于计算机网络和HTTP相关不在本文讨论了，笔者也自觉这一块有时间还需要再深入补一补。 我们的web服务器要做的工作如下： 占着个端口等着某个HTTP 请求包发过来 你知道的HTTP请求包有一定的格式，具体哪些信息进行parse操作 确定该请求要做点什么（分发GET POST） 程序做点什么 形成返回的数据格式，比如html等。 将返回的数据传回去 上面步骤的前两步和最后一步python的 HTTPServer 已经帮我们自动做了，更不用说django和flask这些框架，也早就帮我们做好了。我们只需要关注的是，请求过来的是GET还是POST等，然后当然是程序总要干点什么事，最后就是把要送回去的数据整理好，再一并发过去即可。 更高级的web server 如flask之类的，会提供很多额外的支持，比如请求参数，请求头等信息的整理，然后如果你希望实现restful风格api，只返回一个字典值，对应的一些响应头封装也帮你做好了，当然在返回数据上，比如html会引入jinja2模块引擎等，这些都是很好理解的。总的说来web server干的就是这些事。 第一个例子 针对python3版本代码稍作修改。 from http.server import HTTPServer , BaseHTTPRequestHandler class RequestHandler ( BaseHTTPRequestHandler ): '''Handle HTTP requests by returning a fixed 'page'.''' # Page to send back. Page = ''' \\ <html> <body> <p>Hello, web!</p> </body> </html> ''' # Handle a GET request. def do_GET ( self ): self . send_response ( 200 ) self . send_header ( \"Content-Type\" , \"text/html\" ) self . send_header ( \"Content-Length\" , str ( len ( self . Page ))) self . end_headers () self . wfile . write ( self . Page . encode ()) #---------------------------------------------------------------------- if __name__ == '__main__' : serverAddress = ( '' , 8080 ) server = HTTPServer ( serverAddress , RequestHandler ) server . serve_forever () 上面的 do_GET 方法内部作用原理如下： mname = 'do_' + self.command if not hasattr(self, mname): self.send_error( HTTPStatus.NOT_IMPLEMENTED, \"Unsupported method (%r)\" % self.command) return method = getattr(self, mname) method() 其中 self.command 就是http协议请求头传过来的GET或者POST等，然后 handler类会去找对应的方法，找到了再进行对应的操作。 这种根据函数名来进行行为分发的编程模式，很值得引起大家的注意，在web server里面一直都存在着这个需求。从url server_name 到对应的虚拟server分发，从path method 到对应的函数行为分发，再到后面高级的参数验证valide_what 等也有类似的行为分发需求。 简单的模板输出方案 这个就不码代码了，其实就是简单的python字符串format方法，更复杂的就使用jinja2模板系统来生成html内容，这是后话了。 挂载静态文件 静态文件就是找到对应的文件，然后返回就是了。当然对于 index.html 等特殊文件需要特别的处理。 500lines该文后来提到一种有趣的编码写法： class case_no_file ( object ) : '''File or directory does not exist.''' def test ( self , handler ) : return not os . path . exists ( handler . full_path ) def act ( self , handler ) : raise ServerException ( \"'{0}' not found\" . format ( handler . path )) def do_GET(self): try: # Figure out what exactly is being requested. self.full_path = os.getcwd() + self.path # Figure out how to handle it. for case in self.Cases: cond= case() if cond.test(self): cond.act(self) break # Handle errors. except Exception as msg: self.handle_error(msg) class RequestHandler ( BaseHTTPServer . BaseHTTPRequestHandler ) : Cases = [ case_no_file , case_existing_file , case_always_fail ] 针对多种情况，实现了行为分发，有点像switch语句但更python风格更优美的写法。 简单的cgi接口实现 接下来的cgi接口实现代码也是很简单的： class case_cgi_file ( object ): '''Something runnable.''' def test ( self , handler ): return os . path . isfile ( handler . full_path ) and \\ handler . full_path . endswith ( '.py' ) def act ( self , handler ): handler . run_cgi ( handler . full_path ) def run_cgi ( self , full_path ): cmd = \"python \" + full_path child_stdin , child_stdout = os . popen2 ( cmd ) child_stdin . close () data = child_stdout . read () child_stdout . close () self . send_content ( data ) 其核心就是针对某个python脚本文件，启动cgi协议接口，简单来说就是启动一个python解释器运行一下目标脚本文件，然后获取其返回的内容，作为web server的返回内容返回即可。 然后下面有必要了解下cgi协议，所谓CGI协议，全称是（Common Gateway Interface）通用网关接口，说得再确切一点，是cgi程序和web server之间的接口标准，说得再简单粗糙点，一个web server，比如apache 或者 nginx 会把上面我们讨论的返回静态文件等做好，请读者进一步参看 这篇文章 。 然后有些请求，这些请求就是这里讨论的CGI协议，这里所谓的nginx就是web server，也是本例子中的大部分代码扮演的角色，而这里所谓的cgi程序，实际上就是那个python脚本，当然也可能是某个python框架，这个后面会讨论到。 路径上挂载的参数将作为环境变量传递进来，等等还有其他一些工作，就是CGI协议定义的内容。讲到cgi协议，到了python这边，就不可能不提到pep3333和wsgi标准了。 WSGI PEP3333 定义了 Python Web Server Gateway Interface ，叫做python web server 网关协议，简称WSGI协议。从名字就看到出来，在python的世界里，推荐使用WSGI协议。所以我们可以猜到WSGI同样也要处理好，路径path里面挂载的参数，然后送入环境变量这个问题。继续深入的话还需要把服务器信息，客户端信息，本次请求信息都存入environ变量中，然后WSGI application（这个由python那边的程序或者框架提供），必须是可调用的，还有等等其他规范。 还有WSGI middleware 层，在django和flask（Werkzeug ）里面，我们都将接触到 Middleware 类的概念。 总的说来nginx 扮演的是web server里面服务静态文件的角色，wsgi请求将发给gunicorn：gunicorn的官方介绍是： Gunicorn 'Green Unicorn' is a Python WSGI HTTP Server for UNIX. 简单来说在WSGI协议里面其扮演的也是web server的角色，而gunicorn挂载的另一边，就是django或者flask或者其他什么框架提供的wsgi脚本app，或者说application对象所在。 当然对于我们实际编码使用框架的人来说，不用太在意这些，记得在哪里调用path，path上面挂载的参数，怎么写行为，决定返回什么内容就是了。不过如果你是这些框架的编写人员，那么就要详细的研究WSGI协议了。","tags":"基础","url":"articles/500lines-a-simple-web-server.html"},{"title":"http知识","text":"HTTP知识 URL结构 URL结构如下: scheme:[//[user:password@]host[:port]][/]path[?query][#fragment] 其中: scheme: 描述访问服务器的协议，也就是如何获取该资源，最常见的是http，此外还有ftp等。 user:password: 这里用于http认证 host: 那里获取资源 port: 连接端口号是多少 path: 具体访问该资源的path query: 其他额外参数 fragment: 片段，为client使用。还有一个params不太常用。 URL是只支持ascii字符表示的，其他的字符要经过utf-8编码操作。具体转义字符是 % ，比如空格SPACE，具体在URL中的表示就是 %20 。即使是ascii里面，也有一些字符需要转义，然后比如中文字符等，也需要如此utf-8编码和转义。比如 \"书\" >>> '书'.encode('utf-8') b'\\xe4\\xb9\\xa6' 在URL中对应的就是 %e4%b9%a6 。还有其他一些细节，当然实际操作中各个编程语言都提供了良好的函数接口了的，比如python的urlencode函数。 http header详解 本小节主要参考了 这个网页 ，内容整理得不错，都搬过来了，做备份用。 http协议过程分为http请求过程和http响应过程，http请求过程就是发送http请求信息包，http响应过程就是发送http响应信息包的过程。 http 请求信息包 http请求信息包格式如下: <method> <URL> <version> <headers> <entity-body> 比如打开google主页的请求包是: GET / HTTP / 1 . 1 Host : www . google . com User-Agent : Mozilla / 5 . 0 ( X11 ; Ubuntu ; Linux x86_64 ; rv : 40 . 0 ) Gecko / 20100101 Firefox / 40 . 0 ........ 其中第一行为大家熟知， 就是 GET 方法，具体打开的URL是 / ，然后http的version是 HTTP/1.1 。然后后面的请求包header内容不定，后面再细讲。请求信息包大多都没有entity-body，也就是额外的content内容，但就算没有header完了也要留一空白行。 请求headers详解 header 解释 示例 Accept 指定客户端能够接收的内容类型 Accept: text/plain, text/html Accept-Charset 浏览器可以接受的字符编码集 Accept-Charset: iso-8859-5 Accept-Encoding 指定浏览器可以支持的web服务器返回内容压缩编码类型 Accept-Encoding: compress, gzip Accept-Language 浏览器可接受的语言 Accept-Language: en,zh Accept-Ranges 可以请求网页实体的一个或者多个子范围字段 Accept-Ranges: bytes Authorization HTTP授权的授权证书 Authorization: Basic QWxhZGRpbjpvcGVuIHNlc2FtZQ== Cache-Control 指定请求和响应遵循的缓存机制 Cache-Control: no-cache Connection 表示是否需要持久连接 （HTTP 1.1默认进行持久连接） Connection: close Cookie HTTP请求发送时，会把保存在该请求域名下的所有cookie值一起发送给web服务器。 Cookie: $Version=1; Skin=new; Content-Length 请求的内容长度 Content-Length: 348 Content-Type 请求的与实体对应的MIME信息 Content-Type: application/x-www-form-urlencoded Date 请求发送的日期和时间 Date: Tue, 15 Nov 2010 08:12:31 GMT Expect 请求的特定的服务器行为 Expect: 100-continue From 发出请求的用户的Email From: user@email.com Host 指定请求的服务器的域名和端口号 Host: www.zcmhi.com If-Match 只有请求内容与实体相匹配才有效 If-Match: \"737060cd8c284d8af7ad3082f209582d\" If-Modified-Since 如果请求的部分在指定时间之后被修改则请求成功，未被修改则返回304代码 If-Modified-Since: Sat, 29 Oct 2010 19:43:31 GMT If-None-Match 如果内容未改变返回304代码，参数为服务器先前发送的Etag，与服务器回应的Etag比较判断是否改变 If-None-Match: \"737060cd8c284d8af7ad3082f209582d\" If-Range 如果实体未改变，服务器发送客户端丢失的部分，否则发送整个实体。参数也为Etag If-Range: \"737060cd8c284d8af7ad3082f209582d\" If-Unmodified-Since 只在实体在指定时间之后未被修改才请求成功 If-Unmodified-Since: Sat, 29 Oct 2010 19:43:31 GMT Max-Forwards 限制信息通过代理和网关传送的时间 Max-Forwards: 10 Pragma 用来包含实现特定的指令 Pragma: no-cache Proxy-Authorization 连接到代理的授权证书 Proxy-Authorization: Basic QWxhZGRpbjpvcGVuIHNlc2FtZQ== Range 只请求实体的一部分，指定范围 Range: bytes=500-999 Referer 先前网页的地址，当前请求网页紧随其后,即来路 Referer: TE 客户端愿意接受的传输编码，并通知服务器接受接受尾加头信息 TE: trailers,deflate;q=0.5 Upgrade 向服务器指定某种传输协议以便服务器进行转换（如果支持） Upgrade: HTTP/2.0, SHTTP/1.3, IRC/6.9, RTA/x11 User-Agent User-Agent的内容包含发出请求的用户信息 User-Agent: Mozilla/5.0 (Linux; X11) Via 通知中间网关或代理服务器地址，通信协议 Via: 1.0 fred, 1.1 nowhere.com (Apache/1.1) Warning 关于消息实体的警告信息 Warn: 199 Miscellaneous warning http 响应信息包 http响应信息包格式如下: <version> <status-code> <reason-phrase> <headers> <entity-body> 比如: HTTP / 1 . 1 200 OK Cache-Control : private Content-Length : 231 Content-Type : text / html ; charset = UTF-8 Date : Wed , 02 Sep 2015 08 : 47 : 52 GMT .... 这个响应体 HTTP/1.1 就是的就是http的version，然后 200 是具体的http状态码，然后 OK 是一个描述文字。然后是响应体的header，然后空一行，然后是响应信息包的具体发送的cotent内容。 http的方法method和状态码为大家所熟知，下面就header的一些内容列出来说明之。 响应headers详解 header 解释 示例 Accept-Ranges 表明服务器是否支持指定范围请求及哪种类型的分段请求 Accept-Ranges: bytes Age 从原始服务器到代理缓存形成的估算时间（以秒计，非负） Age: 12 Allow 对某网络资源的有效的请求行为，不允许则返回405 Allow: GET, HEAD Cache-Control 告诉所有的缓存机制是否可以缓存及哪种类型 Cache-Control: no-cache Content-Encoding web服务器支持的返回内容压缩编码类型。 Content-Encoding: gzip Content-Language 响应体的语言 Content-Language: en,zh Content-Length 响应体的长度 Content-Length: 348 Content-Location 请求资源可替代的备用的另一地址 Content-Location: /index.htm Content-MD5 返回资源的MD5校验值 Content-MD5: Q2hlY2sgSW50ZWdyaXR5IQ== Content-Range 在整个返回体中本部分的字节位置 Content-Range: bytes 21010-47021/47022 Content-Type 返回内容的MIME类型 Content-Type: text/html; charset=utf-8 Date 原始服务器消息发出的时间 Date: Tue, 15 Nov 2010 08:12:31 GMT ETag 请求变量的实体标签的当前值 ETag: \"737060cd8c284d8af7ad3082f209582d\" Expires 响应过期的日期和时间 Expires: Thu, 01 Dec 2010 16:00:00 GMT Last-Modified 请求资源的最后修改时间 Last-Modified: Tue, 15 Nov 2010 12:45:26 GMT Location 用来重定向接收方到非请求URL的位置来完成请求或标识新的资源 Location: Pragma 包括实现特定的指令，它可应用到响应链上的任何接收方 Pragma: no-cache Proxy-Authenticate 它指出认证方案和可应用到代理的该URL上的参数 Proxy-Authenticate: Basic refresh 应用于重定向或一个新的资源被创造，在5秒之后重定向 Retry-After 如果实体暂时不可取，通知客户端在指定时间之后再次尝试 Retry-After: 120 Server web服务器软件名称 Server: Apache/1.3.27 (Unix) (Red-Hat/Linux) Set-Cookie 设置Http Cookie Trailer 指出头域在分块传输编码的尾部存在 Trailer: Max-Forwards Transfer-Encoding 文件传输编码 Vary 告诉下游代理是使用缓存响应还是从原始服务器请求 Via 告知代理客户端响应是通过哪里发送的 Warning 警告实体可能存在的问题 WWW-Authenticate 表明客户端请求实体应该使用的授权方案 WWW-Authenticate: Basic http状态码详 MIME type: 其全称是Multipurpose Internet Mail Extensions ，可以看得出来和email系统有关，但不管怎么说，我们知道其在http里面用于描述文件类型即可。具体就是对应的 Content-type : image/jpeg 这一行，image/jpeg 就是MIME type描述，image是主文件类型，jpeg是次文件类型。最常见的是html文件，其MIME type是 text/html 。 URI: Uniform Resource Identifier ，此外常见的还有URN和URL概念。参考了 这个网页 。URN和URL都属于URI的范畴，也就是都视同用一连串的字符串来将所有的资源文件分别表示出来，而URN和URL是两种不同的标识方法，URL有点类似于门牌号码街道的描述，其大致有如下结构: scheme:[//[user:password@]host[:port]][/]path[?query][#fragment] 而URN比如: urn:isbn:0451450523 目前几乎绝大部分URI就是URL，URN只在某些特别领域使用。 参考资料","tags":"html5","url":"articles/httpzhi-shi.html"},{"title":"css布局","text":"css布局 这个网站专门介绍 css布局 ，深入浅出讲的还是很好的，css布局是css里面很重要的课题，建立认真学习一下。 display属性 block 块级元素，占满自身右边所有行的行空间。 div元素和p默认就是所谓的block元素，display属性为 block 。 display : block ; inline span元素默认是 inline 。 display : inline ; 就占据我需要的宽度，其他盒子元素可以继续填满这一行。 比如: li { display : inline ; } 这样你的无序列表和有序列表的各个item不会另起一行了。其默认的是 display:list-item; 。 inline-block inline-block的意思是块级元素还是块级元素，只是几个块级元素对外排布是 inline 模式排布的，这是css较新的一个特性。如果对块状元素设置display属性为 inline ，则这些块状元素都会失去自己内部的尺寸布局，这可能不是你想要的。 none display : none 该元素不会显示。和 visibility:hidden 的区别是其本该显示的空间不会保留了。 float属性 元素居右放置 float : right ; clear属性 两侧都不能出现浮动元素 clear : both ; position属性 css布局控制中，positon是一个很关键的属性。参考了 这个网页 和 这个网页 。position属性有如下四个值可以设置: static static是默认值，没有什么其他额外的位置调整行为，表示它不会被\"positioned\"。 relative relative和static类似，除非你还有其他的属性设置。比如 top , right , bottom , left 这些属性来调整，具体相对的含义是相对于原本它应该在的地方。相对调整之后留下来的地方会被保留下来，没有后续处理动作了。 fixed fixed的应用就是将某个元素总是显示在页面上，比如说某些弹窗广告。 top , right , bottom , left 这些属性可以辅助来调整这个弹窗具体的位置。 absolute absolute类似于fixed，不过其不是相对于视窗固定，而是相对于页面固定。比如下面这个aside设置: aside { margin-left: -200px; width: 181px; position: absolute; background-color:#FDF6E3; } 这个aside是个目录，就放在正文的左边的，如果不用absolute布局的话，右边空间就不会释放出来。请参看 这个网页的那个nav标签元素 。","tags":"html5","url":"articles/cssbu-ju.html"},{"title":"css盒子模型","text":"css的盒子模型 html的显示布局和 (TeX) 的显示布局一样也是采用的浮动盒子模型，从上到下，从左到右，一个个盒子排下来，只是 (TeX) 更复杂，还有一个分页算法。简言之就是每一个标签元素都是一个盒子(我还不太确定一个个字是不是一个盒子，在 (TeX) 里面一个个字都是一个盒子。) 。 下面这个图片来自 这个网页 。 这篇文章 讲解得很好，下面简要介绍之，下面放在短代码环境的都是可以用作css属性的。盒子最中心的是content区域，如果该盒子的 box-sizing 是默认值的话，那么 width 控制的就是content区域的宽度。如果将 box-sizing 设置为 border-box ，那么 width 对应的就是整个盒子的宽度。这个只是一点简单的数学加减法把戏罢了，没什么大不了的。 然后类似的 height 默认是控制content区域的高度，然后有 min-width , min-height 来控制盒子content区域的最小宽度和最小高度，然后有 max-width , max-height 来控制盒子content区域的最大宽度和最大高度，类似的这几个属性如果 box-sizing 设置为 border-box ，那么对应的都是整个盒子的宽度或高度。 content区域外围是padding区域，padding区域是透明的，如果整个盒子设置 background-color 或 backgroud-image ，这是你会看到他们。padding区域有如下属性来控制上面下面左边右边的长度: padding-top , padding-bottom , padding-left , padding-right 。 还有一个简便的写法 padding ，这种写法设置一个值控制上面四个量还是很方便的，但其还可以接多个值，有一定顺序，不太喜欢这种用法。 padding区域外面是border区域，通常我们在网页中看到的一条条边框线就是它了， 用 border-width 来控制边框线的宽度。这实际上是一个简写，类似上面的 padding ，可以跟四个值: 上，右，下，左: border-width : 1px 2em 0 4rem ; 或者三个值: 上，右和左，下: border-width : 1px 2em 1 . 5cm ; 或者两个值: 上下，左右: border-width : 2px 1 . 5em ; 此外还有: border-top-width 对应上宽度， border-bottom-width 等。 border区域外面就是margin边距区域。其有如下属性，含义大家一看应该就明白了: margin-top , margin-bottom , margin-left , margin-right , margin 。 border属性 border属性可以跟上三个值，分别是: border-width border-style border-color img { border: 1px solid #4682b4 } border-style情况比较多，常见的有 solid 实线 dashed 虚线 double 双线 dotted 点线等，更多请参看 这个网页 。v","tags":"html5","url":"articles/csshe-zi-mo-xing.html"},{"title":"css基础","text":"css基础 前面谈到的inline css因为肯定是作用于本标签，所以写法就简化了，style引入之后后面加入一些属性即可。然后前面谈到的外部css，其写法都是如下所示: p { text-indent : 2 em ; /*段落缩进*/ line-height : 180 % ; /*行间距*/ } 第一个元素我们可以简单称之为css选择器，在网络抓取中也有类似的概念。然后花括号里面就是类似 inline css 一样的格式了，用分号隔开，换行不换行都是无所谓的，具体为了美观一般都一个属性占一行吧。 css选择器 这里以html5为例，html5内置的标签都是可以直接引用的，比如body，article，video，table，figure等等。如果你在css中引用section，那么意思就是整个文档的section标签那些元素被选中了。 我们知道html5中可以通过 class 属性来将某个元素归于某一类，现在假设有: < p class = \"emph\" > hello </ p > 那么我们使用 p.emph 其意思就是将选中p标签然后class属性为emph的那些标签。 我们在css中经常看到这样的形式： .hightlight 其完整形式为 *.hightlight ，也就是所有class属性为hightlight的元素都将被选中。 然后id属性可用来定义某个标签的唯一id，一般就用 #idname 选中那个标签即可。 子选择器 h1 > strong ，其只严格选择h1标签下遇到的 第一个 strong标签，这里的下是严格意义上的父子标签包含关系的下，如果某个strong标签在em标签里面，然后这个em标签在h1标签里面，则该strong元素是不会被这里所谓的严格逐级选择选中的。 后代选择器 figure p 其选择的就是所有figure标签元素里面的 所有 p标签元素。前面谈及的那些标签元素表示方法你都可以用的，比如 #footer .emph 选择的就是id为footer的那个标签里面class属性为emph的标签。 更多css选择信息请参看w3school的 css元素选择详解部分 ，但这一块最好不要弄得太复杂。实际上这样的选择逻辑弄得越复杂后面css代码的维护就越困难，最好的实践还是用 class 和 id 来管理各个css属性。 带上其他属性选择 有href属性的a标签才应用样式: a [ href ] { color : red ;} 有href属性和title属性的a标签才应用样式: a [ href ][ title ] { color : red ;} 具体属性是什么值也指定了: a [ href = \"http://www.w3school.com.cn/about_us.asp\" ] { color : red ;} 伪类选定 带个:冒号后面跟着该标签的伪类，主要是值该标签的某种特殊状态，最常见的是a标签的各个状态，如下所示: a : link { color : # FF0000 } /* 未访问的链接 */ a : visited { color : # 00 FF00 } /* 已访问的链接 */ a : hover { color : # FF00FF } /* 鼠标移动到链接上 */ a : active { color : # 0000 FF } /* 选定的链接 */ first-child伪类 p : first - child { color : red ; } 只有是父标签的第一个子标签元素才会被选定。 nth-child伪类 p : nth - child ( 2 ) { color : red ; } 是父标签的第几个子标签元素才会被选定。 css选择权值 如果某个标签被多个css语句选定，那么具体权值如下： 标签权值为1 子选择器和后代选择器两个标签的1+1=2 类选择器权值为10 id选择器权值为100 css样式层叠优先级 内联样式 > 嵌入样式 > 外部样式 !important 用法 css设置有时不可避免会发生样式重叠覆盖，当然一般是尽可能统一css设置，但有时嫌麻烦懒得弄了，你可以用 !important 来手工提高某个css设置的优先级(参考了 这个网页 。)。如下所示： table , th , td { margin : 0 auto ; min-width : 2 em ; text-align : center !important ; padding : 5 px ; } 上面严格控制表格各项都居中对齐。 css的长度单位 css有很多长度单位，这些单位如果你熟悉 (\\LaTeX) 的话你就会对这些单位很眼熟。其中绝对长度单位有：1in = 2.54cm = 25.4mm = 72pt = 6pc ，这些并不推荐使用。 这篇网页 推荐多使用 px ， em 和 % 这样的长度单位。其中\"px\"和\"%\"是css特有的，其会根据显示屏而变动，然后1em我们知道就是当前字体M的宽度（TeX里面的情况）。其中px值得引起我们的注意，其会根据显示设备而有很好的调整，更多信息请参看上面提到的那个参考网页。","tags":"html5","url":"articles/cssji-chu.html"},{"title":"前端开发之-javascript基础","text":"javascript基础 本文主要面向那些已经熟悉一门编程语言的读者，并不十分适合编程初学者来阅读。 第二次修订版：本小节参考aribnb的javascript规范修订重写了。 注释 多行注释推荐如下写法： /** * make() returns a new element * based on the passed-in tag name */ 单行注释用 // ，然后注释都新起一行写，如果是代码块内的注释，则前面空一行： // This is a comment that the computer will ignore. function getType () { console . log ( 'fetching type...' ); // set the default type to 'no type' const type = this . type || 'no type' ; return type ; } 然后就是注释文字具体内容要和注释符号空一空格。 javascript代码放在那里 javascript的代码一般推荐是放在 </body> 之前，这样能够让浏览器更快地加载页面。至于其他倒没有特别的要求，刚开始简单的javascript代码就直接写上去也是可以的: < script > your awesome javascript code </ script > 如果javascript代码量有一点了那么当然还是推荐另外单独放在一个js文件上，然后如下引入进来: < script src = \"where\" ></ script > 声明常量和变量 这是参考的aribnb的javascript规范，简单来说就是不用 var ，声明常量用 const ；声明变量用 let 。理由： const 和 let 都是 block-scoped（我们程序员习惯的变量作用域盒子模型）。 const a = 1 ; const b = 2 ; let count = 1 ; if ( true ) { count += 1 ; } { let a = 1 ; const b = 1 ; } console . log ( a ); // ReferenceError console . log ( b ); // ReferenceError 全局变量 在网页中有个全局对象 window ，所以我们可以把一些全局变量挂在 window 对象里面。 数据类型简介 数值型(number) javascript整数和浮点数都不分了，都统一表示为number，然后数值型那些运算，比如加减乘除之类的就不用多说了。其中 % 和python一样也是求余操作。在python3中有 5//2 是求商的概念，javascript没有这个概念，我们需要如下来获得类似的效果。 console.log(parseInt(5/2)) parseInt() 将字符串转成整数型，否则返回NaN。 parseInt ( '123' , 10 ); // 123 parseInt ( '11' , 2 ); // 3 parseFloat() 将字符串转成浮点型，否则返回NaN。 parseFloat ( '3.14' ) 3.14 NaN也属于number型，判断是否是NaN，airbnb推荐的风格是： Number . isNaN ( 'a' ) false Number . isNaN ( 1 ) false Number . isNaN ( NaN ) true 字符串(string) javascript同python一样单引号和双引号都是可以的，按照aribnb的规范，字符串都推荐用 单引号 包围起来。 const name = 'Capt. Janeway' ; 很长很长的字符串aribnb规范既不推荐用 \\ 也不推荐用 + 连接起来，而是直接写上，这又是一个让人眼睛一亮的建议，理由就是让代码更具搜索性。对此我持保留意见，我觉得用 ` （ Esc下面的那个）来包围多行更便捷一些： `多行 字符串 ` 这类似于python的 \"\"\" 三双引号写法。 aribnb规范提出字符串的程序性拼接推荐使用模块语言，也就是 ${variable} ，这是很好的（注意必须用 ` 符号）。 `How are you, ${ name } ?` javascript的字符串类型和python非常类似，比如 string[0] 是支持的。然后不可以这样用string[0:2]，幸运的是javascript提供了类似python中的那种切片概念，就是使用 slice 方法 console.log(\"hello\".slice(0,2)) console.log([1,3,4,5].slice(0,2)) 不过javascript的slice方法和python的切片操作还是有点区别的，其只有 (start,end) 两个参数，然后其也有负数从末尾算起的概念，不过其不会倒着来，都是从左到右的那种顺序。具体请参看 这里 。 字符串的一些方法 length: 字符串长度 toUpperCase: 变成大写 toLowerCase: 变成小写 indexOf: 返回子字符串出现的索引位置，index索引编号规则和python相同。 substring: 返回子字符串，如果熟悉python的那种切片规则的话，那么推荐就直接使用 slice 方法。 replace: 替换操作 split: 分割操作 toString方法 javascript的数值、布尔值、对象和字符串都有一个 toString 方法，大体类似于python的 str 函数。自己定义的对象也可以加上 toString 方法： class Jedi { constructor ( options = {}) { this . name = options . name || 'no name' ; } getName () { return this . name ; } toString () { return `Jedi - ${ this . getName () } ` ; } } 数组 javascript的数组（array）大体类似于python的列表: 新建一个空array： const items = []; 或者 const items = [ 1 , 2 , 3.14 , 'Hello' , null , true ]; 其索引index编号法则也和python一致。 数组的一些方法 length: 数组长度 indexOf: 返回数组某个子元素的索引位置 slice: 切片操作，类似于python的 lst[0:2] 那种表达方法。slice方法不接受参数就默认返回该列表所有引用，也就是通常所说的 浅拷贝 。浅拷贝简单来说就是复制一个字典或者数组（或者其他复杂对象），根据第一层key赋值第一层value，如果第一层key是另外一个对象的引用，那么拷贝前对象和拷贝后对象都会指向统一对象，深拷贝就是进一步深入递归拷贝。 push: 末尾添加一个元素 pop: 最后一个元素删除 unshift: 数组头部添加一个或多个元素，返回新数组的长度 shift: 数组头部删除一个元素 sort: 排序，破坏型。值得一提的是对于数字排序并不是按照从大到小的顺序来的，不太清楚为何: > var lst = [1,5,2,3,51,4,45,545,541,48,77] > undefined > lst.sort() > [ 1, > 2, > 3, > 4, > 45, > 48, > 5, > 51, > 541, > 545, > 77 ] 在python中最多说字符串就这样，但这里是number类型啊。然后要正常排序，我们需要如下操作（参看 这个网页 ）: var lst = [ 1 , 5 , 2 , 3 , 51 , 4 , 45 , 545 , 541 , 48 , 77 ] function sortNumber ( a , b ){ return a - b } lst . sort ( sortNumber ) alert ( lst ) 这里sort方法接受一个函数参数，这个函数接受两个参量，用来判断a和b的值大小，如果返回值小于0，则a放在前面。如果返回值大于0，则a放在后面。这种排序方法也支持数字字符串的情况。javascript在处理这种 字符串 - 字符串 的情况是会尝试做转换成number类型的才做。 reverse: 反转，破坏型。 splice: 从指定的索引删除某些元素，然后在此处添加某些元素，相当于update更新了。 > var arr = [ 'Microsoft' , 'Apple' , 'Yahoo' , 'AOL' , 'Excite' , 'Oracle' ]; > undefined > arr . splice ( 2 , 3 , 'Google' , 'Facebook' ); > [ \"Yahoo\" , \"AOL\" , \"Excite\" ] > arr > [ \"Microsoft\" , \"Apple\" , \"Google\" , \"Facebook\" , \"Oracle\" ] 参数意思是从索引2开始删除3个元素，然后添加后面的元素。从上面的例子可以看出splice方法是破坏型的方法，然后其返回的是删除了的那是那个元素。 splice方法也可以用于只删除不添加也就是纯删除操作，或只添加不删除的纯添加操作。 // 只删除,不添加: arr.splice(2, 2); // 只添加,不删除: arr.splice(2, 0, 'Google', 'Facebook'); concat: 连接两个数组，非破坏型。 > var lst1 = [1,2,3] > undefined > var lst2 = ['a','b','c'] > undefined > lst1.concat(lst2) > [1, 2, 3, \"a\", \"b\", \"c\"] join: 类似于python字符串的join方法，如下所示: var arr = ['A', 'B', 'C', 1, 2, 3]; arr.join('-'); // 'A-B-C-1-2-3' fill: 数组用某个值来填充 比较两个数组是否相同 参考了 这个网页 。 function arraysEqual ( a , b ) { if ( a === b ) return true ; if ( a == null || b == null ) return false ; if ( a . length != b . length ) return false ; // If you don't care about the order of the elements inside // the array, you should sort both arrays here. for ( var i = 0 ; i < a . length ; ++ i ) { if ( a [ i ] !== b [ i ]) return false ; } return true ; } object javascript的object其大体可以看作python中的字典类型。 创建空的object推荐如下写法： const item = {}; 或者： const person = { name : 'Bob' , age : 20 , tags : [ 'js' , 'web' , 'mobile' ], city : 'Beijing' , zipcode : null }; aribnb提出属性名直接写上就是了，包括函数也是如此： const lukeSkywalker = 'Luke Skywalker' ; const obj = { lukeSkywalker , }; 然后函数可以先通过function声明，或者直接写进去： const atom = { value : 1 , addValue ( value ) { return atom . value + value ; }, }; 然后还有一些属性名在javascript里面是非法的，那么当然只好用单引号包围起来了。 动态生成对象属性名 const obj = { id : 5 , name : 'San Francisco' , [ getKey ( 'enabled' )] : true , }; in语句 'name' in xiaoming ; > var d = {} undefined > d [ 'a' ] = 1 1 > d Object { a : 1 } > 'a' in d true > 1 in [ 1 , 2 , 3 ] true delete语句 其对应的就是python的del语句。然后我们看到javascript的 delete 语句删除不存在键也不会报错。 > d Object { a : 1 } > delete ( d . b ) true > d Object { a : 1 } > delete ( d . a ) true > d Object {} hasOwnProperty方法 对应于python2的has_key方法，不过python2已经移除了，推荐用in语句。 d = { 'a' : 1 } d . hasOwnProperty ( 'a' ) true aribnb提出相关的一些建议，我持保留意见，可能是python出身，个人更喜欢in语句。 // good console . log ( Object . prototype . hasOwnProperty . call ( object , key )); shallow copy const original = { a : 1 , b : 2 }; const copy = { ... original , c : 3 }; // copy => { a: 1, b: 2, c: 3 } 布尔值(boolean) javascript的布尔值是 true 和 false 。然后需要额外强调的是，类似python的比较判断（==）符号在javascript中是 === ，三个等号，这不是什么别出心裁，也没有任何实际的好处，就是javascript的历史遗留问题罢了。 === Equal to !== Not equal to boolean值的判断遵循以下规则： false 0 空字符串 \"\" NaN null undefined 都被视作false 其他都被视作true Boolean ({}) true null javascript的是 null 。其也是一个单独的对象。类似于python的 None ，然后还有一个什么 undefined 。比如函数没有明确return值就会默认返回 undefined ，感兴趣的可能查一下这两个的区别，我看了一下，觉得挺无聊的。上面谈到 == 和 === 的区别，如果用 === ，则 undefined 是不等于 null 的，如果用 == ，则javascript会额外做一些类型转换工作，这两个又会看作相等的。 ECMA-262 规定： null == undefined; -> return true 按照airbnb的推荐风格，比较操作的时候一律推荐使用 === 和 !== ，而不要使用 == 和 != 。这样的话函数返回undefined的情况如何处理呢？ TODO。 typeof操作符 查看某个对象的对象类型，typeof操作符只可能返回以下六种结果，比如说前面提到的数组是属于object的；null也是属于object的。 number string object function array date regexp boolean null undefined symbol (new in es6) typeof x \"undefined\" typeof 1 \"number\" 定义函数 一个简单的函数定义和使用如下所示（下面这种写法是airbnb规范推荐的风格）: let greeting = function ( name ){ console . log ( name ); } greeting ( 'hello' ) 我们看到javascript明确将函数名作为一个变量，这是唯一要值得注意的，不过你也可以采用这种写法，这样更加为我们所熟悉了: function abs ( x ){ if ( x >= 0 ) { return x ; } else { return - x ; } } 这两种定义风格是完全等价的。这里值得一提的是如果函数没有确定return值，则返回的是 undefined 。 arguments用法 javascript的函数内部可以直接使用 arguments 这个变量，其不是一个Array，但可以如下使用: arguments[0] arguments.length 其会接受传入函数的所有参量。 rest用法 这个有点类似于lisp语言的rest参量控制概念，也就是如下 function func ( a , b ,... rest ){ console . log ( rest ); } rest是表示除了a和b之外的所有其余参量。注意前面三个点号: ...rest 。 箭头函数 简单来说箭头函数就是 lambda 表达式的更简洁写法，只是说在javascript语境里面其区别一般function的特点有： 其没有this绑定 。 ( param1 , param2 , … , paramN ) => { statements } 条件判断结构 条件判断结构，和python大同小异，除了那些圆括号（记住这个圆括号必须加上）和花括号。 var feedback = 10 if ( feedback > 8 ) { console . log ( \"Thank you! We should race at the next concert!\" ) } else { console . log ( \"I'll keep practicing coding and racing.\" ) } 虽然javascript不像python那样强制缩进风格，但还是推荐用缩进来增强你的代码可读性和逻辑清晰性，如: age = 20 if ( age < 6 ) { console . log ( 'kid' ) } else if ( age >= 18 ) { console . log ( 'adult' ) } else { console . log ( 'teenager' ) } javascript有switch语句，作为我们pythoner你懂的，用多个else if语句也是可以的。 循环结构 javascript和python都有while语句，但while语句用的较少，更多的是使用for语句。 for循环 var count = 10 ; for ( var i = 0 ; i < count ; i ++ ){ console . log ( i ); } for遍历数组 for ( let value of array ) { // do something with value } 遍历数组还可以这样： > a = [ 'a' , 'b' , 'c' ] < a . forEach ( function ( value , index ){ console . log ( value , index ); }); > a 0 > b 1 > c 2 这大体实现了类似于python的 enumerate 写法。 for遍历对象 然后递归遍历对象的key也是可以的: for ( var i in { 'a' : 1 , 'b' : 2 }) { console . log ( i ) } for实现while循环 下面是用for语句来实现while循环： var count = 10 ; var i = 0 ; for (; i < count ; ){ console . log ( i ); i ++ ; } for实现无限循环 下面是用for语句实现无限循环： for (;;){ dosomething; } while语句 while语句简单了解下吧。 var x = 0 ; var n = 99 ; while ( n > 0 ) { x = x + n ; n = n - 2 ; } 还有do while 语句 var n = 0 ; do { n = n + 1 ; } while ( n < 100 ); 异常处理 类似于python的 try...except... ，javascript有： try { throw （new Error(\"Invalid Parameters\")); }catch (e) { console.log(e); }finally { //always do something. } this关键词 这个有点类似于python中的self，在javascript里面，object里面定义的方法， this 指向的就是本对象的实例。 面向对象传统写法 function Point ( x , y ) { this . x = x ; this . y = y ; } Point . prototype . toString = function () { return '(' + this . x + ', ' + this . y + ')' ; }; var p = new Point ( 1 , 2 ); 新式写法 //定义类 class Point { constructor ( x , y ) { this . x = x ; this . y = y ; } toString () { return '(' + this . x + ', ' + this . y + ')' ; } } 如果 this 在函数里面，如： function (){ this . x = 1 ; } 那么指定的是当这个函数要运行的时候，具体调用这个函数的对象。 比如说某个函数将这样被调用： jquery对象.what 那么这个函数里面的this就是指定的那个jquery实例，通常也就是网页里面的某个标签元素。 集合 javascript中的集合Set大体也和python中的集合概念相近。 var s1 = new Set(); // 空Set var s2 = new Set([1, 2, 3]); // 含1, 2, 3 然后其也有 add 方法用于添加一个元素。用 delete 方法来删除某个元素。 三元运算符 test ? expression1 : expression2","tags":"html5","url":"articles/javascript-tutorial-one.html"},{"title":"前端开发之-jquery","text":"jquery基本语法 jquery的基本语法就是: $ ( selector ). action () 如果单 $(selector) 将返回找到的对象的数组，而进行某个action的时候是对所有找到的对象都进行如此动作。 文档初始化之后执行的动作 $ ( document ). ready ( function (){ // jQuery methods go here... }); 此外我们还常见一种简化的写法： $(function(){}); 然后有时你会看到这种写法： (function($){…})(jQuery) 这是运行了一个匿名函数，其参数为(JQuery)，前面用 $ 符号，是为了不与其他库冲突。（ 参考这篇文章 ） 获取屏幕的宽度和高度 var width = $ ( window ). width () var height = $ ( window ). height () 这两个方法更确切的描述是返回所选元素的宽度或高度。此外还有 innerWidth 和 innerHeight 方法（包含内边距）， outerWidth 和 outerHeight 包含内边距和边框。 hide方法 实际上就是css设置 display:none 。 $ ( '#test' ). hide () 这样将隐藏所有id为test的元素。 获取文本和修改文本 text() $('div').text() # 获取文本 $('div').text('new text') # 修改文本 此外还有 html() 方法，其可以写上html标签。 获取表单value值或修改 val方法 $('input').val() # 获取值 $('input').val('new value') # 修改值 css操作 添加class div.addClass('highlight'); // 添加highlight这个class 删除class div.removeClass('highlight'); // 删除highlight这个class 修改css $('div').css('background-color', '#ffd351'); 让按钮变为不可选 prop方法设置或返回被选元素的属性。 $(\"button\").prop('disabled', true) 移除所选元素 remove方法 $('#target4').remove(); 移动所选元素 将选中的元素移动到目标元素中。 $('#target2').appendTo('#right-well'); 复制所选元素 $('#target5').clone().appendTo('#left-well'); 选中父元素 $('#target1').parent().css('background-color','red'); 选中子元素 $('#right-well').children().css('color','orange'); 选中元素的第几个 $( '.target:nth-child(2)' ) . addClass ( 'animated bounce' ); $( '.target:even' ) . addClass ( 'animated shake' ); # 选中元素的偶数个 ， 0 2 4 ... 事件绑定动作 $(selector).click(function) 鼠标事件 click: 鼠标单击时触发； dblclick: 鼠标双击时触发； mouseenter: 鼠标进入时触发； mouseleave: 鼠标移出时触发； mousemove: 鼠标在DOM内部移动时触发 （接受e ，e.pageX是鼠标x值，e.pageY是鼠标Y值） hover: 鼠标进入和退出时触发两个函数，相当于mouseenter加上mouseleave。 键盘事件 键盘事件仅作用在当前焦点的DOM上，通常是 <input> 和 <textarea> 。 keydown: 键盘按下时触发； keyup: 键盘松开时触发； keypress: 按一次键后触发。 取消某个事件绑定 a.off('click', hello); jquery 动画效果 面板展开和隐藏 < script > $ ( document ). ready ( function (){ $ ( \".slidepanel\" ). click ( function (){ $ ( \"#panel-one\" ). slideToggle ( \"slow\" ); }); }); </ script > < div class = \"slidepanel\" style = \"background-color:#efefef; padding:5px\" > 滑动面板 </ div > < div id = \"panel-one\" style = \"border:solid 1px #efefef; padding:5px\" > just jquery it. </ div > 滑动面板 just jquery it. $(document).ready(function(){ $(\".slidepanel\").click(function(){ $(\"#panel-one\").slideToggle(\"slow\"); }); }); 页内导航慢慢移动 ajax jquery是基于 XMLHttpRequest 的，不得不承认jquery的ajax这块写得实在是太好了。 get $ ( \"button\" ). click ( function (){ $ . get ( \"/try/ajax/demo_test.php\" , function ( data , status ){ alert ( \"数据: \" + data + \"\\n状态: \" + status ); }); 回调函数接受两个参数，传回来的data和状态码。其等价于： $ . ajax ({ url : url , data : data , success : callback , dataType : dataType }); get请求上面的data将附加到url上。 getJSON 等价于： $.ajax({ url: url, data: data, success: callback, dataType: json }); 注意dataType设置为json post jQuery . post ( url , data , success ( data , textStatus , jqXHR ), dataType ) 等价于： $ . ajax ({ type : 'POST' , url : url , data : data , success : callback , dataType : dataType }); 上面的data是发送请求发送给服务器的数据。dataType可选，会智能判断服务器响应的数据。 跨域问题 参看了 js跨域 这篇文章， XMLHttpRequest 是不能跨域的。我们通常所说jsonp，就是一种实现跨域的解决方案，具体我不想太深究，因为一般restful api都是采用的json格式，而除了jsonp之外，服务端如下加上响应头也是可以的： header ( 'Access-Control-Allow-Origin:*' );// 允许跨域请求的域名 ， 允许全部设为 * header ( 'Access-Control-Allow-Methods:POST,GET' ); 先网络加载jquery或者本地加载 这里代码的意思应该是先网络加载jquery，如果没有则本地找找看。 <script src= \"https://code.jquery.com/jquery- {{ JQUERY_VERSION }} .min.js\" ></script> <script> window.jQuery || document.write(' <script src= \"js/vendor/jquery- {{ JQUERY_VERSION }} .min.js\" > < \\/script>') </script> $.fn $.fn 是jquery定义的一个命名空间，后面每个jquery实例都可以引用在这个命名空间中定义的方法。 $.extend $.extend({},{}) 相当于多个字典合并，若key重复，则以后面的字典的value为准。 $.trim 去掉字符串首尾空格 $().each() $().each() 将迭代jquery选中的各个实例。","tags":"html5","url":"articles/jquery.html"},{"title":"django后台api编写之-API设计原则","text":"API设计 首先讲一下这里讨论的API设计和网络上流行的Restful风格的API设计都只是一般性原则，并不是强制性的要求。然后API还分为内部使用和对外的API，如果对外的API那么接口最好遵循无惊讶原则，遵循大家都通用的一些写法风格，但如果是内部使用的API，那么很多情况下，还要考虑自己内部使用的便捷性要求。 url设计 目前url域名都推荐使用 api.what.com 这样的风格，然后关于API的版本，在URL上加上版本号，并不是一个很好的主意。在当前前后端分离的大背景下，这给前端和后端的代码都带来了一些额外的复杂度。 版本号按照 阮一峰的这篇文章 ，推荐使用 Accept 字段： Accept : vnd . example - com . foo + json ; version = 2.0 url的第一个字段我喜欢使用django的app的名字，然后接下来的第二个字段推荐按照 Restful 风格写上目标资源的名字，并不一定要强制写上名词的复数形式，不过如果有两个url，一个是操纵目标资源集，一个是定向操纵某个目标资源，那么尾缀写上s区分是推荐的风格。 然后针对某个资源或者目标资源集的一些额外的动作，这里所谓的额外的动作是指除了常规的Restful风格的那些增删查改动作之外的额外的动作需求，在上面讨论的Restful风格url基础上加上第三个字段，第三个字段是额外动作的名字是个不错的风格。 方法设计 方法通用的 GET POST ，GET用于查询获取资源信息，POST用于创建或修改信息这是没有疑问的。 虽然Restful风格还推荐的DELETE，PATCH等方法，但似乎大家实际编写都只是使用GET和POST方法。 参数设计 查询操作如果针对的是目标资源集合，有以下参数是推荐加上的： limit 返回个数 offset 偏移值，可以通过它来实现分页效果 sort 或者sortby等，总之一个排序的参数 reverse 排序是否反转的参数 状态码设计 具体请参看HTTP的各个状态码。 返回内容结构设计 我喜欢使用这种风格： 1. 成功则直接返回各个结果： { 'a':1 } 有些人会说成功之后也应该加上code:200的代码，可是这是完全没有必要的，如果你需要获取数据，那么拿就是了，如果你怕数据不存在，那么加个针对目标数据的判断即可。加个code:200，但是目标数据字段还是不存在，程序不一样也会报错？ 失败则必须带上code错误码和msg错误信息 { 'code': 10001, 'msg': 'your error msg' } 错误码软件系统内部应该有一个统一的规范，常见的错误类型有： 资源没有找到 找到多个资源 未知错误 输入缺少参数 编写良好的文档 这是当然。 参考 http://cizixs.com/2016/12/12/restful-api-design-guide","tags":"django","url":"articles/djangohou-tai-apibian-xie-zhi-apishe-ji-yuan-ze.html"},{"title":"django后台api编写之-apps.py","text":"apps.py 通过快捷命令创建的app模块是没有这个文件的，但是我看到某些例子里面其有这个文件，后来了解到这个文件是有特殊含义的：这是django项目用来存放app 一些相关配置信息的地方。 一个基本的例子如下： from django.apps import AppConfig class RockNRollConfig ( AppConfig ): name = 'rock_n_roll' verbose_name = \"Rock 'n' roll\" 其中name定义了本app的名字和完整名字，然后你需要在本app的 __init__.py 文件下加入： default_app_config = 'rock_n_roll.apps.RockNRollConfig' 来引入这个配置文件。 有什么用？well，最简单的用处就是本app实际在 INSTALLED_APPS 哪里不是默认的文件夹名字了，而是你这里定义的名字。 另外一个高级用法就是定制 ready 方法，来初始化本app的一些信号设置。","tags":"django","url":"articles/djangohou-tai-apibian-xie-zhi-appspy.html"},{"title":"django后台api编写之-beginning","text":"Beginning 一开始先介绍下Djanog项目的基本文件夹结构，还有一些基本的命令操作和一些基本的常识性东西。 首先是新建一个项目： 新建项目 django-admin startproject project-name 这个命令将创建一个文件夹，文件夹的名字就是这里设置的project-name，然后文件夹里面有一个manage.py文件，这个文件的主要作用就是挂载django的配置（一般是settings.py这个文件，当然你也可以修改为其他比如dev_settings.py文件）。 然后还有一个文件夹，里面有settings.py 、 urls.py 和 wsgi.py 文件。 settings.py 控制django的全部配置管理； urls.py 控制django的路径分发主入口，这个在配置中可以修改的。 wsgi.py 是你用apache或者uwsgi挂载的时候的控制入口。 这样最简单的初始项目就是可以运行的了： 开启服务器 python manage.py runserver localhost:8080 后面控制服务器监听的localhost或者外网0.0.0.0，然后就是端口号。 新建一个app python manage.py startapp app_name 这里顺便说一下，有一些项目你可能找不到 manager.py 这个文件了，其实这个文件就是一个便捷入口罢了，所有的命令一样都可以通过 django-admin 命令来运行的。 数据库操作 定义模型之后，你需要运行: python manage.py makemigrations app_name 这个过程就是创建每个app下的migrations文件夹下面的一些迁移python脚本文件，有的时候某些情况你可能需要手工修改这些迁移文件。 python manage.py migrate 这个命令就是实际执行那些迁移python脚本。 交互式环境 进入python交互环境，这个和纯python交互环境的区别就是里面可以直接使用django里面的一些东西了，比如你定义的模型对象就可以直接使用了。这个对你开发进行测试工作非常有用！ python manage.py shell 或者进入sql实现的交互环境: python manage.py dbshell 创建超级用户 最开始创建的项目就把admin url挂上去了，你可以去 \\verb+/admin+ 这个url下看一下，但要登录除了做一下上面的数据库表格创建工作外，还需要创建一个超级用户用于登录。 python manage.py createsuperuser","tags":"django","url":"articles/djangohou-tai-apibian-xie-zhi-beginning.html"},{"title":"django后台api编写之-部署","text":"部署 这里所谓的部署就是用apache或nginx这样的web服务器来对接django项目，说的再具体一点就把django作为一个wsgi程序服务起来。 本文关于apache的部署讲解较为成熟。 apache 上例子吧： <IfModule !wsgi_module > LoadModule wsgi_module modules/mod_wsgi.so </IfModule> WSGIPythonHome \"/home/wanze/venv\" WSGIPythonPath \"/home/wanze/venv/webapp\" <VirtualHost *:80 > ServerName api.cdwanze.work WSGIScriptAlias / /home/wanze/venv/webapp/webapp/wsgi.py <Directory /home/wanze/venv/webapp > <IfVersion > = 2.4> Require all granted </IfVersion> <IfVersion < 2.4 > Order deny,allow Allow from all </IfVersion> </Directory> Alias \"/static\" \"/home/wanze/venv/webapp/static\" <Directory /home/wanze/venv/webapp/static > <IfVersion > = 2.4> Require all granted </IfVersion> <IfVersion < 2.4 > Order deny,allow Allow from all </IfVersion> </Directory> </VirtualHost> 首先是检测wsgi模块加载了没有，没有把它加载上。 WSGIPythonHome 这个设置你的python的虚拟环境的所在目录，比如上面的例子 venv/bin下面就是python可执行脚本。 WSGIPythonPath 这个设置你的Django项目目录所在 WSGIScriptAlias 这个设置你的WSGI文件所在 Alias 和下面Directory 设置是服务你的项目的静态文件的。 关于静态文件 关于静态文件再补充下，上面服务的静态文件是在项目目录下的static文件夹下，这里所谓的静态文件主要是djano和djangorestframwork等框架带的静态文件，其通过 python manage.py collectstatic 命令来生成这些内容。 你需要在settings那里设置 STATIC_ROOT 值。 STATIC_ROOT= os.path.join(BASE_DIR, 'static') 多django站点部署问题 多个django站点都通过 mod_wsgi 来部署是不能继续像前面那样写： WSGIScriptAlias / /path/to/mysite.com/mysite/wsgi.py WSGIPythonHome /path/to/venv WSGIPythonPath /path/to/mysite.com 而必须每个通过deamon模式来（参考了 这个网页 ）： <VirtualHost *:80> ServerName api.cdwanze.work WSGIDaemonProcess cdwanze_api processes=1 python-path=/home/wanze/venv/myapi python-home=/home/wanze/venv/ threads=10 WSGIProcessGroup cdwanze_api WSGIScriptAlias / /home/wanze/venv/myapi/myapi/wsgi.py process-group=cdwanze_api ... 其中 WSGIProcessGroup 目前来看名字是随意的，但必须写。然后在定义daemon进程的时候 python-path 是定义到你的django project那里， python-home 是定义到你的python虚拟环境那里。 文件权限问题 除了上面设置好 Directory 之外，你可能还会遇到其他某些文件的读写权限问题，在查看日志的时候发现提示说那个文件没有权限读写了。这个时候首先要明确httpd的执行User和Group是谁，然后在看目标文件夹或文件的具体权限。 Django项目的wsgi文件是需要有执行权限的。还有Django项目操纵数据库，比如sqlite3这种文件数据库，你可能也会遇到读写权限问题。 还有值得一提的是如果某个母文件夹没有可执行权限，那么里面的所有文件都是不可见的。 nginx nginx要对接wsgi接口需要uwsgi这个模块将wsgi接口服务起来。 pip install uwsgi 更多细节请参看uwsgi的 官方文档 。 ngnix的配置如下： upstream django { server 127.0.0.1:8001 ; } server { location / { uwsgi_pass django ; include /path/to/your/mysite/uwsgi_params ; } } nginx serve 静态文件 server { listen 80; ...... client_max_body_size 75M; location /media { alias /path/to/media; } location /static { alias /path/to/static; } ...... } 更多nginx配置细节请参看我写的关于nginx配置的专门的文章。 对外部署必看 django项目如果对外部署的话，因为python是一个动态脚本语言，所以会有很多安全性的问题需要检查，否则你的项目对外会很不安全。本文主要参看官方文档的 这里 。 第一当然首先是确保 DEBUG=False ，对外开着 DEBUG=True 那简单是开玩笑了。 然后是运行： python manage.py check --deploy ### settings.py 里密钥外置 settings.py 文件里面不要有任何密钥信息，包括 SECRET_KEY 你的数据库连接信息或者其他密钥等等，所有这些信息都应该作为环境变量引入或者从某个配置文件中读取出来。 ALLOWED_HOSTS 要某是限定好域名，要某是你的nginx服务器那边对入口请求已经做好了限定，凡是不认识的域名HOST请求都抛出444错误： server { listen 80 default_server; return 444; }","tags":"django","url":"articles/djangohou-tai-apibian-xie-zhi-bu-shu.html"},{"title":"django后台api编写之-创建可复用的app","text":"创建可复用的app 创建可复用的app会极大的降低你的目标django项目的复杂度，如果可能，将你的app打造成可复用的风格总是首选。 制作django-what的pypi包 有关pypi包的制作就不赘述了，下面主要在官方文档 这里 的基础上讨论一些问题。 测试问题 我试着如下安装测试过程： python setup.py sdist pip install dist/what.tar.gz 然后安装官方文档，在INSTALL_APPS那里设置好。app是可以正常使用的。但在安装测试过程中，这实在有点繁琐了。推荐还是将整个app文件夹复制到你的测试webapp那边去，然后一边修改一边看。测试好了再把内容同步到pypi安装包那边去。 migrations问题 官方文档之所以选择制作sdist和用pip install tar包这种风格是有原因的，经测试egg包在访问上很成问题，只有用pip安装这种方法，在site-packages那边你安装才是文件夹风格而不是那种egg文件。这样你等下执行： python manage.py makemigrations app_name 才会成功。 而且实际生成的迁移文件就放在site-packages那里的目标文件夹下的。所以你制作pypi包的时候不要把migrations文件夹里面的其他迁移文件包含进去了，要包含就包含 __init__.py 文件即可。 当然就算你不是制作django的目标pypi包，其他django项目在 .gitignore 文件上加上这一行总是不错的： */migrations/* PS: 我知道stackoverflow那边都认为应该加上，还有人专门写了长篇大论认为应该加上。我确定的只有一点：早期测试开发过程，所有的migrations文件夹里面都只有 __init__.py 这个空白文件，保持代码整洁，在测试开发阶段不花精力在这上面，这是没有争议的。","tags":"django","url":"articles/djangohou-tai-apibian-xie-zhi-chuang-jian-ke-fu-yong-de-app.html"},{"title":"django后台api编写之-单元测试","text":"单元测试 单元测试前期开发如果只是关注于后台api的话，实际上编写一套postman请求也是可以的，后期再考虑上代码级的单元测试。 from rest_framework.test import APITestCase from rest_framework import status import django from django.urls import reverse import mock class Tests ( APITestCase ): def test_permutation ( self ): \"\"\" :return: \"\"\" data = { 'n' : 10 , 'k' : 3 } response = self . client . get ( reverse ( 'arithmetic-permutation' ), data ) result = response . data . get ( 'result' ) self . assertEqual ( response . status_code , status . HTTP_200_OK ) self . assertEqual ( result , 720 )","tags":"django","url":"articles/djangohou-tai-apibian-xie-zhi-dan-yuan-ce-shi.html"},{"title":"django后台api编写之-django和celery","text":"django和celery django-crontab这个模块我试过的，还是很便捷的，不过其还是基于系统的crontab，而如果我们将django和celery组合起来，celery灵活的消息分发机制，无疑将给未来开发带来更多的可能性。celery的官方文档在 这里 ，本文主要讲一下celery的基本概念和django的集成问题，更多celery的知识请参阅官方文档。 celery的核心概念 broker 任务队列服务提供者，celery推荐使用redis或者rabbitmq作为broker。 task 具体执行的任务，其实就是定义的一些函数。 backend 用来存储任务之后的输出结果 worker celery的启动就是开启一个worker。 django内文件安排 本小节参考了 这篇文章 和 这篇文章 。需要提醒读者的是，django和celery集成现在并不需要额外安装什么插件了，而且下面讲的配置实际上就是一个单独的celery app大部分都是类似的，只是多了一些细节上的处理和优化。 celeryconfig.py 首先推荐在你的django app settings.py 旁新建个 celeryconfig.py 文件，有的教程让设置这个配置文件名字为 celery.py ，这样很不好，文件名和某个模块名字重复有时会出问题的。里面的内容如下： import os from celery import Celery os . environ . setdefault ( 'DJANGO_SETTINGS_MODULE' , 'project_name.settings' ) app = Celery ( 'project_name' ) app . config_from_object ( 'django.conf:settings' , namespace = 'CELERY' ) app . autodiscover_tasks () @app.task ( bind = True ) def debug_task ( self ): print ( 'Request: {0!r}' . format ( self . request )) 这个下面新建的任务不过是方便测试罢了，然后上面几行配置基本上死的。最值得讲的就是这两行： app.config_from_object('django.conf:settings', namespace='CELERY') app.autodiscover_tasks() 第一行是从django的配置对象中读取配置，特别注意的就是那个 namespace='CELERY' ，这样只有 CELERY_ 开头的配置才会读取，而且对应原celery配置的关系是： CELERY_BROKER_URL -> BROKER_URL 我那次就是 CELERY_BEAT_SCHEDULE 写成了 CELERYBEAT_SCHEDULE 然后老实发现周期性程序启动不起来。 第二行也是一个优化细节，从函数名字也可以看到，就是自动发现任务。在你的django的其他app里面新建一个 tasks.py ，celery会自动发现你定义的任务。 __init__.py 还是你的django项目的project settings.py 那个文件夹里面， __init__.py 推荐写上这几行内容： from .celeryconfig import app as celery_app __all__ = ( 'celery_app' ,) settings.py 具体celery的一些配置就统一写在 settings.py 文件里面，上面也提到了，都要 CELERY_ 开头，大体如下所示： CELERY_BROKER_URL = 'redis://localhost:6379' #CELERY_RESULT_BACKEND = 'redis://localhost:6379' #CELERY_ACCEPT_CONTENT = ['application/json'] #CELERY_RESULT_SERIALIZER = 'json' #CELERY_TASK_SERIALIZER = 'json' CELERY_TIMEZONE = 'Asia/Shanghai' # schedules from celery.schedules import crontab CELERY_BEAT_SCHEDULE = { 'crawl_juhe_every_one_hour' : { 'task' : 'wxarticles.tasks.crawl_juhe' , 'schedule' : crontab ( minute = 0 , hour = '*/3' ), }, 'every_miniute_for_test' : { 'task' : 'wxarticles.tasks.test_celery' , 'schedule' : crontab (), }, } 定义任务 好了，定义任务，实际上就是定义一个函数，比如下面这个简单的打印函数来确认celery周期程序是工作着的： from celery import shared_task @shared_task () def test_celery (): print ( 'celery is working.' ) celery的crontab功能很强大，比如上面的 crontab() 就是每分钟执行一次。具体请参看 官方文档 之。 启动任务 和celery其他操作都是一样的，就是启动worker： celery -A project_name worker -l info -A 选项跟着 celery app的名字，在这里也就是django项目的名字。 -l 选项设置日志打印级别。 你还可以加上 -B 来同时启动周期性任务。 或者另外开个命令： celery -A project_name beat -l info 其他制作脚本啊，制作后台程序，制作服务啊，使用supervisor啊，实际上和celery关系已经不大了，可以不在这里说了。 手工启动一次任务 参考了 这个网页 。 $ python manage . py shell >>> from myapp.tasks import my_task >>> eager_result = my_task . apply ()","tags":"django","url":"articles/djangohou-tai-apibian-xie-zhi-djangohe-celery.html"},{"title":"django后台api编写之-django和scrapy","text":"django和scrapy django也可以和scrapy集成起来，简单来说就是通过 scrapyd ，django发送一个信号，然后scrapyd 后台启动一个爬虫任务。本小节主要参考了 这篇文章 ，谢谢作者。 这样做有什么好处？大体有以下好处： 爬虫的运行状态信息可查询可操作 爬虫后台爬取不卡顿前台显示 以信号为基础可以和celery结合起来从而建立更加复杂的基于简单的HTTP信号机制的爬虫系统（包括周期性任务或者其他任务等等） 读者请参看上面这篇文章，下面我就一些最核心的点来描述之。 从views开始说起 from scrapyd_api import ScrapydAPI scrapyd = ScrapydAPI ( 'http://localhost:6800' ) @api_view ([ 'POST' ]) def crawl_article ( request ): \"\"\" POST : 传递公众号和文章title，然后运行spider去爬取。 GET ; 查询某个爬虫进行到了什么状态 :param request: :return: \"\"\" if request . method == 'POST' : mode = int ( request . data . get ( 'mode' , 1 )) if mode == 1 : gzh_id = request . data . get ( 'gzh_id' , None ) if not gzh_id : return OurResponse . fail_missing_paras ( msg = \"missing gzh_id\" ) settings = { 'gzh_id' : gzh_id , 'mode' : mode , } task = scrapyd . schedule ( 'default' , 'article' , settings = settings , ** settings ) return OurResponse . sucess_response ( task_id = task , gzh_id = gzh_id , status = 'started' ) 你需要安装的pypi包有： django ，当然， python-scrapyd-api 同scrapyd交谈的python api接口。 Scrapy 和 scrapyd 。 最核心的就是 scrapyd.schedule() 这个函数， default 是projecet name，意义有待进一步阐明。然后 article 就是具体你写的爬虫名字，然后还可以传递一些参数进去，这些参数实际传到了scrapy爬虫那边，简单来说就是你如果要手工模拟的话加上 -a mode=1 也是一样的效果。这些参数到了爬虫类那里可以直接 self.mode 调用那是后话了。 所以scrapyd，ok，后台开了一个爬虫，还有什么要说的吗？没了。就django和scrapy集成知识来说没了，scrapy那边数据怎么存等等那都是scrapy那边的问题了。 最后粘贴个查看spider运行状态的视图函数吧，之所以粘贴出来是因为其和本文讨论的 python-scrapyd-api 有关，暴漏了很多api操作，可以简单看下了解下。 @api_view ([ 'GET' , 'POST' ]) def crawl_index ( request ): \"\"\" task_id # 如果有则根据task_id 来查询 或者根据 status 来过滤查询 '' running pending finished project_name 参数默认 default :param request: :return: \"\"\" if request . method == 'GET' : project_name = request . query_params . get ( 'project_name' , 'default' ) task_id = request . query_params . get ( 'task_id' , None ) if task_id : status = scrapyd . job_status ( project_name , task_id ) if not status : return OurResponse . fail_uri_not_found ( msg = 'task_id not found' ) else : return OurResponse . sucess_response ( task_id = task_id , status = status ) status_filter = request . query_params . get ( 'status' , '' ) data = scrapyd . list_jobs ( project_name ) if status_filter : data = scrapyd . list_jobs ( project_name ) data = { status_filter : data . get ( status_filter )} return OurResponse . sucess_response ( ** data ) elif request . method == 'POST' : task_id = request . data . get ( 'task_id' , None ) if not task_id : return OurResponse . fail_missing_paras ( msg = 'missing task_id' ) status = scrapyd . cancel ( 'default' , task_id , signal = 'TERM' ) # kill it twice status = scrapyd . cancel ( 'default' , task_id , signal = 'TERM' ) return OurResponse . sucess_response ( task_id = task_id , status = status )","tags":"django","url":"articles/djangohou-tai-apibian-xie-zhi-djangohe-scrapy.html"},{"title":"django后台api编写之-翻译","text":"翻译 django的翻译其实已经很便捷了，因为我关注于后台api的编写，所以实际上很多教程说的： TEMPLATES = [ { ... 'OPTIONS': { 'context_processors': [ ... 'django.template.context_processors.i18n', ], }, }, ] 这个配置只和模板输出的翻译有关，有需要再加上。 然后MIDDLESWARES 哪里要加上： 'django.middleware.locale.LocaleMiddleware', 然后就是这些配置： LANGUAGE_CODE = 'zh-Hans' USE_I18N = True 设置好你的语言代码，这是没有问题的。 我看了一下 django restframework 的翻译管理相关，发现大体这样配置就可以了，很多教程说的设置 LOCALE_PATHS 变量觉得没必要，默认的每个app下面的locale文件夹够用了。 然后就是目标py文件下的 字符串 如下装饰之： from django.utils.translation import ugettext_lazy as _ ... if username is None : raise TypeError ( _ ( 'Users must have a username.' )) Model字段定义的名字可以加上，verbose_name 可以加上，然后异常信息可以加上等等。 加完了之后运行： django-admin makemessages -l zh_Hans app下面没有locale文件夹的创建个就是了，某些文件你不想管，比如 manage.py ，那么加上 --ignore 选项即可。 windows下不是很方便，推荐在linux服务器下创建了目标 django.po 文件，然后再修改文件即可。其中po文件的头部有些东西，估计： \"Language: zh-Hans\\n\" 已经是必填的，其他有时间也填上吧。 然后运行: django-admin compilemessages 如果不出意外的，翻译就已经生效了。","tags":"django","url":"articles/djangohou-tai-apibian-xie-zhi-fan-yi.html"},{"title":"django后台api编写之-基于类的视图","text":"基于类的视图 首先我们从django哪里初步了解了下基于类的视图的概念，就是如下代码： from django.http import HttpResponse def my_view ( request ): if request . method == 'GET' : # <view logic> return HttpResponse ( 'result' ) 变为更简洁的： from django.http import HttpResponse from django.views import View class MyView ( View ): def get ( self , request ): # <view logic> return HttpResponse ( 'result' ) 然后依赖类的继承，引入Minxin类，可以让我们在http的很多restful风格请求上，总是一次又一次出现的那些套路，实现代码复用。其基本知识就是python的类的继承，我们可以直接从django restframework 这个模块直接用手来见识这种DRY理念的实现。 APIView django restframework的 APIView 继承自 django 的 View，然后针对restful api 进行了很多优化，在某些情况下可能你编写的视图，就继承自APIView就是合适的，后面介绍的通用视图和其他高级视图等等，都是在某些情况下特别合适和让你少写代码，好用就用，仅此而已。如果不合适，那么自己定义 get post put 等等方法也是很方便的。 视图再升级 在某些情况下使用 APIView 类和 Mixin 可能是最合适不过的，下面谈谈django restframework 提供的高级通用视图类。这些类都是继承自 GenericAPIView ，他们都有一个特点，那就是有点类似于 Serializer -> ModelSerializer 的升级过程，如果你的视图类方法主要操作对象是基于数据库Model的各个操作，那么推荐视图类继承自 GenericAPIView 。 GenericAPIView GenericAPIView 继承自 django restframework 的 APIView 类，其提供的一个很重要的特性是 queryset ，你设定 queryset属性或者实现 get_queryset 方法，该视图类的很多方法都是围绕着 queryset 来展开的。 具体 CRUD 数据操作有对应的 Minxin类，然后和GenericAPIView 组合出了很多高级的视图类。 一个好的建议对于这块，看源码，源码都很简单的，看懂了，发现符合自己的需要那就使用它，让自己少写点代码。如果有额外的定制需求，那就重写对应的某个方法就是了。","tags":"django","url":"articles/djangohou-tai-apibian-xie-zhi-ji-yu-lei-de-shi-tu.html"},{"title":"django后台api编写之-扩展用户模型","text":"扩展用户模型 本小节主要参考了这篇 不错的文章 。一般扩展django自带的用户模型，最常见的就下面两种情况，实际上这两种情况你可能都会使用到。第一种是 User 模型 和 Profile 模型的分开，然后User用来存放登录相关信息，而Profile用来存放更多的用户资料信息，一般User 和 Profile 是 onetoone 关系，这个时候我们会考虑建立一个signals文件来保证没创建一个User就会跟着创建一个Profile： from django.db.models.signals import post_save from django.dispatch import receiver from profiles.models import Profile from .models import User @receiver ( post_save , sender = User ) def create_user_profile ( sender , instance , created , ** kwargs ): if created : Profile . objects . create ( user = instance ) @receiver ( post_save , sender = User ) def save_user_profile ( sender , instance , ** kwargs ): instance . profile . save () 然后你可能对django默认的auth机制，比如session cookies等不太满意，那么推荐你直接建立自己的 User 模型， 继承自 AbstractBaseUser ，我大概看了一下 AbstractBaseUser 的源码，其做的工作都是围绕着 password这个字段来的，而且只要你在settings里面定义好了: AUTH_USER_MODEL = ... 就都是可以正常工作的。继承之后定义自己的字段这是不多用多说的，然后推荐进一步继承 PermissionsMixin 这个类。 class User ( AbstractBaseUser , PermissionsMixin ) : email = models . EmailField ( _ ( 'email address' ), unique = True ) PermissionsMixin 这个类定义了一些群组信息还有什么的。 然后这三个字段属性有特殊含义，都是可以自己设置的： USERNAME_FIELD = 'username' EMAIL_FIELD = 'email' REQUIRED_FIELDS = ['email'] 然后你需要写好 objects 这个 UserManager ，其继承自 BaseUserManager ，你可以做其他一些定制，这个是个什么东西？这个就是之前我们看到的 Model.objects.what 之类的这种用法。在这里你需要根据自己的情况定义好： create_user create_superuser 这两个方法即可。就用这两个方法来控制用户的创建行为。其中 create_superuser 主要负责把 is_superuser is_staff 设为True。","tags":"django","url":"articles/djangohou-tai-apibian-xie-zhi-kuo-zhan-yong-hu-mo-xing.html"},{"title":"django后台api编写之-模型的定义和使用","text":"模型的定义和使用 django的模板和sqlalchemy还是有很多地方类似的。 settings那边的配置 INSTALLED_APPS: 你需要加上你新加入的 app 的名字，不加的话是不能通过 makemigrations 来管理数据库的。 DATABASES: 默认会创建一个sqlite3数据库，也能满足基本的需求了，如果你想要使用mysql等数据库，则参考样例修改这里的配置。比如连接mysql的样例是: DATABASES = { 'default': { 'ENGINE': 'django.db.backends.mysql', 'NAME': \"database_name\", 'USER': \"root\", 'PASSWORD': \"\", 'HOST': \"localhost\", 'PORT': \"3306\", 'OPTIONS': { 'charset': 'utf8' } } } 一般会加上 charset 是 utf8这个选项，当然mysql那边你也需要设置好字符编码。有的时候如下设置init_command 来设置字符编码可以让你获得更好的字符编码兼容性。 'OPTIONS': { 'init_command': 'SET character_set_database=utf8 ,\\ character_set_server=utf8,\\ character_set_connection=utf8,\\ collation_connection=utf8_unicode_ci', 'charset': 'utf8'} 使用多个数据库 有的时候你需要使用多个数据库，最常见的情况是某个单独的app使用另外一个数据库。 首先你需要再加上另外一个数据库的定义： DATABASES = { 'default': { 'ENGINE': 'django.db.backends.mysql', 'NAME': \"database_name\", 'USER': \"root\", 'PASSWORD': \"\", 'HOST': \"localhost\", 'PORT': \"3306\", 'OPTIONS': { 'charset': 'utf8' } }, 'youapp': { 'ENGINE': 'django.db.backends.mysql', 'NAME': 'youapp', 'USER': 'root', 'PASSWORD': '', 'HOST': '', 'PORT': '', 'OPTIONS': {'charset': 'utf8'} }, } 然后在你的app那边新建一个dbrouter文件，里面定义一个YourRouter类。 DATABASE_ROUTERS = ['youapp.dbrouter.YourRouter'] 在这个类里面如下定义一些数据库选择行为： NOTICE: 在这个app中定义的模型记得都要加上app_label这个meta属性。 class YourRouter ( object ) : def db_for_read ( self , model , ** hints ) : if model . _meta . app_label == 'youapp' : return 'youapp' return None def db_for_write ( self , model , ** hints ) : if model . _meta . app_label == 'youapp' : return 'youapp' return None def allow_relation ( self , obj1 , obj2 , ** hints ) : if obj1 . _meta . app_label == 'youapp' or \\ obj2 . _meta . app_label == 'youapp' : return True return None def allow_migrate ( self , db , app_label , model_name = None , ** hints ) : if app_label == 'youapp' : return db == 'youapp' return None 定义模型 好了，开始实际定义自己的模型了。首先基本语法如下: from django.db import models class Question ( models . Model ): question_text = models . CharField ( max_length = 200 ) pub_date = models . DateTimeField ( 'date published' ) 这个熟悉sqlalchemy的对这段代码不会很陌生，下面进一步了解一些细节吧。 字段类型 IntegerField: 整型 BigIntegerField: 大整数 BinaryField: raw data BooleanField: bool 值 CharField: 定义字符串类型，比如设置最大长度 max_length 这个属性。 TextField: 大段文字用这个。 DateField: 对应python中的 datetime.date 对象。 DateTimeField: 对应python中的 datetime.datetime 对象。 一个有用的基类: class BaseModel ( models . Model ): class Meta : abstract = True updated_at = models . DateTimeField ( auto_now = True ) created_at = models . DateTimeField ( auto_now_add = True ) 后面的模型都可以继承自该基类，基类是不会创建表格的，因为其Meta设置了 abstract=True 。DateTimeField加上 auto_now=True ，那么该模型每次 save 操作都会自动更新最新日期。 然后 auto_now_add=True 即该记录第一次创建时设置最新的日期。然后如果DateTimeField使用了 auto_now 或者 auto_now_add 这两个选项了就不要使用default选项了，还有就是自动插入的默认的时间是由 django.utils.timezone.now() 获得的。 比如后面你想获得六个小时之前的所有记录那么可以如下查询： checktime = timezone.now() - timedelta(hours=6) result = result.exclude(created_at__gt= checktime) 通用选项 字段声明控制中有一些通用可选项: default: 设置该字段的默认值，注意default还可以接受一个函数对象。 null: 设置为True，则该自动会自动填充sql中的NULL值，字符串类型字段最好默认空字符。 blank: 如果设置为True，则空值也是允许的，其和null的区别是null是说数据库那边的，而blank是说显示那边的。 db_column: 设置该字段具体在数据库中对应的表格的名字。 db_index: 设置为 True 则表示该字段开启索引。 primary_key: 主键 。 unique: 唯一 unique_for_date: 比如title字段设置: unique_for_date=\"pub_date\" 则 title字段和 pub_date 字段都不能相同。也就是在某个日期内某个title只能有唯一值。可以看作一种 unique_together 的应用。 数据库中的关系 ForeignKey: 外键引用，如果该字段的名字是user，那么实际存储在表格中的名字是user_id，你可以通过 db_column 来实际控制该表格的名字。- 我们通常说的onetomany关系就是通过定义ForeignKey来获得的。比如： class City ( models . Model ) : name = models . CharField ( max_length = 60 ) state = models . CharField ( max_length = 40 ) zipcode = models . IntegerField () class Address ( models . Model ) : number = models . IntegerField () street = models . CharField ( max_length = 100 ) city = models . ForeignKey ( City ) 一个city有多个address，但是一个address只能有一个city，也就是一个外键映射到city那边。所以我觉得ForeignKey更确切的表示是manytoone关系，当某个模型有一个外键属性是，也就是可以有多个记录指向同一个它物 参阅了这篇文章 。 OneToOneField OneToOneField 比较简单，就是一个记录只有一个对应的属性，通常在用户管理的时候会用到。 ManyToManyField ManyToManyField 读者请参阅我写的 sqlalchemy模块 一文， 那里写得比较详细。 关于模型定义的字段，更多的内容请参看官方文档。 多字段组合唯一 参考了 这个网页 ，具体就是在 Meta 那里定义 unique_together 属性。 ... title = models.CharField(max_length=255) gzh_id = models.CharField(max_length=255, null=True, blank=True) ... class Meta: db_table = 'article' unique_together = (\"title\",\"gzh_id\") 定义模型中的元类数据 ... class Meta: db_table = 'table_name' db_table 具体指定实际创建的table表格的名字。 abstract 将不会创建表格，该模型为抽象模型。 模型的使用 模型的使用最核心的部分就是查询操作，至于修改记录，则具体查询获得目标记录了，修改属性然后save即可。 新建记录 from people.models import Person Person . objects . create ( name = \"WeizhongTu\" , age = 24 ) 但是要注意如果你插入一条记录出现主键重复问题了，那么程序是会返回异常的。一般推荐使用 get_or_create 方法： obj, created = Person.objects.get_or_create(first_name='John', last_name='Lennon', defaults={'birthday': date(1940, 10, 9)}) 上面这个语句有查询的效果也有新建记录的效果。写的这些属性首先将进行get操作，大体是如下的加强版： try : obj = Person . objects . get ( first_name = 'John' , last_name = 'Lennon' ) except Person . DoesNotExist : obj = Person ( first_name = 'John' , last_name = 'Lennon' , birthday = date ( 1940 , 10 , 9 )) obj . save () 而如果单纯使用get方法，如果记录不存在那么会抛出 DoesNotExist 异常；如果找到多个记录，会抛出 MultipleObjectsReturned 异常。 get_or_created 方法如果找到多个记录也会抛出 MultipleObjectsReturned 异常。 这样 get_or_created 方法将确保总是插入一条记录或者取得记录。其中created=True则表明target是新建的记录。 然后是如何理解 defaults 这样选项，defaults里面定义的属性不会参与get查询过程，其参与的是在没有找到记录的情况下，设置某些值。 查询记录 首先说一下获取所有的记录： result = Person.objects.all() 其返回的是 QuerySet 对象，QuerySet对象可以继续进行下一步的查询操作。比如下面可以继续： result = result.filter(name=\"abc\") 当然就上面的例子来说直接使用filter方法即可： result = Person.objects.filter(name=\"abc\") 排序 QuerySet对象可以进一步排序： result = result.order_by('what') reverse result = result.reverse() exclude 排除某些记录，下面是排除created_at这个字段值大于某个时间的值： result = result.exclude(created_at__gt= checktime) offset and limit result = result[offset: offset+limit] 删除某个记录 找到目标记录的instance，然后调用 delete 方法即可。 确定某记录是否存在 前面已经谈到了一些查询操作，而如果读者只是单纯的想确定某记录是否存在，那么使用 exists 方法是最快和最简便的。参考了 这个网页 。 if Article.objects.filter(unique_id= unique_id).exists(): ... 关系的使用 OnetoOne关系的使用非常简单， a.b 或者 b.a 都是可以的。 ManytoOne关系也就是由 ForeignKey 定义的关系，如果是引用外键的那个对象，那么直接 a.b 即可，如果是反向onetomany那种，则最好你在定义的时候就定义好 related_name ，（参考了 这个问题 ）那么引用如下： b.related_name 具体使用细节还是请查看文档的 这里 。","tags":"django","url":"articles/djangohou-tai-apibian-xie-zhi-mo-xing-de-ding-yi-he-shi-yong.html"},{"title":"django后台api编写之-其他技巧","text":"其他技巧 模型python2兼容性 为了提高模型python2兼容性，推荐模型定义上加个如下装饰器。 from django.utils.encoding import python_2_unicode_compatible @python_2_unicode_compatible class Question ( models . Model ): # ... def __str__ ( self ): return self . question_text 以前不加这个装饰器，python2之前用的是 __unicode__ 方法。 重置migrations 一般的方法把migrations文件删掉，把表格删掉并不能成功，因为他们忽视了django_migrations这个表格里面的数据（参考了 这个网页 ）。 如果你把 django_migrations 里面的对应app的迁移数据删掉，然后再makemigrations和migrate，那么就更重新开始的一样。 python manage.py makemigrations app_name python manage.py migrate app_name 处理列表对象 我们需要自定义一个model的新Field对象来解决这个问题，具体就叫做ListField。 def parse_to_python ( value ) : try : value = ast . literal_eval ( value ) return value except Exception as e : rasie ValidationError class ListField ( models . TextField ) : \"\"\" 存储python列表对象 \"\"\" description = _ ( \"Stores a python list\" ) def __init__ ( self , * args , ** kwargs ) : super ( ListField , self ). __init__ ( * args , ** kwargs ) def to_python ( self , value ) : if value is None : value = value if isinstance ( value , list ) : return value return parse_to_python ( value ) def get_prep_value ( self , value ) : if value is None : return value value = six . text_type ( value ) return value def value_to_string ( self , obj ) : value = self . value_from_object ( obj ) return self . get_prep_value ( value ) def from_db_value ( self , value , expression , connection , context ) : if value is None : return value return parse_to_python ( value ) from_db_value 当数据从数据库里面读取出来，总会调用这个方法。包括（including in aggregates and values() calls。 所以这是最重要最核心的一个定制方法，其含义是很明显的，不用多说了。 这四个方法大体如下流程： python <- to_python <- from_db_value <- database python -> value_to_string -> get_prep_value -> database NOTICE 上图主要是方便读者理解，实际上django并不是这样逐个处理的。按照官方文档的说法 to_python 和django的反序列（deserialization ）有关，其还必须处理好三种情况：None，目标对象，字符串情况。 value_to_string 和序列化有关，和 to_python 是相对的。 get_prep_value 和我们在输入get(what='20170809') 执行查询是有关，讲过其转化成为sql实际查询中用到的字符串（比如说datetimefield）就做了一些额外的处理工作。 多数据库处理 一个django项目里面可能因为某些原因，某些app需要单独操作另外的数据库，这种情况你首先在 settings 那里定义好数据库的配置： DATABASES = { 'default': { ... }, 'newdb': { 'ENGINE': 'django.db.backends.mysql', ... }, 然后加上这个dbroute对象： DATABASE_ROUTERS = ['articles.dbrouter.ArticlesRouter'] 然后在你的app那里定义好dbroute对象： class ArticlesRouter(object): def db_for_read(self, model, **hints): if model._meta.app_label == 'articles': return 'articles' return None def db_for_write(self, model, **hints): if model._meta.app_label == 'articles': return 'articles' return None def allow_relation(self, obj1, obj2, **hints): if obj1._meta.app_label == 'articles' or \\ obj2._meta.app_label == 'articles': return True return None def allow_migrate(self, db, app_label, model_name=None, **hints): if app_label == 'articles': return db == 'articles' return None 从上面的代码可以看出来，你定义的模型 Meta 那里必须定义好 app_label 属性。更多信息请参看官方文档的 这里 。 如何根据django的模型对象来获取其对应的表格的名字 参看 这个网页 。 答: model_instance._meta.db_table 如何使用好django的ImageField 参考了 这篇文章 。 ImageField和FileField很类似，除了还多了 width 和 height 属性，然后就是在上传的时候确保文件是图片文件。 具体在模型文件中的定义如下: banner = models.ImageField(upload_to=game_2048_images, blank=True, storage=OverwriteStorage(), default=\"placeholder.jpg\") 上面的 upload_to 是控制图片在计算机中的保存路径，可以直接指定一个文件夹路径，但这通常不够灵活，这里通过一个函数来实现更加灵活的路径指定: def game_2048_images(instance, filename): \"\"\" where image upload to. \"\"\" return 'game/2048/images/{}/{}'.format(instance.user.username, filename) 这里具体路径是根据你在 settings 里面指定的 MEDIA_ROOT 而来，然后再指定里面的具体的文件夹路径。我们看到函数还可以接受具体模型对应的实例，从而建立自动根据user用户名来分配不同的文件夹路径。 storage=OverwriteStorage() 实现了如果文件名重复则覆盖的逻辑: class OverwriteStorage ( FileSystemStorage ) : ''' 存储文件或图片，如果文件名重复则覆盖。 ''' def get_available_name ( self , name ) : if self . exists ( name ) : os . remove ( os . path . join ( settings . MEDIA_ROOT , name )) return name ImageField 可以和rest_framework的序列化类形成很好的联动，最后序列化之后返回的是文件路径url字符串，测试的时候我们可以如下用django来挂载这些静态资源文件，实际运营的时候则推荐用nginx怎么设置一下url分发。 from django.conf.urls.static import static from django.conf import settings if settings . DEBUG : urlpatterns += static ( '/data/' , document_root = settings . MEDIA_ROOT ) 在保存传过来的图片文件的时候，常规构建form对象也是可行的: form = Game2048InfoForm( request.POST, request.FILES, instance=target_info) if form.is_valid(): new_game_info = form.save() else: logger.warning('form invalid') 否则你需要通过: request.FILES['imgfield'] 这样的语法来获取图片内容。 django的messages系统 本小节主要参看了 这个网页 。 使用django的messages系统，首先需要如下所示在settings里面进行一些配置： INSTALLED_APPS = [ 'django.contrib.messages', ...... MIDDLEWARE_CLASSES = [ 'django.contrib.messages.middleware.MessageMiddleware', ...... TEMPLATES = [ { 'OPTIONS': { 'context_processors': [ 'django.contrib.messages.context_processors.messages', ...... 然后在views那边，使用 messages.add_message() 来往django信息系统里面发送一个信息，此外还有如下的这些快捷方法： messages.debug() messages.info() messages.success() messages.warning() messages.error() 你还可以如下设置每个request请求下的信息系统级别： from django.contrib import messages messages . set_level ( request , messages . DEBUG ) 下面我定义了一个简单的flash函数 def flash ( request , title , text , level = 'info' ): \"\"\" 利用django的message系统发送一个信息，对接模板的sweetalert。 \"\"\" level_map = { 'info' : messages . INFO , 'debug' : messages . DEBUG , 'success' : messages . SUCCESS , 'warning' : messages . WARNING , 'error' : messages . ERROR } level = level_map [ level ] messages . add_message ( request , level , text , extra_tags = title ) return 'ok' 之所以做这样的封装是为了更好地对接sweetalert这个javascript库，然后模块加入如下内容从而从而实现信息的具体弹出行为。 {% if messages %} <script src= \" {% static 'js/sweetalert.min.js' %} \" ></script> <script> {% for msg in messages %} sweetAlert({ title: ' {{ msg.extra_args }} ', text: ' {{ msg.message }} ', type: ' {{ msg.level_tag }} ', }) {% endfor %} </script> {% endif %}","tags":"django","url":"articles/djangohou-tai-apibian-xie-zhi-qi-ta-ji-qiao.html"},{"title":"django后台api编写之-其他问题","text":"csrf认证失败 一般提到的表单那边加上： <form method=\"post\">{% csrf_token %} 但后来我还是遇到csrf认证失败问题，最后参考 这个问题的答案 如下设置才可以。 CSRF_TRUSTED_ORIGINS = ['www.cdwanze.work']","tags":"django","url":"articles/djangohou-tai-apibian-xie-zhi-qi-ta-wen-ti.html"},{"title":"django后台api编写之-请求和响应","text":"请求和响应 request 是的，我们的APIView的一些特殊含义的方法，都会接收一个 request对象，这个对象有： query_params 获得GET传过来的参数 data 获得POST PUT PATCH 传过来的参数，这还没完，传过来的文件，表单都支持。 user 如果请求经过认证了会返回相应的用户记录，你编写auth类的时候会知道的，如果没有认证，那么返回 AnonymousUser Response 也就是一些特殊含义的方法的返回对象，其第一个参数是data，字典值，会自动封装成为json友好的格式。实际上我们经常看到的就是这个套路： return Response(serializer.data) 然后 serializer 有个 is_valid 方法，用来序列化类输出前的预热。这两点在后面序列化的讨论中会涉及。其他一些我们看一下吧： Response(data, status=None, template_name=None, headers=None, content_type=None) headers http协议响应头，status http状态码等等。 整个过程套路，很多高级视图的套路都类似于下面这个例子，多看几遍吧。 class SnippetDetail ( APIView ): \"\"\" Retrieve, update or delete a snippet instance. \"\"\" def get_object ( self , pk ): try : return Snippet . objects . get ( pk = pk ) except Snippet . DoesNotExist : raise Http404 def get ( self , request , pk , format = None ): snippet = self . get_object ( pk ) serializer = SnippetSerializer ( snippet ) return Response ( serializer . data ) def put ( self , request , pk , format = None ): snippet = self . get_object ( pk ) serializer = SnippetSerializer ( snippet , data = request . data ) if serializer . is_valid (): serializer . save () return Response ( serializer . data ) return Response ( serializer . errors , status = status . HTTP_400_BAD_REQUEST ) def delete ( self , request , pk , format = None ): snippet = self . get_object ( pk ) snippet . delete () return Response ( status = status . HTTP_204_NO_CONTENT ) urls.py那边加上的是: url(r'&#94;snippets/(?P<pk>[0-9]+)/$', views.SnippetDetail.as_view()), 这里正则表达式 (?P<pk>[0-9]+) 的意思是收集某一串数字，这一串数字被命名为 pk 。","tags":"django","url":"articles/djangohou-tai-apibian-xie-zhi-qing-qiu-he-xiang-ying.html"},{"title":"django后台api编写之-权限管理","text":"权限管理 认证 在视图类里定义 authentication_classes 来确定目标视图类的认证行为，如果没有则采取默认的认证管理类行为。 自定义身份认证 写自己的身份认证类，继承自 BaseAuthentication ，然后重写 authenticate(self, request) 方法，认证成功则返回 (user, auth) ，否则返回None。request.user 是当前登录的用户实例， request.auth 是当前登录auth的信息。 某些情况下身份认证失败你可能想要抛出 AuthenticationFailed 异常。 权限 在视图类里定义 permission_classes 来确定目标视图类的权限管理行为，如果没有则采用默认的权限管理类行为。 认证完了就会进去权限管理，也就是权限检查的时候 request.user request.auth 已经是可以调用的了。 最简单的权限管理类就是 IsAuthenticated ，允许通过身份验证的用户访问，拒绝没通过的用户访问。 IsAuthenticatedOrReadOnly 类的意思是通过身份认证的用户完全访问，没有通过身份验证的用户只能进行只读访问。 自定义权限管理类 自定义权限管理类，继承自 BasePermission ，然后实现下面一个两个方法： has_permission(self, request, view) has_object_permission(self, request, view, obj) 如果请求被授予权限，则返回True，如果没有权限则返回False。 自定义权限管理类还可以加上 message 属性，用户权限没通过抛出 PermissionDenied 异常的额外显示信息。","tags":"django","url":"articles/djangohou-tai-apibian-xie-zhi-quan-xian-guan-li.html"},{"title":"django后台api编写之-日志","text":"django日志 简介 django使用python的logging模块来作为的自己的日志系统，所以django项目日志管理的深入学习离不开对于logging模块的深入学习。 logging模块中级教程 logging模块的中级使用需要了解如下几个词汇：loggers, handlers, filters, and formatters。 loggers 记录器 之前我们运行logging.info，就是调用的默认的记录器，然后一般我们会针对每个python的模块文件创建一个记录器。 logger = logging.getLogger(__name__) 这个 __name__ 只是一种简便的命名方法，如果你勤快或者某种情况下有需要的话完全可以自己手工给记录器取个名字。 然后这个 getLogger 函数如果你后面指定的名字之前已经定义了（这通常是指在其他第三方模块下定义了），那么你通过这个 getLogger 然后指定目标名字就会得到对应的该记录器。这通常对于DIY某个第三方模块的日志记录器有用。 记录器可以挂载或者卸载某个处理器对象或过滤器对象： - logger.addHandler() - logger.removeHandler() - logger.addFilter() - logger.removeFilter() 记录器通过 setLevel() 方法来设置最小记录级别，这个和后面的Handler级别是协作关系。 handlers 处理器负责分发日志信息到目标地去。这里主要介绍这几个Handler类： StreamHandler 将信息以流的形式输出，这通常指输出到终端 FileHandler 将信息写入到某个文件中去 RotatingFileHandler 将信息写入某个文件，如果文件大小超过某个值，则另外新建一个文件继续写。 TimeRotatingFileHandler 将信息写入某个文件，每隔一段时间，比如说一天，就会自动再新建一个文件再往里面写。 处理器对象也有 setLevel 方法，这个前面也提及了，和记录器的 setLevel 是协作关系，更详细的描述是，信息先记录器处理并分发给对应的处理器对象，然后再处理器处理再分发到目的地。 处理器可以挂载 格式器 对象和 过滤器 对象。 handler.setFormatter() handler.addFilter() handler.removeFilter() filters 过滤器 formatters 格式器，具体信息的格式定义。 字典统一配置 django的setting.py就会有这样的配置，具体含义还是很明显的，就是定义处理器，格式器，记录器等。 LOGGING = { 'version': 1, 'disable_existing_loggers': False, 'formatters': { 'simple': { 'format': \"%(asctime)s %(name)s [%(levelname)s] %(thread)d %(module)s %(funcName)s %(lineno)s: %(message)s\" } }, 'handlers': { 'log_file': { 'class': 'sdsom.common.log.DedupeRotatingAndTimedRotatingFileHandler', 'filename': config.get('web', 'log_path'), 'when': 'midnight', 'maxBytes':int(config.get('web','log_max_bytes')), 'interval': 1, 'backupDay': int(config.get('web', 'log_backup_days')), 'dedupetime': int(config.get('web', 'log_dedupe_time')), 'formatter': 'simple' }, }, 'loggers': { 'django.request': { 'handlers': ['log_file'], 'level': config.get('web', 'log_level'), 'propagate': True, }, } }","tags":"django","url":"articles/djangohou-tai-apibian-xie-zhi-ri-zhi.html"},{"title":"django后台api编写之-url分发","text":"url分发 web框架的一个核心功能就是完成url分发工作，我们先来看下django的这块内容。 基本过程是在你的 project 的 urls.py 那里定义好整个项目的url分发规则。默认的内容如下: from django.urls import path from django.contrib import admin urlpatterns = [ path ( 'admin/' , admin . site . urls ), ] 读者有兴趣可以先看下那个admin页，在 /admin 那边。请确认已经执行前面的数据库操作 makemigrations 和 migrate 了，然后已经创建超级用户了 createsuperuser 。这样你就可以看到django默认自动创建的admin支持页面了。 然后接下来就是类似这样的在这里插入你自己的 app的 各个 urls定义。一般如下简单写上即可: from django.urls import include , path .... path ( 'app_name/' , include ( 'app_name.urls' )), .... 在确定没有特殊url分发需求的情况下，都推荐如上使用django官方教程推荐的这种url分发写法。 在某个app下的 urls.py 将进一步定义url分发规则: from django.urls import path from . import views urlpatterns = [ path ( '' , views . index , name = 'index' ), ] 上面的讨论是根据django的官方教程来的，应该是推荐的写法风格。 url上带参数 from django.urls import re_path from . import views urlpatterns = [ re_path ( r '&#94;add/([\\d]+)/([\\d]+)$' , views . add , name = 'add' ), ] 这里参数将逐个传递个视图函数，唯一值得一提的是django的视图函数默认第一个函数是传递进去的 request 参量。在 views.py 里面的内容如下: from django.http import HttpResponse def add ( request , a , b ): res = int ( a ) + int ( b ) return HttpResponse ( str ( res )) 上面这种正则表达式的写法是老式的django的url写法，一般没有特别的需求的话，应该按照django官方教程，采用下面的推荐写法： from django.urls import path from . import views urlpatterns = [ path ( 'add/<int:a>/<int:b>' , views . add , name = 'add' ), ] url定义name name 这个参量大体类似于flask的 endpoint 的概念，然后django还有的 reverse 函数，其大体类似于flask的 url_for 的概念。 比如上面视图函数的 add 对应的url我们可以如下获得: from django.core.urlresolvers import reverse reverse ( 'add' , args = ( 1 , 2 )) 然后在模板中有: <a href= \"{% url 'add' 1 2 %}\" > link </a> 获取full-url 上面提到的reverse函数返回的url字符串还不是完整的url，而只是相对url。如果我们要获取全站的完整url则可以使用 request.build_absolute_uri(location) ，如果不指定location则默认是当前的url。","tags":"django","url":"articles/djangohou-tai-apibian-xie-zhi-urlfen-fa.html"},{"title":"django后台api编写之-序列化","text":"序列化 理解序列化过程 django restframework的序列化类类似于django的表单类，不同的是django的表单类是用于沟通django的Model和网页form之间的桥梁；而序列化类是用于沟通django的Model类和JSON数据格式之间的桥梁。 注 : Model -> Serializer （其 data挂载的是python的dict字典值了 ） serializer = SnippetSerializer ( snippet ) serializer . data # { 'pk' : 2 , 'title' : u '' , 'code' : u 'print \"hello, world\"\\n' , 'linenos' : False , 'language' : u 'python' , 'style' : u 'friendly' } 上面这个过程通常是在视图类特殊方法下，进行一些数据库操作之后获取数据库的目标Model的记录，然后送入序列化类，然后目标类的 .data 属性就是字典值了，送入Response哪里就可以作为HTTP响应的结果值了。 然后还有下面这种用法，将某个字典data送入序列化类的data属性中， serializer = SnippetSerializer(data=data) 调用序列化类的save方法来进一步完成相应的数据库操作。 serializer.save() 这个save方法具体行为依赖于你进一步定义序列化类里面的 create 和 update 方法。如下所示： def create(self, validated_data): return Comment.objects.create(**validated_data) def update(self, instance, validated_data): instance.email = validated_data.get('email', instance.email) instance.content = validated_data.get('content', instance.content) instance.created = validated_data.get('created', instance.created) instance.save() return instance 某些情况下你可能想直接定义save方法。 ModelSerializer 类似于django的表单类，可以利用 ModelSerializer 类来更快地创建序列化类。 from rest_framework import serializers class SnippetSerializer ( serializers . ModelSerializer ): class Meta : model = Snippet fields = ( 'id' , 'title' , 'code' , 'linenos' , 'language' , 'style' ) 为了证明这种简便写法对于上面的任务（包括create和update方法都会自动实现的）是完全应付得过来的。上面在shell里的代码再撸一遍。 >>> from snippets.models import Snippet >>> snippet = Snippet ( code = 'print \"hello, world2\" \\n ' ) >>> from snippets.serializers import SnippetSerializer >>> snippet . save () >>> serializer = SnippetSerializer ( snippet ) >>> serializer . data { 'language' : 'python' , 'linenos' : False , 'id' : 3 , 'title' : '' , 'code' : 'print \"hello, world2\" \\n ' , 'style' : 'friendly' } is_valid 方法 serializer.is_valid(raise_exception=True) 你可以定义 validate 方法来进行目标对象的验证行为，或者定义 validate_<fieldname> 来定义字段级别的验证行为。 def validate ( self , data ): \"\"\" Check that the start is before the stop. \"\"\" if data [ 'start' ] > data [ 'finish' ]: raise serializers . ValidationError ( \"finish must occur after start\" ) return data 在序列化类里面引用request.user 参考了 这个问题 ，在序列化类里面需要通过 self.context['request'] 来获取 request 对象，进而获取 user对象。 user = self.context['request'].user","tags":"django","url":"articles/djangohou-tai-apibian-xie-zhi-xu-lie-hua.html"},{"title":"django后台api编写之-邮箱认证","text":"邮箱认证 参考了 这篇文章 。 过程分为两步，发送验证邮箱，和接受确认邮箱链接： re_path(r'&#94;users/verify_email/?$', VerifyEmailView.as_view(), name='users_verify_email'), re_path(r'&#94;users/confirm_email/(?P<uidb64>[0-9A-Za-z_\\-]+)/(?P<token>[0-9A-Za-z]{1,13}-[0-9A-Za-z]{1,20})/?$', ConfirmEmailView.as_view(), name='users_confirm_email'), 发送邮件的过程主要是填写一些必要信息，发送邮件即可： class VerifyEmailView ( APIView ): permission_classes = ( IsAuthenticated ,) def post ( self , request ): profile = request . user user = profile . user current_site = get_current_site ( request ) mail_subject = '请确认你的邮箱.' message = render_to_string ( 'verify_email.html' , { 'user' : user , 'domain' : current_site . domain , 'uid' : urlsafe_base64_encode ( force_bytes ( user . pk )) . decode ( 'utf8' ), 'token' : PasswordResetTokenGenerator () . make_token ( user ), }) to_email = user . email email = EmailMessage ( mail_subject , message , to = [ to_email ] ) email . send () return Response ({ 'info' : \"邮件已发送，请查收您的邮箱。\" }) 确认邮件的过程是： class ConfirmEmailView ( APIView ): permission_classes = ( AllowAny ,) def get ( self , request , uidb64 , token ): uid = urlsafe_base64_decode ( uidb64 ) user = None try : profile = Profile . objects . get ( pk = uid ) user = profile . user except Profile . DoesNotExist : pass if ( user is not None ) and PasswordResetTokenGenerator () . check_token ( user , token ): user . is_email_verified = True user . save () return Response ({ 'info' : \"您的邮箱已经被确认。\" }) else : return Response ({ 'info' : '无效的激活链接。' }) 这其中最大的技术点就是传递的token的加密解密过程。 具体这里利用了django自带的密码重置的token检验系统： 'token': PasswordResetTokenGenerator().make_token(user), PasswordResetTokenGenerator().check_token(user, token) 这个有点类似于JWT 的token过程，然后额外加上的uid方便判断登录用户。","tags":"django","url":"articles/djangohou-tai-apibian-xie-zhi-you-xiang-ren-zheng.html"},{"title":"django后台api编写之-自定义命令","text":"自定义命令 在目标app下面新建一个 management 文件夹，然后新建一个 commands 文件夹，注意这两个文件夹都要带上 __init__.py 文件。 然后commands文件夹里面就可以定义一些python脚本了，这些脚本成为命令可以直接如下调用： python manage.py command_name 你可以通过： python manage.py help 来查看目前已经有的命令列表。 一个基本的命令模块如下所示： from django.core.management.base import BaseCommand , CommandError from polls.models import Question as Poll class Command ( BaseCommand ): help = 'Closes the specified poll for voting' def add_arguments ( self , parser ): parser . add_argument ( 'poll_id' , nargs = '+' , type = int ) def handle ( self , * args , ** options ): for poll_id in options [ 'poll_id' ]: try : poll = Poll . objects . get ( pk = poll_id ) except Poll . DoesNotExist : raise CommandError ( 'Poll \" %s \" does not exist' % poll_id ) poll . opened = False poll . save () self . stdout . write ( self . style . SUCCESS ( 'Successfully closed poll \" %s \"' % poll_id ))","tags":"django","url":"articles/djangohou-tai-apibian-xie-zhi-zi-ding-yi-ming-ling.html"},{"title":"html5代码规范","text":"html5代码规范 本文参考了 这篇文章 和 这篇文章 还有 aribnb的javascript规范 。 需要指出的是这些都是一些代码建议，其中有一些还有点大头开蛋还是小头开蛋的意思，比如到底是空四个空格还是两个空格，这些有分歧的我就不写出来了，读者自行决定吧。 总的原则 无论团队人数多少，代码应该看起来就好像一个人写的。——这个原则为大家所公认。 文件名推荐是小写字母加下划线。（小写字母加连字符也是可以的，但是绝对不推荐带上空格） html 缩进，这个一个好的编辑器会提供这个自动缩进功能的。 属性名全部小写，用 - 隔开。 属性的定义用 双引号 包围起来。 <hr> <img src=...> 这样的不用后面加个 / 号了。 关闭标签不要省略 <li>...</li> 这是没有疑问的。 开头格式都是： <!DOCTYPE html> 语言指定遵循规范 ， <html lang=\"zh-cn\"> 字符编码推荐指定utf8， <meta charset=\"utf-8\"> IE兼容模式，推荐加上这样一行： html <meta http-equiv=\"X-UA-Compatible\" content=\"IE=Edge\"> 引用css和javascript，如下所示（不要再像以前加上一些杂七杂八的东西，尽可能保持代码简洁。）： ```html ... ... ``` 属性的顺序： class id name data-* src for type href value title alt role aria-* 布尔属性，html规范原文就是： The values \"true\" and \"false\" are not allowed on boolean attributes. To represent a false value, the attribute has to be omitted altogether. 布尔属性存在就表示true，不存在就取值false。 ```html 1 ``` 代码简洁简洁，尽可能减少标签数量。这是没有疑问的。 css css代码规范有兴趣的请参看前面提到过的参考文章，这个我不太感兴趣，老实说css本来就可读性偏低吧，当然了基本的代码规范可以做一下。 javascript javascript也有好几种代码风格的写法规范，推荐读者安装相应 eslint 插件，我决定主要学习一下 aribnb 的javascript规范，然后接下来的javascript基础篇内容决定按此修订重写之。","tags":"html5","url":"articles/html5dai-ma-gui-fan.html"},{"title":"html5基础","text":"html5基础 第一个模板 <!DOCTYPE html> < html lang = \"zh-cn\" > < head > < meta charset = \"utf-8\" > < title > your awesome title </ title > </ head > < body > </ body > </ html > doctype声明 现在html5的doctype声明非常简单了，开头加入如下简单一行即可: <!DOCTYPE html> 然后进入 html 标签，然后进入 head 标签，在head标签里面的内容不会显示在网页上，主要是一些关于本网页的配置信息。 字符集设置为utf-8 现在html5使用如下更简洁的语法了: <meta charset=\"utf-8\"> 然后 body 标签里面存放这实际要显示的网页内容。 第二个例子 <!DOCTYPE html> < html lang = \"zh-cn\" > < head > < meta charset = \"utf-8\" > < title > basic html </ title > </ head > < body > < nav > < ul > < li >< a href = \"#\" > Home </ a ></ li > < li >< a href = \"#\" > About </ a ></ li > < li >< a href = \"#\" > Products </ a ></ li > < li >< a href = \"#\" > Contact Us </ a ></ li > </ ul > </ nav > < header > < h1 >< a href = \"#\" > Very Basic Document </ a ></ h1 > < h2 > A tag line might go here </ h2 > </ header > < section > < article > < h3 >< a href = \"#\" > First Article Title </ a ></ h3 > < p > Lorem ipsum dolor sit amet, consectetur adipiscing elit. Integer nec odio. </ p > </ article > < article > < h3 >< a href = \"#\" > Second Article Title </ a ></ h3 > < p > Praesent libero. Sed cursus ante dapibus diam. </ p > </ article > </ section > < aside > < h4 > Connect With Us </ h4 > < ul > < li >< a href = \"#\" > Twitter </ a ></ li > < li >< a href = \"#\" > Facebook </ a ></ li > </ ul > </ aside > < footer > < p > All rights reserved. </ p > </ footer > </ body > </ html > html5新加入了很多关于文档结构的标签，这些标签并没有任何布局含义，相当于一个自带名字的div，也就是默认标签的意思。其主要作用就是html内容分组(group)。 下面是常用的这些标签含义，在实际使用中，应该尽量规范使用这些标签。 header: 一个网页总要有个头，推荐都使用这个标签。 nav: 一般是目录或者导航菜单。 section: 一般是本网页的主体信息部分或者主页面——类似于GUI的主要显示窗口。 article: section下面的某一独立内容部分。 aside: 和网页主体信息不太相关的其他信息。 footer: 一般是关于作者，版权或者其他比如脚注等信息。 这些都可以通过div然后class或者id写法来取代，在实际使用中如果上面的默认标签能够满足需求，那么就应该使用html5的这些默认标签。 上面的例子已经出现了一些标签，然后还有一些很常用的标签，下面承接上面所将的继续补充写一个常用html标签清单。 常用html标签清单 ul: 不编号列表，也叫无序列表（Unordered list）。里面的item用 li 标签封装。 ol: 编号列表，也叫有序列表（Ordered list）。里面的item用 li 标签封装。 h1,h2,h3 ... 标题标签，数字表示各个标题的层级。 p: 段落标签。 b: 文字加粗 i: 文字斜体 br 换行 hr 水平线 img 加入图片，其中最常用的属性是 src ，指明具体图片引用地址。 建立一个链接 a: 引用链接标签，其中常用的属性是 href ，指明具体的引用地址， title 是悬浮的提示文字。 <a href= \"/where\" title= \"go to where\" > show </a> 有的时候一个链接是用来下载文件的，你可以使用 download 属性来指定默认的保存文件名。 <a href= \"https://download.mozilla.org/?product=firefox-39.0-SSL&os=win&lang=en-US\" download= \"firefox-39-installer.exe\" > Download Firefox 39 for Windows </a> 如果连接有 target=\"_blank\" 属性，那么目标连接将会在浏览器新标签页打开。 创建一个电子邮箱链接： <a href= \"mailto:nowhere@mozilla.org\" > Send email to nowhere </a> 文字强调的html5规范 按照html5提出的规范，并不推荐用 <b> 标签作为文字的强调用途（我一般使用的文字加粗是那个词提醒读者这个词需要特别记忆）。其推荐的是 <em> 标签作为一级强调，然后 <strong> 标签作为更进一步的强调。在默认样式中， <em> 是斜体，然后 <strong> 是粗体。显然html5的意思是将表达文字的样式这样的标签 <b><i> 尽可能不用直到废弃，然后对于文字强调都推荐使用 <em> 和 <strong> 标签。其设计思路是html完全成为一个描述文档内容结构的标签系统，而不带有任何内容表现形式的东西。还是推荐按照html5规范来，少用 <b> 标签和 <i> 标签。请参看 这个网页 的讨论。 注释 <!-- Make me into a comment. --> 有序列表里面带无序列表 就是把无序列表嵌套进去即可。 < ol > < li > ol li1 </ li > < li > ol li2 </ li > < ul > < li > ul li1 </ li > < li > ul li2 </ li > </ ul > </ ol > table table表格有时也可用于布局，不过不推荐这种风格，因为html标签应该尽可能是文本结构层而非表现形式层。一个完整的table模板如下所示: < table > < caption > 表格的标题用caption标签 </ caption > < thead > < tr >< th > 标签 </ th >< th > fullname </ th >< th > 说明 </ th ></ tr > </ thead > < tbody > < tr >< td > tr </ td >< td > table row </ td >< td > 表格中的一行 </ td ></ tr > < tr >< td > th </ td >< td > table head </ td >< td > 表格的列名 </ td ></ tr > < tr >< td > td </ td >< td > table data </ td >< td > 表格具体要展示的数据 </ td ></ tr > </ tbody > </ table > 表格的标题用caption标签 标签 fullname 说明 tr table row 表格中的一行 th table head 表格的列名 td table data 表格具体要展示的数据 大体在html上画表格就如上所示了，其他一些更漂亮的表格制作都是通过css来完成的，这里先略过了。 div和span div（division）在html标记语言中主要是区块的意思。我们知道html页面要显示的元素就好比一个个盒子逐步排布下来，而 div 可以看作一个这样自定义的盒子。html中有两种显示风格的盒子，一种是块状区块，比如p段落标签；还有一种是inline盒子，比如说em标签，其不会换行。 div标签更确切的表达是块状区块，可以看作其display属性是 block （但不一定，不过推荐接受这样的设定）；此外还有所谓的inline区块，用 span 标签来表示这样的元素，可以理解为改标签元素的display属性是 inline 。 inline css 最基本的css属性可以通过inline css模式直接在html标签中通过 style 属性来加上。 font-size 字体大小 < p style = \"font-size:12pt\" > paragraph </ p > color 字体颜色， 这是css支持的 color关键词清单 。 < h2 style = \"color:green\" > paragraph </ h2 > font-family 字族， 这是css一般支持的 字族信息 。 < ol > < li style = \"font-family:Arial\" > Arial </ li > </ ol > 一般有文字的标签都可以用上面的三个属性来控制其内文字的大小，颜色和字族。虽然现在都推荐用css来控制，但思路顺序应该是优先inline css，太过普遍多次出现的情况下才考虑单独css控制。 background-color 背景颜色。如果读者熟悉LaTeX排版系统的，那么我们都清楚LaTeX排版很核心的一个概念就是盒子。在html这里，我们似乎也可以把一个个标签看作一个个排版用的盒子。然后这里的background-color就是控制这一个盒子的背景颜色。 < body style = \"background-color:yellow\" > </ body > text-align 文字在标签盒子里的对齐方式。可选参数有: left, right, center。 < h3 style = \"text-align:center\" > 居中对齐的标题 </ h3 > 外部css 有一种说法，是将放在html 标签里面的css和具体外部的css文件引用区分开来，在我看来区别不大吧。然后网络上还有一种说法认为html 标签里面应该多用id的css定义，而外部css文件应该只用class定义好做到普适性，在我看来也有点削足适履了。额，目前的国内网络环境大家都懂的，所以我喜欢少用css文件引用，尽量将一些css定义都放在 标签里面，就是为了加载快一点，至于其他，倒没什么特别好讲究的。不过在使用css定义前应该用class，只有觉得某些元素需要个别处理的时候才用id属性控制，我想这是没有问题的。 放在 标签里面的css大致如下格式引入进来: < style > 这里的格式和外部css文件格式完全一致 </ style > 引入外部文件css如下: < link rel = \"stylesheet\" href = \"main.css\" > 然后在外部css文件里面你还可以如下进一步引用其他的css文件: @ import url ( \"http://getbootstrap.com/dist/css/bootstrap.min.css\" ) ; 这种引用语句后面的分号不太清楚是不是必须的，不太关心这个，没事就加上吧。参考了 这个网页 。","tags":"html5","url":"articles/html5ji-chu.html"},{"title":"html5进阶","text":"html5进阶 设置背景图片 background-image : url ( \"https://theurl/tothe/image.jpg\" ); 设置背景图片位置 设置背景图片位置，可能的值有top，center，right，left，top，bottom等，如下所示: top left top center top right center left center center center right bottom left bottom center bottom right 如果只给出一个值，则第二个值是默认值center。 background-position : center center ; 设置背景图片是否重复 默认是repeat，如下设置为 no-repeat ，则背景图片不会重复以铺满整个背景了。 background-repeat : no-repeat ; 设置背景图片不随页面滚动 background-attachment : fixed ; 设置背景图片尺寸 如下设置为 cover ，则背景图片会拉伸到足够大，以覆盖整个区域，图片某些部位可能不会显示在背景中。 background-size : cover ; 如果设置为 contain ，则背景图片会拉伸至最大长度或最大宽度不超过背景为止。 此外还可以如下指定宽高比，下面是宽100px，高150px: background-size : 100px 150px ; 设置背景颜色 这里是html各个标签盒子的背景颜色，而color设置的是里面字体的颜色。 background-color : red ; 控制文本大小写 如下所示，依次为: 大写，首字母大写，小写。 h1 {text-transform:uppercase} h2 {text-transform:capitalize} p {text-transform:lowercase} 边框画一个圆 这样边框就成为一个圆了。 <div style= \"border:1pt solid blue;border-radius:50%;width:100px;height:100px;margin:auto;\" ></div> z-index属性 css中某个标签盒子设置z-index属性，将影响这些标签盒子的堆叠顺序。比如说如下将header标签的 z-index 属性设置为1，而其他的都不设置，则保证header网页头部分总是第一个先堆放。: header { z-index : 1 ; } 表单 之前并没有对html中的表单各个情况进行说明，这里详细说明之。这里所谓的表单是指 form 标签加上其内包含的 input 等元素。这些input元素构成了我们熟知的文本输入框，下拉列表，单选框，复选框等等。 <form> <input> </input> </form> 具体表单元素的类型由input标签的 type 元素定义，下面分别详细说明之: 单行文本输入 单行文本输入用input标签，type类型为 text ，然后具体说明文字推荐用 label 标签。 < form > < label > name: </ label > < input type = \"text\" name = \"yourname\" ></ input > </ form > 然后input的 name 属性很重要，其值具体对应该文本输入的值的变量名（比如python的wsgi机制就将其刷成 form.yourname 这样的引用）。 name: 多行文本输入 多行文本输入使用 textarea 标签生成的，现在先简单了解下即可。 < p > :before </ p > < textarea rows = \"5\" > the textarea you say something </ textarea > < p > :after </ p > :before the textarea you say something :after 加上action 也就是表单form标签上加上action属性，然后表单内定义submit的按钮或者input元素，点击之后将会将数据发送给action那边去，具体方法由method属性定义，默认是GET。 <form action= \"/where\" method= \"POST\" > <input type= \"text\" > <button type= \"submit\" > submit </button> </form> required 加上requird属性，该字段必须填上值。 <input type=\"text\" required> placeholder 预显示的文字 <input type=\"text\" placeholder=\"input your name\" required> 按钮 html有好几种方法创建一个按钮，w3school不推荐button标签，而是推荐使用如下所示的input标签的形式: < form action = \"https://www.google.com\" method = \"get\" > < input type = \"submit\" value = \"click to google\" ></ input > </ form > 其 value 属性定义了具体按钮上显示的文字。然后具体跳转行为用form标签的 action 属性来定义，你还可以定义 method 属性来具体定义HTTP的method，比如下面是一个表单提交的例子: < form action = \"http://httpbin.org/post\" method = \"post\" > < label > name: </ label > < input type = \"text\" name = \"name\" /> < label > password: </ label > < input type = \"password\" name = \"password\" /> < input type = \"submit\" value = \"提交\" /> </ form > name: password: 然后我们注意到上面还出现了一个新的type类型 password ，其类似单行文本输入，不同的是你是在输入密码，所以不会在屏幕上显示出来。 重置按钮 <input type=\"reset\" value=\"重置\" /> 这个按钮将会将表单所有内容清空。 单选按钮 < form action = \"http://httpbin.org/get\" method = \"get\" > < label > Male </ label > < input type = \"radio\" name = \"Sex\" value = \"Male\" checked = \"checked\" /> < label > Female </ label > < input type = \"radio\" name = \"Sex\" value = \"Female\" /> < input type = \"submit\" value = \"提交\" > </ form > Male Female 上面新出现的 checked ，默认单选按钮和下面的复选按钮是没有选中的，而设置成为 \"checked\" 则默认为选中了。 复选按钮 < form action = \"http://httpbin.org/get\" method = \"get\" > < p > 你喜欢吃的水果: </ p > < label > apple </ label >< input type = \"checkbox\" name = \"fruits\" value = \"apple\" /> < label > banana </ label >< input type = \"checkbox\" name = \"fruits\" value = \"banana\" /> < label > pear </ label >< input type = \"checkbox\" name = \"fruits\" value = \"pear\" /> < input type = \"submit\" value = \"提交\" /> </ form > 你喜欢吃的水果: apple banana pear label标签 标签用户说明输入框的一些内容，但还有一个用途，改进鼠标用户的可用性，如果用户点击标签，那么将会聚焦到目标表单对象上，只需要我们如下设置： <label for=\"控件id名称\"> <input id=\"控件id名称\" 响应式布局 提示：现在推荐使用bootstrap来进行响应式设计，下面的内容有助于我们来理解bootstrap内部是如何实现响应式布局的。 请读者先阅读 这篇文章 。这篇刚开始 Ethan Marccote 给出的那个例子有个非常重要的信息，那就是设备的像素分级: 大于1300像素 600到1300像素 400到600像素 小于400像素 这个像素分级可以为后面我们要根据不同的设备进行css进行设置提供了参考。 然后一般网页都要加上这一行: <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" /> 意思是网页默认宽度为设备宽度，原始缩放比为1。 然后就是各个元素宽度最好不要有 width: xxx px 这样写死了的css设置，而是 % 或者 auto 。字体的大小也都推荐使用 em 这样的相对大小。 h1 默认大小是 1.5em 。 h1 { font-size : 1.5 em ; } small 默认是 0.875em 。 small { font-size : 0.875 em ; } 流动式布局，各个区块的位置都是浮动的，有些情况下会需要使用 position: absolute ，这会带来很多麻烦，尽量少用。 根据屏幕响应式多个css配置适应: 【因为css有很多通用配置是多设备皆适用的，下面这些根据屏幕响应的css应该放在css文件的最后面。】 参看 这篇文章 ，其提到了现在流行的 mobile-first 设计思路，也就是有限照顾手机小屏幕设备的设计流程。先写好通用css配置，然后css文件最后面如下设置这些屏幕响应css设置。从最小的屏幕照顾起: @ media screen and ( min-width : 400px ) {} @ media screen and ( min-width : 600px ) {} @ media screen and ( min-width : 1000px ) {} @ media screen and ( min-width : 1400px ) {} 这里 min-width 是指设备宽度至少要大于那个值，此外还有 max-width 是指设置宽度要小于那个值。上面的例子，假设设备750px，那么第一个第二个配置都满足，但因为css覆盖配置，后面如果你定制了那么将生效后面的，这就是先调手机端的mobile-first思路。 图片的自适应，如下设置最大宽度。 img { max-width : 100 % ;} no-js class <html class=\"no-js\" lang=\"zh\"> 他们说这个class可以用来设置某些情况下javascript被禁用之后的css。","tags":"html5","url":"articles/html5jin-jie.html"},{"title":"pyqt5编程之-安装和配置","text":"安装和配置 就是利用pip3 安装之： pip3 install pyqt5 以前是需要安装qt5的，不过在windows下经过测试发现已经不需要安装qt5了，所以我估计ubuntu下也已经不需要安装qt5了。 但是还是把下面这个写上吧，如果读者遇到程序提示没找到qt或者什么类似的错误，那么安装qt之： sudo apt-get install qt5-default sudo apt-get install qtbase5-dev sudo apt-get install qtdeclarative5-dev 以前安装SIP挺麻烦的，现在sip也可以直接通过pip安装了，而且之前你安装pyqt5的时候，应该也顺便装上了。然后我发现windows下已经有 pyuic5 和 pyrcc5 这两个命令了，应该是通过pip安装的时候就装上了。 以前在ubuntu下是要安装下面这个东西的，估计现在也不需要了： sudo apt-get install pyqt5-dev-tools 检查pyqt5安装情况执行以下脚本即可，显示的是当前安装的pyqt5的版本号: >>> from PyQt5.QtCore import QT_VERSION_STR >>> print ( QT_VERSION_STR ) >>> 5.9 . 2 本文的代码都是PyQt版本号都是上面的，没有特别的理由，会一直维持在这个版本号里面了。","tags":"pyqt5","url":"articles/pyqt5-development-environment.html"},{"title":"pyqt5编程之-exe制作和安装程序制作","text":"exe制作和安装程序制作 exe制作 所谓的exe制作也就是把你写的pyqt程序或者说python程序freeze起来，这样目标机器上用户没有安装python或者等等其他依赖都能正常运行程序。 推荐使用pyinstaller。 pyinstaller的官网在 这里 。 首先是用pip 安装之，然后推荐在你的项目根目录下创建一个简单的启动脚本，一方面方便平时测试，一方面作为pyinstaller的程序入口。 \"\"\" for pyinstaller 注意本脚本名字不能设置为 quicktikz \"\"\" import quicktikz.main if __name__ == '__main__' : quicktikz . main . gui () NOTICE: 注意该脚本的名字不要和你的pyqt程序的模块名字相同，之前我安装后闪退就是因为这个脚本名字没取好。 具体使用很简单： import subprocess PROJECT = 'quicktikz' cmd = 'pyinstaller.exe --noconsole -y QuickTikz.py' subprocess . call ( cmd , shell = True ) 上面的 -y 选项是自动删除原输出文件， --noconsole 是隐藏你的pyqt程序的终端界面，否则后面程序会开两个窗口不太好看。 如果一切顺利，到 dist 文件夹下运行你的目标程序exe运行正常，那么一切都OK，如果出问题了，那么请钻研官方文档吧。。 安装程序的制作 推荐使用 advanceinstaller程序，这是该程序的 官网地址 。推荐一开始安装官网的simple 过程来，请参看官网的这个基本 入门tutorial 。 在设置文件和文件夹的时候把在 dist 里面的所有内容都加进去即可，注意这个软件操作说是添加文件那么只能添加文件的，所以dist里面的 PyQt5文件夹需要再操作添加文件夹之。 如果一切运行顺利，那么太好了，我们就有了我们程序的安装程序，赶快分享给小伙伴们吧。","tags":"pyqt5","url":"articles/pyqt5-intall.html"},{"title":"pyqt5编程之-国际化支持","text":"国际化支持 本小节参考资料除了官方文档之外还有 这个网站 。 这里指的pyqt的软件国际化支持主要是指i18n，也就是两种语言，英语和本土语言。其中软件的字符串都是英语，然后用 self.tr() 封装，不过按照官方pyqt5文档的 说明 ，其推荐使用如下形式： from PyQt5.QtCore import QCoreApplication QCoreApplication . translate ( 'A' , \"Hello\" ) 上面translate函数第一个参数是翻译的目标类，第二个是待翻译的字符串。实际可以考虑写个translate函数，然后将所有翻译都统一到本程序的某个主类上。 def translate ( string , targetobj = None ): if targetobj is None : targetobj = \"MainWindow\" return QCoreApplication . translate ( targetobj , string ) 然后在你的项目里新建一个translations文件夹，新建如下一个小文件 wise.pro ，这里的wise是你的模块具体的名字，随意修改之。这个文件的内容简要如下： SOURCES += ../main.py ../__init__.py \\ ../Widgets/__init__.py TRANSLATIONS += wise_zh_CN.ts SOURCES 是你希望扫描的py文件，如果该文件有前面所说的translate封装，那么里面的字符串 pylupdate5 工具就可以扫描出来。这里支持路径的相对表达。但是不支持glob语法。 第二个变量就是TRANSLATIONS就是你希望生成的目标翻译ts文件的文件名，一般是如下格式： {PROJECT_NAME}_{QLocale.system().name()}.ts 其中PROJECT_NAME是你项目的名字，而QLocale.system().name()是你当前机器所用的目标语言简写，你可以在python3的eval模式下查看一下： >>> from PyQt5.QtCore import QLocale >>> QLocale . system () . name () 'zh_CN' 然后你需要用 pylupdate5 小工具处理该pro文件： pylupdate5 wise.pro 这样你就可以看到生成的 wise_zh_CH.ts 文件了。 使用翻译文件 样例如下： from PyQt5.QtCore import QTranslator , QLocale myapp = QApplication ( sys . argv ) translator = QTranslator () if translator . load ( 'wise_' + QLocale . system () . name () + '.qm' , \":/translations/\" ): myapp . installTranslator ( translator ) 首先你需要构建一个QTranslator对象，然后调用该对象的方法load，这里第一个参数是要load的qm文件名，第二个参数是qm文件的路径，可以使用前面谈及的qrc引用路径。 最后你的主母窗口myapp使用installTranslator方法把这个QTranslator对象加进去即可。 使用qt官方翻译文件 有些qt窗体内部文字可能不好DIY，这时需要如上一样加载qt的官方翻译文件。代码如下所示： translator_qt = QTranslator () if translator_qt . load ( 'qt_' + QLocale . system () . name () + '.qm' , \":/translations/\" ): # print('i found qt') myapp . installTranslator ( translator_qt ) 这样你的主母窗口myapp现在需要加载两个翻译文件了。 官方qt翻译文件在qt源码的translations文件夹里面，可以如下通过git clone获取。 git clone https://gitorious.org/qt/qttranslations.git ts文件如前所述用 lrelease 命令处理以下，或者直接用语言工具打开然后发布即可。","tags":"pyqt5","url":"articles/pyqt5-internationalizing.html"},{"title":"pyqt5编程之-布局管理","text":"布局管理 布局管理是GUI设计中不可回避的一个话题，这里详细讨论下pyqt的布局管理。正如前所述及，pyqt5用于布局管理的类都移到了QtWidgets子模块那里了，首先是最基本的 QHBoxLayout 和 QVBoxLayout 。 QBoxLayout QHBoxLayout 和 QVBoxLayout 一个是横向排布，一个是竖向排布。它们的使用方法如下所示： mainLayout = QHBoxLayout () mainLayout . addWidget ( button1 ) mainLayout . addWidget ( button2 ) self . setLayout ( mainLayout ) Layout对象就好像一个封装器，Layout里面还可以有Layout，当然还有其他一些窗体子单元，都通过 addWidget 方法来确立封装关系。最后主母窗口主要接受一个Layout对象，使用的是 setLayout 方法。 【layout/hello】 from PyQt5.QtWidgets import QApplication , QWidget , QLabel , QVBoxLayout , QPushButton , QLineEdit , QMessageBox class Form ( QWidget ): def __init__ ( self ): super () . __init__ () nameLabel = QLabel ( \"Name:\" ) self . nameLine = QLineEdit () self . submitButton = QPushButton ( \"Submit\" ) bodyLayout = QVBoxLayout () bodyLayout . addWidget ( nameLabel ) bodyLayout . addWidget ( self . nameLine ) bodyLayout . addWidget ( self . submitButton ) self . submitButton . clicked . connect ( self . submit ) self . setLayout ( bodyLayout ) self . setWindowTitle ( \"Hello Qt\" ) self . show () def submit ( self ): name = self . nameLine . text () if name == \"\" : QMessageBox . information ( self , \"Empty Field\" , \"Please enter a name.\" ) return else : QMessageBox . information ( self , \"Success!\" , \"Hello %s !\" % name ) if __name__ == '__main__' : import sys app = QApplication ( sys . argv ) screen = Form () sys . exit ( app . exec_ ()) addStretch方法 插入一个分隔符，也就是设计器里面的弹簧。 QGridLayout 在tkinter中有个grid方法，也就是网格布局，同样pyqt中也有个网格布局对象QGridLayout。QGridLayout的用法和上面QBoxLayout类似，除了 addWidget 方法后面还可以接受两个额外的参数表示几行几列。 请看到下面的例子。这个例子很好地演示了QGridLayout的使用。其中 (i-1)//3 即该数对3取商，本来的1 2 3 4 5 6…将变成0 0 0 1 1 1 2 2 2…正好对应网格中的几行，而 (i-1)%3 即该数对3取余，本来的1 2 3 4 5 6…将变成0 1 2 0 1 2 0 1 2…正好对应网格中的几列的概念。 【layout/gridlayout】 from PyQt5.QtWidgets import QApplication , QWidget , QPushButton , QGridLayout class Form ( QWidget ): def __init__ ( self ): super () . __init__ () bodyLayout = QGridLayout () for i in range ( 1 , 10 ): button = QPushButton ( str ( i )) bodyLayout . addWidget ( button ,( i - 1 ) // 3 ,( i - 1 ) % 3 ) print ( i ,( i - 1 ) // 3 ,( i - 1 ) % 3 ) self . setLayout ( bodyLayout ) self . setWindowTitle ( \"the grid layout\" ) self . show () if __name__ == '__main__' : import sys app = QApplication ( sys . argv ) screen = Form () sys . exit ( app . exec_ ()) QFormLayout QFormLayout，表单布局，常用于提交某个配置信息的表单。 请看到下面的例子。这个例子来自pyqt5源码examples文件夹layouts文件夹里面的basiclayouts.py文件，做了简化主要用于演示表单布局。 【layout/basiclayouts】 from PyQt5.QtWidgets import ( QApplication , QDialog , QDialogButtonBox , QFormLayout , QGroupBox , QLabel , QLineEdit , QSpinBox , QVBoxLayout , QTextEdit ) class Dialog ( QDialog ): def __init__ ( self ): super () . __init__ () self . createFormGroupBox () buttonBox = QDialogButtonBox ( QDialogButtonBox . Ok | QDialogButtonBox . Cancel ) buttonBox . accepted . connect ( self . accept ) buttonBox . rejected . connect ( self . reject ) mainLayout = QVBoxLayout () mainLayout . addWidget ( self . formGroupBox ) mainLayout . addWidget ( buttonBox ) self . setLayout ( mainLayout ) self . setWindowTitle ( \"user info\" ) def createFormGroupBox ( self ): self . formGroupBox = QGroupBox ( \"your infomation\" ) layout = QFormLayout () layout . addRow ( QLabel ( \"name:\" ), QLineEdit ()) layout . addRow ( \"age:\" , QSpinBox ()) layout . addRow ( QLabel ( \"other infomation:\" ), QTextEdit ()) self . formGroupBox . setLayout ( layout ) if __name__ == '__main__' : import sys app = QApplication ( sys . argv ) dialog = Dialog () sys . exit ( dialog . exec_ ()) 这里 QDialog 类和 QDialogButtonBox 类我们且不去管他，QDialog类和下面的accept和reject方法有关，而QDialogButtonBox和最下面的两个按钮和绑定的喜好accepted和rejected有关。 然后我们看到下面创建表单的那个函数，其中 QGroupBox 也是一个窗体类型，带有标题。接下来就是QFormLayout表单布局的核心代码： layout = QFormLayout () layout . addRow ( QLabel ( \"name:\" ), QLineEdit ()) layout . addRow ( QLabel ( \"age:\" ), QSpinBox ()) layout . addRow ( QLabel ( \"other infomation:\" ), QTextEdit ()) self . formGroupBox . setLayout ( layout ) 我们看到前面的layout的创建和后面母窗体使用本layout的 setLayout 方法和前面两个布局都是类似的，除了表单布局是一行行的，它的方法不是addWidget，而是 addRow ，然后addRow方法严格意义上可以接受两个窗体类型（包括layout类型）， 另外第一个参数还可以是字符串，即显示的文字 。","tags":"pyqt5","url":"articles/pyqt5-layout.html"},{"title":"pyqt5编程之-第一个例子","text":"第一个例子 窗口 【beginning-first01】 import sys from PyQt5.QtGui import * from PyQt5.QtWidgets import * class MyWidget ( QWidget ): def __init__ ( self ): super () . __init__ () self . setGeometry ( 0 , 0 , 800 , 600 ) #坐标0 0 大小800 600 self . setWindowTitle ( 'myapp' ) myapp = QApplication ( sys . argv ) mywidget = MyWidget () mywidget . show () sys . exit ( myapp . exec_ ()) 首先导入sys宏包，这是为了后面接受sys.argv参数。 接下来我们定义了MyWidget类，它继承自QWidget类。然后通过QWidget类的 setGeometry 方法来调整窗口的左顶点的坐标位置和窗口的大小。 然后通过 setWindowTitle 方法来设置这个窗口程序的标题，这里就简单设置为\"myapp\"了。 任何窗口程序都需要创建一个QApplication类的实例，这里是myapp。然后接下来创建QWidget类的实例mywidget，然后通过调用mywidget的方法 show 来显示窗体。 最后我们看到系统要退出是调用的myapp实例的 exec_ 方法。 加上图标 【beginning-first02】 import sys from PyQt5.QtGui import QIcon from PyQt5.QtWidgets import QWidget , QApplication class MyWidget ( QWidget ): def __init__ ( self ): super () . __init__ () self . resize ( 800 , 600 ) self . setWindowTitle ( 'myapp' ) self . setWindowIcon ( QIcon \\ ( 'icons/myapp.ico' )) myapp = QApplication ( sys . argv ) mywidget = MyWidget () mywidget . show () sys . exit ( myapp . exec_ ()) 这个程序相对上面的程序就增加了一个 setWindowIcon 方法，这个方法调用了 QtGui.QIcon 方法，然后后面跟的就是图标的存放路径，使用相对路径。在运行这个例子的时候，请随便弄个图标文件过来。 为了简单起见这个程序就使用了QWidget类的 resize 方法来设置窗体的大小。 弹出提示信息 【beginning-first03】 import sys from PyQt5.QtGui import * from PyQt5.QtWidgets import * class MyWidget ( QWidget ): def __init__ ( self ): super () . __init__ () self . resize ( 800 , 600 ) self . setWindowTitle ( 'myapp' ) self . setWindowIcon ( QIcon \\ ( 'icons/myapp.ico' )) self . setToolTip ( '看什么看&#94;_&#94;' ) QToolTip . setFont ( QFont \\ ( '微软雅黑' , 12 )) myapp = QApplication ( sys . argv ) mywidget = MyWidget () mywidget . show () sys . exit ( myapp . exec_ ()) 上面这段代码和前面的代码的不同就在于MyWidget类的初始函数新加入了两条命令。其中 setToolTip 方法设置具体显示的弹出的提示文本内容，然后后面调用QToolTip类的 setFont 方法来设置字体和字号，我不太清楚这里随便设置系统的字体微软雅黑是不是有效。 这样你的鼠标停放在窗口上一会儿会弹出一小段提示文字。 关闭窗体时询问 【beginning-first04】 import sys from PyQt5.QtGui import * from PyQt5.QtWidgets import * class MyWidget ( QWidget ): def __init__ ( self ): super () . __init__ () self . resize ( 800 , 600 ) self . setWindowTitle ( 'myapp' ) self . setWindowIcon ( QIcon \\ ( 'icons/myapp.ico' )) self . setToolTip ( '看什么看&#94;_&#94;' ) QToolTip . setFont ( QFont \\ ( '微软雅黑' , 12 )) def closeEvent ( self , event ): #重新定义colseEvent reply = QMessageBox . question \\ ( self , '信息' , \"你确定要退出吗？\" , QMessageBox . Yes , QMessageBox . No ) if reply == QMessageBox . Yes : event . accept () else : event . ignore () myapp = QApplication ( sys . argv ) mywidget = MyWidget () mywidget . show () sys . exit ( myapp . exec_ ()) 这段代码和前面代码的不同就是重新定义了 colseEvent 事件。这段代码的核心就是QtGui类的QMessageBox类的question方法，这个方法将会弹出一个询问窗体。这个方法接受四个参数：第一个参数是这个窗体所属的母体，这里就是self也就是实例mywidget；第二个参数是弹出窗体的标题；第三个参数是一个标准button；第四个参数也是一个标准button，是默认（也就是按enter直接选定的）的button。然后这个方法返回的是那个被点击了的标准button的标识符，所以后面和标准 QMessageBox.Yes 比较了，然后执行event的accept方法。 屏幕居中显示窗体 【beginning-first05】 import sys from PyQt5.QtGui import * from PyQt5.QtWidgets import * class MyWidget ( QWidget ): def __init__ ( self ): super () . __init__ () self . resize ( 800 , 600 ) self . center () self . setWindowTitle ( 'myapp' ) self . setWindowIcon ( QIcon \\ ( 'icons/myapp.ico' )) self . setToolTip ( '看什么看&#94;_&#94;' ) QToolTip . setFont ( QFont \\ ( '微软雅黑' , 12 )) def closeEvent ( self , event ): #重新定义colseEvent reply = QMessageBox . question \\ ( self , '信息' , \"你确定要退出吗？\" , QMessageBox . Yes , QMessageBox . No ) if reply == QMessageBox . Yes : event . accept () else : event . ignore () #center method def center ( self ): screen = QDesktopWidget () . screenGeometry () size = self . geometry () self . move (( screen . width () - size . width ()) / 2 , \\ ( screen . height () - size . height ()) / 2 ) myapp = QApplication ( sys . argv ) mywidget = MyWidget () mywidget . show () sys . exit ( myapp . exec_ ()) 这个例子和前面相比改动是新建了一个 center 方法，接受一个实例，这里是mywidget。然后对这个实例也就是窗口的具体位置做一些调整。 QDesktopWidget类的 screenGeometry 方法返回一个量，这个量的width属性就是屏幕的宽度（按照pt像素计，比如1366×768，宽度就是1366），这个量的height属性就是屏幕的高度。 然后QWidget类的 geometry 方法同样返回一个量，这个量的width是这个窗体的宽度，这个量的height属性是这个窗体的高度。 然后调用QWidget类的move方法，这里是对mywidget这个实例作用。我们可以看到move方法的X，Y是从屏幕的坐标原点 (0,0) 开始计算的。第一个参数X表示向右移动了多少宽度，Y表示向下移动了多少高度。 整个函数的作用效果就是将这个窗体居中显示。 QMainWindow类 QtGui.QMainWindow类提供应用程序主窗口，可以创建一个经典的拥有状态栏、工具栏和菜单栏的应用程序骨架。（之前使用的是QWidget类，现在换成QMainWindow类。） 前面第一个例子都是用的QtGui.QWidget类创建的一个窗体。关于QWidget和QMainWindow这两个类的区别 根据这个网站 得出的结论是：QWdget类在Qt中是所有可画类的基础（这里的意思可能是窗体的基础吧。） 任何基于QWidget的类都可以作为独立窗体而显示出来而不需要母体（parent）。 QMainWindow类是针对主窗体一般需求而设计的，它预定义了菜单栏状态栏和其他widget（窗口小部件） 。因为它继承自QWidget，所以前面谈及的一些属性修改都适用于它。那么首先我们将之前的代码中的QWidget类换成QMainWindow类。 【beginning-first06】 import sys from PyQt5.QtGui import * from PyQt5.QtWidgets import * class MyWidget ( QMainWindow ): def __init__ ( self ): super () . __init__ () self . resize ( 800 , 600 ) self . center () self . setWindowTitle ( 'myapp' ) self . setWindowIcon ( QIcon \\ ( 'icons/myapp.ico' )) self . setToolTip ( '看什么看&#94;_&#94;' ) QToolTip . setFont ( QFont \\ ( '微软雅黑' , 12 )) def closeEvent ( self , event ): #重新定义colseEvent reply = QMessageBox . question \\ ( self , '信息' , \"你确定要退出吗？\" , QMessageBox . Yes , QMessageBox . No ) if reply == QMessageBox . Yes : event . accept () else : event . ignore () #center method def center ( self ): screen = QDesktopWidget () . screenGeometry () size = self . geometry () self . move (( screen . width () - size . width ()) / 2 , \\ ( screen . height () - size . height ()) / 2 ) myapp = QApplication ( sys . argv ) mywidget = MyWidget () mywidget . show () sys . exit ( myapp . exec_ ()) 现在程序运行情况良好，我们继续加点东西进去。 加上状态栏 【beginning-first07】 import sys from PyQt5.QtGui import * from PyQt5.QtWidgets import * class MainWindow ( QMainWindow ): def __init__ ( self ): super () . __init__ () self . resize ( 800 , 600 ) self . center () self . setWindowTitle ( 'myapp' ) self . setWindowIcon ( QIcon \\ ( 'icons/myapp.ico' )) self . setToolTip ( '看什么看&#94;_&#94;' ) QToolTip . setFont ( QFont \\ ( '微软雅黑' , 12 )) def closeEvent ( self , event ): #重新定义colseEvent reply = QMessageBox . question \\ ( self , '信息' , \"你确定要退出吗？\" , QMessageBox . Yes , QMessageBox . No ) if reply == QMessageBox . Yes : event . accept () else : event . ignore () #center method def center ( self ): screen = QDesktopWidget () . screenGeometry () size = self . geometry () self . move (( screen . width () - size . width ()) / 2 , \\ ( screen . height () - size . height ()) / 2 ) myapp = QApplication ( sys . argv ) mainwindow = MainWindow () mainwindow . show () mainwindow . statusBar () . showMessage ( '程序已就绪...' ) sys . exit ( myapp . exec_ ()) 这个程序和前面的区别在于最后倒数第二行，调用mainwindow这个QMainWindow类生成的实例的 statusBar 方法生成一个QStatusBar对象，然后调用QStatusBar类的 showMessage 方法来显示一段文字。 如果你希望这段代码在 __init__ 方法里面，那么具体实现过程也与上面描述的类似。 加上菜单栏 【beginning-first08】 import sys from PyQt5.QtGui import * from PyQt5.QtWidgets import * class MainWindow ( QMainWindow ): def __init__ ( self ): super () . __init__ () self . initUI () def initUI ( self ): self . resize ( 800 , 600 ) self . center () self . setWindowTitle ( 'myapp' ) self . setWindowIcon ( QIcon \\ ( 'icons/myapp.ico' )) #菜单栏 menu_control = self . menuBar () . addMenu ( 'Contorl' ) act_quit = menu_control . addAction ( 'quit' ) act_quit . triggered . connect ( self . close ) menu_help = self . menuBar () . addMenu ( 'Help' ) act_about = menu_help . addAction ( 'about...' ) act_about . triggered . connect ( self . about ) act_aboutqt = menu_help . addAction ( 'aboutqt' ) act_aboutqt . triggered . connect ( self . aboutqt ) #状态栏 self . statusBar () . showMessage ( '程序已就绪...' ) self . show () def about ( self ): QMessageBox . about ( self , \"about this software\" , \"wise system\" ) def aboutqt ( self ): QMessageBox . aboutQt ( self ) def closeEvent ( self , event ): #重新定义colseEvent reply = QMessageBox . question \\ ( self , '信息' , \"你确定要退出吗？\" , QMessageBox . Yes , QMessageBox . No ) if reply == QMessageBox . Yes : event . accept () else : event . ignore () #center method def center ( self ): screen = QDesktopWidget () . screenGeometry () size = self . geometry () self . move (( screen . width () - size . width ()) / 2 , \\ ( screen . height () - size . height ()) / 2 ) myapp = QApplication ( sys . argv ) mainwindow = MainWindow () sys . exit ( myapp . exec_ ()) 和上面讨论加上状态栏类似，这里用QMainWindow类的 menuBar 方法来获得一个菜单栏对象。然后用这个菜单栏对象的 addMenu 方法来创建一个新的菜单对象（QMenu类），addMenu方法里面的内容是新建菜单要显示的文本。 然后继续给之前的菜单对象加上动作，调用菜单对象的 addAction 方法，我们看到menuBar创建了一个菜单栏对象，然后使用addMenu方法创建了一个菜单，同时返回的是一个菜单对象，然后对这个菜单对象使用addAction方法，这个方法给菜单添加了一个动作，或者说一个item一个内容，然后addAction返回的是一个动作对象，然后对这个动作对象进行信号－槽机制连接，将其和一个函数连接起来了。 在这里这个动作对象，就是菜单的下拉选项，如果我们用鼠标点击一下的话，将会触发 triggered 信号，如果我们connect方法连接到某个槽上（或者某个你定义的函数），那么将会触发这个函数的执行。下面就信号－槽机制详细说明之。 信号－槽机制 GUI程序一般都引入一种事件和信号机制，well，简单来说就是一个循环程序，这个循环程序等到某个时刻程序会自动做某些事情比如刷新程序界面啊，或者扫描键盘鼠标之类的，等用户点击鼠标或者按了键盘之后，它会接受这个信号然后做出相应的反应。 所以你一定猜到了， close 函数可能就是要退出这个循环程序。我们调用主程序的 exec_ 方法，就是开启这个循环程序。 pyqt4的旧的信号－槽连接语句我在这里忽略了，在这里值得提醒的是pyqt5已经不支持旧的信号－槽连接语句了。下面就新的语句说明之。 act_exit . triggered . connect ( self . close ) 我们看到新的信号－槽机制语句变得更精简更易懂了。整个过程就是如我前面所述，某个对象发出了某个信号，然后用connect将这个信号和某个槽（或者你定义的某个函数）连接起来即形成了一个反射弧了。 这里的槽就是self主窗口实例的close方法，这个是主窗口自带的函数。 然后我们看到aboutqt和about函数。具体读者如果不懂请翻阅QMessageBox类的静态方法 about 和 aboutqt 。","tags":"pyqt5","url":"articles/pyqt5-lesson-one.html"},{"title":"pyqt5编程之-资源文件管理","text":"资源文件管理 资源管理 pyqt都用qrc文件来管理软件内部的资源文件（如图标文件，翻译文件等）。qrc文件的编写格式如下： <!DOCTYPE RCC> <RCC version= \"1.0\" > <qresource> <file> images/copy.png </file> </qresource> </RCC> qrc的编写还是很简单的，完全可以手工编写之。上面代码第三行的images/copy.png的意思就是qrc文件所在目录下的images文件夹，里面的copy.png文件。 qrc文件编写好了你需要运行如下命令 pyrcc5 wise.qrc -o wise_rc.py 这样将会输出一个 wise_rc.py 文件，你如果要使用里面的资源，首先 import wise_rc 然后引用路径如下 :/images/copy.png ，这样就可以使用该图标文件了。 推荐一个项目里面所有的资源文件都用一个qrc文件来管理。","tags":"pyqt5","url":"articles/pyqt5-resources.html"},{"title":"pyqt5编程之-配置文件管理","text":"配置文件管理 pyqt5里的QtCore子模块里提供了 QSettings 类来方便管理软件的配置文件。 QSettings构造函数 一般先推荐把OrganizationName和ApplicationName设置好。 app . setOrganizationName ( \"Wise\" ) app . setApplicationName ( \"wise\" ) 然后接下来是构建一个QSettings对象。 QSettings ( parent ) 在设置好组织名和软件名之后，如果如上简单 QSettings() 来创建一个配置文件对象，不带任何参数，parent取默认值，那么所谓的format取的默认值是 QSettings.NativeFormat ，然后所谓的scope取的默认值是 QSettings.UserScope 。这里的scope还有QSettings.SystemScope，这个和软件的配置文件权限有关，这里先略过了，一般就使用默认的UserScope吧。 fromat如果取默认的NativeFormat那么具体软件配置文件的安装目录如下： 如果是linux系统，比如上面的例子具体配置文件就是： /home/wanze/.config/Wise/wise.conf 如果是windows系统，那么上面的例子具体就是： HKEY_CURRENT_USER\\Software\\Wise\\wise windows下配置是放在注册表里面的。 IniFormat 如果你希望配置文件都以ini形式存储，那么你需要采取如下格式初始化配置文件对象： self.settings = QSettings(QSettings.IniFormat,QSettings.UserScope,\"Wise\",\"wise\") 这样配置文件就在这里： /home/wanze/.config/Wise/wise.ini 。这里是linux系统的情况，windows系统官方文档给出的是： %APPDATA%\\Wise\\wise.ini ，这个 %APPDATA% 一般是 C:\\Documents and Settings\\*User Name*\\Application Data 你可以通过调用 self.settings.fileName() 来查看该配置文件对象具体的路径所在。 推荐配置文件作为mainwindow实例的属性如上self.settings来确定，然后所有的子窗体都可以通过调用self来获得同一的配置文件对象。 ini文件存放DIY 如果你希望ini文件放在你喜欢的地方，下面是配置文件构造函数的第三种形式： QSettings(\"wise.ini\",QSettings.IniFormat) 第一个参数是你的配置文件名，第二个参数是format。如上相对路径的话则是从你目前软件运行时的文件夹算起。 你可以通过调用 settings.fileName() 来看看该配置文件的具体所在。 ini文件注意事项 ini文件是大小写不敏感的，所以尽量避免两个变量名相近只是大小写不同。 不要使用\"\\\"和\"/\"。windows里\\会转换成/，而\"/\"使用来表示配置文件中分组关系的。 存值和读值 配置文件对象建立之后你就可以很方便地存放一些值和读取值了。存值用 setValue 方法，取值用 value 方法。如下所示： settings.setValue(\"editor/wrapMargin\", 68) margin = self.settings.value(\"editor/wrapMargin\") 如果setValue的键在配置文件对象中已经存在，那么将更新值，如果要修改立即生效，可以使用 sync 方法，sync方法不接受参数，就是立即同步配置文件中的更新。 value 方法第一个参数是\"键\"，第二个参数是可选值，也就是如果没找到这个键，那么将会返回的值。一般最好还是写上，否则可能配置文件不在了，你就会发生读取错误。 其他方法还有： contains: 接受一个\"键\"，字符串对象，返回bool值，看看这个键是不是存在。 remove: 接受一个\"键\"，移除该键。 allkeys: 不接受参数，返回所有的\"键\"。 clear: 不接受参数，清除所有的\"键\"。 群组管理 settings.setValue(\"editor/wrapMargin\", 68) 如上例子所示\"/\"表示数据结构中的分组，如果有很多值都有相同的前缀，也就是同属一组，那么可以使用beginGroup方法和endGroup方法来管理。如下所示： settings.beginGroup(\"editor\") settings.setValue(\"wrapMargin\", 68) settings.engGroup()","tags":"pyqt5","url":"articles/pyqt5-settings.html"},{"title":"pyqt5编程之-快捷键管理","text":"快捷键和Tab键管理 我们在创建ui文件的时候就可以把一些Action对应的快捷键给设置好。 什么是伙伴关系 一般是通过QLabel的setBuddy方法来关联某个输入窗体。然后QLabel有一个快捷键，当你按下这个快捷键，输入焦点就会转到这个QLabel对应的伙伴输入窗体上。 快捷键 QShortcut类 文本前用&会引入对应的Alt+w之类的快捷键。 然后QAction在初始化的时候有 然后QAction有方法 QKeySequence QKeySequence 类在pyqt4和pyqt5中来自QtGui子模块，是快捷键的解决方案。比如可以直接引用 QKeySequence.Open 来表示快捷键Ctrl+O。可用的构造函数如下所示： QKeySequence(QKeySequence.Print) QKeySequence(tr(\"Ctrl+P\")) QKeySequence(tr(\"Ctrl+p\")) QKeySequence(Qt.CTRL + Qt.Key_P) 我不太喜欢第一种表达方式，不是任何软件都有打印操作，况且打印和某个快捷键之间并没有逻辑联系，只有程序员的个人使用经验，这是不小的记忆负担。我比较喜欢第四种写法，看上去意义更加清晰，Qt来自QtCore子模块。 字母按键就是类似 Qt.Key_W 这样的形式，Shift按键是Qt.SHIFT，Meta按键是Qt.META，CTRL按键是 Qt.CTRL ，ALT按键是 Qt.ALT 。","tags":"pyqt5","url":"articles/pyqt5-shortcut.html"},{"title":"pyqt5编程之-信号-槽详解","text":"信号－槽详解 考虑到pyqt5只支持新式信号－槽机制了，这里将新式信号－槽机制详细说明。 信号(singal)可以连接无数多个槽(slot)，或者没有连接槽也没有问题，信号也可以连接其他的信号。正如前面所述，连接的基本语句形式如下： who.singal.connect(slot) 。比如说按钮最常见的内置信号 triggered ，而槽实际上就是某个函数，比如主窗体的 self.close 方法。 信号就是 QObject 的一个属性，pyqt的窗体有很多内置信号，你也可以定义自己的信号，这个后面再提及。信号还没和槽连接起来就只是一个属性，只有通过 connect 方法连接起来，信号－槽机制就建立起来了。类似的信号还有 disconnect 方法和 emit 方法。disconnect就是断开信号－槽机制，而emit就是激活那个信号。 pyqt很多内置信号和内置槽将GUI的事件驱动细节给隐藏了，如果你自己定义自己的信号或者槽可能对who.singal.connect(slot)这样简洁的形式如何完成工作的感到困惑。这里先简要地介绍一下。 信号都是类的一个属性，新的信号必须继承自QObject，然后由 PyQt5.QtCore.pyqtSingal 方法创建，这个方法接受的参数中最重要的是types类型，比如int，bool之类的，你可以认为这是信号传递的参数类型，但实际传递这些参数值的是emit方法。然后槽实际上就是经过特殊封装的函数，这些函数当然需要接受一些参数或者不接受参数，而这些参数具体的值传进来的是由emit方法执行的，然后我们通过who.singal.connect(slot)这样的形式将某个信号和某个槽连接起来，who的信号，然后信号类自带的连接方法，然后连接到slot某个函数上，在这里隐藏的一个重要细节就是emit方法，比如说你定义一个新的信号，需要将点击屏幕的具体x,y坐标发送出去，内置的信号－槽将这一机制都完成了，如果你自己定义的信号和槽的话，比如 pyqtSingal(int,int) ，发送给func(x,y)，具体x和y的值你需要通过emit(x,y)来发送。至于什么时候发送，已经发送的x,y值的获取，这应该又是另外一个信号－槽机制的细节。 请看下面这个例子： 【singal-slot/age】 import sys from PyQt5.QtWidgets import QHBoxLayout , QSlider , QSpinBox , QApplication , QWidget from PyQt5.QtCore import Qt app = QApplication ( sys . argv ) window = QWidget () window . setWindowTitle ( \"enter your age\" ) spinBox = QSpinBox () slider = QSlider ( Qt . Horizontal ) spinBox . setRange ( 0 , 130 ) slider . setRange ( 0 , 130 ) spinBox . valueChanged . connect ( slider . setValue ) slider . valueChanged . connect ( spinBox . setValue ) spinBox . setValue ( 35 ) layout = QHBoxLayout () layout . addWidget ( spinBox ) layout . addWidget ( slider ) window . setLayout ( layout ) window . show () sys . exit ( app . exec_ ()) 第16行将spinBox的 valueChanged 信号和slider的 setValue 槽连接起来了，其中QSpinBox内置的 valueChanged 信号发射自带的一个参数就是改变后的值，这个值传递给了QSlider的内置槽 setValue ，从而将slider的值设置为新值。第17行如果slider的值发生了改变，那么会发送valueChanged信号，然后又传递给了spinBox，并执行了内置槽setValue，由于此时的值即为原值，这样spinBox内的值就没有发生改变了，如此程序不会陷入死循环。 自定义信号 正如前所述及自定义信号由 PyQt5.QtCore.pyqtSingal 方法创建，具体格式如下： from PyQt5.QtCore import QObject , pyqtSignal class Foo ( QObject ): closed = pyqtSignal () range_changed = pyqtSignal ( int , int , name = 'rangeChanged' ) 上面Foo类里面自定义了一个新的信号，它必须是GObject的子类。然后定义了一个closed信号，没有接受任何参数。下面是range_changed信号，接受了一个int和一个int类型，然后这个信号的名字是rangeChanged，name选项是一个可选项，如果不填那么信号的名字就是range_changed。 信号还可以overload，不过似乎不太适合python。 注意信号必须定义为类的属性，同时必须是GObject的子类。 自定义槽 按照python格式自己定义的函数就是所谓的自定义槽了。不过推荐用pyqt的槽装饰器来定义槽。 from PyQt4.QtCore import pyqtSlot #1 @pyqtSlot () def foo ( self ): pass #2 @pyqtSlot ( int , str ) def foo ( self , arg1 , arg2 ): pass #3 @pyqtSlot ( int , name = 'bar' ) def foo ( self , arg1 ): pass #4 @pyqtSlot ( int , result = int ) def foo ( self , arg1 ): pass #5 @pyqtSlot ( int , QObject ) def foo ( self , arg1 ): pass 上面的第一个例子定义了名叫foo的一个槽，然后不接受任何参数。第二个槽接受一个int类型的值和str类型的值。第三个槽名字叫做bar，接受一个int类型的值，第四个槽接受一个int类型的值，然后返回的是一个int类型的值，第五个操作接受一个int类型的值和一个GObject类型的值，此处应该暗指其他pyqt窗体类型都可以作为参数进行传递。 @pyqtSlot ( int ) @pyqtSlot ( 'QString' ) def valueChanged ( self , value ): pass 这里定义了两个槽，名字都叫做valueChanged，一个接受int类型，一个接受QString类型，同前面信号的overload一样，在python中不推荐这么使用，还是明晰一点比较好。 发射信号 信号对象有emit方法用来发射信号，然后信号对象还有disconnect方法断开某个信号和槽的连接。 一个信号可以连接多个槽，多个信号可以连接同一个槽，一个信号可以与另外一个信号相连接。 下面通过一个例子详解自建信号还有自建槽并建立发射机制的情况。 【singal-slot/FindDialog】 from PyQt5.QtWidgets import QDialog , QLabel , QLineEdit , QCheckBox , QPushButton , QHBoxLayout , QVBoxLayout , QApplication from PyQt5.QtCore import Qt , pyqtSignal , QObject , pyqtSlot class FindDialog ( QDialog ): findNext = pyqtSignal ( str , Qt . CaseSensitivity ) findPrevious = pyqtSignal ( str , Qt . CaseSensitivity ) def __init__ ( self , parent = None ): super () . __init__ ( parent ) label = QLabel ( self . tr ( \"Find &what:\" )) self . lineEdit = QLineEdit () label . setBuddy ( self . lineEdit ) self . caseCheckBox = QCheckBox ( self . tr ( \"Match &case\" )) self . backwardCheckBox = QCheckBox ( self . tr ( \"Search &backward\" )) self . findButton = QPushButton ( self . tr ( \"&Find\" )) self . findButton . setDefault ( True ) self . findButton . setEnabled ( False ) closeButton = QPushButton ( self . tr ( \"Close\" )) self . lineEdit . textChanged . connect ( self . enableFindButton ) self . findButton . clicked . connect ( self . findClicked ) closeButton . clicked . connect ( self . close ) topLeftLayout = QHBoxLayout () topLeftLayout . addWidget ( label ) topLeftLayout . addWidget ( self . lineEdit ) leftLayout = QVBoxLayout () leftLayout . addLayout ( topLeftLayout ) leftLayout . addWidget ( self . caseCheckBox ) leftLayout . addWidget ( self . backwardCheckBox ) rightLayout = QVBoxLayout () rightLayout . addWidget ( self . findButton ) rightLayout . addWidget ( closeButton ) rightLayout . addStretch () mainLayout = QHBoxLayout () mainLayout . addLayout ( leftLayout ) mainLayout . addLayout ( rightLayout ) self . setLayout ( mainLayout ) self . setWindowTitle ( self . tr ( \"Find\" )) self . setFixedHeight ( self . sizeHint () . height ()) def enableFindButton ( self , text ): self . findButton . setEnabled ( bool ( text )) @pyqtSlot () def findClicked ( self ): text = self . lineEdit . text () if self . caseCheckBox . isChecked (): cs = Qt . CaseSensitive else : cs = Qt . CaseInsensitive if self . backwardCheckBox . isChecked (): self . findPrevious . emit ( text , cs ) else : self . findNext . emit ( text , cs ) if __name__ == '__main__' : import sys app = QApplication ( sys . argv ) findDialog = FindDialog () def find ( text , cs ): print ( 'find:' , text , 'cs' , cs ) def findp ( text , cs ): print ( 'findp:' , text , 'cs' , cs ) findDialog . findNext . connect ( find ) findDialog . findPrevious . connect ( findp ) findDialog . show () sys . exit ( app . exec_ ()) 首先自建的信号必须是类的属性，然后这个类必须是QObject的子类，这里QDialog是继承自QObject的。请看到第9行和第10行，通过pyqtSignal函数来自建信号，此信号有两个参数，一个是str字符变量，一个是Qt.CaseSensitivity的枚举值。假设我们输入一些文字了，然后点击Find按钮，请看到第26行，点击之后将执行findClicked槽，按钮的clicked信号是不带参数的。所以后面定义的findClicked槽（简单的函数也可以）也没有任何参数。 findClicked槽的53-57行确定了当前的QLineEdit的text值和cs也就是大小写是否检查的状态。然后根据向前或者向后是否勾选来确定接下来要发送的信号。比如findNext信号调用emit方法，对应两个参数也传递过去了。而这个findNext正是我们前面自定义的信号，正是对应的两个参数类型。 我们再看到这里简单做了一个测试程序，70-73行定义了两个简单的函数，然后75，76行将findDialog的这两个信号和上面两个函数连接起来。于是当我们点击Find按钮，首先执行findClicked槽，然后假设这里发送了findNext信号（附带两个参数），然后信号又和find函数相连（参数传递给了find函数），然后执行find函数。整个过程就是这样的。 信号－槽机制的反思 在接下来Qt designer这一章也会详细讨论这个问题，我们使用Qt designer来设计和修改ui文件——对应程序中大部分的静态视图元素，主要的目的倒不是为了快速GUI程序编写，其实写代码也挺快的，主要的目的就是为了代码复用。当我们养成习惯，强迫自己程序中的静态视图元素都进入ui文件，这不仅增强了ui文件的复用性，而且也增强了剩下来的python代码的复用性。这其中很大一部分就是这里讨论的信号－槽机制的功劳。 当我们自定义的类加载好ui文件之后，该类里面的代码实际上就剩下两个工作： 把本窗体的信号和槽都编写好 把母窗体和子窗体和信号－槽接口写好。 一般程序的用户互动接口大多在最顶层，也就是用户一般喜欢在菜单栏找到所有可能对程序的控制，这些控制的实现函数如果放在都放在母窗体，那么整个程序的代码复用性会降到最低，而如果我们将这些实现函数分别移到和其视图窗体最紧密的窗体类中，那么不仅代码复用性会大大提高，而且这些槽或函数的编写也会简单很多。那么我们该如何组织这些信号和槽（实现函数）呢？我在这里提出组织学上的一些抽象原则： 最小组织原则，凡是小组织能够自我实现的功能绝不上传到更大一级的组织中去。 大组织对小组织元素的某些实现的引用，采用明文引用原则。比如说母窗体中有一个小窗体有一个编辑器，母窗体想要操控这个编辑器执行剪切操作，那么采用明文引用，也就是self.textEdit.cut。 小组织对大组织属性的引用采用信号激活原则，比如说某个编辑器发生了内容修改，你可以自定义一个信号，该信号为标题修改信号，然后信号触发母窗体的某个方法，这样达到修改母窗体的标题的目的。而在母窗体中，只需要在声明是将小组织的信号和大组织的某个方法连接起来即可。 引用信号发射对象 sender 方法来自GObject，所以一般Qt里的窗体对象都可以用。其用法主要在槽里面，调用 self.sender() ，即返回一个发射该信号从而调用该槽的对象。","tags":"pyqt5","url":"articles/pyqt5-singal-slot.html"},{"title":"pyqt5编程之-ui文件管理","text":"ui文件管理 利用 Qt designer 设计输出的 ui 界面文件，是可以直接用 PyQt5.uic.loadUi 来加载进来的，不过ui文件需要利用pypi的资源管理机制，这固然是一种解决方案，但不够pythonic。 推荐是用 pyuic5 处理来输出ui文件对应的py文件。大体是利用如下命令行： pyuic5 { filename } . ui - o { filename } _ui . py -- import - from = { project } '.format(filename=filename, project = PROJECT ) 这里的 --import-from 选项影响输出py文件的资源引入语句，默认是 import main_rc ，设置这个选项之后更改为： from project import main_rc 然后就是利用输出py文件里面的ui类了。 from .uis.main_ui import Ui_MainWindow class MainWindow ( QMainWindow ): def __init__ ( self , parent = None , * args ): super () . __init__ ( parent , * args ) ### setup ui self . mainUi = Ui_MainWindow () self . mainUi . setupUi ( self ) 具体引入按照官方教程有几种写法，上面这种写法中 setupUi 函数跟着本窗体的parent，如果是self则是挂在本窗体上，然后如果本窗体挂在其他母窗体即可。","tags":"pyqt5","url":"articles/pyqt5-ui-file.html"},{"title":"前端开发之-bootstrap","text":"bootstrap 本文档现在基于bootstrap v4重写了，本文档不求全，大体点到为止讲解一下，读者简单了解即可，具体还是要自己练手来学习。 安装 本文是如下加载的： <link rel= \"stylesheet\" href= \"https://cdn.bootcss.com/bootstrap/4.0.0-beta.2/css/bootstrap.min.css\" integrity= \"sha384-PsH8R72JQ3SOdhVi3uxftmaW6Vc51MKb0q5P2rRUpPvrszuE4W1povHYgTpBfshb\" crossorigin= \"anonymous\" > <script src= \"https://cdn.bootcss.com/jquery/3.2.1/jquery.slim.min.js\" integrity= \"sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN\" crossorigin= \"anonymous\" ></script> <script src= \"https://cdn.bootcss.com/popper.js/1.12.9/umd/popper.min.js\" integrity= \"sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q\" crossorigin= \"anonymous\" ></script> <script src= \"https://cdn.bootcss.com/bootstrap/4.0.0-beta.2/js/bootstrap.min.js\" integrity= \"sha384-alpBpkh1PFOepccYVYDB4do5UnbKysX5WZXm3XxPqe5iKTfUKjNkCk9SaVuEZflJ\" crossorigin= \"anonymous\" ></script> viewport元数据声明 为了确保适当的绘制和触屏缩放，需要加上如下viewport元数据声明: <meta name=\"viewport\" content=\"width=device-width, initial-scale=1, shrink-to-fit=no\"> container类 通过container class的 div 来获得一个固定宽度的响应式容器。 <div class= \"container\" style= \"background:#FFF0F5\" > 我在container类里面。 </div> 我在container类里面。 此外还有一个 container-fluid class，区别就是container类会根据当前设备的尺寸来自动调整自身大小。一般推荐页面的某部分都应该被包围在container盒子里面。 栅格系统 栅格系统是bootstrap框架里面很有用的一个特性了，其基本思路如下: 每一行 row 类都放在上面谈及的 container 类里面。 然后在每一行row类里面（这里所谓的什么类实际上就是该类属性的div盒子）再添加行类。 具体行类有很多种，请参看 这个网页 和官方文档的 这里 来具体设计之。 < div class = \"container\" style = \"background:#FFF0F5\" > 我在container类里面。 < div class = \"row\" style = \"background-color:yellow\" > < div class = \"col-md-8\" style = \"background-color:red\" > 我在col-md-8盒子里面，黄色是row盒子。 </ div > < div class = \"col-md-4\" style = \"background-color:blue\" > 我在col-md-4盒子里面，8+4=12，bootstrap最多12列。 </ div > </ div > </ div > 我在container类里面。 我在col-md-8盒子里面，黄色是row盒子。 我在col-md-4盒子里面，8+4=12，bootstrap最多12列。 其他常规css设置 其他常规css设置比如说h1-h6字体大小啊，等等其他常规标签的字体大小啊颜色啊代码背景的设置啊等等，这些都可以通过浏览器的开发者工具来查看具体的css代码设置，如果觉得默认设置不好则另外再弄个css文件重载也是可以的，这些就不多说了。 bootstrap提供了 text-lowercase , text-uppercase , text-capitalize class: <p class= \"text-lowercase\" > HELLO world </p> <p class= \"text-uppercase\" > hello world </p> <p class= \"text-capitalize\" > hello world </p> HELLO world hello world hello world 控制文本对齐方式 主要作用于p段落盒子的属性支持: text-left , text-center , text-right , text-justify , text-nowrap 。 具体这些css都很简单: <pre class= \"pre-scrollable\" > .text-left { text-align: left; } .text-right { text-align: right; } .text-center { text-align: center; } .text-justify { text-align: justify; } .text-nowrap { white-space: nowrap; } </pre> lead盒子 后面都如此约定，所谓的 lead盒子 是指class属性为lead的div标签，即: < div class = \"lead\" style = \"border:1px solid\" > hi ，我在lead盒子里面，边框是额外加上去的。可以用来作为某个特别重要的话的强调。 </ div > hi ，我在lead盒子里面，边框是额外加上去的。可以用来作为某个特别重要的话的强调。 jumbotron盒子 bootstrap提供的jumbotron盒子一般在首页用于展示某个特别重要希望读者阅读的信息。 < div class = \"jumbotron\" > < p > 大家好，我在jumbotron盒子里面。 </ p > </ div > 大家好，我在jumbotron盒子里面。 pull-left和pull-right bootstrap用这个class属性来左对齐或右对齐某个标签元素。 tabs的制作 利用bootstrap制作tabs，就是建立一个ul无序列表，然后class属性设置为 nav nav-tabs ，这样就制作了一个简单的tabs了。 < ul class = \"nav nav-tabs\" > < li class = \"active\" >< a href = \"#\" > Features </ a ></ li > < li >< a href = \"#\" > Details </ a ></ li > </ ul > Features Details pill形状tabs制作 < ul class = \"nav nav-pills\" > < li class = \"active\" >< a href = \"#\" > Features </ a ></ li > < li >< a href = \"#\" > Details </ a ></ li > </ ul > Features Details list-inline 给ul或ol加上 list-inline 属性，来是li列表元素水平inline-block显示，如下所示: 第一个li 第二个li kbd标签 kbd标签用来显示按键组合: Ctrl+X 如何制作一个 Bootstrap 风格的带链接的按钮 参看 这个网页 。 我更喜欢这种写法: <a href= \" {{ message [ \"body\" ] }} \" target= \"_blank\" role= \"button\" class= \"btn btn-success btn-large\" > Click here! </a>","tags":"html5","url":"articles/qian-duan-kai-fa-zhi-bootstrap.html"},{"title":"让一个函数成为装饰器的装饰器函数","text":"python中的装饰器的作用就是可调用对象（一般情况下指函数）名字的重绑定。重绑定行为通常发生在原函数def结束之后，原函数将作为参数被传入装饰器函数中，从而实现函数行为上的重制。 所以装饰器函数的最基本定义就是接受一个可调用对象再返回一个可调用对象。 本文的任务就是让一个函数成为装饰器的装饰器，这在某些情况下是有用的，比如说 def post(self): pass 在flask中我们定义的视图函数，如果需要添加参数检查逻辑，那么大概我们会写一系列的验证函数，将post进来的参数 ----> ----> ----> 一直传过去，直到传出来那么就说明参数都没有问题的，嗯，很直观的一种设计模式。 要实现这种代码风格，就需要做到让一个或者一些函数成为装饰器，而为了代码复用，最好写出一个装饰器函数装饰目标函数即可。 我们知道装饰器最直观的写法如下： def build_passing_decorator_func(func): \"\"\" 使一个函数成为一个装饰器 \"\"\" def wrapper(method, *args, **kwargs): ok, response = method(*args, **kwargs) return func(ok, response) return wrapper @build_passing_decorator_func def test(ok, data): pass @test def post(self): pass 按照装饰器的含义，我们有： test(post)(self) build_passing_decorator_func(test)(post)(self) wrapper(post)(self) # func=test 最后程序似乎执行的是： ok, response = post(*args, **kwargs) return test(ok, response) 如果这个test方法返回的还是某种参数格式，那么多个装饰器可以一直这样写下去。 但是上面的这种写法有个问题 ： 如果装饰的是简单的函数，那么是没问题的，但如果装饰的是类的方法的话，self实例并不能很好的解析。参考 Mark Lutz 的python学习手册一书，按照上面的写法，装饰的方法会重绑定到装饰器类中，从而丢失了self本身的实例，导致self不能正常解析。 但如果采用下面这种嵌套函数写法则不会有如上问题： def build_passing_decorator_func(func): \"\"\" 使一个函数成为一个装饰器 \"\"\" def wrapper(f): @wraps(f) def decorator(*args, **kwargs): ok, response = f(*args, **kwargs) return func(ok, response) return decorator return wrapper 具体原因我还不是特别清楚，之前我想到是可能python里的装饰器优先级特别高，先于类的实例化就已经加载了，而这种嵌套函数有惰性解析参数的含义，所以类的实例化self解析才不会出错。","tags":"python语言","url":"articles/rang-yi-ge-han-shu-cheng-wei-zhuang-shi-qi-de-zhuang-shi-qi-han-shu.html"},{"title":"pycharm和webstrom编辑器使用技巧","text":"一般的操作就不多说了，下面主要说一些略显高级的技巧。 直接上传文件到服务器 其实原理就是利用sftp上传，但在pycharm这个大环境下，确实有时很方便的。这个功能只在pycharm专业版下才有。 Tools -> Deployment -> configuration 主要是某些需要在服务器上频繁测试的工作，但是有不方便git频繁commit的情况，这个时候可以先测试好，在git推送。 设置环境为远程python解释器 在： Settings -> Project -> Project Interpreter 哪里，可以利用pycharm新建一个本地的虚拟环境，或者用pipenv建立环境之后，pycharm会自动找到，从而利用已经存在的python虚拟环境，而这里要讲的是，你还可以设置解释器环境为远程服务器的python环境，这样你的开发调试将更加接近程序实际运行时的环境。 在： Tools -> Start SSH session... 你可以在terminal哪里打开一个连接到远程服务器的ssh终端，加上上面的设置好文件upload功能，基本上你不需要使用另外一个额外的ssh终端连接程序了。 本部分讨论的都是基于ssh连接的，你需要在： Tools -> Deployment -> Configuration 哪里设置好ssh server 的连接方式。 正则表达式替换 按下路径替换之后，可能有些复杂点的任务需要做正则表达式替换，正则表达式大家都很熟悉了，这里就不多说了，主要是group替换的时候，如何表示。 首先原表达式一样用 () 来包围你想要设定的group，然后本表达式引用这个group（从1开始数），是 \\1 \\2 ... 而后面要替换的表达式要引用上面的group依次是 $1 $2 ... 更多内容请参看官方文档的 这里 。","tags":"others","url":"articles/pycharm-webstrom-editor.html"},{"title":"学习gunicorn","text":"简介 gunicorn 挂载python的 wsgi 服务还是不错的，多进程多线程支持，大大提升服务性能。 配置 配置可以就是一个python文件，然后大体内容如下： from multiprocessing import cpu_count from os import environ def max_workers (): return cpu_count () bind = '127.0.0.1:8000' max_requests = 1000 worker_class = 'gevent' workers = max_workers () 写上这么一个python文件之后，启动gunicorn挂载django服务大体如下： gunicorn -c gunicorn_config.py youapp.wsgi 其他配置还有： pidfile reload 代码改变之后自动reload，这个前期开发会很有用 accesslog access日志所在地 errorlog error 日志所在地 workers 进程数 threads 一个进程的线程数 worker_class worker_connections 单进程最大连接数 loglevel 日志级别","tags":"linux","url":"articles/learning-gunicorn.html"},{"title":"数据处理的程序的设计原则讨论","text":"数据量很大的情况下，通常指数据库下数据量较大的情况下，我们编写数据处理程序应该具有怎样的设计原则： 我对分布式流式计算框架不太熟悉，也许使用那些框架是个思路，现在是我纯粹从自己面对的问题作出的一些然后提出的一些原则： 大的基本操作应考虑以从数据库的某处移动到某处来标记操作的完成，因为大的基本操作变动性并不是太大，这样数据库某个地方的数据都是有特别含义的。 大的基本操作下还有一些小的操作步骤，这是一个难点，第一入口数据不断更新甚至老数据也会有变化，第二处理代码也可能会有变更，这部分并没有一劳永逸的完美的可扩展方案，有有的时候也是带来了太多的复杂性。一个比较好的建议是记录如下operations的处理信息： operations : op_name op_state last_op_time op_day 2.1 操作名 2.2 op_state 操作状态，每个操作前都将state调为2，最后程序快结束的最后一行，state调为1，这样确保了op操作 state=0 或者 =2 或者没有state这个参量都表示本操作有问题 2.3 操作碎片化，一个好的建议以目标数据的 进入天数 作为一个小的处理单元，这样某一步出现问题，可以重复刷，保证数据处理的可中断，状态可记录。 2.4 上一次的操作时间，这个信息的记录是为了便于处理某种情况下老数据发生了更新，我们把这种模式成为update模式，就是只有经过一个稍长的时间后（减轻服务器压力），然后再update更新目标数据，然后更新last_op_time ，加入update模式主要在系统初期或者某些老数据变化的情况下，读者需要根据自己情况考虑是否引入这个记录，但上一次的操作时间记录一下是没有问题的。 数据聚合操作，数据聚合操作一个问题就是按照上面的操作，可能对于确定op_day 不是很方便，因为不同的数据入口来源可能不同，一个好的思路是数据聚合确定一个 主数据源， 然后 op_day 是以这个主数据源的目标数据进入时间为准。 原则上我们设计工作流程一般是某一日事今日毕，当然如果读者如果有其他考虑处理手段也是可以的，但让操作碎片化我确定这个思路还是不错的。","tags":"设计","url":"articles/data-process-design-principle.html"},{"title":"fire模块","text":"前言 初次接触 fire模块 就不自觉的和 click模块 进行对比，老实说我一开始还真不太相信这是google团队的作品，google团队的产品会这么简洁，不过毕竟后面写着 ： This is not an official Google product. 首先说下fire模块的优点，这个初步了解一下优点是很明显的： 可以让你少写点代码。作为一个程序员最大的愿望是什么： 少写点代码就能把事办成了。当然继续往下说，fire模块可以让你的代码更简洁，现在真的一个python脚本就是一个命令行工具了，一句废话都没有了，包括函数类里面的文档定义都是有用的。就作为一般最简单的命令行需求，我是推荐fire模块的。 但是fire模块目前github上 commit很少，版本号也才 0.1.2，可能模块还有很多不稳定或者bug都是可能的，如果读者在项目需求上只是一两个python脚本需要做成命令行工具，我还是推荐click模块。如果读者有大量的python脚本转成命令行工具的需求，这在目前数据处理工作越来越多的大环境（实际上我怀疑这也是他们开发fire模块的初衷），那么使用fire模块无疑是能省点力气的，毕竟当初人们觉得click模块方便那也是只是相对于写一个命令行工具而言，现在情况确实有所不同了。 pip install fire 官方文档已经说的很详细了，本身使用是很简单的，下面我随便说说吧。 第一个例子 import fire def hello ( name ): return 'hello {name}.' . format ( name = name ) def main (): fire . Fire () if __name__ == '__main__' : main () 查看帮助信息 你需要在前面加上一个分隔符 -- 然后再跟上 --help 或者 -h 才会显示帮助信息。 Usage : test . py test . py fire test . py hello test . py main 我们看到 main 函数 fire 模块 hello 都暴漏出来了，这不太好。可以稍微改造一下，把文件名改为 hello.py import fire def hello ( name ): return 'hello {name}.' . format ( name = name ) if __name__ == '__main__' : fire . Fire ( hello ) 这样： PS C:\\Users\\a3580\\Desktop> python .\\hello.py -- --help Usage: hello.py NAME hello.py --name NAME 这种写法的好处就是控制只显示你想要的几个函数，而且输出少了很多乱七八糟的东西。如果你想写多个命令，可以这样： 多个命令 import fire def hello ( name ): return 'hello {name}.' . format ( name = name ) def bang (): return 'bang' if __name__ == '__main__' : fire . Fire ({ 'hello' : hello , 'bang' : bang }) PS C:\\Users\\a3580\\Desktop> python .\\hello.py -- --help Type: dict String form: {'hello': <function hello at 0x000001ED71FB2E18>, 'bang': <function bang at 0x000001ED740A5620>} Length: 2 Usage: hello.py hello.py hello hello.py bang 也许这样会更好一点，免得烂七八杂的东西混进来了。 不过本着尽量少些代码的追求，多个命令这样写也不错啊： def hello ( name ): \"\"\" 打印hello \"\"\" return 'hello {name}.' . format ( name = name ) def bang (): \"\"\" 打印bang \"\"\" return 'bang' if __name__ == '__main__' : import fire fire . Fire () 总之fire模块会把你定义的函数或者类（包括类里面的属性或者函数或者类）都暴露出来。 挂载类 fire模块挂载类不需要实例化，似乎是fire自动实例化了，然后你还可以指定实例化的参数： class Hello (): def __init__ ( self , punctuation ): self . punctuation = punctuation def hello ( self , name ): \"\"\" 打印hello \"\"\" return 'hello {name}{p}' . format ( name = name , p = self . punctuation ) @staticmethod def bang (): \"\"\" 打印bang \"\"\" return 'bang' if __name__ == '__main__' : import fire fire . Fire ( Hello ) PS C:\\Users\\a3580\\Desktop> python .\\hello.py hello world --punctuation=! hello world! 总的感觉fire模块在开发前期可以让程序员写命令行工具省点心，专心在代码的编写上，后期有时间和精力觉得还是用click代码来实现更友好的命令行界面等。","tags":"python好伙伴","url":"articles/fire-module.html"},{"title":"学习centeos7系统","text":"安装系统 centos7的安装目前最大的难点在硬盘分区上，加上新生代的uefi启动方式，还是有些新的问题需要讨论的。 记得以前早起折腾ubuntu系统时，最大的一个影响就是需要给linux系统安装预先分出一个swap分区，大约是内存的两倍，当时还不太懂这个有什么，按照 鸟哥的私房菜 一章的描述， 服务器一般内存都十几G-64G的内存，就不能按照这个公式来了，总之，分出3-4Gswap分区意思一下就可以了。 各个硬件在linux下的名字 这个需要了解下，参考 鸟哥的私房菜第二章 ， 硬盘或者USB模拟的硬盘 ： /dev/sd[a-p] CDROM或者DVDROM : /dev/scd[0-1] , /dev/cdrom（当前cdrom） , /dev/sr[0-1] 打印机 ： /dev/lp[0-2] , /dev/usb/lp[0-15] 鼠标 ： /dev/input/mouse[0-15] , /dev/mouse (当前鼠标) UEFI 启动 分区推荐 按照鸟哥的私房菜推荐，不是随便玩玩，而是作为工作服务器，那么推荐还是如下多分几个区： /boot / /home /var swap firewall-cmd 防火墙策略管理命令： firewall-cmd ， 其中 --list-all 列出开启的端口号等情况， --add-port 来开放某个端口号，比如： firewall-cmd --add-port=80/tcp 更多细节请参看 这篇文章 ，下面就一些常用的用法简要说明之。 firewall-cmd --get-active-zones # 查看活动的区域 firewall-cmd --zone = work --add-interface = eth0 # 为某个区域指定网卡界面 # 默认的zone是public firewall-cmd --zone = work --list-ports # 列出所有开放的端口 firewall-cmd --zone = work --add-port = 8080 /tcp # 为某个区域开发端口 firewall-cmd --zone = work --add-service = ssh # 为某个区域开发服务 # 类似的还有 --remove-prot 和 --remove-service firewall-cmd --get-services # 列出所有可用服务 NOTICE: 上面提及的操作如果不加 --permanent 参数那么只是临时有效，重启firewalld服务就会配置丢失。 systemd centos7引入了systemd，这真是一个好用的工具，以前我们接触的 /etc/init.d 下编写的服务脚本非常麻烦，然后我们喜欢使用supervisor来管理各个进程，现在假设有一个工具，一样简洁的配置管理语法，而且还是centos系统自带的，那么为什么不用这个工具来管理各个后台进程呢？这个工具就是systemd。 systemd服务都通过 systemctl 命令来管理的，实际上systemd是如此的基本，因为它已经取代inid成为了pid为1的进程，也就是后面的很多进程都是通过它来启动的，你甚至还可以通过systemctl来重启电脑，你就知道systemd服务是多么的底层了： systemctl reboot systemctl poweroff system的systemd服务脚本放在 /usr/lib/systemd/system 哪里，用户的systemd服务脚本是放在 /usr/lib/systemd/user 哪里。或者你也可以放在 /etc/systemd/system 或者 /etc/systemd/user 哪里。 说是服务脚本，其实就是一个配置配置文件，内容大体如下： [Unit] Description = nginx - high performance web server Documentation = http://nginx.org/en/docs/ After = network.target remote-fs.target nss-lookup.target [Service] Type = forking PIDFile = /usr/local/nginx/logs/nginx.pid ExecStartPre = /usr/local/nginx/sbin/nginx -t -c /usr/local/nginx/conf/nginx.conf ExecStart = /usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.conf ExecReload = /bin/kill -s HUP $MAINPID ExecStop = /bin/kill -s QUIT $MAINPID PrivateTmp = true [Install] WantedBy = multi-user.target Unit - Description 描述服务 Unit - Documentation 服务文档 Unit - After 服务依赖，只有依赖服务启动本服务才启动 Service - Type 启动类型，simple： 默认值，立即启动该服务； forking：以fork方式启动进程；oneshot：一次性进程；dbus：dbus启动；notify：服务启动完毕，通知systemd，然后继续向下执行。 Service - PIDFile pid文件路径 Service - ExecStartPre 启动前动作 Service - ExecStart 启动动作 Service - ExecReload reload动作 Service - ExecStop 停止动作 Service - PrivateTmp 临时空间 Service - ExecStartPost 启动后动作 Install - WantedBy systemd 东西还有点，后面有时间再慢慢补上，强烈推荐 金步国翻译的systemd中文手册 。 服务文件修改之后 一般是推荐配置文件外移，服务文件设置好之后就没必要修改了，如果服务文件修改了那么需要： systemctl daemon-reload 日志管理 systemd统一管理所有日志，可用 jourlnalctl 命令来查看之。点名要看某个服务Unit： jourlnalctl --unit=nginx 启动服务等等 启动服务重启服务暂停服务等等我想大家都很熟悉了吧： systemctl start what.service systemctl stop what.service systemctl restart what.service centos7配置dns 发现centos7配置dns之后重启 network 服务配置就会丢失，需要在 /etc/NetworkManager/NetworkManager.conf main哪里加上 dns = none 然后重启 systemctl restart NetworkManager.service 然后再如同以前一样修改 /etc/resolv.conf 。 配置语言 查看当前操作系统语言 cat /etc/locale.conf 或者 localectl status 列出可用语言 locale -a 或者 localectl list-locales | grep zh 修改操作系统语言 sudo localectl set-locale LANG=zh_CN.utf8 参考资料 鸟哥的私房菜 systemd入门教程之命令 systemd详解","tags":"linux","url":"articles/learning-centos7-system.html"},{"title":"pipenv模块","text":"pipenv模块刚开始听说觉得virtualenv够用了，就没太在意。后来一试发现真的可以，很方便的，在设计理念上和nodejs那边的包管理有点接近了，很不错。 刚进入一个文件夹，然后运行： pipenv install 当然运行前你需要： pip install pipenv 其会创建 Pipfile 和 Pipfile.lock 这两个文件。如果读者有点熟悉nodejs那边的包管理机制，就对这两个文件的作用不需要做过多的说明了。 那么怎么激活进入虚拟环境呢： pipenv shell 或者你直接调用虚拟环境下运行某个命令： pipenv run you_awesom_command 读者打开 Pipfile 文件会发现这一行 url = \"https://pypi.douban.com/simple\" 以前还要在系统的另外的地方去配置，现在直接在这里修改就可以了。 然后安装模块就是： pipenv install requests 或者remove模块： pipenv uninstall requests 值得注意的pipenv模块很好地解析的各个包包的依赖关系，这就是他比原 requirements.txt 要好一点的地方。 还有忘了什么 pip freeze 命令吧。 读者在使用pycharm的时候需要设置下pipenv管理的虚拟环境路径：在当前用户家目录下的 .virtualenvs 哪里。 文件夹格式引入 文件夹格式引入，就是一个简单的pypi包格式，主要是写好setup.py的那种，然后如下： pipenv install -e \"../what_your_pypi_package\" 这种格式懂得人都会明白，这个功能简直是让人拍案叫绝。某个python模块，你直接修改源码就可以了，pycharm那边对接好，不管是python shell还是自动进入虚拟环境的shell都直接直接使用哪个文件夹格式的pypi包， 关键是重点 ：你不需要像以前那样运行 python setup.py build 或者install之类的等等，就已经正常工作了，有的你拍案叫绝有没有，有没有。","tags":"python好伙伴","url":"articles/pipenv-module.html"},{"title":"pillow模块","text":"简介 pillow模块的前身是PIL模块，其有更好的github和pypi支持，所以简单的安装就可以通过pip命令安装之即可。不过pillow模块对于某些特殊格式的图片处理支持可能依赖于系统的一些额外的图形处理模块，比如libjpeg，libtiff等。可能你的系统已经安装了，也可能没有，根据具体情况来，这里就不一一讨论了。 安装官方文档的叙述（also reference this ），下面这些可能需要装上。 sudo apt-get install python3-dev python3-setuptools sudo apt-get install libtiff4-dev libjpeg8-dev zlib1g-dev \\ libfreetype6-dev liblcms2-dev libwebp-dev tcl8.5-dev tk8.5-dev 测试安装情况 可以如下找个图片简单测试一下安装情况: from PIL import Image img = Image . open ( \"test.jpg\" ) print ( img . format , img . size , img . mode ) img . show () pillow模块在这里名字叫PIL是因为它的父亲是PIL，pillow fork自它，并setuptools兼容。 我们看到pillow模块的语法还是很清晰的，Image是个类，open方法返回具体的jpg img 对象，这里就简单称作img对象了，img对象有format, size , mode方法，分别是图片的格式（JPEG），图片的尺寸（(1920, 1080)）和图片的模式（RGB）。然后img对象调用show方法会（通过系统内部工具）显示图片。 open方法就目前按照官方文档的叙述支持如下格式：bmp，eps，gif，im，jpeg，jpeg2000，msp，pcx，png，ppm ，spider，tiff，webp，xbm，xv等。还有一些格式要某只支持读要某只支持写这里不说明了。其中写的时候save方法需要明确说明图片的目标格式，而open方法打开的时候图片名字是随意的，pillow会自动检测图片的格式。 如果open方法图片打开失败，将会返回 IOError 异常。 获取图片信息 首先一般是如下引用: from PIL import Image 然后利用这个Image类的open方法来创建一个图片对象: im = Image.open('lena.jpg') 然后如下获取图片的格式，尺寸和模式信息。 >>> im.format 'JPEG' >>> im.size (512, 512) >>> im.mode 'RGB' >>> 图片格式转换 接触pillow模块的第一个应用就是图片格式转换，请看下面我写的两个函数，都是利用的pillow模块，一个单独转换图片，一个根据文件夹某个后缀文件批量进行格式转换。 from __future__ import print_function import os.path from PIL import Image import subprocess import logging logging . basicConfig ( level = logging . DEBUG ) def mkdir_p ( path ): try : os . makedirs ( path ) except OSError as exc : # Python &gt;2.5 if exc . errno == errno . EEXIST and os . path . isdir ( path ): pass else : raise def convert_imgformat ( inputimg , imgext2 , outputdir = '' ): '''support convertion: pillow处理点阵图之间的互换png jpg gif eps tiff bmp ppm 已经加上了输出dir自动支持 。 ''' pillow_support = [ 'png' , 'jpg' , 'gif' , 'eps' , 'tiff' , 'bmp' , 'ppm' ] imgname , imgext = os . path . splitext ( os . path . basename ( inputimg )) #pillow if imgext [ 1 :] in pillow_support and imgext2 in pillow_support : outputimg = imgname + '.' + imgext2 try : im = Image . open ( os . path . abspath ( inputimg )) logging . info ( os . path . abspath ( inputimg )) if not os . path . exists ( os . path . abspath ( outputdir )): mkdir_p ( outputdir ) outputimg = os . path . join ( os . path . abspath ( outputdir ), outputimg ) logging . info ( outputimg ) im . save ( outputimg ) except IOError : logging . error ( 'IOError, I can not convert {}' . format ( inputimg )) else : logging . warning ( 'pillow doesnot support the output format {}' . format ( imgext2 )) def batch_convert_imgformat ( inputext , outputext , inputdir = '' , outputdir = '' ): '''转换图片格式函数的批量封装，加上了目标图片dir和输出图片dir，默认是当前目录 然后第一个参数改成了inputext，也就是目标文件夹只有该输入图片格式才会被转换。''' import glob inputdir = os . path . abspath ( inputdir ) inputimgs = glob . glob ( os . path . join ( inputdir , '*.' + inputext )) for inputimg in inputimgs : convert_imgformat ( inputimg , outputext , outputdir = outputdir ) 图片缩小尺寸 仿照上面的api我们写两个函数吧: resize_img 和 batch_resize_img 。 def resize_img ( inputimg , outputsize , outputdir = '' , outputname = '' ): '''outputsize parameter is like (120,100) width=120,height=100 resize是保留图片原宽高比的情况下，目标图片宽度或高度不小于指定值 已经加上了输出dir自动支持 。 如果不指定输出文件名，那么默认是 原文件名_width*height.原扩展名 ''' imgname , imgext = os . path . splitext ( os . path . basename ( inputimg )) try : im = Image . open ( os . path . abspath ( inputimg )) im . thumbnail ( outputsize ) logging . info ( os . path . abspath ( inputimg )) if not os . path . exists ( os . path . abspath ( outputdir )): mkdir_p ( outputdir ) if not outputname : outputname = imgname + '_{}*{}' . format ( im . size [ 0 ], im . size [ 1 ]) + imgext outputimg = os . path . join ( os . path . abspath ( outputdir ), outputname ) logging . info ( outputimg ) #### im . save ( outputimg ) except IOError : logging . error ( 'IOError, I can not resize {}' . format ( inputimg )) resize_img ( \"lena.jpg\" ,( 300 , 200 ), outputdir = \"out\" ) def batch_resize_img ( inputext , outputsize , inputdir = '' , outputdir = '' ): '''缩小图片尺寸的批量封装，加上了目标图片dir和输出图片dir，默认是当前目录 然后第一个参数改成了inputext，也就是目标文件夹只有该输入图片格式才会被转换。''' import glob inputdir = os . path . abspath ( inputdir ) inputimgs = glob . glob ( os . path . join ( inputdir , '*.' + inputext )) for inputimg in inputimgs : resize_img ( inputimg , outputsize , outputdir = outputdir ) 图片去背景边 本小节主要参考 这个网页 。然后我们稍作封装即可。 from PIL import ImageChops def trim_img ( inputimg , outputdir = '' , outputname = '' ): '''图片去白边（背景白，如果背景黑也可） 输出名字默认 原名_trim.原后缀 ''' imgname , imgext = os . path . splitext ( os . path . basename ( inputimg )) try : im = Image . open ( os . path . abspath ( inputimg )) bg = Image . new ( im . mode , im . size , im . getpixel (( 0 , 0 ))) diff = ImageChops . difference ( im , bg ) diff = ImageChops . add ( diff , diff , 2.0 , - 100 ) bbox = diff . getbbox () ### new_im = im . crop ( bbox ) logging . info ( os . path . abspath ( inputimg )) if not os . path . exists ( os . path . abspath ( outputdir )): mkdir_p ( outputdir ) if not outputname : outputname = imgname + '_trim' + imgext outputimg = os . path . join ( os . path . abspath ( outputdir ), outputname ) logging . info ( outputimg ) #### new_im . save ( outputimg ) except IOError : logging . error ( 'IOError, I can not trim {}' . format ( inputimg )) def batch_trim_img ( inputext , inputdir = '' , outputdir = '' ): '''批量图片去边''' import glob inputdir = os . path . abspath ( inputdir ) inputimgs = glob . glob ( os . path . join ( inputdir , '*.' + inputext )) for inputimg in inputimgs : trim_img ( inputimg , outputdir = outputdir ) 这个算法最核心的语句是: bg = Image.new(im.mode, im.size, im.getpixel((0,0))) diff = ImageChops.difference(im, bg) diff = ImageChops.add(diff, diff, 2.0, -100) bbox = diff.getbbox() new_im = im.crop(bbox) 其中 bg = Image.new(im.mode, im.size, im.getpixel((0,0))) 这一句看得出来是新建一个图片对象，这个图片对象可以看作纯色背景图片，最后的参数是color，其是用 im.getpixel 来去原图片(0,0)的这个像素点的颜色，也就是最左边最顶上的那个点。 diff = ImageChops.difference(im, bg) 这一句，按照官方文档的描述， PIL.ImageChops.difference(image1, image2) 相当于对图片每个像素点逐个进行如下算术运算: $$ out = abs(image1 - image2) $$ 然后 diff = ImageChops.add(diff, diff, 2.0, -100) 按照官方文档的描述， PIL.ImageChops.add(image1, image2, scale=1.0, offset=0) 相当于对图片每个像素点做如下算术运算: $$ out = ((image1 + image2) / scale + offset) $$ 到这里我们看到diff这个图片对象实际上是原图片减去背景，然后双倍重叠在除以2。这些操作我们都可以看作让四周背景边框更加的趋于0。然后offset设为100，这是我最有疑问的地方，一，像素值变为负值会如何？二，为什么是减去100，有什么特殊的理由吗？ bbox = diff.getbbox() new_im = im.crop(bbox) 接下来实际上还好理解了，首先通过Image对象的 getbbox 方法来获得一个矩形边框值（其由left，upper，right，lower四个像素点坐标组成）。具体内部算法是根据非0的值来计算图形的边界。这个里面的算法可能还很复杂吧。 然后就是调用Image对象的 crop 方法执行裁剪操作，其接受的也是一个矩形边框值，所以可以直接使用上面获得的边框来获得一个新的图形对象。 具体裁剪效果如下所示: 然后去边裁剪之后的效果为: 附录 有名的lena图 还有福利图。。 if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js','mhchem.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"python好伙伴","url":"articles/pillow-module.html"},{"title":"统计学入门","text":"均值中位数众数 mean 也就是均值，也就是算术平均数，也就是大家熟知的把所有的数加起来然后除以个数，看看这些数平均有多大。 median 中位数，是这样的概念：如果我们把一组数从小到大排列，然后最中间的那个数就是中位数。其中最中间的解释是，如果一共有奇数个数字，那么去掉一个最小去掉一个最大，这样类推，最后剩下来的那个数就是中位数；如果一共有偶数个数字，那么最后会剩下两个数字，而中位数就是最后这两个数字的均值。 mode 众数，也就是这一组数中出现频率最高或者说分布最多的数。比如说[1,2,2,3]这样一个样本，其中数字2出现次数最多，我们就说这个样本的众数为2。 统计意义 平均值的概念是大家最熟悉的，其是最基本的统计学手段。比如物理学上的测量，为了精确总是需要多次测量取平均值。再比如我们衡量某一类数据的大致平均情况，比如你的考试平均成绩，通过这个平均成绩可以大致得到你对待本学期学业的态度等。 中位数和均值一样也能考察样本总体存在状态，不过区别是中位数对一些极值（特殊的偏离特别远的值）不敏感。以收入来举例子：某些人的收入特别的高，那么如果你用均值来考察社会的收入水平就会有抬高的嫌疑。因为不同的家庭之间的收入并没有共享，但是你在计算中却一并考虑了。这个时候用中位数来考察能更加合理地看着社会总体的收入水平。因此考察家庭平均收入要用中位数。 众数只关注出现次数最多的数，严格来讲其并不具有考察样本总体存在状态的能力了，不过在某些情况下却可以。比如说你头发的颜色这样的定性描述，用众数就很合适。 python相关 自python3.4起，python加入了statistics模块了，所以我们不需要重复发明轮子了。上面的mean，median和mode这三个名字在statistics模块中都是对应的函数，下面是一些演示例子： from statistics import mean , mode , median >>> lst = [ 23 , 29 , 20 , 32 , 23 , 21 , 33 , 25 ] >>> mean ( lst ) 25.75 >>> median ( lst ) 24.0 >>> mode ( lst ) 23 这三个函数都接受一个可迭代对象，然后进行相关操作，如果是空数据，那么将raise statistics.StatisticsError 。 值得注意的是mode还可以操作字符串： >>> mode(['a','b','a','c','d']) 'a' 然后mode函数并不能处理几个数都是频率最高的情况，比如运行下面命令，将raise statistics.StatisticsError 。 >>> lst = [1,1,2,3,3] >>> mode(lst) 我们可以利用collections模块的Counter类的most_common方法来获得更健壮的mode函数。 from collections import Counter def mode ( obj ): \"\"\" 多个可能的情况 \"\"\" c = Counter ( obj ) most = 0 first = True for k , v in c . most_common (): if first : most = v first = False yield k else : if most == v : yield k else : break python3的 statistics 内置模块进行 均值 中位数 和 众数的运算，还是存在一些问题的，python2没有那个模块就不说了，其次就是没有考虑矢量思维和计算效率问题。好了，numpy 和 scipy 出场了。 首先我们需要把python的可迭代对象（Iterable）变成numpy的ndarray对象，然后如果已经是了，就pass掉。 然后就是利用numpy和scipy的函数支持了。 import numpy as np from collections import Iterable def to_ndarray ( pyobj , dtype = None ): if not isinstance ( pyobj , Iterable ): raise TypeError ( 'it is not a iterable object' ) if isinstance ( pyobj , np . ndarray ): return pyobj if dtype is not None : return np . array ( pyobj , dtype ) else : return np . array ( pyobj ) def mean ( obj ): obj = to_ndarray ( obj ) return obj . mean () def median ( obj , axis = None ): obj = to_ndarray ( obj ) return np . median ( obj , axis = axis ) mode统计频数在scipy那里是有个 scipy.stats.mode 函数，不过其只是返回出现频数最大的那个，而且如果最大的频数有多个相同的情况也只返回一个。 方差和标准差 首先来说总体的情况，总体均值是 \\(\\mu\\) ，而总体方差具体公式如下所示: $$ {\\sigma }&#94;{2 } =\\frac { 1 }{n } \\sum _{ i=1 }&#94;{ n }{( X_i - \\mu)&#94;2} $$ 也就是总体方差是每一个数和总体均值的差的平方和的均值。 >>> from statistics import * >>> pvariance ([ 0 , 0 , 5 , 5 ]) 6.25 statistics . pvariance ( data , mu = None ) 如上所示，pvariance还可以接受 mu 可选参数，也就是总体均值，这样可以避免重复计算，若没有赋值则函数会自动计算。 然后总体标准差就是总体方差的平方根，或者说就是上面的 \\(\\sigma\\) 。 >>> from statistics import * >>> pstdev ([ 0 , 0 , 5 , 5 ]) 2.5 pstdev（Population standard deviation）同样还可以接受 mu 可选参数。 在实际应用中，绝大多数情况都是考察的样本而不是总体，所以更常用的是样本方差: $$ {S }&#94;{2 } =\\frac { 1 }{n-1 } \\sum _{ i=1 }&#94;{ n }{( X_i - \\overline { X } )&#94;2} $$ 你可能已经注意到了，上面的是 (n-1) 而不是 (n) ，这其中有些统计学的考虑，什么无偏估计，也就是用样本来评估总体的方差的时候，总会估计值偏小，然后再加上一个额外的数据量来让估计值更准确些，大体就是这样，至于具体为何是 n-1 ，那就是统计学里面的高级内容了，总之就是为了更好的估计（从样本估计总体）。 python中的样本方差是 variance 函数，样本标准差是 stdev 函数: >>> variance([0,0,5,5]) 8.333333333333334 >>> stdev([0,0,5,5]) 2.886751345948129 >>> 统计意义 方差是来描述数据集的离散程度的，标准差就是方差的平方根，当然同样可以用来描述数据集的离散程度。标准差和实际数据会更一致，比如说统计一班的身高的标准差是 10cm ，这样可以给人一个直观的感受。然后在正态分布中有 均值 $ \\pm $ 三个标准差，那么样本中大约 99点几的数据都包含在内了。 简单来说，总体就是整个你要考察的对象，即使是对于上面简单的均值，中位数，众数等等描述性概念，对于总体来说通常都是很难全部考察的。于是我们从总体中取出某一些考察对象（理论上要求是近似于完全的随机取样），然后组成一个样本。然后我们希望对于样本的一些统计描述性数据能够很好地反应总体的数据存在状况。这样所有统计学量实际上都有两种类型，比如均值有总体均值 \\(\\mu\\) 和样本均值 \\(\\overline{X}\\) 。 python相关 我们还是利用numpy来进行计算： def pvariance ( obj ): obj = to_ndarray ( obj ) return np . var ( obj ) def pstd_deviation ( obj ): obj = to_ndarray ( obj ) return np . std ( obj ) def variance ( obj ): obj = to_ndarray ( obj ) return np . var ( obj , ddof = 1 ) def std_deviation ( obj ): obj = to_ndarray ( obj ) return np . std ( obj , ddof = 1 ) 注意上面计算样本方差 variance的时候 ddof=1 设置为1，默认是0。在计算样本的时候需要使用样本方差和样本标准差。 中位数和分位数 中位数前面谈过了，就是最中间的那个数。同时还有一种说法是数据集里有 50% 的数比它小，有 百分之50的数比它大。于是分位数的概念由此来了，比如 25% 分位数（quantile）的意思就是在数据集里有 25% 的数比它小。所以如果我们联想到统计学的分布图的话，进而可以把 25%的分位数看作以这个数画一条线，左边的面积是总面积的 25%。 python相关 def quantile ( obj , seq = None ): obj = to_ndarray ( obj ) if seq is None : seq = range ( 0 , 101 , 25 ) res = pd . Series ( np . percentile ( obj , seq ), index = seq ) return res numpy 里面有 percentile 函数就是分位数 quantile，只是具体要显示要几个分位数位置需要定制。然后上面利用pandas的 Series 数据结构返回，好说明清楚具体是那个分位数。 极差 中程数 极差（range）就是这一组数的最大值和最小值的差值。中程数（midrange）就是这一组数的最大值和最小值的均值。 python相关 因为极差range这个名字和python语言的range函数相冲突，所以python并没有为极差定义一个函数，由于计算公式较简单，我们也不需要额外定义一个公式。就是： max ( lst ) - min ( lst ) 而中程数就是 ( max ( lst ) + min ( lst )) / 2 统计意义 极差是统计学上入门级别的粗略的对样本的离散程度的考察，比如一组数不是很分散，都集中在均值附近，那么其极差就会很小，而同样的情况另一组数如果极差更大，那么我们说第二组数离散程度更大。 中程数可以作为如果样本数组离散程度不是很高的话，作为均值的近似快速计算。 标准分 标准分 \\(z = \\frac{x- \\mu}{\\sigma}\\) 标准分是将不同的正态分布映射到一个标准正态分布上的手段，简单来说就是一种将不同均值不同标准差的正态分布标准化的过程，要理解这个过程首先需要理解标准正态分布： 所谓标准正态分布是值均值为0，标准差为1的正态分布。 标准分比较做出的假设就是 目标研究数据集 或者说学生的得分数据集是 正态分布 。所以现在的任务就是比较不同的正态分布。在正态分布中有个规律： 95.45% 的数据位于两个标准差的范围内 99.73% 的数据位于三个标准差的范围内。 （还是要公式来明确获得） 参考同济大学概率论和数理统计第四版一书 p48 引理： 若 X 分布是正态分布，则 \\(Z = \\frac{X-\\mu}{\\sigma}\\) 分布是标准正态分布。嗯，简单看了下数学公式推导，信心足一些了，没问题的。 条件概率 条件概率的维恩图解很有意思： $$ P(A|B) = \\frac{P(A \\cap B)}{P(B)} $$ 用维恩图基本上可以直接写出上面的公式，含义是很明确的。 并继而有： $$ P(A|B) P(B) = P(A \\cap B) $$ $$ P(A \\cap B) = P(B \\cap A) = P(B|A) P(A) $$ 用概率树来理解，就是先发生B然后发生A事件，最后事件AB的概率为两个事件的概率乘积，这里我仍然有困惑，AB事件和BA事件两个概率一样吗？（只是针对古典概率模型，到了要考虑顺序的地方人们又使用 P(a,b) 这样的符号，那个时候 P(a,b) 就不等于 P(b,a)。） 互斥事件A，B，即不可能同时发生的事件，则有 \\(P(A \\cap B) =0\\) 全概率公式： $$ P(B) = P(A) \\times P(B | A) + P(A') \\times P(B | A') $$ 贝叶斯定理： $$ P(A|B) = \\frac{P(B|A) P(A)}{P(B) = P(A) \\times P(B | A) + P(A') \\times P(B | A')} $$ 贝叶斯定理提供了一个计算逆条件概率的方法，也就是实际情况是先发生 A 再 发生B ，而你想知道B发生之后A发生的概率。 贝叶斯定理思想比上面提及的更深，现在我们假设 A 事件，然后机器或者人针对A事件做了推断 B，我们想知道这个推断B正确的可能性有多大，其中A事件发生的概率，A事件发生后B推断的概率，或者A事件没有发生B推断发生的概率都是从经验数据中可以学习的。而所谓后验就是B推断已经发生了，如果A事件没有发生那么推断错误，如果A事件发生了那么推断正确，所以 $P(A|B) $ 这个也常被统计学家们称为 后验概率，其实际上也就是逆概率，具体计算过程也就是用上面的贝叶斯公式来计算的。 参考资料 深入浅出统计学 同济大学 概率论和数理统计 机器学习 周志华 if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js','mhchem.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"数学","url":"articles/statistics-tutorial.html"},{"title":"自然语言处理第一谈","text":"简介 自然语言处理的可能应用领域有： 机器翻译 自动文摘 信息检索 文档分类 问答系统 信息过滤，信息抽取 文字编辑和自动校对 作文自动评分 语音识别 语音合成，text to speech ​ 信息熵 信息熵是个非常让人难懂的概念，尤其是当你在很多领域都接触到信息熵的概念和各种应用的时候，你会发现你根本就没理解信息熵这个概念。比如自然语言处理领域，信息熵有着非常多的应用，然后自然信息传输领域也有很多应用，信息熵的概念基本上是现在信息论的基石吧。 不管怎么说，我们先死记硬背一下，信息熵的定义，就是一个事物或者一个什么东西吧，在一个系统中出现的几率为p，则这个东西在这个系统中的信息熵为： $$ H = - p log_2{p} $$ 首先从最简单的抛硬币开始吧，对于正面来说出现的几率为1/2，则一次抛硬币你看到正面的信息熵为 0.5，然后反面的信息熵也是0.5 1 。信息熵的单位是bit，然后信息熵服从可加性（也就是总系统的信息熵是各个子系统的信息熵的加和），所以抛一枚硬币，正面和反面的信息熵总和就是 1 bit。从信息论的角度来说就是用一个字节就可以描述抛一枚硬币的可能信息量了。信息论一开始就是专注于信息传输领域的。 所以我们又看到这样一个问题，本问题摘自宗庆成统计自然语言处理第二版例2-3： 假设a,b,c,d,e,f 6个字符出现的概率分别是 1/8 1/4 1/8 1/4 1/8 1/8 ，那么传输一个字符的信息熵为？ 传输一个字符 a b c d e f只可能有这六种情况，分别信息熵为： H = -[1/8log1/8 + 1/4log1/4 + 1/8log1/8 + 1/4log1/4 + 1/8log1/8 + 1/8log1/8] = 2.5 bit 也就是传输这六个字母需要2.5bit，则给三个bit位就完全够用了，然后具体设计一种信息编码规则即可，在设计编码规则的时候还要考虑具体情况出现的概率问题，这里具体细节就不讨论了。总之信息熵一开始就是干这个用的。 如果一个事件一定会发生，那么其信息熵等于0，如果一个事件发生的概率为0，其信息熵也等于0。信息熵为0表示这个事件发送给你并没有为你带来额外的信息。就以抛硬币来描述一个事件，则你对硬币一无所知的时候，信息熵=1为最大信息熵的可能，也就是一半一半0.5的情况。 所以薛定谔的猫在一半生一半的死的情况下打开黑盒子，流出来的信息熵是最大的，或者说流出来的信息量是最多的。 信息增益 信息增益在决策树算法的分类特征选择中很重要，暂时先简单理解为就是引入这个特征分类信息熵增量很大，这样获取这个特征对整个系统确定程度影响最大，或者简单来说就是这个特征好啊，引入之后能够收获更多的信息。 联合熵和条件熵 实际是从概率分布的联合概率和条件概率推出来的概念。而所谓联合概率就是两个事件一起出现的概率；而所谓条件概率就是已知Y已经发生了，X事件发生的概率。 $$ H(X,Y) = - \\sum_{x \\epsilon X} \\sum_{y \\epsilon Y} p(x,y)log(p(x,y)) $$ XY的联合熵是描述一对随机变量平均所需要的信息量。 熵的连锁规则： $$ H(X_1,X_2 ...) = H(X_1) + H(X_2|X_1) + H(X_3| X_1, X_2) $$ 也就是多个事件一起出现的信息熵等于第一个事件出现的信息熵加上第一个事件出现了第二个事件再出现的信息熵，以此类推。 互信息 互信息是用来衡量两个事件的相关度的。互信息的定义如下： $$ I(X;Y) = H(X) - H(X|Y) $$ 注意这个分号，如果是逗号，表示两个事件一起出现，如果是|则是Y已经出现了求X的条件概率。 其含义就是X和Y的互信息是知道Y事件之后对X事件发生产生的信息熵的减少量。也就是假设不知道Y事件X事件的信息量=2，而知道Y之后X事件再发生的信息量=1，则X和Y的互信息量=1。 假设XY不相干，则XY的互信息量=0；假设Y事件发生则X事件必发生，则XY的互信息量=X的信息熵。 由熵的链式规则有： $$ I(X;Y) = H(X) - H(X|Y) = H(X) + H(Y) - H(X,Y) $$ 相对熵或者交叉熵 相对熵也被称为交叉熵【似乎相对熵和交叉熵是两个不同的概念，数学之美上的说法存疑。】，这个我们在机器学习核对学习算法的误差是接触过，相对熵是用来两个取值为正数的函数相似性的。 对于两个完全相同的函数，他们的相对熵为0 相对熵越大，两个函数差异越大，反之相对熵越小，两个函数差异越小。 如上所述，相对熵可以用来衡量两个概率分布函数的差异性 互信息就是两个事件的联合分布和独立分布的相对熵，所以两个事件越接近独立分布，则相关性越小，则相对熵越小，则互信息越小；反之两个事件越不接近独立分布，则相关性越大，则相对熵越大，则互信息越大。 统计语言模型 S 表示一连串顺序排列的词语，S在文本中出现的可能性，P(S) ， 利用条件概率： $$ P(S) = P(word1)P(word2|word1)P(word3|word1word2)...P(wordn|word1word2word3...wordn-1) $$ 马尔科夫假设 任何一连串事件序列某个状态发生的概率只依赖于它的前几个状态，这一事件序列叫做马尔科夫链。 如果只依赖于它的前一个词，那么这种模型称为二元模型，也就是一阶马尔科夫链，记作 bigram 如果依赖于它的前两个词，那么这种模型称为三元模型，也就是二阶马尔科夫链，记作 trigram 下面以二元模型为例子，计算一句话出现的概率： $$ P(S) = P(word1)P(word2|word1)P(word3|word2)...P(wordn|wordn-1) $$ \\(P(w_i|w_{i-1})\\) 是一个词出现之后下一个词出现的条件概率，利用条件概率有： $$ P(w_i|w_{i-1}) = P(w_iw_{i-1})/P(w_{i-1}) $$ 令句首标记为 <BOS> 令句末标记为 <EOS> 。 其中 \\(P(w_iw_{i-1})\\) 的概率就是两个词在整个文本中所占的频率，具体等于 目标两个词序列的记数/总文本记数 而 \\(P(w_{i-1})\\) 是前一个词出现的次数/总文本数，最后得到： $$ P(w_i|w_{i-1}) = 两个词序列计数/前一个词的计数 $$ 请参看宗庆成的自然语言处理第二版P85的例子详细理解如何计算一个句子出现的概率的计算方法。 大数定理 在试验不变的条件下，重复试验多次，随机事件的频率近似于它的概率。 高阶语言模型 上面简单的二元模型只假设一个词只和其前面的那个词相关，如果假设前面的N-1个词和这个词相关，那么这个模型就称为N元模型。 古德-图灵估计 上面的统计一个句子出现概率的计算方法，某些序列在语料库（统计文本）中并没有出现过，或者出现次数极少。这些句子概率的计算都估算为零是不合适的。古德-图灵估计就是来解决这个问题的。 对于没有看见的事件，我们不能认为它发生的概率就是零，因此我们从概率的总量中分配一个很小的比例给予这些没有看见的事件。 基本计算公式是： $$ N = \\sum_1&#94;{\\infty}r N_r $$ 这个公式含义很明显，就是出现1次（r=1）的词有多少个（ \\(N_r\\) ），逐个相加得到总词数。写成下面的形式会简单一些： $$ N = 1N_1 + 2N_2 + 3N_3 ... $$ 而古德-图灵估计就是假设r次（一般要到非常小的时候才会上这个估计）有如下规律（因为次数低，甚至可能为0所以这里的多少次是未知的）： $$ r&#94;* N_r = (r+1)N_{r+1} $$ 这个公式看起来很突兀，但我们可以这样理解： $$ N = 2N_2 + 3N_3 + 4N_4 ... $$ 也就是出现次数很少的词出现的次数乘以具体那些词的次数大体可以用次数加一，上一次数的情况来估计。因为次数很少，这个公式一直加到无穷大，是可以认为估计损失极小的。 于是对于具体出现 \\(r&#94;*\\) 次的某个词，其出现的概率为： $$ P_r = \\frac{r&#94;*}{N} $$ 这种估计方法，还剩下来一个 \\(1N_1\\) ，其就是给未知事件的，未知事件的概率估计为： $$ P_0 = \\frac{N_1}{N} $$ 也就是未知事件出现的概率等于出现1次的词的计数除以总词数。 中文分词 自然语言是上下相关的，自然语言研究需要为这种上下文相关的特性建立数学模型，这个数学模型就是人们常说的统计语言模型（Statistical Language Model）。 贾里尼克认为： 一个句子是否合理，就看它的可能性大小如何。 这其中有个问题就是如何穷举所有可能的分词方法：这是一个动态规划问题，可以利用维特比算法（Viterbi）来解决这个问题。 总的说来如上面讨论的，基于统计和词典的，来获得一个最大可能性的句子的分词方法，是目前兼顾准确性和性能的最佳方案了，后续很多方法都应该站在其肩膀上，试着更好地解决词典完善和命名实体识别等等问题。 隐马尔科夫模型 广义通信模型 人与人之间的语言，或者其他任何形式的信息交流，都可以看做是一种广义上的通信模型，一个信号编码序列通过某种信息载体在信道中发送出去，然后被接受者接受，并进行转码的过程。 我们需要找到的就是根据观测信号o1 o2 o3... 对应的最大条件概率状态信号 s1 s2 s3... 。 $$ s_1, s_2, s_3, \\dots = \\underset{all s_1,s_2,s3,\\dots}{\\arg\\max} P(s_1,s_2,s_3,\\dots | o_1,o_2,o_3,\\dots) $$ 按照条件概率有： $$ s_1, s_2, s_3, \\dots = \\underset{all s_1,s_2,s3,\\dots}{\\arg\\max} \\frac{P(s_1,s_2,s_3,\\dots) \\cdot P( o_1,o_2,o_3,\\dots |s_1,s_2,s_3,\\dots)}{P(o_1,o_2,o_3,\\dots)} $$ 因为要求最大值，具体观测信号的发射概率可以忽略： $$ s_1, s_2, s_3, \\dots = \\underset{all s_1,s_2,s3,\\dots}{\\arg\\max} P(s_1,s_2,s_3,\\dots) \\cdot P( o_1,o_2,o_3,\\dots |s_1,s_2,s_3,\\dots) $$ s1,s2--> o1,o2 的条件概率是状态信息s1...在传输后成为接受者接受的o1...的概率。而 s1,s2...是发送端出现这个随机过程的概率。 这个计算过程可以利用隐马尔科夫模型来计算。 马尔科夫模型 首先是马尔科夫模型，其还是比较简单易懂的。首先从随机过程开始，假设你要研究一个系统，这个系统随机吐出一些信号，s1 s2 ... 具体就是这个系统的某种激活状态。这种随机过程的生成可以用下面的图形来描述： 这个例子来自宗庆成统计自然语言处理第二版P109。 具体上面的转移矩阵如下所示： $$ \\begin{bmatrix}0.3 & 0.5 & 0.2 \\\\ 0.5 & 0.3 & 0.2 \\\\ 0.4 & 0.2 & 0.4\\end{bmatrix} $$ 这样我们观察到序列 名 动 形 名 的概率为 0.5 * 0.2 * 0.4 ，详细讨论请参看宗庆成统计自然语言处理第二版P109。 在上面的习题中，我们已经看到了，马尔科夫模型其内暗含了这样的假定： 其内的随机过程为马尔科夫链过程，状态只受前一个状态影响。 隐马尔科夫模型 隐马尔科夫模型在上面的讨论上，引入这样的东西，那就是我们不能直接观察这个系统的s1 s2 状态，我们只能观察这个而系统抛出来的信号 o1 o2...，这就和之前讨论的广义通信模型有点接近了，也正因为如此隐马尔科夫模型很是通用，即使是后面的条件随机场模型也是站在隐马尔科夫模型的基础上的，因为隐马可夫模型其内有些思想内核是触及了广义通信模型的内核的，而广义通信模型几乎可以用来看待一些信息传输问题，包括自然语言，人的沟通交流也可以看做一种信息传输过程（我们也可以想象，人和机器语言若存在某种人机交互，那么也是符合这个广义通信模型的）。 而隐马尔科夫模型又说我们观察到的 o1 o2 ... 是和这个系统的状态 s1 s2相关的，这是自然。继而隐马尔科夫模型应用马尔科夫链过程简单模型做了如下假定： o1只和最近的s1相关，o2只和最近的s2相关。 我们看到隐马尔可夫模型大方向是没问题的，就是引入马尔科夫链对状态的前后相关性做了太多的简化，这个后面条件随机场模型会进一步完善。 其实讨论到这里，我们算是基本理解隐马尔科夫模型了。下面就是数学了... 一般会提及HMM的三个问题，这里我就提两个算是很实际的问题吧： 如何训练模型？ 如何使用模型？ 这两个问题，一个是鲍姆-韦尔奇算法，一个是维特比算法。没什么好说的，硬下头皮来啃数学吧。 条件随机场 条件随机场算是现在实际广泛应用中的一个算法了，其基于HMM隐马尔可夫模型。 维特比算法 参考资料 数学之美 第二版 吴军著 统计自然语言处理 第二版 宗成庆 脚注 请读者参看 知乎这里 maxdeath的讨论。 ↩ if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js','mhchem.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"自然语言处理","url":"articles/nlp-talk-one.html"},{"title":"有向无环图","text":"图论，听起来挺高大上的，嗯，那就是数学家画圈圈和画线线还很有乐趣的地方。 如果线没有方向，那么叫做无向图，如果线有方向，那么叫做有向图。 在有向图中，任意一个节点的流向流着流着都流不回自身，那么我们就说这个图为 有向无环图 ，英文缩写是 DAG，（directied acyclic graph）。 这东西有什么用？ 一开始我最先接触 DAG 这个术语，是在找工作流软件的时候，一种工作流的通用表示方法就是用 DAG 来表示。为什么？假设你是工作流中的某个节点的员工，你按照某个workflow走下去，最后闭环了，然后你无限循环在某个流程中了，那可真蠢了。 然后比如说 git 的版本控制，其内部也是用的 有向无环图表示，如果你版本修改修改，又回到某个老版本了，那版本控制也失效了。 聪明的朋友肯定想到了我们的宇宙时间是不可逆的，也就是说如果用模型来表示宇宙所有的信息数据变动流结构的话，那么一定是有向无环图。 python实现 在 algorithms项目的这里 有有向图的实现代码，实际存储就是一个字典值，然后再加上了一些辅助方法，其中 key 就是节点的值，value是一个列表，存放着本节点到其他节点的流向地。整个实现过程还是很好理解的，在jieba分词中： def get_DAG ( self , sentence ): self . check_initialized () DAG = {} N = len ( sentence ) for k in xrange ( N ): tmplist = [] i = k frag = sentence [ k ] while i < N and frag in self . FREQ : if self . FREQ [ frag ]: tmplist . append ( i ) i += 1 frag = sentence [ k : i + 1 ] if not tmplist : tmplist . append ( k ) DAG [ k ] = tmplist return DAG 其大体也是类似这样的实现。 也就是在实际操作中，并没有对无环条件进行判断，这多少有点出乎我的意料之外。图论里面关于这个已经有算法了，我们也没什么好想的，就是图论的拓扑排序方法来判断一个有向图是否是无环的。 wiki上有伪代码，我们可以下看一下： L ← Empty list that will contain the sorted elements S ← Set of all nodes with no incoming edge while S is non-empty do remove a node n from S add n to tail of L for each node m with an edge e from n to m do remove edge e from the graph if m has no other incoming edges then insert m into S if graph has edges then return error (graph has at least one cycle) else return L (a topologically sorted order) 这个算法叫做 Kahn 算法，具体思路就是请读者假想目标研究有向图里面有一个闭环，那么这个闭环里面的所有节点都有有进入箭头的，也就是其不可能在set S，其在算法中只可能在 m 中被选中，而且闭环中的节点一定不会出现在n中，这样上面的算法再怎么运算，if语句对于闭环中的m来说都不会成立。 然后假设某几个节点都有入口，那么顺藤摸瓜，逐个删除是可以把这些节点都放到S里面去的。 我心里还有一个担心，也就是上面的算法的终止问题，主要是闭环那边。初步的判断是闭环内的节点m不会进入S，其他节点慢慢会被放入L。OK，让我们开始写代码，然后再实际看一下吧。 下面的代码除了参考了上面提及的 algorithm 项目之外， 还参看了 这个网页 ，然后进行了深度优化。 #!/usr/bin/env python # -*- coding: utf-8 -*- from copy import deepcopy from collections import defaultdict import logging logger = logging . getLogger ( __name__ ) class CyclicError ( Exception ): pass class DAG (): def __init__ ( self ): self . _dag = defaultdict ( list ) self . _vertex_count = 0 self . _edge_count = 0 @property def data ( self ): return self . _dag @property def vertex_count ( self ): \"\"\" Returns the number of vertices in the graph. Worst Case Complexity: O(1) \"\"\" return self . _vertex_count @property def edge_count ( self ): \"\"\" Returns the number of edges in the graph. Worst Case Complexity: O(1) \"\"\" return self . _edge_count def add_edge ( self , src , dest ): \"\"\" Adds an undirected edge 'src'-'dest' to the graph. Worst Case Complexity O(1) \"\"\" def _add_edge ( self , src , dest ): if src in self . _dag : if dest not in self . _dag [ src ]: self . _dag [ src ] . append ( dest ) self . _edge_count += 1 else : logger . warning ( 'src->dest already exists' ) else : self . _dag [ src ] = [ dest ] self . _vertex_count += 1 self . _edge_count += 1 if dest not in self . _dag : self . _dag [ dest ] = [] self . _vertex_count += 1 backup = deepcopy ( self ) _add_edge ( backup , src , dest ) if not backup . sort (): raise CyclicError else : _add_edge ( self , src , dest ) def remove_edge ( self , src , dest ): \"\"\" remove edge src -> dest \"\"\" if src in self . _dag : if dest in self . _dag [ src ]: self . _dag [ src ] . remove ( dest ) self . _edge_count -= 1 else : raise ValueError else : raise ValueError ## clear data if self . indegree ( src ) == 0 and self . outdegree ( src ) == 0 : if src in self . _dag : del self . _dag [ src ] self . _vertex_count -= 1 if self . indegree ( dest ) == 0 and self . outdegree ( dest ) == 0 : if dest in self . _dag : del self . _dag [ dest ] self . _vertex_count -= 1 def adjacent ( self , src ): \"\"\" Returns the vertices adjacent to vertex 'src'. Worst Case Complexity: O(1) \"\"\" return self . _dag [ src ] def outdegree ( self , src ): \"\"\" Returns the degree of the vertex 'src' Worst Case Complexity: O(1) \"\"\" count = 0 if src in self . _dag : count = len ( self . _dag [ src ]) return count def indegree ( self , src ): \"\"\" Returns the in degree of the vertex 'src' \"\"\" count = 0 for k , v in self . _dag . items (): if src in v : count += 1 return count @property def vertices ( self ): \"\"\" Returns an iterable of all the vertices in the graph. Worst Case Complexity: O(V) \"\"\" return self . _dag . keys () def __str__ ( self ): s = [] s . append ( \"{0} vertices and {1} edges \\n \" . format ( self . vertex_count , self . edge_count )) for key in self . vertices : s . append ( \"{0}: \" . format ( key )) for val in self . adjacent ( key ): s . append ( \"{0} \" . format ( val )) s . append ( \" \\n \" ) return \"\" . join ( s ) def __repr__ ( self ): s = [] for key in self . vertices : s . append ( \"{0}: \" . format ( key )) for val in self . adjacent ( key ): s . append ( \"{0} \" . format ( val )) s . append ( \" \\n \" ) return '' . join ( s ) def sort ( self ): \"\"\" L ← Empty list that will contain the sorted elements S ← Set of all nodes with no incoming edge while S is non-empty do remove a node n from S add n to tail of L for each node m with an edge e from n to m do remove edge e from the graph if m has no other incoming edges then insert m into S if graph has edges then return error (graph has at least one cycle) else return L (a topologically sorted order) \"\"\" target = deepcopy ( self ) top_order = [] from collections import deque queue = deque () for k in target . vertices : if target . indegree ( k ) == 0 : queue . append ( k ) logger . debug ( 'queue append {0}' . format ( k )) while queue : n = queue . pop () top_order . append ( n ) for m in self . adjacent ( n ): target . remove_edge ( n , m ) logger . debug ( 'remove n->m {0} {1}' . format ( n , m )) if target . indegree ( m ) == 0 : logger . debug ( 'append {0}' . format ( m )) queue . append ( m ) if len ( top_order ) != len ( self . vertices ): return False else : return top_order","tags":"算法","url":"articles/directied-acyclic-graph.html"},{"title":"jupyter notebook","text":"magic function 运行某个python脚本 %run test . py 运行某个python脚本，里面的变量也会赋值在里面 运行系统的某个命令 !cat text.txt 在windows下是： !type text.txt 脚本或命令运行计时 %timeit what 更好地集成matplotlib %matplotlib inline","tags":"python好伙伴","url":"articles/jupyter-notebook.html"},{"title":"powershell入门","text":"简介 之前一直在linux系统做服务器的环境下玩一些东西，现在竟然要在windows服务器下做一些东西，其实python这一块都还好，很多python模块现在都支持windows系统，就是到了很多和linux系统相关的进程等等东西就出现差异了。 实际项目中确实有这样的需求，尤其到数据处理这一块，后台各个处理进程是多个杂的，luigi模块更多的关注工作流，有的时候有些处理进程各自是完全毫无关系的，这个时候就需要开两个进程等等。在linux系统下，进程的开启和后台管理还有bash脚本的编写都是基本功，在wondows下感觉这一块也是需要学习接触好的。 bat脚本是针对cmd的，现在powershell越来越成为主流了，而且powershell功能也是更加强大和完善的，只是powershell更加不为人们熟悉罢了。 本文作者也是一边用一边有问题，一边写吧，题目权记作 powershell 入门。 powershell脚本的后缀是 ps1 ，人们开始编写powershell遇到的第一个挫折就是会提示没有权限执行脚本，这是windows的默认安全策略，你需要以管理员身份运行： set-executionpolicy remotesigned 启动一个进程 Start-Process -FilePath \"ping.exe\" -Args \"www.baidu.com\" 然后进程的输出可以如下进行重定向： Start-Process -FilePath \"ping.exe\" -Args \"www.baidu.com\" -RedirectStandardOutput '.\\console.out' -RedirectStandardError '.\\console.err' 获取当前工作目录 下面的例子也同时讲解了基本的关于powershell里面如何定义变量和字符串中如何使用变量等知识。 $curpath =$( Convert-Path .) echo $curpath cd \"$curpath\\logs\" echo $( Convert-Path .) cd $curpath 熟悉脚本的看到这个例子，基本上所谓的子命令调用返回，或者字符串中变量的替换，或引用变量等都一看就清楚了。","tags":"others","url":"articles/powershell-tutorial.html"},{"title":"elasticsearch数据库","text":"简介 需求：一般的数据库对全文搜索支持不是很好，mongodb的中文全文搜索支持是只有企业版才有的功能，而且我估计中文分词效果等也不会太好，而elasticsearch专注于数据库搜索，所谓术业有专攻，对于这样的搜索需求，有时我们是需要elasticsearch来解决这个问题的。 首先推荐elasticsearch的这个 中文插件版 ，其集成了很多中文支持插件，elasticsearch官方内置的中文分词效果很是不好，比如其集成了 ik分词插件 ，其分词效果还是可以的。这个项目能够让新手马上上路，获得一个还算可以的效果，后面有精力再考虑进一步优化吧。 elasticsearch的python接口有官方的 elasticsearch-py ，然后在实际编写代码的时候强烈推荐 elasticsearch-dsl-py 项目，其也是基于 elasticsearch-py 项目，并提供了更便捷的接口封装。 elasticsearch数据库基本结构有点类似于mongodb，其一条记录也称为一个文档（doc），一个文档大体是一个字典值，可以字典套字典的那种。然后其还有一个索引（index）的概念，大体类似于database，然后其还有一个type概念，大体类似于collections。显然elasticsearch也属于nosql数据库，nosql数据库存储时很重要的一个思路就是，一个文档一个doc对应一个实体。 elasticsearch是基于Lucene的，这我们应该了解下，喝水不忘挖井人吗。 elasticsearch在windows下的安装还是很简单的，下载好代码，解压然后直接运行bin文件夹的 elasticsearch.bat 文件即可，当然你需要先安装好java，还有配置好 JAVA_HOME 变量。这通过下载安装jdk，然后在PATH里添加那个jdk的bin所在目录即可。 运行之后在 localhost:9200 那里可以打开看一下，有文字响应则说明你的elasticsearch运行正常了。 有关本文的例子 本文的例子中 book_info 是 index，使用的elasticsearch版本是 6.2 ，其默认 doc_type 是 doc 搜索文档 用elasticsearch不就是为了搜索吗，具体使用后面会更多讨论python api接口，下面简单了解一下elasticsearch的基本搜索操作，有个大体的概念。 只是搜索 GET /book_info/_search 每给出任何搜索关键词，将返回目标index的所有文档。我们可以看到一些有用的信息，这种返回格式现在详细讲讲: { \"took\": 11, \"timed_out\": false, \"_shards\": { \"total\": 5, \"successful\": 5, \"skipped\": 0, \"failed\": 0 }, \"hits\": { \"total\": 4223547, \"max_score\": 1, \"hits\": [ { \"_index\": \"book_info\", \"_type\": \"doc\", \"_id\": \"5aa2349e7227a6501fba4653\", \"_score\": 1, \"_source\": { \"unique_id\": \"5aa2349e7227a6501fba4653\", \"name\": \"史上最强少年阿武\", \"author\": \"最强绅士物语\", \"book_type\": \"同人小说\", \"title\": \"第9章 ... } } } } 目前我们先关注最核心的hits字段哪里，其内有： total 总共找到多少个 max_score 最大得分 hits 实际搜索到的记录信息， _index 目标记录的索引 _type 目标记录的 doc_type _id 目标记录的id _score 目标记录的搜索得分 _source 目标记录的实际内容 DSL查询表达式 实际我们搜索会使用一种专门的查询语言，DSL（领域特定语言）。这东西支持非常复杂的搜索，当然有的时候查询表达式也非常的复杂。 比如下面就是按照name来搜索，这里需要讲一下，index一开始的数据结构设计很重要，比如content 一开始设计的是 Text 字段，然后设置好中文分词之后那么就是全文搜索，再比如name 是 Keyword 字段，那么match搜索则是精确匹配模式。 GET /book_info/_search { \"query\" : { \"match\" : { \"name\" : \"未来之霸气小吃货\" } } } 下面是对content字段使用全文搜索，也是使用的 match query词。 GET /book_info/_search { \"query\" : { \"match\" : { \"content\" : \"未来之霸气小吃货\" } } } 用from和size进行分页 from 和 size 字段还有 query字段 是DSL语言最靠前的三个字段，后面更复杂的DSL查询语句都是 query字段里面继续字典套字典。 GET /book_info/_search { \"query\" : { \"match\" : { \"content\" : \"未来之霸气小吃货\" } }, \"from\" : 30 , \"size\" : 10 } 高亮搜索结果 和第一级 query 是平行关系，可以额外返回一个 highlight 搜索匹配的高亮信息。 \"query\" : { \"match\": { \"content\": \"kimchy\" } }, \"highlight\" : { \"fields\" : { \"content\" : {} } } 一般查询语句 match_all 什么都没说下的默认查询，通常和过滤操作进行 match 不管是全文搜索还是精确匹配，match一般都是你所需要的 multi_match 多字段查询 range 通常是限定区间内的数字或时间 term 数字，时间，布尔值或者不分析的文本的精确匹配 terms 多个候选项的匹配 exists 查某个字段是否存在 关于某个字段查询的Argument \"match\": { \"title\": { \"query\": \"BROWN DOG!\", \"operator\": \"and\" } match下指明关于某个字段的查询，是如上结构， query 是查询词，然后平行的还可以指定更多的Argument，比如： operator 多词查询默认or逻辑，可以设置为and逻辑，也就是要求同时出现 minimum_should_match 最小匹配度， boost 某个字段评分权重加大 bool组合查询 bool下可有三个字段值（must, must_not, should），其将其形成组合查询逻辑。（must must_not, should对应的逻辑就是 and not or） 'query': { 'bool':{ 'must': {'match': {'source': 'what', } }, 'must': { 'match': {'content': q } } } } 比如上面这个例子就是content进行q字段搜索，然后source字段必须是'what'。bool组合查询也可以用于过滤语句。 此外bool还可以加上 filter 来执行过滤逻辑，其中查询是参与评分的，而过滤则不参与评分。 DSL 查询语句有的时候很复杂很多是由一些复合查询语句拼成的，bool是一个，dis_max 是一个，还有一些，后面再了解。 多字段搜索 用 multi_match 来实现对多个字段同时搜索。如下所示， { \"query\" : { \"multi_match\" : { \"query\" : \"elasticsearch guide\" , \"fields\" : [ \"title\" , \"summary\" ] } }, } 其默认的搜索类型是 best_fields 也就是找到得分最高的字段，然后得分就按那个得分最高的来。 \"dis_max\": { \"queries\": [ { \"match\": { \"title\": \"elasticsearch guide\" }}, { \"match\": { \"summary\": \"elasticsearch guide\" }} ], } 其等于一个 dis_max 复合查询语句。 dis_max 就是执行多个查询语句然后考虑 tie_breaker 因素，tie_breaker 默认是0，也就是指考虑得分最高的字段查询的得分。 多字段搜索的第二个类型就是 most_field ，各个字段的查询得分会相加。 多字段搜索的第三个类型是 cross_field ， 其会把多个字段合并在一起然后计算出一个得分。 多字段搜索情况很是复杂，可能默认的某个类型就满足了你的要求，也可能还要你自己怎么写出一个很复杂的复合查询语句。 更好的写多字段搜索 本小节主要参考了这篇 不错的文章 。 插入文档 PUT /book_info/doc/<id> { \"field_one\": 1111, \"field_two\": \"abcdefg\" } 这里 <id> 指定目标记录文档的存储 _id 。 定向id取出某个文档 GET /book_info/doc/<id> 更新文档 PUT /book_info/doc/<id> { \"field_one\": 1111, \"field_two\": \"abcdefg\" } 和插入文档类型，不同的时候返回的 _version 会加1，旧版本文档还是会在哪里，elasticsearch后面会慢慢删除一些旧版本文档。 部分更新文档 部分更新文档和上面提到的依靠版本控制更新文档并没有本质区别，只是一个便捷的内部api，其还是更新全部文档和删除旧文档等过程。 POST /book_info/doc/<id>/_update { \"doc\" : { \"tags\" : [ \"testing\" ], \"views\": 0 } } 部分更新文档就是和原文档合并，覆盖写上已有的字段和新增新的字段。 删除文档 DELETE /book_info/doc/<id> 删除文档并不会立即删除文档，只是将这个文档标记为已删除，后面es会自动删除这些文档。 python那边对接 elasticsearch_dsl 刚开始不是很推荐使用，尽可能使用 elasticsearch-py 模块，其内部使用的doc语法和 官方文档 和一些教程都是一致的，而且原生的查询语句在 kibana上也是很好输入和测试的。就是查询语句多少复杂繁琐点了，这个需要另外开个python脚本文件统一管理。 创建索引 elasticsearch 数据库除了有 index 索引的概念，还有一个 doc_type 的概念，然后不使用那个 doc_type ，发现大体也是可以使用的，刚开始我没有考虑 doc_type 概念。 from datetime import datetime from elasticsearch import Elasticsearch es = Elasticsearch () res = es . index ( index = \"test-index\" ) print ( res [ 'created' ]) elasticsearch数据库默认开启了自动创建索引，删除索引等操作暂时先不涉及吧，所以下面集中精力把搜索和修改数据库弄清楚。 忽略某些连接异常 可能你在编程的时候希望能够忽略某些连接异常，加上 ignore 参数即可： from elasticsearch import Elasticsearch es = Elasticsearch () # ignore 400 cause by IndexAlreadyExistsException when creating an index es . indices . create ( index = 'test-index' , ignore = 400 ) # ignore 404 and 400 es . indices . delete ( index = 'test-index' , ignore = [ 400 , 404 ]) 返回内容过滤 search方法可以加上 filter_path 参数来指明只需要那些属性。 es . search ( index = 'test-index' , filter_path = [ 'hits.hits._id' , 'hits.hits._type' ]) 搜索 基本的搜索格式如下所示： res = es . search ( index = \"test-index\" , body = { \"query\" : { \"match_all\" : {}}}) print ( \"Got %d Hits:\" % res [ 'hits' ][ 'total' ]) for hit in res [ 'hits' ][ 'hits' ]: print ( \" %(timestamp)s %(author)s : %(text)s \" % hit [ \"_source\" ]) 更新文档 使用 Elasticsearch 对象的 update 或 update_by_query 方法，具体参数就是： def update(self, index, doc_type, id, body=None, params=None) 是的看了下源码，update方法前几个都是必填参数。可以考虑使用 update_by_query： def update_by_query(self, index, doc_type=None, body=None, params=None) 似乎不太方便，同步存储风格可能会更好一点，因为elasticsearch对同一文档有版本控制，旧文档会慢慢自动删除的。 同步存储 同步存储用 elasticsearch-dsl 模块还是很方便的，官方文档推荐使用 DocType ，如下所示： class Post ( DocType ): title = Text () title_suggest = Completion () created_at = Date () published = Boolean () category = Text ( analyzer = html_strip , fields = { 'raw' : Keyword ()} ) class Meta : index = 'blog' def save ( self , ** kwargs ): self . created_at = datetime . now () return super () . save ( ** kwargs ) 然后连接推荐如下设置默认连接风格： from elasticsearch_dsl.connections import connections connections . create_connection ( hosts = 'localhost' , timeout = 20 ) 你首先需要调用该 DocType 的 init 方法： Post.init() 然后就是赋值和 save 了。 指定某个字段为es的_id 本小节参考了 这个网页 。 具体就是如下设置 self.meta.id 属性： def save(self, **kwargs): \"\"\" 自动填充doc创建时间 自动填充_id 根据unique_id \"\"\" self.created_at = datetime.utcnow() self.meta.id = self.unique_id super().save(**kwargs) 附录 插入点数据 数据库的学习总要先往里面插入点数据，否则再好的戏也出不来。按照 阮一峰的elasticsearch数据库入门教程 描述，其参考的是 这篇文章 ，说elasticsearch5目前一个index下可以有多个type，elasticsearch6一个index下只能有一个type，elasticsearch7下将彻底移除type这个概念，这样将更加简单了。我们来看 elasticsearch-dsl-py 项目提供的 插入数据的 有点类似于 model的 这段代码： class Article ( DocType ): title = Text ( analyzer = 'snowball' , fields = { 'raw' : Keyword ()}) body = Text ( analyzer = 'snowball' ) tags = Keyword () published_from = Date () lines = Integer () class Meta : index = 'blog' 刚开始我没意识到问题，后来开始意识到问题了，那就是这样操作，和网上的 elasticsearch权威指南 这本书描述的很不一样，那就是这样定义elasticsearch的数据模型，除了说明下index之外，doctype的名字没看到在哪里定义的，后来发现大部分搜索工作都能正常进行就没管了，一开始还有点不放心，现在放心了，也就是我们以后思考elasticsearch数据库的架构，完全可以丢弃type这个概念了。 但是需要提醒读者的是，这是个逐步移除的过程，所以你可能还是需要仔细核对下你的elasticsearch数据库的返回数据结构信息。 自定义插件 现在开始脱离上面提及的elasticsearch中文插件版，使用elasticsearch最新版本6.X，然后初步琢磨下怎么安装个分词插件。JAVA那块我并不是太熟悉，但我们慢慢来吧。 插件有两种安装方法，绿色版的推荐将插件安装放在 plugins 文件夹哪里，或者推荐找到你的elasticsearch的bin文件夹，调用 ./bin/elasticsearch-plugin 命令，大体如下所示： ./bin/elasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v6.2.2/elasticsearch-analysis-ik-6.2.2.zip 然后重启elasticsearch服务即可。 开启外网端口 程序host的配置在 config 的 elasticsearch.yml 中配置： network.host: 0.0.0.0 正式产品运营是不应该设置为 0.0.0.0 的，这样任何人都可以访问的。 Kibana kibana是什么，简单来说就是pgadmin之于postgresql，一个非常方便的图形界面查看elasticsearch数据库的工具。其中的 Dev Tools 在学习elasticsearch语法是特别有用，更多细节请参看官方文档。 查看集群健康 GET _cluster/health 备份 elasticsearch的备份就是建立快照的概念，然后快照是增量备份策略。 新建一个快照仓库 PUT _snapshot/backup { \"type\": \"fs\", \"settings\": { \"location\": \"/path/to/elasticsearch/backup\" } } 记得elasticsearch的配置文件 elasticsearch.yml 里面配置好： path.repo : [\"/path/to/elasticsearch/backup\"] 新建一个快照 PUT _snapshot/backup/snapshot_1 查看已有的快照 GET _snapshot/backup/_all 删除目标快照 DELETE _snapshot/backup/snapshot_1 插件 列出插件 bin/elasticsearch-plugin list 安装插件 bin/elasticsearch-plugin install [pluginname] 移除插件 bin/elasticsearch-plugin remove [pluginname] 参考资料 Elasticsearch: 权威指南 IT自学教程之Elastic全文检索 23个有用的elasticsearch查询例子 elasticsearch入门教程","tags":"数据库","url":"articles/elasticsearch-database.html"},{"title":"luigi模块","text":"简介 luigi模块其实很早以前就接触过，但因为当时没有特别的需求所以对这个模块还是处于一种浅尝辄止的状态。到现在因为各种数据处理任务，开始强烈感觉到需要一个大的框架来管理这些小的数据处理脚本任务，使之更加的自动化和流程化。然后我开始找相应的软件，最后发现相关的软件不是少而是杂而多，请读者参看 这篇文章 。 首先有这么多项目证明程序员对于这个软件需求是很强烈的，但是如此的杂乱，大概两三百个，没有像scrapy或者django那种特别出色脱颖而出的项目，这多少是令人遗憾的。这也间接反应了这个问题，那就是这方面任务，恐怕最后还是要靠程序员自己编写大量定制代码来完成任务，而不能完全依靠某个工具。 我选luigi学习的原因无非有二： python github星数靠前 其实之前对luigi似乎是不太满意的，官方文档是一部分原因，可能以前对这块需求也不是特别强烈是一部分原因，或者还有其他？但还是决定硬着头皮学习，然后再慢慢定制吧。 定义任务 首先当然是定义任务，其继承自 luigi.Task ，其内有特殊含义的方法有： run 实际执行任务的动作 output 描述任务的输出对象 requires 描述任务的依赖 requires 返回某个任务对象或者某些任务对象列表，作为本任务的前置任务。看得出来作为任务对象的一些参数是区别对待的，比如即使是依赖于本对象，如果参数是前一日期时间，则需要上一任务完成之后再执行本任务。 依赖于某个Target 可以如下创建一个 ExternalTask ： class LogFiles ( luigi . ExternalTask ): date = luigi . DateParameter () def output ( self ): return luigi . contrib . hdfs . HdfsTarget ( self . date . strftime ( '/log/%Y-%m- %d ' )) 然后依赖于这个外部文件对象，当目标文件对象创建之后，才会进行下面的任务。 Parameter对象 任务类里面可以定义一些 Parameter 对象，当我们通过命令行调用该任务的时候，可以提供这些参数。 date = luigi.DateParameter(default=datetime.date.today()) date_interval = luigi.DateIntervalParameter() use_hadoop = luigi.BoolParameter() input方法 input方法是luigi框架里面任务对象调用本任务的前依赖输出对象的便捷方法，比如你使用 self.input ，就对应本任务的 requires Target 对象，或者说当你调用 self.input() 实际上得到的就是 self.requires() 的输出。 运行任务 luigi --module autowriting.workflow examples.HelloWorldTask --local-scheduler 一般生产环境会去掉 --local-scheduler 然后使用中央调度器，你需要用 luigid 来开启它。 默认你可以在localhost的 8082 端口看到监视任务的画面。 Target对象 描述任务的观察对象，比如硬盘里的某个文件或者数据库里的某条记录，其内部唯一具有特殊含义的方法就是 exists ，其用来判断目标对象是否存在，如果存在则返回True，如果不存在则返回False。 LocalTarge 描述本地磁盘文件对象 luigi.contrib.mongodb.MongoTarget mongodb target luigi.contrib.mongodb.MongoCellTarget 具体到mongodb的某个doc的某个属性 luigi.contrib.mongodb.MongoRangeTarget mongodb的某些doc的某个属性 ​ 日志管理 luigi 的日志不做任何调配的话，就是默认的 luigi-interface 然后流打印到终端。如下所示： def setup_interface_logging ( conf_file = '' , level_name = 'DEBUG' ): # use a variable in the function object to determine if it has run before if getattr ( setup_interface_logging , \"has_run\" , False ): return if conf_file == '' : # no log config given, setup default logging level = getattr ( logging , level_name , logging . DEBUG ) logger = logging . getLogger ( 'luigi-interface' ) logger . setLevel ( level ) stream_handler = logging . StreamHandler () stream_handler . setLevel ( level ) formatter = logging . Formatter ( ' %(levelname)s : %(message)s ' ) stream_handler . setFormatter ( formatter ) logger . addHandler ( stream_handler ) else : logging . config . fileConfig ( conf_file , disable_existing_loggers = False ) setup_interface_logging . has_run = True 如果我们在运行luigi命令的工作目录下写上配置文件 luigi.cfg : [core] logging_conf_file = luigi_logging.cfg 然后在 luigi_logging.cfg 里面写上一些logging的配置： [loggers] keys = luigi,root [logger_luigi] handlers = custom qualname = luigi level = DEBUG propagate = 0 [logger_root] handlers = output [formatters] keys = simple [formatter_simple] format = %(asctime)s %(name)s [%(levelname)s] %(thread)d %(module)s %(funcName)s %(lineno)s: %(message)s [handlers] keys = output,custom [handler_output] class = StreamHandler formatter = simple args = (sys.stdout,) [handler_custom] class = FileHandler formatter = simple args = ('logs/luigi.log',) 这样所有的日志将输出到你指定的文件下。 具体请进一步 参看 logging.config.fileConfig 中配置文件的写法。具体在luigi的任务脚本中如下使用 logger： import logging logger = logging . getLogger ( 'luigi' ) 遗留的问题有： 更多的logger -> 多些几个就是了。 RotateFileHandler 怎么加载 -> 如下写法： class = logging . handlers . RotatingFileHandler args =( 'logs/elasticsearch_sync.log' , 'a' , 200000 ) 经过测试每个logger的 qualname 参数不能省略。 NOTICE : logger最好放在任务类里面，否则你彼此引用任务脚本会把环境污染了。 所有任务集中于一个任务 所有的任务每天都执行一次。 class AllReports ( luigi . WrapperTask ) : date = luigi . DateParameter ( default = datetime . date . today ()) def requires ( self ) : yield SomeReport ( self . date ) yield SomeOtherReport ( self . date ) yield CropReport ( self . date ) 执行循环任务 luigi --module all_reports RangeDailyBase --of AllReports --start 2015-01-01","tags":"python好伙伴","url":"articles/luigi-module.html"},{"title":"mongodb","text":"简介 mongodb作为一款主流的nosql和sql数据库区别还是很大的，虽然有类似的比较，比如mongodb的collection概念大体类似于table，或者其他等等，但最好还是摒弃这种思维。然后mongodb相对sql明显有这两个优点，在开发的时候最好要好好使用，而不要因为之前的sql思维而自我设限。 mongodb是不要求一个collection里面各个文档具有相同的chema或者简单说，相同的key的。 不要把sql的join思维带入进来了，而应该更好地利用mongodb可以字典里面套字典，列表里面塞字典的特性。对于这种数据结构，mongodb有对应的查询语法，速度还是很快的。 user_doc = dbh . users . find_one ({ \"facebook.username\" : \"foofacebook\" }) 你看上面的例子，本来一个doc（mongodb把最小的一条记录叫做doc）大概类似一个字典了，然后我们还可以点着去查询，所以必要的时候，字典里面放字典，放心，对于这种结构速度还是有保证的。 安装 本来安装是不想多说了的，但因为历史原因，把以前在ubuntu下的一些东西放在这里吧，可能对读者有帮助。 ubuntu下的安装是： sudo apt install mongodb 其中mongo命令是client接口，然后mongod命令是服务端接口。默认开启了mongod后台服务，你可以看一下： sudo service --status-all mongodb后台服务默认端口是 27027 ，你可以通过 mongod 来指定数据库的存放位置和具体开启端口号： mongod --dbpath ~/mongodb --port 12321 默认的mongodb的数据库存放点是 /var/lib/mongodb 。 robomongo 一个不错的图形界面管理mongodb的软件，强烈推荐。基本上在里面可以满足一般的mongo命令需求了，不过下面还是列出来一些东西吧： show dbs 显示所有数据库 db 显示当前数据库名字 use dbname 切换到某个数据库或者创建某个数据库，要实际新建一个数据库还需要往里面塞点东西。比如: db.users.save({username:'zhangsan'}) show collections 显示当前数据库的所有colletions名字。 exit 退出mongo pymongo mongodb的数据类型 使用pymongo之后，很多python中的数据类型都能够对应到某个数据类型中，所以这不是很大的问题，如果有其他数据类型需求，则需要查阅文档了。 值得一提的就是python的datetime模块的datetime对象是可以直接用来作为Date类型被pymongo接受的。 然后 ObjectId 如果要查询： find_one({'_id': target['_id']}) 可以这样直接引用，而如果进一步要执行某个 ObjectId 那么需要如下： from bson import ObjectId mongodb的数据到json文件 参考了 这个网页 ，比如说你想要mongodb里面的数据读出来然后存到json文件中，那么你可能会遇到这个错误： TypeError : ObjectId ( '' ) is not JSON serializable 关于这种json文件的读入和写入操作，推荐的风格如下所示： >>> from bson import Binary , Code >>> from bson.json_util import dumps >>> dumps ([{ 'foo' : [ 1 , 2 ]}, ... { 'bar' : { 'hello' : 'world' }}, ... { 'code' : Code ( \"function x() { return 1; }\" )}, ... { 'bin' : Binary ( \"••••\" )}]) 额外要提醒读者的是，这个bson模块，你在安装pymongo的时候就自动安装了。然后在 bson.json_util 里面有 dumps loads 很有用，然后 bson 里面提供了很多mongodb的数据类型支持，如前面提及的 ObjectId Binary Code 等。 连接数据库 下面的代码我想能够说明一切了，repset是连接mongodb集群的写法。 from pymongo import MongoClient from pymongo.errors import ConnectionFailure def get_mongodb_client ( host = 'localhost' , dbport = 27017 , repset = None ): dbport = int ( dbport ) try : if repset is None : mongodb_client = MongoClient ( 'mongodb://{}/' . format ( host ), port = dbport ) else : mongodb_client = MongoClient ( 'mongodb://{}/' . format ( host ), replicaset = repset , port = dbport ) return mongodb_client except ConnectionFailure as ex : logging . warning ( ex ) 查找数据 在实际pymongo的写法中，我们一般喜欢定位到具体的某个collection，然后再进行一些操作： db = client['dbname'] collection = db['collection_name'] 具体查找数据有 find 和 find_one 这两个方法，其中find_one 是只找一个目标记录（doc），而find则是找到很多。 具体就是使用过滤器语法来进行查找工作，下面简单介绍一些： 过滤器语法 首先是最简单的如下直接写上一些你希望目标记录有的属性， q = { \"firstname\" : \"jane\", \"surname\" : \"doe\" } 这个说的专业点叫做各个语句and连接，不管怎么说就理解为目标doc的属性符合这些条件吧。 然后就是对属性使用操作符，比如下面： q = { \"score\" : { \"$gt\" : 0 } } 就是查询得分大于0的。 类似的还有很多过滤操作符，如 $or 或 $exists 等等，这个后面慢慢了解之。 $exists \"email\": {\"$exists\":True} 排序 find之后后面可以继续跟着 sort 方法来进行排序，默认是升序（pymongo.ASCENDING）。 for doc in collection.find().sort([ ('field1', pymongo.ASCENDING), ('field2', pymongo.DESCENDING)]): print(doc) 插入文档 col.insert_one() col.insert_many() 更新文档 replace_one(filter, replacement, upsert=False) update_one(filter, update, upsert=False) update_many(filter, update, upsert=False) upsert 设为True是如果用过滤器找到则更新数据，否则执行插入操作。 replace_one 是直接用一个新文档替换旧文档，而 update_one 是用 更新修饰符 来操作的。 更新修饰符 更新修饰符大体有下面这些： $inc doc的某个属性数值加上多少，比如 \"$inc\":{\"score\":1} 是 score 属性加1。 $set doc的某个属性设为多少。 $unset 删除属性 $push 列表append操作 $pop 列表右边最后一个元素删除 $pull 列表中某个元素将被删除 $pullAll 一次删除多个 $rename 属性名更改 $addToSet 给某个列表添加元素，有则不加，没有则加上。 删除文档 col.delete_one(filter) col.delete_many(filter) 长时间查询丢失cursor 有的时候你写一个脚本，因为数据库数据比较大，find可能会执行很长时间，然后会返回一个cursor 找不到的错误，这是因为mongodb自动关闭了那个cursor，你需要在find方法上加上选项： no_cursor_timeout=True 。 PS: 之前我设置这个选项了，后来还是有时候会出现这个异常，后来确定的原因是因为目前我操作的文档doc记录文本较大，所以需要设置 batch_size ，默认是 4M ， 最多只能设置到 16M。 col.find({}, no_cursor_timeout=True).batch_size(16) doc的创建时间 不要写什么 created_time 了，mongodb的 ObjectId 是有该doc的创建时间含义的： from bson import ObjectId id = ObjectId ( \"5a505b643004c52888489b02\" ) id . generation_time datetime . datetime ( 2018 , 1 , 6 , 5 , 15 , 16 , tzinfo =< bson . tz_util . FixedOffset object at 0x0000022CEDC414E0 > ) 原生mongo命令 比如 update_many 对应的是 updateMany ，在pymongo那边很多命令都是对应的。 索引 很多初学mongodb的人用了一段时间就会抱怨，mongodb很慢，实际上mongodb不慢，这其中很大一部分原因是，他们没有进行创建索引操作。 mongodb的记录 _id 字段默认是会创建索引的，然后可能会有某些字段，如果你的程序里面会频繁查询使用，那么当你的文档记录很多了之后，是一定要加上索引的，否则你的程序会很慢很慢。 db.COLLECTION_NAME.ensureIndex({KEY:1}) 然后某些查询会涉及到多个字段，那么推荐创建一个多值索引（或者叫复合索引？）： db.getCollection('clean').ensureIndex({'name':1,'author':1,'chapter_id':1}) 备份和还原 mongo命令可能你平时不是特别需要了，不过 mongodump 和 mongorestore 这两个命令有时还是需要的，其一个是进行mongodb的备份操作，一个是进行还原操作。 mongodump mongorestore dump 最简单的流程如上，这里的备份文件就放在dump文件夹下。更多选项请读者自行了解之。比如下面： mongodump --host = atlas-04 --db = mls06085 -o mongodump_2015-07-29 --db 指定数据库名， -o 指定导出文件夹名。 连接数据库 windows下连接数据库 请参看 这个网页 ，使用 -u -p 输入用户名和密码之后不知道怎么还是连不上，最后查询发现还需要加上 admin，不太清楚为什么（现在有点清楚清楚了，这个在linux对应的选项是 -authenticationDatabase ， 也就是你管理认证相关的数据库名字）。 mongo admin -u admin -p SECRETPASSWORD 连接mongodb集群 mongo --host=inors0504/redstone:27019,ltprod01:27108,innoali02:27018 查询只显示某些字段 db . getCollection ( 'qidian_book_info' ). find ({},{ 'bookInfo.updTime': 1 }). sort ({ 'updated_time' :- 1 }) 参考资料 mongodb and python, Author:Niall O'Higgins, year:2011 mongodb - the definitive guide, Author:Kristina Chodorow, May 2013:Second Edition MongoDB Basics , Author:David Hows, Peter Membrey etc. year: 2014","tags":"数据库","url":"articles/mongodb.html"},{"title":"crontab定时任务","text":"crontab工具可以用来让系统执行一些周期性任务，其在ubuntu下服务名字叫cron；在centos下服务名字叫crond。 你可以通过crontab这个命令查看或修改具体的配置： crontab -l #列出配置文件内容 crontab -e #进入配置文件编辑 编辑一般就是进入的vi编辑器。用crontab -e修改的配置会直接生效，不需要重启crontab的后台服务。如果重启后台服务了，那么所有的任务都会重新开始计时。当你的配置写着每隔一个小时执行某个任务，那么要等到下一个小时的时候才会执行任务。 一开始推荐写上这样一个每分钟的echo命令来看看crontab的具体运行情况。 * * * * * echo \"test\" 一般日志是默认在 /var/log/cron 那里（centos）。 然后上面的配置含义是 ： 分 时 日 月 星期几 命令 其中小时是24时制，星期几0表示星期日，1表示星期一。后面的命令就是一行简单的shell命令，如果是多行命令的话建议写成bash脚本，然后给这个脚本可执行权限，然后写上该脚本的绝对路径名即可。 NOTICE ： crontab里面执行的命令不是在shell环境下，比如pyenv环境就可能不会正常工作，推荐要使用什么命令什么文件都使用绝对路径。 每五分钟： */5 * * * * 每三个小时： 0 */3 * * * 注意前面分钟一定要写上0，这是新手很容易犯的一个错误。 每天早上七点钟： 0 7 * * * 一些常见的crobtab配置 本小节参考了 这篇文章 。 每月 0 0 1 * * 每周 0 0 * * 0 每天 0 0 * * * 每五个小时 0 */5 * * * 每三十分钟 */30 * * * * 定时备份crontab配置 远程连接服务器，在进行crontab -e编辑的时候如果失去连接或者怎么意外终止了，那么你之前所有的crontab配置都会清空！！ 所以请加个定时备份你的crontab配置命令： * */1 * * * crontab -l > /home/backup/crontab.back","tags":"linux","url":"articles/crontab.html"},{"title":"git版本控制","text":"git基础 下面就git命令使用的基本流程说明如下： 远程仓库文件到本地 网上创建项目之后，你需要将网上的存档下载到本地，在你希望下载的地点，打开终端： git clone https://github.com/a358003542/xelatex-guide-book.git 初始化本地仓库 git init 命令用于初始化本地仓库， git clone 下来的仓库文件已经初始化了，然后 origin 这个远程服务器名字也已经加上去了。 本地仓库进入索引 你可以先用 git status 命令查看一下当前仓库的改动情况，如果某个文件你不想改动，可以用 git checkout what 来放弃这个更改，如果某项改动你想提交上去，则用 git add what 把目标文件加入索引。这个add命令也可以跟上某个文件夹名，则该文件夹下所有的文件都将被跟踪。然后你本地删除了某个文件，如果你希望仓库也删除这个文件，那么可以加上 --all 选项： git add --all which_folder 将索引改动提交到本地仓库 git commit -m '2013-08-25:19:00' 具体文字信息是对于这次更改的注释，你也可以不加上 -m 选项，来直接进入编辑器写上一些信息。 本地仓库改动提交到远程仓库 第一次提交你需要给你的远程服务器取个简单点的名字： git remote add origin https://github.com/a358003542/xelatex-guide-book.git 这里的 origin 是远程服务器的简称，按理来说这个名字是可以随便取的，不过大家似乎都是取得origin，然后你从github上clone下来的仓库默认远程服务器名字大多也是 origin。 然后以后都可以用这个简单的命令来更新了： git push origin master 现在最新的git版本简单的写作 git push 也是可以的。 远程仓库的改动更新到本地 下面这个命令git对文件的操作是合并式的，也就是只是替换最新改动的文件。如果你希望远程仓库所有改动包括删除也更新到本地，使用可选项 -- all （--all是个方便的处理删除动作的选项，否则你需要对你想要删除的文件使用git rm 命令之后git仓库才会记录这次删除动作，从而本地和远程仓库都跟踪这次删除动作） 。 git pull origin master 现在最新版本的git 简单写上 git pull 就可以了，它内部可以更加智能的判断分支之类的参数了。 一般情况下就 add commit push 这三步。这是基本的日常维护提交流程。如果你在网站上对远程仓库做了一些修改，记得先用pull命令将远程仓库的改动更新到本地。 第一次使用的配置 设置你的名字和email： git config --global user.name \"Your Name\" git config --global user.email \"your_email@whatever.com\" 这个是git的全局设置，和具体项目无关。你可以打开你的家目录下的 .gitconfig 文件看一下。 .gitignore文件 你在github创建项目的时候如果选择好了项目语言，就会自动创建一个 .gitignore 文件，文件语法很简单，比如 *.out 则项目内所有后缀为out的文件都不会被加入索引。 推荐你到 gitignore项目 那里看一下。 初始化仓库 git init git init 即在当前工作目录下初始化git的管理仓库，如果你打开查看隐藏文件，会看到一个 .git 文件夹，git用于管理当前项目的一些文件就存放在这里面，你以后可能会用到的就是那个 config 文件。 比如如果你是在github上创建的项目，然后将这个项目克隆下来（已经创建了一个文件了），那么就不需要再执行init命令，远程仓库已经执行了。而且你打开那个config文件会看到remote origin 也已经定义好了。 如果你之前clone的时候使用的http连接，然后你又想使用ssh连接，那么直接在那个config文件下修改即可。 删除文件动作的跟踪 如果你本地删除了文件，你希望远程仓库也删除这些文件，那么你可以先看一下 git status 看看又那些文件改动了。 然后使用 git rm 目标文件 来跟踪目标文件的删除动作。 如果我们在 git add 某个文件夹的时候，加上 --all 选项，那么这个文件夹内的文件的删除动作也会自动跟踪的。 查看git仓库目前文件改动情况 git status 查看git仓库更改记录 git log 使用git log 命令就可以查看本地仓库的更改记录。git log有很多设置，这里有个最简单的例子（参考了githowtu网页）： git log --pretty=format:'%h %ad | %s%d [%an]' --graph --date=short 你可以创建一个别名来方便后面使用，比如在你的家目录的 .gitconfig 文件里面写上： [alias] hist = log --pretty=format:'%h %ad | %s%d [%an]' --graph --date=short git命令的别名功能 比如上面提到修改家目录的 .gitconfig 文件来获得输入 git hist 就很获得git仓库更改记录的好看的打印信息。 你也可以这样 git config --global alias.hist \"log --pretty=format:'%h %ad | %s%d [%an]' --graph --date=short\" 这个命令实际上还是修改了主文件夹的.gitconfig文件，你可以打开看一下。 切换版本 切回到另外一个版本中去： git checkout 3fbdf2c 具体commit的hash值可用git log查看之，这个命令将会将本地文件夹返回到某个特定的版本状态。 取消对文件的修改 git checkout file_or_folder 如果你修改了某个文件，还没有add和commit，然后对现在修改不满意，想全部舍弃。那么可以如上使用checkout某个文件或者文件夹来取消修改，从而文件回滚到最后一次commit时未修改的样子。 最后一次commit的更改 有的时候你提交一个commit了，然后又发现还有那个地方没有修改，或者commit的附加信息你不满意等等，你可以使用: git commit --amend 来覆写上一次你的commit记录，amend的意思是改进修正的意思。这里你只能amend你最近的那次commit，然后运行命令之后，等于你上一次所有的commit都被取消掉了，然后你做了一些修改，再重新进行一个commit。 取消已经add了的文件 如果你不小心 add . 所有的文件，然后有些文件你不想add的，那么可以如下取消add操作。 git reset HEAD file_or_folder 分支功能 git的分支功能特别强大，推荐多使用来做到灵活开发。git保存的不是文件差异或者变化量而是一系列的文件快照。git在commit之后，除了相关的提交信息之外，还有一个指向这棵树的指针。而git中的分支本质上仅仅是个指向commit对象的可变指针。当使用 git branch testing 来新建一个分支之后，就是在目前这个commit对象上又新建了一个分支指针。然后git还保存了一个名叫 HEAD 的特别指针，其指向你正在工作的本地分支。因此运行git branch仅仅是新建了一个分支，系统并不会自动切换到那个分支，要切换到那个分支需要使用 git checkout testing 命令。如果master分支和testing分支各自向前commit推一次，然后一个分支样貌就如下图所示出来了: 上图HEAD说明当前正在工作的分支点在那里，master是默认的主分支，然后上图还有一个testing分支。上图是在f30ab那里开了一个testing分支，然后testing分支又commit了一次，然后master分支那边也推了一次，然后本地文件夹当前工作分支是在master那里。 按照 pro git 一书的说法，Git中的分支实际上仅是一个包含所指对象校验和（40 个字符长度 SHA-1 字串）的文件，所以创建和销毁一个分支非常的廉价，而且切换也是非常的快。Git鼓励开发者频繁使用分支。 新建分支 如下新建一个git分支： git branch the_branch_name ​ 额外需要提醒的是新建一个git分支之后，你还需要用checkout命令来切换到那个分支，否则是停留在原来的分支上的。 查看分支 git branch 可用于查看分支状态。如果加上选项 -a 还会显示远程分支的状态。 ​ 切换分支 git checkout the_branch_name ​ 克隆分支 使用git clone某个项目如果你只想克隆某个分支，你可以加上 -b 选项来只clone远程仓库的某个分支： git clone -b the_branch_name the_project_url ​ 合并分支 比如说上面的testing分支和master分支你想合并在一起了。那么首先切换到master分支，然后使用git merge合并分支之，如下所示: git checkout master git merge the_branck_name 合并策略是没有的新建，有的迭加合并，其中某些文件有冲突的则需要手工处理。 删除本地分支 本小节参考了 这个网页 。 git branch -D branch_name 删除远程分支 git push origin :branch_name 分支对分支的推送 git push origin dev:dev 这里的意思是本地有一个dev分支，现在将其推送到远程的dev分支上去。我们看到这和删除远程分支的语法有点类似，除了冒号前面没有指定本地分支。 还有一种很不规范的做法: git push origin dev:master 这是将本地的dev分支推送到远程master分支上去，不推荐这么做，尽量让本地分支和远程分支名字一样吧，免得自己也弄混了。 tag功能 我们看到github上有个release栏就是基于git的tag功能 ，参考了 这篇文章 。 查看tag git tag 添加tag git tag tag_name 将tag推送到远程 git push --tag commit几次之后的后悔行为 如果你commit几次了，然后对这几次commit都不太满意，想回滚到之前的某个commit下。可以如下： git reset --hard commit_id ## 修改 ## 新的commit git push --force 我喜欢使用 --hard 选项彻底回滚到之前的某个commit下（还有什么 --soft 和 --mixed 选项。），因为远程仓库那边都有记录的，再对照比对选择就是了。记得后面的push操作一定要加上 --force 选项。 子模块功能 添加子模块 一个git仓库里面可能有一些文件夹是另外一个git仓库，我们称该git仓库为子模块，对于这些内容我们应该如下添加子模块来管理： git submodule add the_folder 这样你的子模块里面的内容都是通过其自身的git来管理的，但如果子模块内容更新了，而主模块是需要记录这些更新的，否则你的主模块记录的子模块还是以前的版本。 子模块更新 具体子模块更新实际上就是常规的 git add submodule_folder 然后commit操作。 git add --all submodule_folder git commit -m \"update submodule\" clone包括子git模块 如果某个项目里面有子git模块，然后简单使用git clone命令里面的内容是不会下载下来的。参考了 这个网页 。 如下加上 --recursive 选项就会下载项目里面的子git模块。 git clone --recursive what.git ​ 中文乱码问题 主要参考了 这个网页 。 我的用户家目录下的 .gitconfig 文件有这些设置，读者可以参考下： [core] quotepath = false autocrlf = false safecrlf = true [gui] encoding = utf-8 [i18n \"commit\"] encoding = utf-8 [i18n] logoutputencoding = utf-8 这其中 autocrlf = false 是git for windows的一个设置，就是把Linux的换行符变成windows的换行符行为关闭；然后 safecrlf=true 设置是什么就是什么，git for windows不做任何更改。 quotepath 是把git的路径默认转义行为关闭。 然后下面一些设置为utf8编码的行为。 ​ 参考资料 git简明指南 git howto 图解git git community book中文版 pro git第二版","tags":"linux","url":"articles/git.html"},{"title":"bash脚本入门","text":"下面简单讲一下 bash shell 脚本知识，点到为止，主要是关注一行之内的shell命令，更加复杂的逻辑请使用python来编写脚本。 变量 i=2 echo $i 一般赋值就如上所示，和其他编程语言变量赋值大体类似吧， 但是要特别注意变量和值之间的等号是相连的，不能用空格隔开 。变量的符号一般就是字母数字，可以加下划线。这样声明的变量为局部变量，也就是本shell中适用。如果要创建全局变量需要使用export命令。 一般使用这个变量就是在前面加上 $ 符号，如果你需要用变量的字符和其他字符组合成一个新的字符，那么需要用花括号将变量名包围起来。即这样的形式 ${i}what 。一般来说使用变量都推荐使用 ${} 这样的形式。 应用：修改终端前缀 export PS1=\"=>\" 利用export命令就可以将这个变量变为全局变量（这里所谓的全局变量主要指子shell继承了父shell的变量。），这样所有的shell脚本都可以通用。 如果你将以上代码放入你家目录的 .bashrc 文件里面，每次终端启动都会自动加载这个文件的。这样你后面开启的那些终端前缀都会变成 => 这样的形式。 这样可以节省点屏幕空间。你可以用pwd命令查看一下，其他一切都没有影响的。 这个PS1就对应的终端的一级前缀符号，PS2对应的是进一步输入时候的提示符号。你可以换成这样的形式： export PS2=\">\" echo命令 echo命令前面接触很多了，这里不赘述了。echo命令就是用于查看某个变量的值或者直接输出一行字符串。 unset命令 取消bash某个变量的赋值。 read命令 请求用户输入某个变量的值 read name ; echo '你输入的是：' ${ name } bash里面的特殊符号 上面的分号bash和其他编程语言都大体类似，就是表示一行的结束。但bash还有很多其他的特殊符号，下面讲一下，这些特殊符号有的时候看到了搜索都不太好搜索。 更多信息请参阅 这个网页 。 $0 本命令名字，在shell脚本里面那么就成了本脚本的名字。 $1 $2 ... 命令接受的参数 $@ 所有参数： {$1, $2, $3 ...} ，其是一个array。 $? 上一个命令返回的状态，一般0表示成功。 $! 上一个命令运行的进程号 && 比如 cmd1 && cmd2 意思是前一个命令执行成功了再执行第二个命令 & 如果某个命令以 & 结尾，那么该命令将是异步的，进入后台执行。（PS：虽然这样，但如果你是通过远程连接服务器来创建的命令，远程关闭该后台进程也将自动关闭。这需要使用nohup或者screen。） if条件判断 if条件语句格式是： if [ test expression ] then do what fi 对于短小的shell命令行，可以写成这样的一行格式，其中分号表示换行。 if [ test expression ] ; then do what ; fi 还值得提醒一下的是：条件判断语句（就是上面的test expression）要和那个方括号[]有一个空格表示分开，（上古神器都有一些怪僻，淡定就好）。 应用：确认某个文件夹是不是存在 if [ ! -d workspace ] ; then mkdir workspace ; fi -d 表示检测某个文件夹是不是存在， ! 符号在这里进行逻辑否操作。也就是这里如果workspace不存在，那么新建workspace文件夹。 for循环 本小节参考了 bash for loop 这篇文章，其关于bash编程的循环部分讲的很详细。 for循环语句格式如下： for var in 1 2 3 do cmd1 cmd2 done 同样，你也可以将其写成一行的样子： for var in 1 2 3 ; do cmd1 ; cmd2 ; done ​ 其中加分号的地方为多行格式下必须换行的地方。 应用：小数点递加输出流 for animate in $( seq 4 .0 0 .1 8 .0 ) ; do echo ${ animate } ; done 关于seq命令我简单说下，请通过 --help 来查阅具体信息： 用法：seq [选项]... 尾数 或：seq [选项]... 首数 尾数 或：seq [选项]... 首数 增量 尾数 应用：批量创建文件 在文件夹里面输入如下命令： for (( i = 1 ; i< = 10 ; i++ )) ; do touch file $i .txt ; done 应用：批量缩小图片大小 这是一个多行脚本，用于批量缩小图片的大小。 if [ ! -d smallsize ] ; then mkdir smallsize ; fi cd smallsize let i = 1 for it in $( ls *.png ) do convert -resize 50 %x50% $it $i - $it let i = i+1 echo $it is smallsized done 应用：批量重命名文件 let i = 1 && for f in $( ls *.jpg ) ; do mv -vi ${ f } 0000 ${ i } .jpg && let i = i+1 ; done 调用子命令返回值 在前面几个例子中，已经出现多次这个形式了： $(cmd) ，其将执行子shell命令，并将返回结果作为字符串值。 array shell编程最好不要过多涉及复杂的编程的内容，那将是很痛苦的，但是在某些情况下你可能需要了解array这个概念。下面来演示这样一个例子，其需求就是在一个自动备份程序之上再加上自动删除逻辑。 DATE = $( date +%F ) DAYS = 30 ## here is the autodump code, and the output filename is whatdump_${DATE} ### the allowed list ALLOWED [ 0 ]= whatdump_ ${ DATE } for (( i = 1 ; i & lt ; = ${ DAYS } ; i++ )) do ALLOWED [ i ]= whatdump_ $( date -d \"now - ${ i } days\" + \"%F\" ) done ### use the python script , it is really hard to write it on bash python ~/thepython/scripts/whatdump_autoremove.py ${ ALLOWED [@] } 这个程序整个逻辑就是创建一个名字叫做 whatdump_DATE 的备份文件（你可以通过crontab来控制好每天运行一次），然后我们希望目标文件只保留最近三十天的文件。因为这个逻辑较为复杂，本来我是打算直接将 DATE 参数传递给python脚本来做接下来的工作的，但是在了解到date命令强大的人类友好的日期时间表达功能（请参考 这个问题 ），我决定将整个允许存在的文件名都传递进python脚本中去。 有兴趣的可以了解下date命令-d选项的灵活表达支持，比如 date -d \"now -3days\" 就是现在之前三天的日期时间，而 date -d \"+3weeks\" 就是现在三周之后的日期时间。用兴趣的可以继续了解下，这个date命令的-d选项真的好强大。 好了下面详细讲一下这里array涉及到的语法。 赋值和引用 = >array [ 0 ]= \"hello\" = >array [ 1 ]= \"world!\" = >echo ${ array [0] } ${ array [1] } hello world! 这种表达和我们常见的那种数组概念相近，记得索引从0开始这个惯例即可。或者如下一起赋值: = >array2 =( \"hello\" \"python\" ) = >echo ${ array2 [@] } hello python 上面的 ${arrayname[@]} 这种表达方式就是引用所有的array，然后还有 ${#arrayname[@]} 这种表达是返回这个array的长度。 =>echo ${ #array2[@] } 2 然后最后这句: python ~/thepython/scripts/whatdump_autoremove.py ${ ALLOWED [ @ ] } 就是将收集到的所有允许的文件名array传递进python脚本中去了。在python脚本中一个粗糙的做法就是如下这样引用 def main(args,path=\"\"): print args main(sys.argv[1:]) 这样所有的这些array就传递进args里面去了，读者有兴趣可以试一下，这个args在python中就是一个列表对象了。到python里面了更复杂的逻辑我们都可以很快写出来了，我就不说了。 大概类似下面所示，注意这里的pathlib在python3.4之后才会有，之前需要用pip安装之。 #!/usr/bin/env python # -*- coding: utf-8 -*- from __future__ import print_function import sys from datetime import datetime import os from pathlib import Path import shutil def main ( args , path = \"\" ): allowed = args p = Path ( path ) pfolds = [ p for p in p . iterdir () if p . is_dir ()] print ( pfolds ) for p in pfolds : if p . name in allowed : print ( p . name , \"passed\" ) else : print ( p . name , \"removed\" ) ### really do the remove thing shutil . rmtree ( p . name ) if __name__ == '__main__' : ### 切换到autodump目录 os . chdir ( os . path . expanduser ( \"~/autodump\" )) main ( sys . argv [ 1 :]) date命令 之所以把date命令放在一章是因为date命令如果单独作为一个命令来使用，打印显示日期其实意义不是很大。但是在bash脚本中，在管道中，date命令却变得非常有用了。读者可以用 --help 查看一下帮助信息，这个命令比我们预想的还要复杂的多，而且这里的那些输出格式参数控制语法，就是到了其他编程语言中也是有用的（比如python的time模块中的strftime函数）。 date返回日期字符 date命令返回某个特定格式的日期在某些shell脚本中很有用，如下所示就是一个简单的例子： date=$(date +\"%F_%R\");echo $date date命令前面已谈到一点，更多信息请参看 这篇文章 。这里就不赘述了。","tags":"linux","url":"articles/bash-tutorial.html"},{"title":"ansible自动化运维","text":"ansible是一个自动化运维工具，当我们学习到后面之后，就会发现只写一个简单的web app是不够的，常常远程计算机那边的环境需要很多配置，比如后台脚本的执行啊，nginx配置来服务静态文件啊等等。而每个任务都手工用 ssh 端来操作的将是非常低效率的了，尤其到后面各个任务繁多，环境需要重复部署的时候。ansible就是解决这一问题的。 第一个例子：假设你现在可以免密钥登录某一个远程服务器了，然后你在 /etc/ansible/hosts 这个文件里面把你的服务器名字加进去，然后执行: ansible all -m ping 如果一切正常的话其将返回 SUCESS 信息，证明现在你已经通过ansible正常连通你的远程服务器了。 hosts文件配置 这里讨论的 /etc/ansible/hosts 这个文件是所谓的默认 inventory 文件，除了这个默认inventory配置文件之外，还可以写很多其他的配置文件的。而这些配置文件内容大体如下: [webservers] foo.example.com bar.example.com [webservers] 这个字段定义的是所谓的主机组的概念，之前我们随便写上去的那个主机没属于任何主机组，然后一个主机组似乎还可以属于另外一个主机组等，这个有点复杂了。似乎主机组里面的主机可以怎么统一管理，这个后面再说。 主机变量设置 组的变量情况请看文档下面，主机变量大体就是后面写上一些值就是了，因为这些变量在定义后playbooks也是可以使用的，而playbooks无疑是后面的重头戏，所以这还是值得提一下的。 [atlanta] host1 http_port = 80 maxRequestsPerChild=808 host2 http_port = 303 maxRequestsPerChild=909 主机的其他参数控制 应该大多和具体ssh连接的配置有关吧，比如: some_host ansible_ssh_port=2222 ansible_ssh_user=manager ansible_ssh_host 这个一般没啥好设置的，不过可能你的主机名很长，则通过这个设置一下作为具体连接的主机名。而前面写的 some_host 只是作为主机别名。如果你的ansible版本号大于2了，那么推荐使用 ansible_host 。 ansible_ssh_port 端口号，默认不需要配置。如果你的ansible版本号大于2了，那么推荐使用 ansible_port 。 ansible_ssh_user ssh登录用户名，默认是你当前电脑的当前登录用户名，这个可能在某些情况下需要配置。如果你的ansible版本号大于2了，那么推荐使用 ansible_user 。 ansible_ssh_pass 登录密码，免密钥登录不需要配置。文档说不推荐使用。 playbooks之熟悉yaml 当然首先需要简单了解下yaml语法，一个简单例子如下: --- # 一位职工记录 name : Example Developer job : Developer skill : Elite employed : True foods : - Apple - Orange - Strawberry - Mango languages : ruby : Elite python : Elite dotnet : Lame yaml文件一开始都要加上这个: --- 。 注释是 # 然后相同缩进级别 - 开头的表示一个列表，然后其他键值对表示字典，大体就是这样。 playbook入门 下面是最简单的一个例子，新建这么一个 first.yaml 文件: --- - hosts : work tasks : - name : ping and pong ping : 然后执行是: ansible-playbook first.yaml 这里只是简单的ping pong 了一下，这个配置简单的内容就是主机 work ，这个是在之前提到 /etc/ansible/hosts 那个文件里定义的。然后对这个主机执行某个任务 tasks 。这是一个任务列表清单，name 描述了该任务，文字随意。然后执行了 ping 模块。 这个任务确保nginx重启了一次: - name: make sure nginx restarted service: name=nginx state=restarted 这个任务是确保nginx服务是运行着的: - name: make sure nginx is running service: name=nginx state=running playbook最佳实践 hosts文件 在项目的文件夹下新建一个hosts文件，其类似之前讨论的 /etc/ansible/hosts 文件，然后在本地通过如下语法引入： ansible-playbook -i hosts site.yml ​ site.yml 刷脚本的主入口 tags单独运行子任务 在roles文件夹里面新建一个common文件夹，然后common文件夹里面新建一个tasks文件夹，tasks文件夹里面定义一个main.yml，该文件内容大体如下: --- - name: task的名字 command: ... 然后site.yml里面如下定义： --- - name : ansible 必要参数侦测 hosts : all remote_user : root roles : - { role : common , tags : [ 'common' ]} 然后只运行某个子任务如下利用tags来完成。 ansible-playbook -i hosts site.yml --tags=common ​ 临时加上某个 tags 任务 - name : create odoo superuser shell : su - postgres -c \"createuser -s {{ user }}\" tags : - psql_user role的全局参数 全局参数放在 group_vars 文件夹的 all 文件里面，其也是一个简单的yaml文件。 role里的局部参数 这些参数推荐在site.yml文件对应的role哪里定义，如下所示定义了一个 folder_name 变量 ： roles : - { role : update-sdsomweb , folder_name : \"resource/install_venv\" , tags : [ 'update-sdsomweb' ]} 我们看到ansible-playbook就最基本的配置编写和使用还是很简单的，关键是具体任务那边要熟悉好一些特定的模块。 playbook之模块 官方模块很多，内容很丰富，这里就不赘述了，请参看官方文档。 如何实现本地安装 在hosts里面添加一行： localhost ansible_connection=local 同时需要注意本地安装不需要提供ssh用户名和密码了，然后也不需要上传ssh key了，所以如果你之前有上传操作的应该加上这么一行： when : ansible_connection != \"local\" ​ 将压缩包解压包远程机器目标点 值得一提是unarchive模块最近才支持 remote_src 模式，所以推荐还是采用本地压缩包源然后解压过去的方式。 - name : 解压 apr unarchive : src : \"{{folder_name}}/apr-1.5.2.tar.gz\" dest : /root rsync风格的将某个文件夹复制过去 为什么不利用copy模块，因为scp如果文件夹里面结构稍微复杂点就会很慢，这时推荐使用 synchronize 模块： - name: 上传源 synchronize: src=resource/winstore dest=/root mode=push 值得一提的是，rsync那边如果远程机器不是免密码ssh连接的话，这时又要输入密码，所以推荐你的playbook一开始就将pub密钥传过去，然后rsync功能需要远程机装了libselinux-python和 rsync 这两个软件包。 - name: 上传ssh key authorized_key: user=root key=\" {{ lookup ( 'file' , '/home/what/.ssh/id_rsa.pub' ) }} \" 这里的user是登录远程机器的用户名。 如何获得远程机器的更多参数信息 ansible的 setup 模块能够获得远程机器很多有用的信息，甚至能够知道远程机器运行的虚拟机软件是什么。不过你可能需要一些更多信息，比如远程机器默认的python版本是多少，这个时候我们可以用如下方式来获得： - name : get python version command : python - c 'import sys;print(\"{0}.{1}\".format(sys.version_info.major,sys.version_info.minor))' register : python_version_check 这里的register注册的是执行上述命令command之后的返回结果，在ansible整个运行时里都是可以用，具体结果你可能还需要通过 python_version_check.stdout 这样的方式获得。 command和 shell的区别 command和shell在很多情况下似乎都没有区别，shell严格意义上来讲就类似于你在shell中执行了某个命令，其可以使用bash的一些环境变量等，后面应该没事会优先考虑使用shell模块吧。 如何在pip的虚拟环境下工作 参考了 这个网页 ，如下所示是在目标虚拟环境文件夹下根据requirements.txt文件夹描述来安装那些目标python模块到虚拟环境中。 - name : Install requirements pip : requirements : /my_app/requirements.txt virtualenv : /user/home/venvs/myenv virtualenv_python : python3.4 如何安装本地的rpm包 有兴趣的可以看一下ansible的 yum 模块，不过要实现免网络完全利用本地下载的rpm包来安装的话用这个模块似乎并不是很好用，因为其并不能很好地处理各个模块之间的依赖。推荐就直接调用shell模块，如下所示： - name: install rpms shell: yum localinstall -yC --disablerepo=* `ls /path/to/rpms/*.rpm` 具体这些rpm包如果是base的，那么推荐用： yum install yum-utils yum install --downloadonly --downloaddir=. the_rpm_name 来下载之。如果来自epel，那么推荐在 pkgs.org 搜名字，在 这个网站 下载。 删除文件或文件夹 删除文件或文件夹推荐使用 file 模块而不是调用rm命令，如下所示： - name: 确保目标venv文件夹不存在 file: path=/opt/sdsom/venv state=absent 如何微调配置文件 一般配置文件在远程机器上已经有个原样了，只是某几行需要修改一下，这个时候用lineinfile模块来微调这些配置很是适宜的。 - name : 调配apache的 httpd.conf lineinfile : dest : /etc/apache/conf/httpd.conf regexp : \"{{item.regexp}}\" insertafter : \"{{item.insertafter}}\" line : \"{{item.line}}\" with_items : - { regexp : \"&#94;Listen \" , insertafter : \"&#94;#Listen \" , line : \"Listen 8880\" } - { regexp : \"&#94;User \" , insertafter : \"&#94;#User \" , line : \"User sdsadmin\" } - { regexp : \"&#94;Group \" , insertafter : \"&#94;#Group \" , line : \"Group sdsadmin\" } - { regexp : \"&#94;ServerName \" , insertafter : \"&#94;#ServerName \" , line : \"ServerName {{server_name}}\" } 上面这个例子的意思就是用 regexp 来匹配目标行， 然后替换为内容 line 。insertafter是如果匹配到那个了，则将line插入到该行的后面。 下面这个例子是插入一行new line： - name : Load config files from the config directory conf.d/*.conf lineinfile : dest : /etc/apache/conf/httpd.conf line : \"{{item.line}}\" with_items : - { line : \"Include conf.d/*.conf\" } 此外template模块可以利用本地的模板文件（jinja2模块系统）来生成一个配置文件。 只在某个版本的操作系统下才执行某个动作 用 when 语句来表达，下面的意思是只在远程机器操作系统是CentOS而且版本号是7.2时才执行某个动作（参考了 这个网页 。 - name: only for centos7.2 do some tweak command: ... when: ansible_distribution == 'CentOS' and ansible_distribution_version.startswith('7.2') ansible_distribution 还可能是 Ubuntu ，Debian ， Red Hat Enterprise Linux 等。 register的用法 比如说我们写上这么一个简单的 test.yml 文件，内容如下： --- - hosts : localhost tasks : - name : test shell : date register : test - name : debug debug : msg=\"{{ test['stdout'] }}\" 然后我们运行： ansible-playbook -i \"localhost,\" -c local test.yml 运行结果就显示之前运行的那个date命令的结果已经注册到ansible的全局变量池里面去了，名字通过register来赋值，然后在后面的jinja2模板系统中都可以调用的。 with_items的用法 这个具体请参看官方文档的 这里 。 换行写或者一行写 这个是个小细节，官方文档看了一些就会看到这两种形式，不多说了。 lookup的用法 lookup上面在上传ssh key的时候已经用到过一次了， 这个在ansible里面也是一个高级应用。 command 模块的skip判断 如下加上 creates 参数来作为这个command是否跳过的判断标准，如果该文件存在则认为command已经执行过了则会跳过。 local_action是什么 local_action 是 delegate_to: 127.0.0.1 的缩写，简单来说就是只在本机或说操作机上执行某个动作。这里顺便提一下 delegate_to 的含义，是指定某个主机执行某个动作，是脱离ansible默认的由inventory输出的那个几个hosts的，也就是这个 delegate_to 的主机可以是默认的那个几个hosts中的一个，也可以是其他主机。 tasks : - name : take out of load balancer pool local_action : command /usr/bin/take_out_of_pool {{ inventory_hostname }} handlers是什么 - name : template configuration file template : src=template.j2 dest=/etc/foo.conf notify : - restart memcached - restart apache handlers : - name : restart memcached # The service module was used, but you could use whatever module you wanted service : name=memcached state=restarted - name : restart apache service : name=apache state=restarted 有时你会在playbook的某个role下面看到hanlders这个文件夹，简单来说就是某个任务如果执行了（跳过的不算，只有真正执行也就是changed state返回了），然后将执行notify: 下面定义的一些hanlders任务。 参考资料 ansible官方文档 ，这里有个翻译的 中文ansible官方文档 。 you-should-know-ansible 这篇文章写了一些关于ansible的东西写得挺好的。","tags":"linux","url":"articles/ansible-auto-operations.html"},{"title":"apache web服务器","text":"关于apache2 web server的简要介绍请参看 apache http server wiki 。目前推荐使用apache2.4，这是它的 apache官方文档 。 Ubuntu系统或者Centos系统之间httpd的安装配置环境等差异很大，我想说的是那些知识都不是重点，跟着官方文档，咱首先折腾出一个绿色本地安装版本的httpd，然后跟着官方文档学配置才是王道。什么在那个系统那个命令啊，那个系统那个文件夹下那个配置啊都是不重要的东西。 apache的本地安装 apache本地安装过程大体分为下面几步： 安装apr 安装apr-util 安装httpd 安装mod_wsgi （可选项，使用django或者flask你需要它的） 更多的细节在官方文档的 install 那一章节里，读者如果懂ansible的话，可以看看 我写的 green-install项目 里面的apache role 部分。 正如前面说到的，日志文件在那里，配置文件在那里加载啊等等都是可以定制的，摸清楚配置语法才是王道。 挂个简单的静态网站 首先httpd.conf 那里我们写上了 LISTEN 80 了，这样apache将会监听80端口。你的域名指向你的远程服务器ip就可以了。然后一般我们在httpd.conf 后面写上这么一句： Include conf.d/*.conf 也就是conf.d文件夹下的所有配置自动加载进来。这个conf.d文件夹和conf文件夹是平行关系。然后conf.d里面我们主要就是定义 VirtualHost 。 上个完整的例子吧： <VirtualHost *:80 > ServerName www.cdwanze.work DocumentRoot /home/wanze/venv/html DirectoryIndex index.html <Directory /home/wanze/venv/html > <IfVersion > = 2.4> Require all granted </IfVersion> <IfVersion < 2.4 > Order deny,allow Allow from all </IfVersion> </Directory> </VirtualHost> ServerName： apache监听80端口的信号将经过这个ServerName进一步进行分发，比如请求域名是 api.cdwanze.work，那个这个情况将不会被上面例子的VirtualHost处理。 DocumentRoot ： 服务的静态网站的那些内容所在的文件夹。重要级别五颗星。 DirectoryIndex ： 某些文件夹请求比如 /a/b ，如果这个文件夹下有index.html文件，那么将显示这个文件的内容。 Directory： 文件夹权限管理，重要级别五颗星，不写就会出现没有权限访问错误。 403 Forbidden You don't have permission to access / on this server apache2.4版本使用语法是 Require all granted ，对应的原2.2的配置是： Order allow,deny Allow from all 有考究癖的可以了解下2.2这种写法的意思： Order allow,deny —— 先写allow规则，再写deny规则 Allow from all —— 所有都可以访问 Deny from all —— 所有都拒绝 2.2的这个配置 Order deny,allow Deny from all 等同于2.4的： Require all denied \\end{Verbatim} 然后2.2的这个： Order Deny,Allow Deny from all Allow from example.org 意思是所有都拒绝，只允许 example.org的访问。 等同于2.4： Require host example.org 我们看到2.4的Require语句更简洁了，比如下面的这个： Require all granted Require not ip 10.252.46.165 所有都允许，除了谁谁禁止访问。 挂个wsgi站点 上例子吧： <IfModule !wsgi_module > LoadModule wsgi_module modules/mod_wsgi.so </IfModule> WSGIPythonHome \"/home/wanze/venv\" WSGIPythonPath \"/home/wanze/venv/webapp\" <VirtualHost *:80 > ServerName api.cdwanze.work WSGIScriptAlias / /home/wanze/venv/webapp/webapp/wsgi.py <Directory /home/wanze/venv/webapp > <IfVersion > = 2.4> Require all granted </IfVersion> <IfVersion < 2.4 > Order deny,allow Allow from all </IfVersion> </Directory> Alias \"/static\" \"/home/wanze/venv/webapp/static\" <Directory /home/wanze/venv/webapp/static > <IfVersion > = 2.4> Require all granted </IfVersion> <IfVersion < 2.4 > Order deny,allow Allow from all </IfVersion> </Directory> </VirtualHost> 首先是检测wsgi模块加载了没有，没有把它加载上。 WSGIPythonHome 这个设置你的python的虚拟环境的所在目录，比如上面的例子 venv/bin下面就是python可执行脚本。 WSGIPythonPath 这个设置你的Django项目目录所在 WSGIScriptAlias 这个设置你的WSGI文件所在 Alias 和下面Directory 设置是服务你的项目的静态文件的。 其他文件权限问题 除了上面设置好 Directory 之外，你可能还会遇到其他某些文件的读写权限问题，在查看日志的时候发现提示说那个文件没有权限读写了。这个时候首先要明确httpd的执行User和Group是谁，然后在看目标文件夹或文件的具体权限。 Django项目的wsgi文件是需要有执行权限的。还有Django项目操纵数据库，比如sqlite3这种文件数据库，你可能也会遇到读写权限问题。 还有值得一提的是如果某个母文件夹没有可执行权限，那么里面的所有文件都是不可见的。","tags":"linux","url":"articles/apache-web-server.html"},{"title":"linux系统基础","text":"debian系或者rpm系 目前Linux主流的包管理系统分为debian系和rpm系这两个。CentOS和Redhat属于rpm系；ubuntu和debian系统属于rpm系。在ubuntu中第一个要学习的命令就是 apt 命令，通过它来进行系统软件的安装卸载更新等等工作；在centos第一个要学习的命令是 yum 命令，与apt命令类似进行了一系列的系统的软件包管理操作。 yum命令和rpm命令 yum install what 安装某个软件 yum groupinstall what 安装某个软件组。 yum update 更新系统软件包 yum remove what 卸载某个软件 yum groupremove what 卸载某个软件组 yum clean 清除系统软件包管理相关的缓存 rpm -i what.rpm 本地安装某个rpm包，一般使用会加上 -vh 选项来显示更多的安装信息和安装进度。 apt命令和dpkg命令 系统安装好之后第一件要做的事是选一个好的源，然后安装更新。在系统设置→软件和更新那里，在\"下载自\"的哪里就是软件源的服务商，你最好还是自己搜索一个速度最快的源。然后在终端中执行以下命令来升级系统软件包： apt update 更新源 apt upgrade 升级源下已经安装了的软件（如果有很多软件需要升级的时候推荐使用命令： （ apt dist-upgrade 这样不容易出错些。） apt install what 安装某个软件 apt autoremove 清理软件残余 apt autoclean 清理安装软件留下的缓存 apt remove what 删除某个软件 apt purge what 删除软件包括相应的软件配置 设置root用户的密码 不管Centos还是Ubuntu安装好之后，你可能已经创建了另外一个用户和它的密码，但root用户的密码还是没有设置的。进入终端然后输入： sudo passwd root 设置好密码之后，以后输入： su 就可以进入root账户了，输入： exit 退出root用户。 passwd命令当然还可以修改其他用户的密码： sudo passwd youname 。 还有一种情况是你忘了所有用户的可能密码包括root的密码，这个时候可以如下操作来修改root密码： 系统重启进入菜单选项是，按 e 进入grub的编辑模式，然后在kenerl那一行再按 e 编辑该行，行尾加上 single ，然后 Enter确认，然后按 b 进入单用户维护模式，然后用 passwd 命令来修改root密码 （此条参考了vbird的第五章 ）。 最基本的命令 当我们打开终端的时候，看到一个美元 $ 符号，如果我们输入 su 命令，然后进入root账户，看到开头有一个 # 符号，其中 $ 表示普通用户， # 表示现在是超级用户。然后我们看到一个波浪号 ~ ，这个波浪号的意思就是当前用户的个人家目录，比如现在我这里 ~ 的意思就表示目录 /home/wanze 。 进入Linux系统最常用的两个命令就是 ls 和 cd 。 ls 命令会列出当前目录所包含的文件夹或者文件， 而 cd folder_name 就进入这个文件夹了。如果我们再输入 cd ，这个时候会回到个人的家目录那里。其实际等于执行了 cd ~ 。 关于cd命令我们还需要了解 cd . ，那个点表示当前目录，而 cd .. 表示返回上一级目录。然后 cd /etc ，这样我们就直接跳到系统的 /etc 目录下了。 下面这些基本的命令那是必须学会用熟的，具体使用请读者通过 --help 学习之： cp 复制文件命令 which 查看系统某个命令的位置 touch 创建某个文件或者对已存在的文件更新时间戳 rm 删除某个文件，如果使用 -r 选项也可以删除一个文件夹，也就是该文件夹和文件夹下面的所有文件。 mkdir 创建文件夹，如果加上 -p 选项可以创建多层目录。 rmdir 删除文件夹，如果加上 -p 选项可以删除多层目录，当然必须保证文件夹是空的。 mv 移动某个文件，也可以通过这个命令来完成重命名操作。 什么是shell shell就好像一个包装层，在shell的里面就是Linux操作系统的核心kernel，如果你要深入进去，将会遇到另外一个更加艰深的领域，比如计算机硬件啊，驱动程式啊还有Linux系统的设计核心等等之类的，这些知识都比较专业了，一般的人是不需要深究的。 Shell是提供操作系统核心（称为kernel）与用户之间交互的特殊程序，参见下图。这个kernel在启动时被装入内存,并管理系统直到关机为止。它负责建立和控制进程，管理内存、文件系统、通信等等。其他的实用程序，包括Shell在内都存储在硬盘上。kernel把程序从硬盘中装入内存，运行它们，并在程序运行结束后回收被程序占用的系统资源。Shell 是从你登录就开始运行的实用程序，它允许用户通过 Shell 脚本或者命令行的方式输入命令，并通过翻译这些命令完成用户与kernel的交互。 目前系统一般用的是Bourne Shell（bash shell）。本文提到shell即指bash shell，还有其他的shell这里就不讨论了 PATH变量 上面我们输入ls命令，shell是通过 PATH 这个变量来搜索相关命令的具体文件所在的。读者可以如下来查看这个变量： echo $PATH 比如你安装了某个软件，但是通过shell却发现找不到，那么将那个软件的可执行文件目录加入到系统的 PATH 环境下就可以找到了。一般用如下语法： PATH = $PATH:/where/your/bin 管道 简单了解了shell之后，下面简单地说明下管道和重定向这两个重要的概念，因为后面即使对于最简单的一行bash命令也可能会涉及到这两个概念。 所谓管道最简单的理解就是第一个shell命令的输出流流向了另外一个shell命令中作为输入。比如说你的火狐浏览器卡住了（随便举个例子，没别的意思。。），你需要看一下它的pid然后kill掉，那么可以如下查看： ps aux | grep firefox 这个 | 就是所谓的管道概念，这里首先是 ps aux 命令，然后输出送入到 grep 命令中去，抓取具体包含firefox字符的匹配行。 重定向 kernel处理的每一个进程都默认都0，1，2这样三个文件说明符。其中0表示标准输入，1表示标准输出，2表示标准错误输出。所谓的标准输出一般指输出到当前的终端，而所谓的标准错误输出也是输出到当前的终端。 当文件说明符被分配给其他非终端，就叫做I/O重定向。Shell通过关闭标准输出，并把标准文件说明符 1（终端）分配给其他某个文件，来把输出重新定向给该文件； 通过文件说明符0，来把标准输入重新定向；通过文件说明符2来重定向标准错误输出。 > 就表示这样的重定向操作。 >> 表示文件追加操作，也就是相当于文件操作的 a 操作。 最简单的重定向应用就是： cat *.txt > test.txt 其将本目录下glob抓取到的所有txt文件都合并成一个字符串流，然后重定向送入到test.txt文件中去。 cat *.txt 这个命令并没有什么神奇之处，神奇的是Linux终端对于文件glob操作对于 * （任意数目的任意字符）和 ? （一个任意字符）的支持。具体你可以用 echo *.txt 命令来查看一下。 再学几个命令 clear 终端清屏，其实内容并没有清除，现在终端一般都带有记忆功能和回滚功能，如果你向上滚，还是看得到之前的内容的。 history 显示当前登录用户已经执行过的命令，具体对应的是当前登录用户的家目录下的 .bash_history 这个文件里面的内容。 cat cat命令简单的用法就是： cat test.txt ，来查看某个文本文件的内容，但cat命令来自英文单词(concatenate)，这个英文单词通用意思是联接，延伸到计算机领域现在这个单词的意思就是指将两个字符联接成一个。这里cat命令的具体功能就是将两个或者更多的字符流文件联接成为一个字符流，默认是显示到终端上，你可以通过重定向将这个字符流流向某个文件从而保存起来。 more more命令常用来接受管道传过来的字符流信息，然后进行延缓打印方便读者阅读。 这里额外值得一提的是 windows下的 powershell也可以使用more，而且一样也可以使用管道： type test.txt | more head 打印文件前几行内容，可通过 -n 来指定具体打印多少行。 tail 打印文件后几行内容，同样可通过 -n 来指定具体打印多少行。然后tail还有一个用法， 加上 -f 选项来跟踪打印文件后面附加的内容。 uname 这个命令输入之后简单的返回\"Linux\"字符串，似乎用处不大。不过通过查看uname命令的帮助信息我们得知这个命令能够返回关于你目前电脑的操作系统，硬件架构，内核版本号等等重要信息。比如： =>uname -s #内核名字 Linux =>uname -n #主机名字 wanze-ubuntu =>uname -r #内核发行号 3.13.0-36-generic =>uname -m #硬件架构 i686 =>uname -p #处理器类型 i686 =>uname -o #操作系统名字 GNU/Linux whoami whoami返回当前登录用户的名字，等价于 id -un 。 文件和用户 本小节另外参考了 阮一峰关于inode的文章 。 Linux系统有一句很有名的一句话，那就是 一切都是文件 。具体文件分为： 普通文件、目录文件、字符设备文件、块设备文件、链接文件、套接字文件等。 Linux操作系统要找某个文件，比如 /etc/passwd 这个文件的时候。它首先根据这个具体的文件名，也就是这一连串字符串，来找个对应的inode号，然后通过这个inode号来获取inode信息，然后根据inode信息，找到该文件所在的block，从而读出数据。 Linux具体文件名有两种写法，一种是绝对路径，一种是相对路径。所谓绝对路径就是以 / 开头的文件名，而以 . 或者 .. 开头的是相对路径写法。所谓相对路径是相对于shell当前的工作目录而言的，你可以用pwd命令来查看当shell的当前工作目录。 pwd命令 pwd命令用来查看当前工作目录在文件系统中的路径。 然后有： / Linux文件系统开始的地方。 ~ 当前shell登录用户的家目录所在，对应于shell的 $HOME 变量的值。 . 相对路径写法，当前目录的意思。 .. 相对路径写法，上一级目录的意思。 stat命令 stat 命令可以用来具体查看文件的一些信息。 [root@host ~]# stat /etc File: `/etc' Size: 4096 Blocks: 8 IO Block: 4096 directory Device: 802h/2050d Inode: 37 Links: 76 Access: (0755/drwxr-xr-x) Uid: ( 0/ root) Gid: ( 0/ root) Access: 2017-09-05 01:35:41.983000000 -0400 Modify: 2017-09-21 15:10:57.103000000 -0400 Change: 2017-09-21 15:10:57.103000000 -0400 上面这些信息除了 Inode 也就是具体的inode号（可以看作电脑认识的文件名）之外，所有这些信息都是存放在Inode table 里面的。大体有：文件大小，文件类型，权限，所有者id，所有群id，access time（上一次打开时间），modify time（上一次修改时间）， change time（上一次这些inode信息比如读写权限之类的更改时间）。 下面这个是普通文件的例子，然后Links一般是1，而我们看到上面的目录文件Links不是1，其含义是有多少硬连接（hard link）指向它，一般来说是 2+n个，这里的n是该目录下面的子目录数目，而Linux下每个新建的文件夹都预先包含了 . 和 .. 这两个子文件夹，其具体用途读者应该猜到了，就是做相对路径用的（参考了 这个网页 ）。然后后面讨论硬连接的时候会讨论到不能硬连接文件夹，就是硬连接文件夹会破坏Linux的层级文件系统。 [root@host ~]# stat /etc/passwd File: `/etc/passwd' Size: 986 Blocks: 8 IO Block: 4096 regular file Device: 802h/2050d Inode: 17775 Links: 1 Access: (0644/-rw-r--r--) Uid: ( 0/ root) Gid: ( 0/ root) Access: 2017-09-21 11:23:26.112000000 -0400 Modify: 2017-09-21 11:23:26.112000000 -0400 Change: 2017-09-21 11:23:26.113000000 -0400 下面是块设备文件，然后其是一个文件系统，具体大小查看需要加上 -f 选项。 [root@host ~]# stat /dev/sda File: `/dev/sda' Size: 0 Blocks: 0 IO Block: 4096 block special file Device: 6h/6d Inode: 9005 Links: 1 Device type: 8,0 Access: (0660/brw-rw----) Uid: ( 0/ root) Gid: ( 6/ disk) Access: 2017-09-05 01:36:41.869000000 -0400 Modify: 2017-09-05 01:36:41.869000000 -0400 Change: 2017-09-05 01:36:41.869000000 -0400 [root@host ~]# stat -f /dev/sda File: \"/dev/sda\" ID: 0 Namelen: 255 Type: tmpfs Block size: 4096 Fundamental block size: 4096 Blocks: Total: 61502 Free: 61465 Available: 61465 Inodes: Total: 61502 Free: 60924 ls命令 ls命令最常用的两个选项是 -a 和 -l ，一个是要显示隐藏文件（Linux系统中文件名以 . 开头的是隐藏文件），一个是显示更多更多的信息。 然后 -i 选项显示文件的Inode号。 Linux系统最精彩的部分就是管道重定向等概念将各个小的程序小的工具揉合成为一个协作的整体，下面先举个简单的例子看下： ls *.txt 将会把一个文件夹里面的所有后缀是txt的文件名字符流扫描出来，这个字符流包含目标文件的文件名然后通过管道来进一步操作。 ls的 --sort 选项用来排序，似乎很有用，可以了解一下，但也可以通过管道传递给sort命令来进一步排序操作。如下所示： ls *.txt | sort ls这里抓取的文件字符流可以方便作为后面的操作，如下所示： for i in $( ls *.txt | sort ) ; do echo $i ; done ; ​ 这段代码里面的 $i 就是对应的一个个文件字符流。 -l选项详解 先看下面这个例子： -rw-rw-r-- 1 wanze wanze 41034 8月 27 15:19 wisesystem.xoj drwxrwxr-x 4 wanze wanze 4096 5月 28 18:50 yEd lrwxrwxrwx 1 wanze wanze 22 9月 11 18:37 到 git 的链接 -> /home/wanze/桌面/git 这里最重要的是先把第一栏看懂，文件所有者和文件所有群后面再讨论。 第一栏文件属性我们可以看到开头 d 表示这个文件是目录文件，开始 - 表示这个文件是普通文件，开头 l 表示这个文件是链接文件（后面讨论的软连接和这个相关）。然后后面三个是rwx表示这个文件的所有者对这个文件可读可写可执行，如果要控制其不可执行，那么就要将其属性改为rw-，具体文件权限控制更详细的讨论在后面。 第二栏是有多少hard links连接，这个上面提到过。 第三栏是文件所有者，第四栏是文件所有群，第五栏是文件大小。第六栏是文件最近修改日期或建档日期。 UID和GID 当用户通过shell登录Linux系统的时候，其首先进入一个login接口，你需要输入用户名和密码才能进行后面的操作。 首先系统会根据 /etc/passwd 来找里面有没有你的用户名，如果有，则把UID和GID取出来，然后对应的shell和家目录也一并设置了。 然后根据UID和 /etc/shadow 文件里面的内容来核对密码。密码核对成功，那么就成功登入shell了。 /etc/passwd 内容大体如下所示： root : x : 0 : 0 : root :/ root :/ bin / bash bin : x : 1 : 1 : bin :/ bin :/ sbin / nologin 其具体含义是： name : x : UID : GID : 说明信息 : home目录 : which shell shell有个特别的值： /sbin/nologin 表示无法登录。 继续接着上面的来，系统可以根据 /etc/passwd 获得的当前登录用户的GID来查看 /etc/group 来获得该用户的所属群组的一些信息。 root : x : 0 : bin : x : 1 : bin , daemon 其一行的含义是： name : x : GID : 群组所含的用户，用逗号隔开 useradd和usermod命令 useradd和usermod这两个命令很多选项是类似的，简单创建一个新用户就可以 useradd new_user_name 还有很多选项设置在useradd的时候可以设置，也可以后面用 usermod 命令来设置。 其中 -d 用于设置新用户的家文件夹。然后还有个 -m 选项只能和 -d 选项一起使用如下所示： usermod user_name -md /newhome/newpath 这是把某个用户的原家目录移到新的位置（请参看 这个网页 ）。 userdel命令 userdel用于删除某个用户的数据，就是 /etc/passwd /etc/shadow 还有群组等相关数据。如果加上 -r 选项，将会把该用户的家目录也一并删除了。 groupadd和groupmod命令 类似的有groupadd和groupmod，还有groupdel命令。 su命令和sudo命令 su命令用于切换身份，最常用的一个选项是 -c ，用于以某个用户的身份执行一次命令。 su root -c \"ls /root\" su命令需要新切换用户的密码，而sudo命令只需要自己的密码即可，不知道root用户的密码也没关系。Linux系统是通过 /etc/sudoers 这个文件来管理sudoer的权限的，用户不是sudoer，其是不能运行sudo命令的。 sudo -u root ls /root 上面的 -u 指定用户，默认是root用户，所以上面的 -u root 一般是不写出来的。 让某个用户是sudoer 首先运行 visudo 命令，然后跳到文件最后，找到下面这一行： ## Allows people in group wheel to run all commands # %wheel ALL=(ALL) ALL 将第二行 # 去掉，然后将目标用户加入到wheel群组中去： usermod -aG wheel user_name 这样目标用户就可以执行sudo命令了。 NOTICE ： 按照上面的做我不知道为什么没有成功，那么直接把你想要的用户名加上去把，大体如下： user_name ALL=(ALL) ALL chown和chgrp命令 前面讲到了Linux系统中所有的文件都有这两个属性：文件的所有者是谁，所有群是谁。如果当前登录用户（或者说进程执行用户）是某个文件的所有者，那么再来看这个文件权限的前三位rwx写的是什么，如果是可读则可读，如果可写那么可写。可见权限管理第一步是先管理好文件的所有者和所有群。 chown user_name filename # 改变文件所有者 chgrp group_name filename # 改变文件所有群 这两个命令都可以接受 -R 选项来递归修改该目录和目录下所谓文件的文件属性。 chmod命令 chmod命令改变文件的权限。用法是： chmod a+x filename chmod 755 filename 该命令可以接受 -R 选项来递归修改该目录和目录下所谓文件的文件属性。 权限有两种表示方法： r ead、 w rite、执行( x )。上面的 a 表示all，除此之外还有， u ser（所有者）， g roup（所有群）和 o thers（其他用户）。 + 或者 - 表示加权限或者减权限（此外还有 = 即设定某个值的意思）。 第二个表示方法是权限rwx分为三位，r对应数字4，w对应数字2，x对应数字1，比如说数字7那么就是rwx，比如说数字6那么就是 rw- ，比如说数字5就是 r-x 。 目录文件权限的含义 普通文件权限的含义是很直接的，而目录文件权限的含义就不是那么直白了。 目录文件可读就是可以用ls命令列出来。 目录文件可写就是可以在该文件夹下面新建文件或子文件夹，删除里面的文件，当然包括更名等等。 目录文件可执行就是可以cd进入该目录。比如其他用户是不能cd进入 /root 文件夹里面去的。不能cd进去，里面的文件也是不能执行的，所以 web 服务器服务某个文件夹时，rx权限是要给的，w权限不能给，然后要小心，母文件夹如果权限没设置好，比如没有x权限，那么也会导致web 服务器出现权限问题：即Permission denied 错误。 硬连接和软连接 硬连接（hard link）前面已经有所谈论了，然后当时提到一个普通文件的Links一般是1，而这里讨论的创建硬连接就是创建一个新的文件名指向同一个inode节点，这就是所谓的硬连接。硬连接不能跨文件系统，不能连接目录。 软连接也叫符号连接，软连接就相当于新建一个快捷方式文件。由于硬连接有其局限，比如不能连接目录，所以实践中常用的是软连接。软连接就是创建了一个链接文件。 ln命令默认创建硬链接，加入 -s 参数是创建符号连接。 ln -s 源文件 目标文件 ​ tar命令 打包解压文件一般使用tar命令，其同时支持gzip和bzip2这两种格式。 首先是常见的打包和解压： tar -cf archive.tar foo bar tar -xf archive.tar 这里 -c 的意思是创建打包文件， -f 选项指定文件名，就是后面跟着的那个 archive.tar 文件名，然后后面跟着你想打包进压缩文件的具体的文件或者文件夹名。 然后解压文件就是带上 -x 选项，你经常看到认为带上一个 -v 选项是linux命令中常见的verbose模式，就是显示更多的打印信息。 然后tar命令还支持其他格式的打包和解压，比如gzip格式，就要带上 -z 选项，文件名一般是 .tar.gz ，然后记住不管是打包还是解压都要带上这个选项。 还有bzip2格式，就要带上 -j 选项，一般文件名是 .tar.bz2 。 --exclude 选项： 在压缩某个文件夹的时候排除掉文件夹里面的某个子文件夹，更确切的表述是以某个 PATTERN 来排除，所以排除某个文件也是可以得。类似的排除选项还有很多，最简单的就是直接把某个子文件夹的名字写上去，排除这个子文件夹。 -C 选项： 这也是很有用的一个选项，比如你想要解压出来的内容具体到某个文件夹下就用这个选项。 --strip-components 选项： 上面的 -C 选项单独使用有一个问题，那就是比如你想解压一个压缩包，其原来的文件夹目录是 what2.2/what ，那么假设你指定要解压到 /root 的test文件夹下面，其在test文件夹下面还会创建 what2.2文件夹然后再是里面的内容。而这个 --strip-components 和 -C 结合有一个很有用的用法，那就是 重命名输出文件夹 ，这个选项的用处就是将输出的文件夹路径名剔除掉几个： 比如下面这个，其原来文件夹路径名expython开头，然后定制输出到test文件夹，然后剔除所有文件文件路径名第一个，也就是expython/，这样就实现了重命名输出文件夹的功能 （参考了 这个网页 ）。 tar -zxvf expython-0.2.2.tar.gz -C ./test --strip-components 1 ps命令 ps是查看系统正在运行的进程的命令，用法就是： ps [option] 有的时候某个进程卡住了，一般运行 ps aux 来查看那个进程的进程号（PID），然后kill（kill命令，杀死某个进程。）就行了。 ssh登录 SSH协议用于计算机之间的加密远程登录。本小节主要参考了 阮一峰的ssh remote login 一文 。 ssh登录在各个操作系统都有一些便捷的工具，推荐读者先了解一下那些工具，下面主要讨论一些基本的ssh命令用法和一些基本的概念。 ssh登录命令格式如下: ssh username@host 其中ssh默认的端口号是22，你可以通过 -p 来指定其他端口号。这里的username是远程计算机的用户名，这里的host是远程计算机的ip地址。 默认情况下ssh登录远程终端是需要输入远程计算机的密码的，你也可以通过一种将自己的公钥上传到远程计算机的方法来实现不用输入密码来登录之。首先你需要生成自己的公钥: ssh-keygen -t rsa 具体生成的公钥文件文件在 $HOME/.ssh 那里（在windows系统下也是当前登录用户的家目录下），其为 id_rsa.pub ，还有一个 id_rsa 是什么私钥文件。然后将公钥文件上传上去即可: ssh-copy-id username@host 如果你懒得记这个什么 ssh-copy-id 这个命令，把 id_rsa.pub 也就是你的公钥文件的内容，复制粘贴到远程计算机的（你想登录的登录用户）登录用户的家目录下的 .ssh （没有新建）文件夹下的 authorized_keys 这个文件后面（没有新建）。 这样你就可以免密码ssh登录了，然后Github走ssh通道的免密码方式，也是类似的要把你的计算机的公钥文件内容设置上去。 ssh连接进行某个长时间的任务 ssh连接远程主机，然后要执行某个长时间的命令任务，如果你有一段时间没去管那个终端窗口了，ssh连接就可能会自动中断，终端之后远程的相关进程也会被kill掉。这是会返回什么 Broken pipe 错误。 一个简单的解决方案是在远程主机上执行某个命令，然后这个命令前面加上 nohup 这个命令，类似下面这种格式: nohup thecommand 更好地解决方案是使用 screen 这个小工具，然后在远程通过screen命令来开启一个执行某个shell命令的全屏窗口（这样其就不会被自动关闭了），哪怕你本地的那个终端窗口关闭了，远程主机相关进程还是会在那里运行的。screen命令常见的用法有: screen命令 screen -S name 创建一个screen进程，并给他取个名字，后面的screen进程可以直接使用这个名字。 screen -ls 看看当前电脑里面都有那些screen进程。 screen -r thename_or_thepid 重连某个screen进程，默认只能连Detached（失连）的进程。 exit 完全退出 Ctrl+a 再按d 断连，该screen进程还在。 screen -wipe 清除某些Dead的screen进程。 screen -D -r 有的时候某个screen进程可能已经断开连接了，但其还是显示的Attached，可以用这样的选项组合来强制某个screen进程失连，然后再重连。 设置后台服务 下面将写一个后台服务脚本，让其成为Linux系统的一个后台服务。本小节参考了 这个网页 。 #!/bin/sh ### BEGIN INIT INFO # Provides: shadowsocks # Required-Start: $remote_fs $syslog # Required-Stop: $remote_fs $syslog # Default-Start: 2 3 4 5 # Default-Stop: 0 1 6 # Short-Description: Example initscript # Description: The shadowsocks service ### END INIT INFO PROG_BIN = ssserver PIDFILE = /var/run/shadowsocks.pid OPTIONS = \"--pid-file $PIDFILE -c /etc/shadowsocks/config.json\" RETVAL = 0 start () { echo -n $ \"Starting $0 : \" $PROG_BIN $OPTIONS -d start RETVAL = $? return $RETVAL } stop () { echo -n $ \"Stopping $0 : \" $PROG_BIN $OPTIONS -d stop RETVAL = $? return $RETVAL } status (){ if [ -e $PIDFILE ] ; then echo $0 is running, pid = ` cat $PIDFILE ` else echo $0 is stopped RETVAL = 1 return $RETVAL fi RETVAL = 0 return $RETVAL } # See how we were called. case \" $1 \" in start ) start ;; stop ) stop ;; status ) status ;; reload | restart ) stop start RETVAL = $? ;; * ) echo $ \"Usage: $0 {start|stop|restart|reload|status}\" RETVAL = 2 esac exit $RETVAL 然后上面的服务脚本要放入 /etc/init.d 里面去。 这个时候就可以通过 service what start+ 来调用服务脚本了。 要让服务脚本开机自启动，推荐用 chkconfig+ 命令来做。 chkconfig --add what 添加服务让chkconfig可以管理它。 chkconfig --del what 删除服务 chkconfig --level <级别> what on 设置服务启动级别 启动级别有： 等级0表示：表示关机 等级1表示：单用户模式 等级2表示：无网络连接的多用户命令行模式 等级3表示：有网络连接的多用户命令行模式 等级4表示：不可用 等级5表示：带图形界面的多用户模式 等级6表示：重新启动 ​ 似乎较常用的级别设置是 35 chkconfig --level 35 what on 网络配置 IP地址 IP地址是由32位二进制组成，表示为十进制最小 0.0.0.0 最大 255.255.255.255 。具体是由NetID和后面的HostID组成，所谓同一网域意思就是NetID相同。 IP地址的分类： 以二進位說明 Network 第一個數字的定義： Class A : 0xxxxxxx.xxxxxxxx.xxxxxxxx.xxxxxxxx ==> NetI_D 的開頭是 0 |--net--|---------host------------| Class B : 10xxxxxx.xxxxxxxx.xxxxxxxx.xxxxxxxx ==> NetI_D 的開頭是 10 |------net-------|------host------| Class C : 110xxxxx.xxxxxxxx.xxxxxxxx.xxxxxxxx ==> NetI_D 的開頭是 110 |-----------net-----------|-host--| Class D : 1110xxxx.xxxxxxxx.xxxxxxxx.xxxxxxxx ==> NetI_D 的開頭是 1110 Class E : 1111xxxx.xxxxxxxx.xxxxxxxx.xxxxxxxx ==> NetI_D 的開頭是 1111 五種分級在十進位的表示： Class A : 0.xx.xx.xx ~ 127.xx.xx.xx Class B : 128.xx.xx.xx ~ 191.xx.xx.xx Class C : 192.xx.xx.xx ~ 223.xx.xx.xx Class D : 224.xx.xx.xx ~ 239.xx.xx.xx Class E : 240.xx.xx.xx ~ 255.xx.xx.xx 一般系统只有ABC三个等级。 IP只有两种IP， 一种是 公网IP ，另一个是 私网IP 。 私网IP在三个等级之下范围如下所示： Class A：10.0.0.0 - 10.255.255.255 Class B：172.16.0.0 - 172.31.255.255 Class C：192.168.0.0 - 192.168.255.255 ​ 子网掩码 子网掩码这个概念确实比较难理解，关键是不要太拘泥于某个特例细节，正如鸟哥最前面说的，子网掩码这个东西就是为了分割网域的，或者换言之一个实际存在的网域定义是由 Network 该网域最小IP Netmask 子网掩码 Broadcast 广播地址 ​ 来描述的，至于最常见的 192.168.0.0/24 这里的24是指子网掩码24个1。然后这种表达定义了完整的网域为： 192.168.0.0 - 192.168.0.255 最核心的知识就是这些，而子网掩码的重要性就在于你给定了某个具体IP，然后根据其子网掩码就可以推断出该网域的Network和Broadcast。至于子网掩码最常见的是24个1或者16个1等，但其他的都是可能的，这个是不定的。 路由 理论上只有位于同一网域内的计算机才可能直接进行文件交互，而不同网域之间的计算机的信息都是通过路由的IP分发来达到信息互通目的的。这一块刚开始会很生疏，建议跟着鸟哥的私房菜的下面这幅图好好把基本的route流程过一下： 首先是每个机器上都有一个所谓的路由表，现在假设PC1要传资料给PC11，首先其会分析自己的路由表，如果发现目标IP和自己的IP在一个网域，那么就直接通过区域网功能传输数据了。 如果发现目标IP和自己的IP不再同一网域，本机会查询自己的路由表，如果没有相关设定，则封包发送给默认的路由器（gateway），然后后面类似，gateway也类似进行了一些转发工作。 route命令 route命令就是查看当前主机的路由表设置的。一般会加个 -n 参数，其会将主机名以IP的形式显示。 查看路由表需要先把第一栏 Destination 目标和 第三栏 Genmask 子网掩码组合成为网域的概念（windows下的route PRINT 是第一栏和第二栏），然后如果网关是 0.0.0.0 则是缺省值的意思，意思也就是直接通过本机的网卡interface发送。 FLAG标志 U 表示该路由可用，G 表示该路由需要网关Gateway， H 表示改行路由对应一个主机而不是一个网域。 路由表里面的规则产生有： 依据网络界面产生出来的IP而存在的路由 手工设定的路由，你所设定的路由必须是你的网卡设备或IP可以broadcast。 动态路由生成 ​ route add -net 192.168.5.0 netmask 255.255.255.0 dev etho03 网卡界面设置 在 /etc/sysconfig/network-scripts/ifcfg-XXX 那里的配置是： DEVICE=網卡的代號 BOOTPROTO=是否使用 dhcpHWADDR=是否加入網卡卡號(MAC) IPADDR=就是IP位址 NETMASK=子網路遮罩啦 ONBOOT=要不要預設啟動此介面 GATEWAY=就是通訊閘啦 DEVICE：這個設定值後面接的裝置代號需要與檔名 (ifcfg-eth0) 那個裝置代號相同才行！否則可能會造成一些裝置名稱找不到的困擾。 BOOTPROTO：啟動該網路介面時，使用何種協定？ 如果是手動給予 IP 的環境，請輸入 static 或 none ，如果是自動取得 IP 的時候， 請輸入 dhcp (不要寫錯字，因為這是最重要的關鍵字！) GATEWAY：代表的是『整個主機系統的 default gateway』， 所以，設定這個項目時，請特別留意！不要有重複設定的情況發生喔！也就是當你有 ifcfg-eth0, ifcfg-eth1.... 等多個檔案，只要在其中一個檔案設定 GATEWAY 即可 在 /etc/resolv.conf 那里设置DNS规则： nameserver DNS的IP 在 /etc/hosts 那里设置： 私有IP 主機名稱 別名 在 /etc/sysconfig/network 那里设置： NETWORKING=要不要有網路 NETWORKING_IPV6=支援IPv6否？ HOSTNAME=你的主機名 在 /etc/services 那里记录記錄架構在 TCP/IP 上面的總總協定，包括 http, ftp, ssh, telnet 等等服務所定義的 port number ，都是這個檔案所規劃出來的。如果你想要自訂一個新的協定與 port 的對應，就得要改這個檔案了； 在 /etc/protocols 那里定义出 IP 封包协定的相关资料，包括 ICMP/TCP/UDP 這方面的封包协议的定义等。 重启网络 /etc/init.d/network restart 這個 script 最重要！因為可以一口氣重新啟動整個網路的參數！ 他會主動的去讀取所有的網路設定檔，所以可以很快的恢復系統預設的參數值。 ifconfig命令 ifconfig命令主要用来查看当前的网络配置信息，这些信息含义如下： - eth0：就是網路卡的代號，也有 lo 這個 loopback ； - HWaddr：就是網路卡的硬體位址，俗稱的 MAC 是也； - inet addr：IPv4 的 IP 位址，後續的 Bcast, Mask 分別代表的是 Broadcast 與 netmask 喔！ - inet6 addr：是 IPv6 的版本的 IP ，我們沒有使用，所以略過； - MTU：就是第二章談到的 [MTU](http://linux.vbird.org/linux_server/0110network_basic.php#tcpip_link_mtu) 啊！ - RX：那一行代表的是網路由啟動到目前為止的封包接收情況， packets 代表封包數、errors 代表封包發生錯誤的數量、 dropped 代表封包由於有問題而遭丟棄的數量等等 - TX：與 RX 相反，為網路由啟動到目前為止的傳送情況； - collisions：代表封包碰撞的情況，如果發生太多次， 表示你的網路狀況不太好； - txqueuelen：代表用來傳輸資料的緩衝區的儲存長度； - RX bytes, TX bytes：總接收、傳送的位元組總量 ifup和ifdown命令 ifup {interface} ifdown {interface} 启用或关闭某个网络界面。这两个命令实际去修改前面提到的 /etc/sysconfig/network-scripts/ 里面对应的网卡界面配置文件。 修改主机名 centos7新加入了一个命令可以很方便的修改主机名，那就是 hostnamectl ，主机名有几个类似： 静态主机名 static 瞬态主机名 transient 灵活主机名 pretty hostnamectl status hostnamectl set-hostname <hostname> 上面的第二个命令将设置所有的主机名，如果要指定具体的一个进行设置则要加上选项： --pretty , --static , 和 --transient 。 df命令 Linux系统中一切都是文件，包括硬盘光盘之类的。其中某个硬盘必须挂载到系统中的某个目录下才可以使用，比如 / 之所以可以使用是自动挂载了的。而如果你的计算机额外加上了某个硬盘，那么可能会没有自动挂载，这样是不可以使用。你需要使用挂载操作。 在执行挂载操作之前，可先用df命令来看一下当前计算机的磁盘挂载情况。 [root@host ~]# df Filesystem 1K-blocks Used Available Use% Mounted on /dev/sda2 9952216 2879484 6547532 31% / tmpfs 258184 0 258184 0% /dev/shm /dev/sda1 289293 141262 132671 52% /boot Filesystem是目标文件系统，然后1K-blocks列出目标文件系统的大小，单位是KB，后面Used是已经使用了多少，Available是还有多少可用的。Use%是使用百分比，Mounted on是目标文件系统的挂载点。 blkid命令 blkid命令可以列出目标文件系统的 UUID 号，还有文件系统类型。这方便后面mount命令调用。 [root@host /]# blkid /dev/sda1 /dev/sda1: UUID=\"ec5c9ab8-b71e-46e6-aac9-5ccc757a02d2\" TYPE=\"ext3\" [root@host /]# blkid /dev/sda1: UUID=\"ec5c9ab8-b71e-46e6-aac9-5ccc757a02d2\" TYPE=\"ext3\" /dev/sda2: LABEL=\"ROOTPART\" UUID=\"971ffe7e-0c71-40c1-97a9-bdb6b167d4b7\" TYPE=\"ext4\" mount命令 mount命令是具体来挂载某个文件系统的，注意挂载点，也就是对应的挂载目录最好是个空文件夹，否则原空文件里面的内容在挂载后将不可访问了。 mount -l # 列出当前计算机的挂载情况 mount -t 文件系统类型 UUID=\"***\" 挂载点 # 具体进行挂载操作 mount -t 文件系统类型 文件系统名 挂载点 开机自动挂载 进行开机自动挂载设置就是修改 /etc/fstab 这个文件。 UUID=971ffe7e-0c71-40c1-97a9-bdb6b167d4b7 / ext4 defaults,discard,noatime 1 1 UUID=ec5c9ab8-b71e-46e6-aac9-5ccc757a02d2 /boot ext3 defaults 1 2 对照前面的例子，我们可以知道 /dev/sda1 是挂载 /boot 的。前面三项意思很清晰，那个UUID号改为目标文件系统名如 /dev/sda1 也是可以的。 下面重点讲下第四列，第五列和第六列： 第四列是设置目标文件系统的挂载参数的，这个mount命令通过 -o 选项也可以指定。 async/sync 推荐设置async auto/noauto 是否主动测试挂载，默认auto。 rw/ro ro就不可以写入了 exec/noexec 是否可执行 user/nouser nouser的意思是一般用户不可以挂载 defaults 同时具有rw，exec，auto，nouser，async等参数，一般设置为defaults即可。 和备份相关，现在第五列一般设置为0。 第六列，是否以fsck检查分区，现在一般设置为0即可。 ​ unmount命令 卸载命令 unmount 目标文件系统名或者挂载点 lsof命令 我最先接触lsof命令是如下需求：查看端口号是不是被谁占用了，如果你希望释放该端口号，则kill掉该进程即可。 lsof -i :1080 lsof 命令倒不是专门为了查看端口号而设置的，其完整名字为list open files，也就是列出系统当前打开的文件的意思。由于在linux系统中， 一切皆文件 ，所以通过查看打开的文件信息能够获得很多有用的当前系统运行情况的信息。 这个命令具体使用方法很多，请读者参看 这个网页 和 这个网页 。 telnet命令 telnet命令来查看某个TCP端口是否可以正常访问。 telnet ip地址 port端口 nmap命令 扫描目标主机的端口号，参考了 这个网页 。 最常见的应用需求就是查看目标主机那些端口号打开了： nmap ip地址 curl命令 最基本的用法就是 curl the_url 你可以看作一个简单版的web browser吧，其内选项很多，从HTTP的method方法选择，到user-agent甚至cookie的设定等等都可以。 查看更多信息读者可以参考 这个网页 。 查看本机的外网ip curl ifconfig.sh 还有 httpbin这个网站也是可以的： curl httpbin.org/ip 离线安装rpm包 推荐安装 yum-utils 这个软件包： yum install yum-utils 然后利用其提供的 yumdownloader 命令来下载对应的rpm包。 下载相关依赖完全实现本地安装 在安装某些rpm包的时候，可能还是需要某些依赖，要某从 fedoraproject 下载对应的epel安装包，或者干脆用yum 安装 epel-realse ，然后你还需要安装上面提及的 yum-utils ，然后运行： yum install --downloadonly --downloaddir=. what.rpm ... 这样将自动下载并补齐这些rpm包还确实的依赖，然后你可以用上面的完全本地安装语句实现完全的面网络安装这些rpm包了。 完全本地安装 完全免网络从本地安装某些rpm包，自动解决其相互依赖问题。 yum localinstall -C --disablerepo=* what.rpm ... centos6和centos7的区别 本小节参考了 这篇文章 和 这篇文章 。 默认文件系统从ext4到xfs。 之前的 /bin /sbin /lib /lib64 全部移到了 /usr 下。（区别较大） 防火墙由iptables变成firwalld。（区别较大） 默认数据库由mysql变成mariadb，这个如果只是单纯的使用的话并不用考虑太多。 python2.6升级到python2.7，这是极好的。 修改主机名推荐用 hostnamectl 。 语言字符集管理配置文件在 /etc/local.conf 修改时区推荐用 timedatectl 命令。 修改地区推荐使用 localectl 命令。 服务管理推荐用 systemctl 命令，不过之前的service命令也还是可以用的。然后之前的chkconfig也推荐用systemctl命令。 systemctl restart/start/stop service_name systemctl enable/disable service_name 强制终止进程，之前是 \\verb+kill -9 PID+ ，现在推荐使用： systemctl kill --singal=9 PID ifconfig命令需要单独安装了（net-tools），现在推荐使用ip命令。 通过U盘安装ubuntu 在安装之前请先把硬盘中的资料做一些调整，空出一个大于20G的硬盘做将来要安装ubuntu根目录的地方。然后还需要一个大约为你内存两倍的硬盘分区等下要作为linux系统的swap交换分区。（更复杂的还可以开个分区给/home等等这里就不讨论了。） 到ubuntu的官网上下载系统的光盘映像。 用ultroiso软件（其他具有类似功能的软件也行）（注意ultroiso最好选择最新的版本，ubuntu10.10之后的一定要用9.3版本之上的）将该光盘映像写入到你的U盘中去。 重启计算机，BIOS稍作改动使计算机变成从U盘启动。 进入安装过程，其他过程都比较直观，就是硬盘分区设置上我们选择高级手动，然后将你分出来的那个20G硬盘作为／的加载点，并设置格式化成ext4日志系统（其他文件系统如ext3等也行）。然后设置交换分区，安装完成。 在ubuntu下通过ISO文件硬盘安装win7系统 用gparter分区 先mount 把文件复制到d盘 执行 sudo update-grub 重启到新加入的那个恢复模式下即可. Virtualbox 网络连接模式 本小节参考了 这个网页 。 NAT模式 网络地址转换，我的理解是Guest机发送的IP包通过主机（在这里类似做了路由器的功能）分发之后再出去的。 网桥模式 这个模式是最好理解的，虚拟机就类似于一台真实机器和Host同等地位的接入网络，如果你的内网不具有分发IP地址功能这种模式可能是不可行的。 Host-only模式 可以理解Guest在Host上模拟了一张网卡，然后所有的虚拟机都是连接在这张网卡上的。所有的虚拟机可以互相访问。虚拟机和主机之间，虚拟机和外网之间都可以通过设置来实现访问。 共享文件夹设置 安装增强功能之后，在virtualbox那里设置好共享文件夹之后，记得进入客机系统，还需要如下加载文件夹： sudo mount -t vboxsf share /home/wanze/share 上面的 share 名字是你在virtualbox那边设置的名字，然后具体挂载的文件夹请在客机系统那里新建一个。 找不到什么的错误 本章节加上了一些内容，都是我遇到了说什么，No Such file等等之类的报错，一般是某些软件包依赖出了问题。下面的讨论有时是Ubuntu系统（debian系），有时是Centos（RPM系），具体看到那个包的名字，我想读者就能获得一些灵感的。 ffi.h 参考了 这个网页 。 报错： fatal error: ffi.h: No such file or directory 解决方案： sudo apt-get install libffi-dev opensslv.h 报错： fatal error: openssl/opensslv.h: 没有那个文件或目录 解决方案： sudo apt install libssl-dev 参考资料 网络，有关别人博客知识的引用我是能在文章中列出来就列出来，只是Linux系统的很多知识很多网页内容都很接近，已经实在不知道原创者是谁了，所以这里一并用网络这个词来表示了。在此谢谢各位博客和其他的网页编写者们了，你们的劳动传播了知识，提升了IT从业者的技能和帮助他们解决了很多问题，从而促进了整个人类的IT技术进步。也许你们没有因此赚到一分钱，和获得半点的名利，但你们做出的贡献是不能为人们遗忘的，都是得到上帝嘉许的。 有名的鸟哥的linux私房菜基础篇和网络篇。请参看 鸟哥的文章官网 。其中基础篇在 /linux_basic ，然后网络篇在 /linux_server 。 unix编程艺术 unix编程艺术 [美] Eric S·Raymond , 姜宏 (译者), 何源 (译者), 蔡晓骏 (译者) ​","tags":"linux","url":"articles/linux-system-basic.html"},{"title":"vi编辑器","text":"推荐先安装完整版的vim，这样一些按键乱码问题会自动解决。然后注意中文输入法状态下可能会造成你切换vi模式的困扰。 进入vi编辑器第一条，记住按 i 进入编辑模式，下面的一些按键都需要按 Esc 退出编辑模式才有效。 常用快捷键 这里按键是针对常见的键盘，MAC下按键对应会有所不同。 Ctrl + f 屏幕向下移动一页 G 移动到最后一行 gg 移动到第一行 推荐就直接用 1G 行跳转操作， 100G 意思是跳转到第100行。 dd 删除当前行 yy 复制当前行 p 粘贴 u 撤销 r redo 块选择 按键 v 进入块选择，然后移动光标进行块选择。 y 复制块 d 删除块 查找 匹配某个单词 /Lao Zi 这样我们就开始搜索精确匹配含有\"Lao Zi\"这个字符串了，如果你按 n 那么就是继续查找\"Lao Zi\"，也就是查找下一个 查找历史 如果输入 / 然后按方向键，就如同我们在终端上直接按方向键可以调用上一个命令一样，现在我们可以调用上一次的查找命令。这个有时很有用的。 反向查找 使用问号 ? 什么就是反向查找。同样 n ，下一个也是反向的，你可以理解n是将上一次的查找命令重做一次。 锚定行的开始 这个是正则表达式的知识了： &#94; 符号表示一行的开始。现在我们执行如下查找命令： /&#94;Th 这算是一个小型的正则表达式匹配模式了，用自然语言来描述就是：匹配以T为行首，后面还跟一个字母h的文本。我们看到一些The和This开头的行都匹配进去了，请读者试试 /&#94;This 来精确匹配以T为行首，后面跟着字母his的文本。 锚定行的结尾 $ 符号表示一行的结尾。 空行的表示就是 /&#94;$ 。这样将会匹配每一条没有任何字符的空行。 替换 全局替换 %s / 源字符串 / 目的字符串 / g 这里 % 表示整个文档， 快速移动 shift+g 快速移动到文档尾部 gg 快速移动到文档头部 vimrc配置 在当前用户主文件夹下的 .vimrc 文件里面可以进行一些vi编辑器的定制配置。 然后在当前vi编辑器下输入 : ，然后写下下面的这些配置，会在当前编辑器上生效。 解决Backspace键乱码和方向键乱码 set nocompatible set backspace=2 自动缩进 set autoindent 显示行号 set nu 开启语法高亮 syntax on ​","tags":"linux","url":"articles/vi-editor.html"},{"title":"如何让自己更有名-seo入门","text":"seo简介 SEO是英文（Search Engine Optimization）的缩写，意思是搜索引擎优化。简单来说就是让自己的网站在搜索引擎中排名更高的方法研究。 外链 也就是别的网站引用本网站能有效提高本网站排名，在各个搜索引擎算法中现在仍然是一个很重要的指标。 meta标记 早期搜索引擎是会爬取meta源标记信息，如下所示： <meta name=\"keywords\" content=\"search engine optimization, SEO, Jennette Banks, 搜索引擎优化, tttwaca\"/> 不过现在搜索引擎的发展方向是忽略这些指定的关键词，而是自己分析得到关键词。 那么无疑现在seo最最重要的就是内容： 积极更新的高质量的内容 积极更新的高质量的内容 无疑将是seo的重中之重。而考虑到搜索引擎以后的发展越来越智能化， 更能满足用户需求 的网页， 用户体验好的网页 无疑将能够获得更高的排名。所以我在这里做个假想，甚至搜索引擎都能够检测目标网页的评论数，点赞数等等，来给目标网页更高的评分，而目前已知的下面这些因素以后在衡量一篇网页或网站价值上会越来越重要： 其他因素 跳出率 只访问了入口网页就离开的访问量占总访问量的百分比 用户访问深度 用户访问你的网站打开的总页面数（跳出率在衡量网站价值上可能会有失偏颇，比如博客。） 按照 2017排名因素这篇文章 的介绍，推荐网站做到 https 安全链接。 然后网站的流量和点击率对排名也是有影响的，但主要是对高查询量的关键词。 查询本站点收录情况 site : you_domain google seo帮助文档学习 具体参看的 google的这个帮助文档 。 title很重要 description 元标记很重要，其不要过短也不要过长和重复多次的说明元标记 html <meta content=\"本指南的适用对象&#10;如果您通过 Google 搜索运营、管理或推广在线内容，或通过在线内容获利，则本指南对您适用。如果您是业务快速发展的商家、拥有 \" name=\"description\"> 说明元标记很重要，因为 Google 可能会将其用作您网页的摘要。 上面是google 帮助文档的原话，说的是可能，但该优化还是优化下。 em 和 strong 标签会影响google分析你的文档，它将其视为重要的文字，所以这些强调文字最好和本文关键词有很好的关联性。 添加结构化的数据标记（TODO） 网站结构和导航条优化 了解读者所想的并提供给他们 链接文字优化，避免点击这里，文章，而应加入描述文字（这个我做的不太好） 优化图片的 alt 信息 推广你的网站（这个google的言下之意应该是网站访问量也是个因素） 使用 google的网站管理员工具 或者 bing的网站管理员工具 。 分析网站上的用户行为 facebook爬虫 当我们在facebook上分享我们的网页的时候，facebook的爬虫就会工作，我们可以根据facebook推荐的 Open Graph Tags来定制具体分享的页面效果： < meta property = \"og:type\" content = \"article\" /> < meta property = \"og:title\" content = \"自訂網頁在Facebook, Google+等社群平台的顯示內容\" /> < meta property = \"og:description\" content = \"透過社群分享中繼標籤，我們可以優化顯示在社群網站上的內容，包含標題、縮圖、說明文字、作者…等，還有其他豐富的訊息。這篇文章就要教你如何使用社群分享中繼標籤來自訂顯示在社群網站上的分享訊息。\" /> < meta property = \"og:image\" content = \"http://blog.shihshih.com/social-meta-tag/demo/images/social-sharing.png\" /> < meta property = \"og:url\" content = \"http://blog.shihshih.com/social-meta-tag/\" /> twitter爬虫 同样twitter在分享的时候也类似的有所谓的twitter card标准： < meta name = \"twitter:card\" content = \"summary\" /> < meta name = \"twitter:site\" content = \"@sullen1209\" /> < meta name = \"twitter:title\" content = \"自訂網頁在Facebook, Google+等社群平台的顯示內容\" /> < meta name = \"twitter:description\" content = \"透過社群分享中繼標籤，我們可以優化顯示在社群網站上的內容，包含標題、縮圖、說明文字、作者…等，還有其他豐富的訊息。這篇文章就要教你如何使用社群分享中繼標籤來自訂顯示在社群網站上的分享訊息。\" /> < meta name = \"twitter:image\" content = \"http://blog.shihshih.com/social-meta-tag/demo/images/social-sharing.png\" /> < meta name = \"twitter:url\" content = \"http://blog.shihshih.com/social-meta-tag/\" /> seo术语 PV page view 页面浏览量 Visit 访问次数 UV 独立访客数 参考资料 seo教程-极客学院 social-meta-tag","tags":"others","url":"articles/seo-tutorial-one.html"},{"title":"mol文件格式","text":"前言 本文主要参考了Molfile的 wiki页面 。 因为openbabel在heroku上不好安装，其有c依赖，然后pubchem数据库那边是可以输出sdf文件的，然后chemdoodle那边是可以接受mol文件格式从而显示分子的3D图形的，一开始我试着用openbabel将smiles输出到mol file： def smi2mol ( smiles ): \"\"\" read smiles string , retrun 3d mol file content. :param smiles: :return: \"\"\" mol = pybel . readstring ( \"smi\" , smiles ) mol . make3D () return mol . write ( \"mol\" ) 这大体是没有问题的。后来看到pubchem restful api输出record全记录时有很详细的原子数目和坐标，所以想可不可以根据这些数据自动输出mol file。 目前最简单的方法是，利用pubchem获得目标分子的sdf文件，sdf文件是前兼容mol 文件的，我在前端网页初步测试结果也是将文件前一行到 M END 之间的内容复制粘贴新建成为一个mol file，经过测试是可行的。所以一个最简单的方法就是写一个简单的函数，将这之间的内容返回出去即可。 更复杂点的方法就是深入理解化学信息学的连接表结构，读取pubchem各个原子坐标和键信息，然后本地绘制连接表。 mol文件具体行信息 第一行说明分子的名字 第二行说明本程序信息 第三行空行或者注释 接下来就是连接表的信息了，到 M END 结束，连接表信息如下： 几个原子 几个键 ........ V2000 标准 第一个原子 x坐标 y坐标 z坐标 元素符号 ... ... 第一个键 连接了 第几个原子 到 第几个原子 类型 ... sdf文件 sdf文件在连接表内容上是一致的，1-3行header说明修改不影响分子的显示。然后sdf文件最后结尾会加上： $$$$ mol file没有这个。之上会会继续写分子的其他属性信息： > <PUBCHEM_IUPAC_OPENEYE_NAME> 1-bromobutane > <PUBCHEM_IUPAC_CAS_NAME> 1-bromobutane > <PUBCHEM_IUPAC_NAME> 1-bromobutane > <PUBCHEM_IUPAC_SYSTEMATIC_NAME> 1-bromanylbutane > <PUBCHEM_IUPAC_TRADITIONAL_NAME> 1-bromobutane > <PUBCHEM_IUPAC_INCHI> InChI=1S/C4H9Br/c1-2-3-4-5/h2-4H2,1H3 > <PUBCHEM_IUPAC_INCHIKEY> MPPPKRYCTPRNTB-UHFFFAOYSA-N > <PUBCHEM_XLOGP3> 2.8 > <PUBCHEM_EXACT_MASS> 135.989 > <PUBCHEM_MOLECULAR_FORMULA> C4H9Br > <PUBCHEM_MOLECULAR_WEIGHT> 137.02 > <PUBCHEM_OPENEYE_CAN_SMILES> CCCCBr 看的出来这种结构是很方便程序分析的，比pubchem返回的json格式还好分析一点。后面我应该更多的对接和分析sdf文件。","tags":"chemistry","url":"articles/mol-file.html"},{"title":"化学信息学第二谈","text":"表示分子 价键模型是现代化学的基石，也是现代化学信息学的基石。当化学家想要研究一个问题的时候的，他首先是用图形来表示出一个个节点，也就是原子，然后一个个节点之间连成边，也就是化学键。 就价键理论和分子轨道理论区别它们有意义其实只在量子化学的计算层面上，老实说以前我学习的时候，就是简单的将化学键理解为电子的运动轨迹，至于具体这个电子是两个原子共享的还是分子层面共享的其实当时我的理解，就离子键和共价键还说，只是一种程度的问题。大体是 离子键 -> 共价键单键 -> 苯的化学键 -> 共价键双键。不过不是从事量子化学计算，就作为应用的理解化学世界来说，确实价键理论够用了。 连接表格 早期人们研究化学信息学来表示一个分子用的是连接表（connection table），就是列出原子，还有原子们之间的连接键（描述了谁和谁连接起来）。 SMARTS (SMiles ARbitrary Target Specification). 子结构搜索语言，比如说 [C,N] 将会找一个原子或者是碳原子或者是氮原子 子结构搜索和索引 索引indexing是预处理某些问题来加速搜索过程。 化学信息学对于分子结构的索引过程就是将目标分子降解（decompose）成为一些小部分，然后索引它们。 子结构搜索在数学上是图同构问题（graph isomorphism），子图同构是NPC问题，图同构不是P问题也不是NPC问题是NP问题（参考wikipedia）。简单来说就是P问题是多项式复杂度的问题，计算机还是应付得来的；而NP问题就是非多项式复杂度的问题，计算机很难应付过来。 在化学信息学上，子结构搜索的复杂度随着原子和化学键数目的增长是指数级别的增长的。目前已经在数学上证明子结构搜索是一个NPC问题，所以就没必要去试着找一个多项式复杂度的算法了。好消息是大多数分子有很低的连接性（low connectivity），意思是大多数原子有的化学键少于四个，不像数学家们研究的那些复杂的奇怪的图形。在实践中，大多数子结构搜索的计算复杂度能够在 \\(N&#94;2\\) 到 \\(N&#94;3\\) 之间完成。但是即使是这样，子结构搜索对于计算机来说都是一个昂贵的计算任务。 所以索引indexing对于化学信息学系统来说非常的重要，现代计算机能够在一秒钟内检索几千个分子，百万的分子检索也不成为问题，indexing起了关键性的作用。 分子相似度 子结构搜索很有用，但是有的时候会把分子之间很重要的信息给忽略了，比如对于某个子结构，只有某个地方一个单键一个双键的区别，但是子结构搜索给忽略了。这是我们需要分子相似度搜索来获得更多有用的信息。 用来检测分子相似度的手段有： 2D拓扑计算，2D拓扑计算只考虑分子的原子和化学键，但是不考虑他们的形状。 3Dconfiguration 医药分子的3D形状对医药价值很重要，3D构造分析，电子表面分析 物理性质 clustering 化学注册系统 化学注册系统（Chemical Registration System）和化学信息学是两兄弟。化学注册系统主要要解决以下问题： 单个分子只注册一次 结构规范化 结构绘制 维护各个相关分子之间的关系。 注册混合物，配方的描述， 注册未知的分子 和公司的角色、安全性、责任、工作流程等结合在一起 更新、修正、控制化合物的繁衍增进（比如混合物的不同混合比例） 假设你有五个烧杯： 第一个烧杯仔细的分析了，发现它们是单一的立体异构体 第二个烧杯仔细的分析了，发现它们是一个立体异构体的外消旋混合物 第三个烧杯未知，可能是纯物质，也可能是单一的立体异构体或者外消旋混合物。 第四个烧杯是将第二个烧杯进行了色谱分离，它是单一立体异构的，但是你不知道是那个立体异构。 第五个烧杯是制作第四个烧杯过程的另外一部分，它也是单一的立体异构纯，但是你不知道它是那个立体异构，你只知道和第四个烧杯的立体构造相反。 化学注册系统应该将这些情况都记录分清楚，而这已超出了化学信息学的研究领域。化学信息学只是关心结构，而化学注册系统则是要记录所谓化学家研究的知道的事实和不知道的事实。 参考资料 openbabel提供的化学信息学 介绍一章节 。 if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js','mhchem.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"chemistry","url":"articles/cheminformatics-talk-two.html"},{"title":"postgresql数据库","text":"安装和配置 在ubuntu下可以这样简单安装之： sudo apt-get install postgresql centos下如下安装： sudo yum install postgresql-server postgresql-contrib centos下继续运行以下命令： sudo postgresql-setup initdb 这样安装之后，你需要牢记一点的是，新安装的PostgreSQL数据库还只有 postgres 这个用户有新建role（或说用户）和新建数据库的权限。你需要通过 postgres 这个用户来执行 createuser 或 createdb 命令。这里我们先不急着学习SQL语句，因为postgresql里面关于用户群组权限的设置稍微有点复杂，而要使用postgresql，这一块是必须有个基本的了解的。 用户群组权限管理 postgresql处理我们通常所谓的登录用户或者其他用户概念的术语是Rules，后面都称之为用户（rules），可以理解为为这个用户确立的一系列访问修改数据库的规则。然后rules是可以包含其他rules的，这个包含其他rules的rules我们通常称之为群组（group rules），然后群组也可以包含群组，但一般都推荐简单分为用户（rules）和群组用户（group rules）这两类。然后用户如果有登录权限的话则可以称之为登录用户（login rules），群组用户也可以赋予登录权限，但出于简单的考虑没谁这么做。所以现在rules简单的划分就分为这三类: 一般用户，这里主要指没有登录权限的一般用户。 登录用户，或叫做一般登录用户，其属于一般用户，但有登录权限。 群组用户，包含一般用户的rules。 此外postgresql还提供 superuser 超级用户这一类型，其默认不能登录，但对于数据库几乎拥有所有的权限——比如创建数据库，创建用户，对于数据库的查增删改等。实际上superuser也可以加上 login 属性，但非常不推荐这么做，最好是不使用超级用户，而是对于具体的用户具体的数据库权限进行分配。 默认创建的postgres这个用户是可以连接的，而且我们看到其至少对postgres这个数据库具有所有权限，但是我还不太确定其是不是superuser，因为其可能对其他数据库并没有权限，这个后面再谈。 修改postgres的密码 sudo -u postgres psql postgres postgres=# \\password postgres Enter new password: Enter it again: 这里需要强调一点的是这里通过psql来进行连接（postgres）然后输入 \\password 修改postgres的密码是具体通过 TCP/IP 方式连接postgresql数据库的密码，不是系统passwd管理的那个密码。 postgres这个用户 postgres这个用户的一些信息如下所示: postgres : x : 121 : 131 : PostgreSQL administrator ,,,:/ var /lib/postgresql:/bin/ bash 然后还有新建的postgres这个群组: postgres : x : 131 : 这里的121是uid，131是gid，然后后面 /var/lib/postgresql 这个文件夹就是postgres该用户的主文件夹，你的关于postgresql的一些配置和数据都放在这里面的。你可能会遇到保存 .psql_history 这个文件的权限问题，参看 这个网页 ，这个时候需要确认该文件夹的所有用户和所有群组都是postgres。 查看当前有多少用户 按照 这篇网页 的介绍， pg_roles 是一个view视图，其只是一个对 pg_authid 的简单可读的视图封装，如下面所示，两者目前来说没有差异，然后我们看到postgres其是为superuser，也是login user。 select rolname,rolsuper,rolcreaterole,rolcreatedb,rolcanlogin from pg_roles; rolname | rolsuper | rolcreaterole | rolcreatedb | rolcanlogin ----------+----------+---------------+-------------+------------- postgres | t | t | t | t wanze | t | t | t | t select rolname,rolsuper,rolcreaterole,rolcreatedb,rolcanlogin from pg_authid; rolname | rolsuper | rolcreaterole | rolcreatedb | rolcanlogin ----------+----------+---------------+-------------+------------- postgres | t | t | t | t wanze | t | t | t | t 新建用户 新建一个用户: create role the_name; 但最起码要有登录login权限吧: create role the_name login; 在使用postgresql时，如果某个用户不存在，那么PostgreSQL将会报错: createdb : could not connect to database template1 : FATAL : role \"wanze\" does not exist 删除用户 drop role the_name; 或者该用户名不存在也不会报错的写法: drop role if exists the_name; 改变用户的权限 如下所示就改变一个用户的权限了。 alter role the_name createdb; 参照手册，后面的关键词有: SUPERUSER | NOSUPERUSER CREATEDB | NOCREATEDB CREATEROLE | NOCREATEROLE CREATEUSER | NOCREATEUSER INHERIT | NOINHERIT LOGIN | NOLOGIN REPLICATION | NOREPLICATION 改变用户密码 在新建用户的时候，我们可以如下: create role the_name password \"the_password\"; 后面也可以通过 alter role 来: alter role the_name password \"the_password\"; 新建一个群组 CREATE ROLE royalty INHERIT; 给群组用户增加登录用户 GRANT royalty TO leo; GRANT royalty TO regina; pg_hba.conf 很多连接问题就是因为这个文件没有配置好，下面详细研究这个文件之。 # # local DATABASE USER METHOD [OPTIONS] # host DATABASE USER ADDRESS METHOD [OPTIONS] # hostssl DATABASE USER ADDRESS METHOD [OPTIONS] # hostnossl DATABASE USER ADDRESS METHOD [OPTIONS] local 是指本地连接 host 是指plain或者ssl加密的TCP套接字连接（一般指http和https） hostssl 是指ssl加密的TCP套接字连接 hostnossl 是指plain 简单的TCP套接字连接 DATABASE 设置要连接的数据库，常见的all ADDRESS 有 127.0.0.1/32 也就是本地连接ipv4，或者 0.0.0.0/0 指所有的ipv4外网。这是一种网域段表示法。 METHOD 有trust，reject，md5（加密的密钥），password（明文密钥） 让人困惑的peer方法查阅文档解释如下： The peer authentication method works by obtaining the client's operating system user name from the kernel and using it as the allowed database user name (with optional user name mapping). This method is only supported on local connections. peer认证方法获取客服端操作系统的用户名，然后将其作为允许数据库的用户名。这个方法只适用于local连接。 ident方法如果是本地连接的话就会使用peer方法，官方文档在解释上字面也很相同，区别就在 an ident server ,一个是from kernel， 一个是from ident server， 这个暂时不懂？ psql 这里参考了 这个网页 。 \\l 或 \\list : 列出所有的数据库 \\du : 列出所有的用户 \\dt * : 列出当前数据库所有的表格 \\c 或者 \\connect : 切换数据库 数据库操作基础 创建数据库 CREATE DATABASE mydb; 有 CREATEDB 权限的用户可以新建数据库。 然后创建一个数据库，并指定这个数据库的owner。 CREATE DATABASE mydb WITH owner = mydb_admin; 然后以mydb_admin登录开始进行数据库的其他操作。 备份和还原 两个backup方法 pg_dump 和 pg_dumpall 用pg_restore 来还原， 改变某个数据库的所有者 首先你需要以postgres的身份连接postgres数据库，因为你要进行更改某个数据库的所有者，就必须是目前该数据库的所有者。 wanze@wanze-ubuntu:~$ sudo -u postgres psql postgres psql (9.3.8) Type \"help\" for help. postgres=# ALTER DATABASE mydb OWNER TO learner; ALTER DATABASE postgres=# \\q 这里ALTER DATABASE语句里面 mydb 是具体你要更改的数据库名字，然后后面的learner是具体更改为的所有者名字。 类似上面谈及的，还有 dropdb 用于删除数据库， dropuser 用于删除用户。 CREATE TABLE语句我们都熟悉了，不过具体到数据类型上，还需要详细讨论一番。 postgresql字段数据类型 int , smallint , real , double precision , char( N ) , varchar( N ) , date , time , timestamp , and interval , 而postgresql支持的数据类型就多了，有：int，smallint，real，boolean，date，time，integer，text，char(N)，varchar(N) 甚至还有json。这个可以后面慢慢了解，更多细节请具体参看官方文档第八章 Data Types，这是 版本9.3的网页链接 。 其中对于整数简单的就用integer，字符串简单的就用text，然后小数简单的就用real，布尔值就用boolean，此外还有一些特殊用途的数据类型值得引起我们的注意，如uuid，json，arrays，money，bytea，还有日期和时间的date，time；几何类型支持的point，line等等 附录 配置文件在那里 sudo -u postgres psql postgres psql> SELECT name,setting FROM pg_settings WHERE category = 'File Locations'; name | setting -------------------+------------------------------------------ config_file | /etc/postgresql/9.3/main/postgresql.conf data_directory | /var/lib/postgresql/9.3/main external_pid_file | /var/run/postgresql/9.3-main.pid hba_file | /etc/postgresql/9.3/main/pg_hba.conf ident_file | /etc/postgresql/9.3/main/pg_ident.conf (5 rows) 重启postgresql服务 在linux下可以运行如下命令行来达到目的: sudo service postgresql restart 或者 sudo service postgresql reload 参考资料 PostgreSQL官方参考文档 PostgreSQL Up and Running, 2nd Edition","tags":"数据库","url":"articles/postgresql-database.html"},{"title":"heroku on fire","text":"在heroku上部署项目其实很简单，本文将简单的将heroku的容器作用原理和简单的git推送和相应的一些额外的配置说明一下，整个过程不通过 heroku 命令行工具，或者网页操作，或者修改文件之。 本文主要面向python的，首先推荐读者参考一下 heroku 官方在github 上的项目，比如说 这个项目 。其是基于最近的django1.11的，看着这个模板理解一些东西，然后在heroku上设置好自动同github同步就可以了。 runtime.txt 这个文件用来执行python的版本，里面简单写上即可： python-3.6.3 这样，远程heroku会帮你确定python运行环境为python-3.6.3。 requirements.txt 熟悉python开发的人都知道这个文件是什么意思，只是在heroku这里，是必须填写好的一个文件了，其和heroku远程调配好pip的环境有关。 Procfile 这个文件包含了一些进程类型声明，每个进程类（process type）由一行组成是： <process type>: <command> 比如写着 web 的意思就是启动一个web server。 还有就是具体执行何命令来启动这个web server了。我们看到gunicron的官方文档写着对django项目如下支持语法： $ gunicorn myproject.wsgi 或者明确指定django的settings位置 $ gunicorn --env DJANGO_SETTINGS_MODULE = myproject.settings myproject.wsgi 所以我们在教程中看到如下一行： web : gunicorn myproject . wsgi -- log - file - 上面的 --log-file - 在gunicron那边是把日志输出到默认stdout的意思。 通过git推送你的项目 你可以设置github自动同步，这样直接推送到你的github仓库即可。这里讲的是heroku默认的git url。 git remote add heroku https://git.heroku.com/ {{ heroku_project_name }} .git 重要提示：添加的这个heroku的remote url直接和后面的heroku 命令行工具相关。 （参阅了 这个网页 ） 那个heroku命令行工具因为在windows下环境有点不好配，所以很多功能都略过了，不过 heroku run 功能是无法回避的，有些工作比如django的数据库初始化要手工输入命令完成： heroku run python manage.py makemigrations heroku run python manage.py migrate django的静态文件 我在heroku的处理日志中看到这样一行： python manage.py collectstatic --noinput 说明其自动处理好了django的静态文件问题。 django的数据库 在官网上管理好项目addon，然后看到 settings 有个 Config Vars 字段，里面定义了一个 DATABASE_URL 值。 然后 dj-database-url 这个pypi包会自动刷这个 DATABASE_URL 成为django的settings配置，如下配置： # Update database configuration with $DATABASE_URL. import dj_database_url db_from_env = dj_database_url . config ( conn_max_age = 500 ) DATABASES [ 'default' ] . update ( db_from_env ) heroku命令行工具 heroku create 大体类似于你在官网上操作新建一个app，只是名字是随机的。 如何加入数据库 heroku pg:psql --app cheminfo heroku addons:add heroku-postgresql:dev --app cheminfo","tags":"others","url":"articles/heroku-on-fire.html"},{"title":"mindmaptree","text":"如下思维导图，我们如何设计一种数据格式来便捷的进行后续csv或者json操作？ 然后其对应的csv格式如下： 奴隶社会,非洲,古埃及文明,金字塔 ,亚洲,两河流域文明,汉谟拉比法典 ,,古印度,种姓制度 ,,,佛教的创立 ,欧洲,希腊,希腊城邦 ,,,雅典民主 ,,罗马,城邦 ,,,帝国的征服与扩展 ,,希腊罗马古典文化,建筑艺术 ,,,公历 这个问题实际上和前面谈论的二叉搜索树有点类似，只是那个问题的变种罢了，同样在这种树形结构下不可避免要用到递归思维。下面是一个很粗糙版本的实现，其中最核心的一个点就是我这个Node只做好自己的分内事情就行了，然后放到整体的支持功能递归展开即可。 基本类的设计 import logging logger = logging . getLogger ( __name__ ) logging . basicConfig ( level = logging . DEBUG ) class MindMapTree ( object ): def __init__ ( self , data = None , parent = None ): self . data = data self . parent = parent self . children = [] def introspection ( self ): \"\"\" 核心内省函数，返回我和我的所有children。 \"\"\" stack = [] tree = self if tree . data is not None : logger . debug ( 'intorspection add node:{0}' . format ( tree )) stack . append ( tree ) for child in tree : stack += child . introspection () return stack def __str__ ( self ): if self . children : return '<MindMapTree:{0}> has children: {1}' . format ( self . data , self . children ) else : return '<MindMapTree:{0}>' . format ( self . data ) def __repr__ ( self ): if self . children : return '<MindMapTree:{0}> has children: {1}' . format ( self . data , self . children ) else : return '<MindMapTree:{0}>' . format ( self . data ) def append ( self , child_data ): child = MindMapTree ( child_data , parent = self ) self . children . append ( child ) def remove ( self , child_data ): child = MindMapTree ( child_data , parent = self ) self . children . remove ( child ) def insert ( self , parent_data , child_data ): for target in self . introspection (): if target . data == parent_data : target . append ( child_data ) def find ( self , key ): for target in self . introspection (): if target . data == key : return target raise KeyError def set_nodedata ( self , data ): self . data = data def __iter__ ( self ): if self . children is not None : for child in self . children : yield child def to_json ( self ): return { self . data : [ i . to_json () for i in self . children ]} def get_path ( self ): res = [] while True : res . append ( self . data ) if self . parent is None : break else : self = self . parent return res [:: - 1 ] if __name__ == \"__main__\" : tree = MindMapTree ( \"奴隶社会\" ) tree . append ( \"非洲\" ) tree . append ( \"亚洲\" ) tree . insert ( \"非洲\" , \"古埃及文明\" ) tree . insert ( \"古埃及文明\" , \"金字塔\" ) tree . insert ( \"亚洲\" , \"两河流域文明\" ) tree . insert ( \"两河流域文明\" , \"汉谟拉比法典\" ) tree . insert ( \"亚洲\" , \"古印度\" ) print ( tree ) print ( '######################' ) stack = tree . introspection () print ( stack ) yazhou = tree . find ( \"亚洲\" ) print ( yazhou . introspection ()) print ( yazhou . parent ) print ( yazhou . children ) print ( tree . to_json ()) print ( tree . get_path ()) csv的读写 import csv from collections import defaultdict class MindMapCSV ( csv . Dialect ): delimiter = ',' # 分隔符 quotechar = '\"' # quote符号 doublequote = True # 双引号在字符中的情况 skipinitialspace = True # 分隔符后空白忽略 lineterminator = ' \\n ' # 换行符 quoting = csv . QUOTE_MINIMAL # 最小quote csv . register_dialect ( \"MindMapCSV\" , MindMapCSV ) import logging logger = logging . getLogger ( __name__ ) logging . basicConfig ( level = logging . INFO ) from mindmaptree import MindMapTree class MindMapReader (): def __init__ ( self , f , dialect = 'MindMapCSV' ): self . data = MindMapTree () last_stack = {} first = True # 根元素，目前还只处理一个根元素的情况 for line in csv . reader ( f , dialect ): logger . debug ( 'got original line data: {0}' . format ( line )) for index , item in enumerate ( line ): if item : if first : last_stack [ index ] = item self . data . set_nodedata ( item ) first = False else : last = last_stack [ index - 1 ] last_stack [ index ] = item self . data . insert ( last , item ) else : # \"\" continue logger . debug ( 'init data: {0}' . format ( self . data . introspection ())) def getdata ( self ): return self . data class MindMapWriter (): def __init__ ( self , f , dialect = 'MindMapCSV' ): self . data = MindMapTree () self . writer = csv . writer ( f , dialect ) def setdata ( self , data ): self . data = data 其他函数接口 def read_csv ( f ): with open ( f , newline = '' , encoding = 'utf8' ) as f : reader = MindMapReader ( f ) data = reader . getdata () return data def csv2json ( f ): with open ( f , newline = '' , encoding = 'utf8' ) as f : reader = MindMapReader ( f ) data = reader . getdata () res = data . to_json () import json res = json . dumps ( res , sort_keys = True , indent = 2 , ensure_ascii = False ) return res def find ( mindmaptree , key ): try : target = mindmaptree . find ( key ) return '.' . join ( target . get_path ()) except KeyError : return '找不到关键字：{0}' . format ( key ) if __name__ == '__main__' : data = read_csv ( 'history.csv' ) print ( data ) json_data = csv2json ( 'history.csv' ) print ( json_data ) find_res = find ( data , \"汉谟拉比法典\" ) print ( find_res ) find_res = find ( data , \"美洲\" ) print ( find_res )","tags":"算法","url":"articles/mindmaptree.html"},{"title":"二分查找","text":"二分查找 二分查找以前也接触过吧，当时不怎么重视，认为就是一种快速查找方法了，参看 这个网页 ，其认为python的 index 方法并不是使用的二分查找，所以对大规模查询会很吃力。考虑到python一般的sequence对象都没有预排序，所以这种说法可信度还是很高的。然后利用python的 bisect 模块，我们可以构建出一种预排序的支持更快查询的接口，其内部就是使用的二分查找。 关于二分查找的原理我就不啰嗦了，这里我想说的是，最近在看MIT的那个视频，其中第三课讲到了利用二分查找的思想来求解平方根的问题，这个对我启发很大。尤其是那一句: 任何计算机问题如果找不到好的方法，实际上都可以穷举而得，而穷举的过程，我们不需要一个个都试一下，我们只需要将这些可能的结果集排序之后，进行二分查找来快速缩小可能的结果集，那么我们就可以逐步更快地趋近理想结果了。 这使得我认识到，二分查找思想的应用可不限于查找，而是更普遍，可以看作一种有关计算机的最核心的最底层的那种计算思想的东西。所以本小节关于二分查找主要分为两个内容，一是关于查找部分，主要集中讨论了python bisect模块；一是以一种更加抽象的思维来描述二分查找思想。 抽象的二分查找思想讨论 现在我们将可能的结果集认为是某个函数f(x)的输入参数，然后我们有目标参数target，令f(x)=target的时候我们说我们就找到了目标结果x，或者说目标x符合函数f(x)=target这个关系。然后假设我们的考察对象f(x)在目标结果集内存在简单的增减关系，即目标集合可以由此排序，那么我们就可以开展二分查找来找到目标结果x了。 以相等查找为例，f(x)函数即f(x)=x，也就是输入什么同样输出的是什么。如果x=target，则我们说目标x复合条件f(x)=target，则该x就是我们要找的目标结果x。 如果我们定义 f(x)=x*x ，则意思是我们要找某个x符合条件 x*x=target ，这就是求平方根的过程。 程序主体 binary_search 函数大体是这样的，主要参考了 algorithms模块 binary_search.py 文件，然后稍作修改。 def binary_search ( f , seq , target ): low = 0 high = len ( seq ) - 1 while high >= low : mid = low + ( high - low ) // 2 print ( low , high , mid ) if f ( seq [ mid ]) < target : ##higher area low = mid + 1 elif f ( seq [ mid ]) > target : ##lower area high = mid - 1 else : print ( 'exactly' ) return seq [ mid ] else : print ( 'nearly' ) return seq [ mid ] 首先我们来看最简单的查找匹配操作，即: def f ( x ): return x 然后我们有: seq = list('abcdefg') res = binary_search(f,seq,'e') print(res) 0 6 3 4 6 5 4 4 4 exactly e >>> 然后我们要求平方根，也就是某个 x*x=target 的过程，把之前定义的函数简单改一下即可: def f ( x ): return x * x 然后我们利用numpy的 arange 函数来生成一个可能结果集。 >>> import numpy as np >>> np . arange ( 0 , 10 , 0.1 ) array ([ 0. , 0.1 , 0.2 , 0.3 , 0.4 , 0.5 , 0.6 , 0.7 , 0.8 , 0.9 , 1. , 1.1 , 1.2 , 1.3 , 1.4 , 1.5 , 1.6 , 1.7 , 1.8 , 1.9 , 2. , 2.1 , 2.2 , 2.3 , 2.4 , 2.5 , 2.6 , 2.7 , 2.8 , 2.9 , 3. , 3.1 , 3.2 , 3.3 , 3.4 , 3.5 , 3.6 , 3.7 , 3.8 , 3.9 , 4. , 4.1 , 4.2 , 4.3 , 4.4 , 4.5 , 4.6 , 4.7 , 4.8 , 4.9 , 5. , 5.1 , 5.2 , 5.3 , 5.4 , 5.5 , 5.6 , 5.7 , 5.8 , 5.9 , 6. , 6.1 , 6.2 , 6.3 , 6.4 , 6.5 , 6.6 , 6.7 , 6.8 , 6.9 , 7. , 7.1 , 7.2 , 7.3 , 7.4 , 7.5 , 7.6 , 7.7 , 7.8 , 7.9 , 8. , 8.1 , 8.2 , 8.3 , 8.4 , 8.5 , 8.6 , 8.7 , 8.8 , 8.9 , 9. , 9.1 , 9.2 , 9.3 , 9.4 , 9.5 , 9.6 , 9.7 , 9.8 , 9.9 ]) >>> 然后我们有: import numpy as np seq = np . arange ( 0 , 10 , 0.000001 ) res = binary_search ( f , seq , 2 ) print ( res ) nearly 1.414214 在这里讲个题外话，提到可能结果集的时候，我就想到将多个函数参数作为(a,b,c)这种形式，可是这种多元函数问题，怎么排序，怎么比较大小，怎么确定增减性？所以只好回滚到最原始的穷举过程，这里讲的意思是计算思想很核心的一个思想就是穷举思想，然后二分查找方法是在某些条件符合的情况下的加速穷举过程。 比如说孙子算经里面的: 今有雉兔同笼，上有三十五头，下有九十四足，问雉兔各几何？ 穷举的基本函数是: def iter_search ( f , seq , target ): for item in seq : if f ( item ) == target : yield item 很简单的一个函数，很简单的逻辑，但实际上这种先迭代某个对象，然后找到某个对象复合某个条件，则返回某个对象的过程在程序模式里面是非常常见的。 然后我们根据笛卡尔积生成可能结果集: >>> from itertools import product >>> seq = list ( product ( range ( 35 ), range ( 35 ))) >>> seq [( 0 , 0 ), ( 0 , 1 ), ( 0 , 2 ), ( 0 , 3 ), ( 0 , 4 ), ( 0 , 5 ), .............. ............. 然后我们可以很直观的将问题化为两个满足条件来对可能结果集进行过滤操作: def f(d): x = d[0] y = d[1] head = x + y return head def g(d): x = d[0] y = d[1] foot = 2*x + 4*y return foot 然后我们有: res = list(product(range(35),range(35))) res = iter_search(f,res,35) res = iter_search(g,res,94) print(list(res)) [(23, 12)] 很简单的一些函数，但是整个过程是我很感兴趣的一种风格。 bisect模块 bisect模块提供了二分查找的支持，比如bisect_left函数： def bisect_left ( a , x , lo = 0 , hi = None ): \"\"\"Return the index where to insert item x in list a, assuming a is sorted. The return value i is such that all e in a[:i] have e < x, and all e in a[i:] have e >= x. So if x already appears in the list, a.insert(x) will insert just before the leftmost x already there. Optional args lo (default 0) and hi (default len(a)) bound the slice of a to be searched. \"\"\" if lo < 0 : raise ValueError ( 'lo must be non-negative' ) if hi is None : hi = len ( a ) while lo < hi : mid = ( lo + hi ) // 2 if a [ mid ] < x : lo = mid + 1 else : hi = mid return lo 其底层有c加速，然后其返回的是一个索引值，根据这个索引值，如果你执行 a.insert(x) ，那么将把目标值插入到目标位置，如果x已经在a中存在，则插入的是最左边的位置。于是我们有： def binary_search ( seq , target ): \"\"\" seq已排序，二分查找 返回的是已经找到的索引值或者没有找到返回-1 :param seq: :param target: :return: \"\"\" pos = bisect_left ( seq , target ) return ( pos if ( pos != len ( seq ) and seq [ pos ] == target ) else - 1 ) 仔细体会python官方的源码，他写的版本比上面的版本要稍微好一点，代码更精炼，上面的版本可以根据它来改造，最后效果都差不多的。","tags":"算法","url":"articles/binary-search.html"},{"title":"二叉搜索树","text":"TODO 之前以为python的dict是基于红黑树或者二叉搜索树实现的，理解错了，那部分讨论删除了，本文需要进一步整理。 二叉搜索树 本文很大程度上参考了 algorithms 项目，在此谢谢作者们了。 二叉搜索树（Binary Search Tree）大概如下图所示这么个东西: 其每一个节点都至多有两个子节点，然后所有的节点都满足以下三个条件 左节点的值小于它的父节点 右节点的值大于它的父节点 所有节点的值均不相等 二叉搜索树的插入复杂度是 O(log n) ，查找复杂度最好情况 O(log n) ，最坏情况 O(n) 。 比如上面图片的那个二叉树，假设我们要插入19，那么首先和8比较，大，则右，再和10比较，大则右，再和14比较，大则右，然后空就可以插入了。 然后假设我们要查找19，那么过程大体也是类似的和8比较，大则右，再和10比较，大则右，再和14比较，大则右，然后相等则找到。我们看到我们的查找过程，涉及到一些比较判断操作等，假设元素两边分的话，那么树中一半的元素都跳过去了。所以利用这个数据结构加速查找和存储数据好处是显而易见的。 二叉搜索树的python实现 关于python的二叉树实现主要参考了 参考资料2 ，其中有个伙计的评论说为什么不合并为一个类，这个提议实际上非常的好。这样的话具体的data，也就是节点里面存储的数据，是什么都是可以的，这个根据实际需要来设计，然后我们在下面比较data的大小采用 hash(object) 也就是调用 __hash__ 方法，同时判断时候相等采用 == ，也就是调用 __eq__ 方法。 基本结构和插入查找操作 值得一提的是key的比较大小判断采用的是 hash(data) 这种形式，就作为键的唯一id的一种方法，这是没有问题的。然后data不可以为sequence。然后需要强调的是这里的比较大小，并不具有某种实际意义。比如: >>> hash(11)> hash(\"22\") True 一般具有实际含义的某种比较大小，我们必须确保比较对象是属于同一个类，或者更抽象的讨论，属于同一个概念或同一个聚合类等。 ### ref http://www.laurentluce.com/posts/binary-search-tree-library-in-python/ class BSTree ( object ): '''use hash(data) ,but notice the data can not be sequence''' def __init__ ( self , data = None , parent = None ): self . left = None self . right = None self . data = data self . parent = parent def __repr__ ( self ): return '<BSTree {}>' . format ( self . data ) def insert ( self , data ): '''insert data''' if hash ( data ) < hash ( self . data ): if self . left is None : self . left = BSTree ( data , parent = self ) else : self . left . insert ( data ) elif hash ( data ) > hash ( self . data ): if self . right is None : self . right = BSTree ( data , parent = self ) else : self . right . insert ( data ) else : self . data = data def find ( self , data ): if hash ( data ) < hash ( self . data ): if self . left is None : raise KeyError else : return self . left . find ( data ) elif hash ( data ) > hash ( self . data ): if self . right is None : raise KeyError else : return self . right . find ( data ) else : return self 绘制图形 因为我对这个很感兴趣，就把这个先弄了。其中很大程度上依赖一种遍历树的机制。 def introspection ( self ): '''walk a round,and get myself information''' stack = [] node = self while stack or node : if node : stack . append ( node ) node = node . left else : node = stack . pop () yield node node = node . right 这个函数看的参考资料的，稍微做了一些改动，返回的不是data，而是node对象，方便后续很多函数的支持调用。这种堆然后这种遍历老实说一开始我估计是想不出来的，看跟着程序走一下发现确实遍历树了，很是巧妙。 然后绘图函数如下所示: def get_ymove ( self ): if self . parent is None : return 0 return self . parent . get_ymove () + 1 def get_xmove ( self ): if self . parent is None : return 0 if self == self . parent . left : return self . parent . get_xmove () - 1 elif self == self . parent . right : return self . parent . get_xmove () + 1 def draw ( self ): from PIL import Image , ImageDraw , ImageFont font = ImageFont . truetype ( \"arial.ttf\" , 15 ) w = 800 h = 600 image = Image . new ( 'RGB' ,( w , h ),( 255 , 255 , 255 )) draw = ImageDraw . Draw ( image ) last_x = None last_y = None for node in self . introspection (): node_point_x = node . get_xmove () * 50 + 400 node_point_y = node . get_ymove () * 50 + 50 if node . parent is not None : node_point_x_parent = node . parent . get_xmove () * 50 + 400 node_point_y_parent = node . parent . get_ymove () * 50 + 50 draw . line (( node_point_x_parent + 15 , node_point_y_parent , node_point_x + 15 , node_point_y ), fill = ( 0 , 0 , 0 )) #del draw draw . ellipse ([( node_point_x , node_point_y ),( node_point_x + 30 , node_point_y + 30 )], outline = ( 0 , 0 , 0 )) draw . text (( node_point_x + 15 , node_point_y ), str ( node . data ), fill = ( 0 , 0 , 0 ), font = font ) last_x = node_point_x last_y = node_point_y image . show () 利用pillow的一个很粗糙的绘图过程，因为我对这块还不熟悉，这其中如何绘图的细节和优化还很值得商榷。 删除操作 删除操作可能稍微复杂点， def children_count ( self ): \"\"\"Return the number of children @returns number of children: 0, 1, 2 \"\"\" cnt = 0 if self . left : cnt += 1 if self . right : cnt += 1 return cnt def delete ( self , data ): \"\"\"Delete node containing data @param data node's content to delete \"\"\" # get node containing data node , parent = self . lookup ( data ) if node is not None : children_count = node . children_count () if children_count == 0 : # if node has no children, just remove it if parent : if parent . left is node : parent . left = None else : parent . right = None else : self . data = None elif children_count == 1 : # if node has 1 child # replace node by its child if node . left : n = node . left else : n = node . right if parent : if parent . left is node : parent . left = n else : parent . right = n else : self . left = n . left self . right = n . right self . data = n . data else : # if node has 2 children # find its successor parent = node successor = node . right while successor . left : parent = successor successor = successor . left # replace node data by its successor data node . data = successor . data # fix successor's parent node child if parent . left == successor : parent . left = successor . right else : parent . right = successor . right 比较二叉树 def compare_trees ( self , node ): \"\"\"Compare 2 trees @param node tree to compare @returns True if the tree passed is identical to this tree \"\"\" if node is None : return False if self . data != node . data : return False res = True if self . left is None : if node . left : return False else : res = self . left . compare_trees ( node . left ) if res is False : return False if self . right is None : if node . right : return False else : res = self . right . compare_trees ( node . right ) return res 查找二叉树最短路径 root = Node ( 8 ) root . insert ( 3 ) root . insert ( 10 ) root . insert ( 1 ) root . insert ( 6 ) root . insert ( 4 ) root . insert ( 7 ) root . insert ( 14 ) root . insert ( 13 ) def gen_relative ( node ): lst = [] if isinstance ( node , list ): for n in node : lst . extend ([ i for i in [ n . left , n . right , n . parent ] if i ]) else : return lst else : return [ i for i in [ node . left , node . right , node . parent ] if i ] res = [[ start ]] def gen_path ( start , end ): res . append ( gen_relative ( start )) if end in res [ - 1 ]: return else : start = gen_relative ( start ) return gen_path ( start , end ) from itertools import product def check_continuous ( lst ): for i , e in enumerate ( lst [ 1 :]): pre = lst [ i ] if e in [ pre . left , pre . right , pre . parent ]: pass else : return False else : return True def find_shortpath ( start , end ): gen_path ( start , end ) path = [ p for p in product ( * res ) if end in p ] path = [ p for p in path if check_continuous ( p )] return path path = find_shortpath ( start , end ) print ( path ) print ( len ( path [ 0 ])) 本小节参考资料 https://github.com/qiwsir/algorithm/blob/master/binary_tree.md http://www.laurentluce.com/posts/binary-search-tree-library-in-python/ https://zh.wikipedia.org/wiki/%E4%BA%8C%E5%85%83%E6%90%9C%E5%B0%8B%E6%A8%B9","tags":"算法","url":"articles/binary-search-tree.html"},{"title":"github pages","text":"自定义域名 简单来说就是写一个 CNAME 文件，实际上github的 settings那里还提供了功能，具体实际做的工作也就是创建了一个 CNAME 文件。 挂上gitbook的内容 下面的内容过时了： 把 gitbook build 之后的 _book 里面的内容复制到主目录下，然后如下引用即可： /html5-learning-notes 也就是指向文件夹就可以正常工作了。 参考了 这个网页 和 create-react-app 关于分支的管理建议 ，综合更好的解决方案如下： yarn init 如果读者对yarn npm不太熟悉的话，那么全部都 Enter 吧。 yarn add gh-pages 在 packages.json 里面加上 （PS: 注意json语法object最后一项不能带逗号）： \"scripts\" : { \"predeploy\" : \"npm run build\" , \"deploy\" : \"gh-pages -d _book\" , \"build\" : \"gitbook build\" } 然后运行 gitbook deploy 好了，现在你的gitbook已经挂载在 you_name.github.io/project 那里了。 自定义域名https支持 本小节参考了 这篇文章 。简单来说就是利用 cloudflare 提供的服务。其提供的是DNS域名解析服务，然后还做了很多额外的工作，比如缓存啊，统计啊，https支持啊等等。 具体设置它那边说明得很详细，很多就是一键式设置吧，里面有些东西我也不是很清楚，比如 SSL 模式推荐选择 Flexible 但是 Full 是否也支持github pages就不得而知了，具体设置后好等好几个小时才能生效。 然后 Automatic HTTPS Rewrites 和 Always use HTTPS 是推荐选上的，然后上面那篇文章提到 page rules 需要如下设置下，但是因为前面已经勾选了 Always use HTTPS 这个总选项，所以不确定是不是重复设置了。","tags":"others","url":"articles/github-pages.html"},{"title":"云服务器的一些知识","text":"什么是弹性ip 参考了 这个网页 。 简单来说弹性ip就是和用户绑定的外网ip，而不是和你的云主机绑定的。所以这是一种资源，如果你更换云主机了，再将这个弹性ip绑定到第二个云主机上即可。","tags":"others","url":"articles/yun-fu-wu-qi-de-yi-xie-zhi-shi.html"},{"title":"numpy模块","text":"前言 本文对于numpy模块具体各个函数细节不做过多说明，具体请参看文档。本文主要是就numpy的一些核心概念进行理清。 numpy模块里面最核心的概念就是 ndarray对象，请参看 这个问题 ，当时我也有疑问，numpy里面的array函数和ndarray对象有什么区别，答案就是：一般使用推荐使用 numpy.array 来创建 ndarray对象，其他还有 zeros ，empty等等其他的函数，他们都是很好的接口去创建一个 numpy.ndarray 对象，当然你也可以通过 numpy.ndarray 来创建一个ndarray对象，但这不是 numpy模块开发人员推荐的风格。 numpy ndarray对象和python的列表的区别 numpy array内部的item是固定内存size的，改变size将会重新创建一个array。 numpy array内部的item是相同的data type的，因此是固定内存size的。 numpy的array有助于大型数据的高级数学运算或其他操作，比python的序列那些执行会更有效率。 一系列的科学和数学计算python模块都是基于numpy的array的，当然他们支持python的序列类型输入，但都是转变成为numpy的array之后再进行相关计算的，然后他们的输出也通常是numpy的array。 ndarray对象 numpy模块中很核心的一个概念就是ndarray对象。ndarray对象按照numpy官方手册的绘图是这样一个数据结构： ndarray有一个头header来控制所有接下来存储的数据类型(dtype)，然后存储的数据则必然都是相同的数据类型，这是一个不同于列表的限定条件，这样约定将大大提高数据处理的效率。 你可以利用array函数简单将一个列表变成ndarray对象： >>> x = np.array([1,2,3,4,5]) >>> x array([1, 2, 3, 4, 5]) >>> type(x) <class 'numpy.ndarray'> >>> x.dtype dtype('int32') 在上面的例子中我们看到，每一个ndarray对象都有一个属性( dtype )，其存储的就是前面讲的ndarray对象后面一连串数据的数据类型，比如这里的数据类型是\"int32\"。 dtype清单 这个基本上讨论numpy的资料都会把这个清单列出来，这里也列出来吧。 bool_: True or False int_: 相当于C语言的long，一般是int32或int64。整数型其内细分: intc: 等于C语言的int，int32或int64 intp: 整数用于索引，和C语言的ssize_t相同，一般是int32或int64。 int8: Byte（-128 ~ 127） int16: Integer（-32769 ~ 32767） int32: Integer int64: Integer uint8: Unsigned Integer（0 ~ 255） uint16: Unsigned Integer（0 ~ 65535） uint32: Unsigned Integer uint64: Unsigned Integer float_: 具体为float64。浮点型细分为: float16: 半精度浮点型 float32: 单精度浮点型 float64: 双精度浮点型 complex_: 就是complex128。 复数型细分为: complex64: 复数型，由32位浮点型组成 complex128: 复数形，由64位浮点型组成 具体使用声明如下: >>> t = np.array([1,2,3],dtype='int32') >>> type(t) <class 'numpy.ndarray'> >>> t.dtype dtype('int32') >>> 在实际使用的时候，dtype若指定为int，则实际就是对应的 np.int_ >>> t = np.array([1,2,3],dtype='int') >>> t.dtype dtype('int64') 类似的 float 对应 np.float_ ; bool 对应 np.bool_ ; complex 对应 np.complex_ 。 ndarray的dtype变换 在改变某个ndarray对象的dtype的时候，原ndarray对象实际上被删除了，等于重新创建了一个ndarray对象。可以通过上面的类型声明来直接进行转换，如: >>> t = np.array([1,2,3],dtype='int8') >>> t.dtype dtype('int8') >>> new_t = np.int32(t) >>> new_t.dtype dtype('int32') 还可以通过调用ndarray的 astype 方法来实现。注意这个方法是 非破坏型 方法，具体使用如下面例子所示： >>> t = np.array([1,2,3],dtype='int8') >>> t.astype('int32') array([1, 2, 3], dtype=int32) >>> t array([1, 2, 3], dtype=int8) dtype对象的从属关系 用 np.issubdtype 函数来判断某个ndarray的dtype对象是不是整型的子集。 >>> t array([1, 2, 3], dtype=int8) >>> t.dtype dtype('int8') >>> np.issubdtype(t.dtype,'int') True >>> np.issubdtype(t.dtype,'float') False shape属性 此外，每一个ndarray对象都有 shape 属性，用于控制后面跟着的这些数据的维度。请看下面的例子： >>> x array([1, 2, 3, 4, 5, 6]) >>> x.shape (6,) >>> x.shape = (2,3) >>> x array([[1, 2, 3], [4, 5, 6]]) shape 属性用来控制对于后面数据维度的理解，一个数字表示一维，二个数字表示二维几行几列（也就是数学中我们常见的概念矩阵），三个数字表示三维等。这里直接修改ndarray对象的shape属性将直接影响程序对于该对象数据的理解，此外更常用的是用 reshape 方法，其并不原地修改某个ndarray对象的shape，而是返回一个被修改shape属性的新的ndarray对象。 创建一个ndarray对象 从python数据结构中创建 这个就是前面接触过的 np.array 函数，用来接受一个python list 或 tuple ，从而返回一个ndarray对象。 >>> x = np.array([[1+2j,2+3j],[3+4j,4+5j]]) >>> x array([[ 1.+2.j, 2.+3.j], [ 3.+4.j, 4.+5.j]]) >>> x.dtype dtype('complex128') >>> 生成一系列的随机数 这个经常在各个例子中看到： np.random.randn(2,3) array([[-0.26670745, 1.09572856, -0.38875728], [ 1.04339429, 0.06330302, 1.35696512]]) 填充一个2行3列的随机数，randn后面的n是normal，也就是正态分布的意思。 arrange函数 arange(start,end,step) 参数类似range函数。生成一个数据递增（减）的ndarray对象： >>> x = np.arange(5) >>> x array([0, 1, 2, 3, 4]) >>> x = np.arange(1,10,0.5) >>> type(x) <class 'numpy.ndarray'> >>> x array([ 1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5, 5. , 5.5, 6. , 6.5, 7. , 7.5, 8. , 8.5, 9. , 9.5]) 其是一维的，但通过reshape操作可以生成二维的ndarray对象，其可以接受 dtype 对象来控制dtype属性。 linspace函数 linspace函数可以看作上面 arange函数的补充，arange函数虽然指定了start和stop，最后的数值是不被包含的，然后具体生成了多少个item是不易知的，而linspace可以接受这样三个参数: start end number ，其中start和end一定是在ndarray中包含的，然后number给定了具体生成了多少个item。 >>> np.linspace(1,10,6) array([ 1. , 2.8, 4.6, 6.4, 8.2, 10. ]) 结束元素包不包含倒不是很重要，关键是某些情况下你需要控制具体生成了多少个item，那么就需要使用 linspace 函数。 zeros函数 zeros函数用于快速创建一个ndarray对象，其内数据都填充的是 0. ，默认dtype是 float64 。其接受的一个参数你可以简单看作就是shape属性参数，如下所示： >>> np.zeros((10,)) array([ 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) >>> np.zeros(10) array([ 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) >>> np.zeros((5,5)) array([[ 0., 0., 0., 0., 0.], [ 0., 0., 0., 0., 0.], [ 0., 0., 0., 0., 0.], [ 0., 0., 0., 0., 0.], [ 0., 0., 0., 0., 0.]]) ones函数 ones函数类似于zeros函数，不同的是填充的数据是1。就不做例子演示了。 empty函数 empty函数和前面谈论的 zeros ones 函数类似，除了各个item都是原内存的随机数值，并不做任何修改。 >>> np.empty((2,3)) array([[ 0.00000000e+000, 4.99297208e-317, 4.94026911e-317], [ 6.94094003e-310, 1.03878549e-013, 0.00000000e+000]]) >>> 索引值 ndarray对于值的索引操作和python中列表索引值的操作非常相似，即方括号语法索引 [index] : >>> x = np.array([[1,2,3],[4,5,6],[7,8,9]]) >>> x array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) >>> x[0] array([1, 2, 3]) >>> x[0][0] 1 >>> y[1][5] 5 此外你还可以用这种语法: >>> x array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) >>> x[0,0] 1 >>> x[1,1] 5 >>> 通过上面描述的索引值语法可以直接修改该ndarray对象的这个元素的值。此外numpy还提供了另外一种表示语法： [a,b] ，对于ndarray对象其和 [a][b] 的意思是一样的。但是矩阵 不 支持 [a][b] 这种索引语法，而只支持 [a,b] 这种表示语法，推荐对于矩阵都用带逗号的这种索引方法，表示矩阵的a行b列。 >>> A = np.matrix([[1,2,3],[4,5,6],[7,8,9]]) >>> A[0] matrix([[1, 2, 3]]) >>> A[0][0]#并没有索引下去 matrix([[1, 2, 3]]) >>> A[0,0] 1 索引多个值或说view 同样ndarray对象也有在上面谈及的索引规则下 [start:end:step] : >>> x = np . array ([[ 1 , 2 , 3 ],[ 4 , 5 , 6 ],[ 7 , 8 , 9 ]]) >>> x array ([[ 1 , 2 , 3 ], [ 4 , 5 , 6 ], [ 7 , 8 , 9 ]]) >>> x [ ::- 1 ] array ([[ 7 , 8 , 9 ], [ 4 , 5 , 6 ], [ 1 , 2 , 3 ]]) >>> y = np . arange ( 10 ) >>> y array ([ 0 , 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 ]) >>> y [ 0 :: 2 ] array ([ 0 , 2 , 4 , 6 , 8 ]) 支持索引多个值，但注意上面不是说切片，而是 view 视图。因为python的list如果你索引多个值，切片了，则等于制造了一个新的列表，如: >>> lst = [1,2,3,4,5] >>> lst[0:2] [1, 2] >>> x = lst[0:2] >>> x[0] = 12 >>> x [12, 2] >>> lst [1, 2, 3, 4, 5] 在调用 lst[0:2] 时，python程序是制造一个新的子列表，然后赋值给x，但是我们看ndarray对象不是这样的: >>> array = np.array([1,2,3,4,5]) >>> array array([1, 2, 3, 4, 5]) >>> x = array[:2] >>> x array([1, 2]) >>> x[0] = 12 >>> x array([12, 2]) >>> array array([12, 2, 3, 4, 5]) 这就是ndarray对象索引多个值称之为 视图 的原因，其返回的还是指向原处的那个片段！ 最后对于索引多个值的视图赋值操作，是所有元素都赋值为那个值: >>> x[:] = 99 >>> array array([99, 99, 3, 4, 5]) 多维切片 上面的 [start:end:step] 语法只是第一个维度上的切片，numpy支持下面的语法，可以灵活地在多个维度进行切片 [d1, d2, d3] ，上面的d1是具体在第一个维度上的索引值，也就是对于每个维度都可以进一步使用 [start:end:step] 这样的进一步切片操作。 import numpy as np arr = np . array ([[[ 5 , 10 , 15 ], [ 20 , 25 , 30 ], [ 35 , 40 , 45 ]], [[ 1 , 2 , 4 ], [ 3 , 4 , 2 ], [ 1 , 2 , 4 ]]] ) arr Out [ 5 ]: array ([[[ 5 , 10 , 15 ], [ 20 , 25 , 30 ], [ 35 , 40 , 45 ]], [[ 1 , 2 , 4 ], [ 3 , 4 , 2 ], [ 1 , 2 , 4 ]]]) arr [ 0 ,:] Out [ 6 ]: array ([[ 5 , 10 , 15 ], [ 20 , 25 , 30 ], [ 35 , 40 , 45 ]]) arr [ 0 ] Out [ 7 ]: array ([[ 5 , 10 , 15 ], [ 20 , 25 , 30 ], [ 35 , 40 , 45 ]]) arr [:, 0 ,:] Out [ 8 ]: array ([[ 5 , 10 , 15 ], [ 1 , 2 , 4 ]]) 注意看最后一个例子，含义是第一维度所有元素，第二维度选择索引值0，第三维度所有元素。 copy方法 如果你希望达到原python的那种索引多个值的效果而不影响原ndarray对象，你可以调用ndarrary对象的 copy 方法: array[:2].copy() 布尔值索引 布尔值索引是基于 ndarray对象进行布尔值判断操作，如 == > < 等等之类的时候，将输出一个原维度的bool值ndarray对象。然后将这个ndarray对象送入array的索引输入框中，其将返回bool值为True的那些值。 >>> array array([0, 0, 3, 4, 5]) >>> array == 0 array([ True, True, False, False, False], dtype=bool) >>> array[array == 0] array([0, 0]) >>> array[array == 0] = 99 >>> array array([99, 99, 3, 4, 5]) 布尔值索引返回的也是 视图 ，对齐操作将改变原ndarray对象。 你还可以用 & 和 | 来形成组合逻辑，但不能使用 and 和 or 。 一大用法就是利用某个item各个属性的映射关系，利用其他属性来过滤另外某个data: >>> data = np.random.randn(7,3) >>> data array([[-0.82117767, 1.02481308, 0.50908019], [ 0.79851282, 0.37692996, -1.0129145 ], [-1.30120201, 1.71270027, 0.2113716 ], [-1.33386207, 0.02978504, -0.58061781], [ 0.72466458, 1.94170572, 2.09521622], [-1.24241997, -1.20557331, -0.66292731], [-0.66145326, 0.28330579, 0.2803069 ]]) >>> names = np.array(['a','b','c','a','b','d','a']) >>> data[names == 'a'] array([[-0.82117767, 1.02481308, 0.50908019], [-1.33386207, 0.02978504, -0.58061781], [-0.66145326, 0.28330579, 0.2803069 ]]) 这里将索引的是每一行，其行对应的name是'a'的值。 基本的运算 两个ndarray对象之间进行基本的数学运算，如果两个ndarray维度是相同的，则称之为 vectorization ，矢量化操作。大致意思就是 加减乘除幂 具体操作都是 对应的元素和对应的元素进行加减乘除幂操作 : >>> x = np.array([[4,0,5],[-1,3,2]]) >>> x array([[ 4, 0, 5], [-1, 3, 2]]) >>> y = np.array([[1,1,1],[3,5,7]]) >>> y array([[1, 1, 1], [3, 5, 7]]) >>> x + y array([[5, 1, 6], [2, 8, 9]]) >>> x - y array([[ 3, -1, 4], [-4, -2, -5]]) >>> x * 2 array([[ 8, 0, 10], [-2, 6, 4]]) >>> x ** 2 array([[16, 0, 25], [ 1, 9, 4]]) 如果两个ndarray对象的维度（多维的情况不讨论了吧），如果 列维数目相同，则似乎也是可以的，但应该不推荐这么使用。而如果列维数目不同，则会抛出 ValueError 。 >>> z = np.array([1,2,3]) >>> x+z array([[5, 2, 8], [0, 5, 5]]) 我们看到这里z是重复应用到x的每一行了。 ndarray对象上的一些方法 flatten方法 flatten，拉平。flatten是ndarray对象（包括矩阵）的一个方法，可将其变为一维形式， 非破坏型 方法。 这里将flatten方法归到矩阵这里是因为多维数组必须各个维度所含元素数目相等（也就是必须要有类似矩阵的空间矩形排布感）才有意义。然后矩阵返回的是行矢量形式。 >>> x = np.array([[1,2,3],[4,5,6],[7,8,9]]) >>> x array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) >>> x.flatten() array([1, 2, 3, 4, 5, 6, 7, 8, 9]) >>> x array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) >>> y = np.array([[1,2,3],[4,5,6,7]]) >>> y array([[1, 2, 3], [4, 5, 6, 7]], dtype=object) >>> y.flatten() array([[1, 2, 3], [4, 5, 6, 7]], dtype=object) >>> z matrix([[1, 2, 3], [4, 5, 6]]) >>> z.flatten() matrix([[1, 2, 3, 4, 5, 6]]) sort方法 sort方法虽然可以作用多维，但似乎对一维更显的有意义些，其是一个 破坏型 方法。 如下所示，注意看，每一行并没有变动，只在行内一维情况下排序。 >>> data array([[ 0.68518059, 1.05271585, 1.00174264], [-1.44506879, 1.45532422, 1.30856608], [ 0.1121552 , -3.04487041, -0.03301996]]) >>> data.sort() >>> data array([[ 0.68518059, 1.00174264, 1.05271585], [-1.44506879, 1.30856608, 1.45532422], [-3.04487041, -0.03301996, 0.1121552 ]]) mean方法 计算给定维度下所有元素的值的的均值。 ndarray.mean(axis=None, dtype=None, out=None, keepdims=False) 在这里的难点在于理解按照维度扩展这个概念，如果是矩阵的话，竖向列是axis=0，横向行是axis=1。 numpy.mean(axis=0) 这里一般的理解是按照竖向列计算均值，更好的理解是行表示记录，列表示特征，一般第一维度表示样本维，第二维度表示特征维，这里axis=0，官方文档对于axis的解释是沿着某个维度或者轴进行计算，这里axis=0选择的实际上是样本维，然后沿着样本维每个特征计算得到一个均值。 std方法 计算给定维度下所有元素的值的标准差，具体使用类似于上面的mean方法。 一些通用函数 下面讲的一些通用函数，大多是numpy自带的，然后接受的参数一般是ndarray对象，一般也不会改变目标ndarray对象的shape（有些会稍微做一些改变），然后对各个元素进行一些函数操作。 sqrt函数 开个平方根 x = np.arange(10) array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) np.sqrt(x) array([0. , 1. , 1.41421356, 1.73205081, 2. , 2.23606798, 2.44948974, 2.64575131, 2.82842712, 3. ]) exp函数 算个指数函数 \\(e&#94;{x}\\) np.exp(x) maximum函数 点对点返回最大值 【会自动进行广播操作】 x = np.random.randn(8) y = np.random.randn(8) np.maximum(x, y) abs函数 x = np.random.randn(2,3) array([[-0.11653471, 0.72362219, 0.93142213], [-2.03263166, -0.1941374 , 1.23463108]]) np.abs(x) array([[0.11653471, 0.72362219, 0.93142213], [2.03263166, 0.1941374 , 1.23463108]]) tile函数 np.tile(A, reps) 输入一个array，根据reps决定在那个维度重复数据： >>> a = np.array([0, 1, 2]) >>> np.tile(a, 2) array([0, 1, 2, 0, 1, 2]) >>> np.tile(a, (2, 2)) array([[0, 1, 2, 0, 1, 2], [0, 1, 2, 0, 1, 2]]) >>> np.tile(a, (2, 1, 2)) array([[[0, 1, 2, 0, 1, 2]], [[0, 1, 2, 0, 1, 2]]]) argsort函数 ndarray对象调用argsort函数将返回一个按照大小排序的索引值： >>> x = np.array([3, 1, 2]) >>> np.argsort(x) array([1, 2, 0]) 上面的含义是排序后第一个值是 x[1] ，后面以此类推。 np. np.allclose numpy.allclose(a, b, rtol=1e-05, atol=1e-08, equal_nan=False) 类似于isclose，不过返回的True或者False np.isclose numpy.isclose(a, b, rtol=1e-05, atol=1e-08, equal_nan=False) 点对点的比较两个ndarray的值，rtol是相对容忍度，atol是绝对容忍度，这是一种近似的数值相近比较判断操作。 np.logical_and 点对点的逻辑and操作。 np.all 沿某个轴或者所有数值执行all操作。 ndarray对象转置 就是调用ndarray对象的 T 属性，这更接近于矩阵中的转置操作（但是对于一维ndarray并没有任何改变）。而之前提及的 data[::-1] 这么使用，只是把行翻转了一下，对于一维倒是整个array都翻转了。 >>> data = np . random . randn ( 4 , 3 ) >>> data array ([[ 0.53700477 , - 1.30139712 , 1.12184318 ], [ - 0.91918847 , 1.52850268 , 0.73218978 ], [ - 1.14840704 , - 0.0413753 , 0.52820585 ], [ 1.84307255 , 0.21356674 , 0.23331023 ]]) >>> data . T array ([[ 0.53700477 , - 0.91918847 , - 1.14840704 , 1.84307255 ], [ - 1.30139712 , 1.52850268 , - 0.0413753 , 0.21356674 ], [ 1.12184318 , 0.73218978 , 0.52820585 , 0.23331023 ]]) >>> data [ ::- 1 ] array ([[ 1.84307255 , 0.21356674 , 0.23331023 ], [ - 1.14840704 , - 0.0413753 , 0.52820585 ], [ - 0.91918847 , 1.52850268 , 0.73218978 ], [ 0.53700477 , - 1.30139712 , 1.12184318 ]]) 广播(broadcasting) 广播一种操作，shape较小的张量和shape较大的张量进行点对点运算时，需要对shape较小的张量进行广播操作，使其在运算上shape兼容。 广播具体操作规则是： shape较小的张量添加新的维度是的两个张量维度数相同 shape较小的张量在新的维度中的数据是重复的，相当于没有原维度的数据，即： y[1,j] = y[2,j] = y[3,j] =... y[j] 矩阵对象 矩阵对象是ndarray对象的子类，也就是说ndarray对象的一些属性和方法它都是可以使用的。行矢量和列矢量是属于矩阵中的特殊情况。矩阵这个概念在以后的数学运算中较为重要，然后对于一些概念，比如转置啊，点乘啊等，总之和矩阵的数学运算相关的，虽然ndarray对象也可以做，但推荐将其变成矩阵（matrix）对象之后再处理，这样容易理清概念。 matrix函数 用numpy的matrix函数可以创建一个矩阵对象: >>> data = np.random.randn(3,3) >>> data array([[-0.79589206, -0.97535141, 1.05750453], [ 0.05051448, 0.19753523, 0.99618112], [ 2.09805081, -0.33623748, 0.26033154]]) >>> x = np.matrix(data) >>> type(x) <class 'numpy.matrixlib.defmatrix.matrix'> >>> x matrix([[-0.79589206, -0.97535141, 1.05750453], [ 0.05051448, 0.19753523, 0.99618112], [ 2.09805081, -0.33623748, 0.26033154]]) 矩阵转置 transpose 方法，将矩阵转置过来。只返回结果， 非破坏型 方法。 >>> x = np.matrix([[1,2,3],[4,5,6],[7,8,9]]) >>> x matrix([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) >>> x.transpose() matrix([[1, 4, 7], [2, 5, 8], [3, 6, 9]]) 行矢量和列矢量 行矢量和列矢量是矩阵的特殊情况，需要用matrix函数创建之。行矢量转置之后就是列矢量请注意看它的写法。 >>> x = np.matrix([1,2,3,4,5]) >>> x matrix([[1, 2, 3, 4, 5]]) >>> x.transpose() matrix([[1], [2], [3], [4], [5]]) 矩阵的点乘 学过线性代数印像最深的可能就是矩阵那个怪异的乘法运算了。这里有了numpy模块的支持，就可以直接用 * 来执行两个矩阵的乘法，或者 np.dot 函数。 >>> A = np.matrix([[1,0,3,-1],[2,1,0,2]]) >>> B = np.matrix([[4,1,0],[-1,1,3],[2,0,1],[1,3,4]]) >>> A * B matrix([[ 9, -2, -1], [ 9, 9, 11]]) >>> x = np.matrix([1,2,3]) >>> y = np.matrix([4,5,6]).transpose() >>> x * y matrix([[32]]) >>> y * x matrix([[ 4, 8, 12], [ 5, 10, 15], [ 6, 12, 18]]) >>> np.dot(x,y) matrix([[32]]) >>> np.dot(y,x) matrix([[ 4, 8, 12], [ 5, 10, 15], [ 6, 12, 18]]) >>> if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js','mhchem.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"机器学习","url":"articles/numpy-module.html"},{"title":"小分子网页显示第二版","text":"第二版说明 在 第一版中 我们介绍了在html文件中如何绘制数学表达式和化学分子式，简单来说就是利用 mathjax 这个javascript库。但是我们是如此喜欢markdown和pelican，那里在pelican下该如何做呢。 最优雅的方法就是引入 render_math 这个插件。 # the plugin PLUGIN_PATHS = ['myplugins'] PLUGINS = [extract_toc', 'render_math'] MATH_JAX = {'tex_extensions': ['mhchem.js']} 然后剩下的一切就交给pelican来处理吧，其可以检测你的markdown下是否插入了数学公式或者说化学分子式，然后决定是否引入 mathjax 库。 数学环境简要介绍 行内数学环境就像 TeX 里面一样 $ $ ，然后单独一行的数学表达式是 ： $$ ... $$ 更多用 Tex写数学的知识请参看这个 wikibook 。值得一提的是 LaTeX风格 \\( 这样的并不支持。然后 \\begin{equation} 是支持的，不过这边markdown编辑器并不支持实时预览，所以推荐就使用 $ 和 $$ 了。 如下： $$ {\\sigma }&#94;{2 } =\\frac { 1 }{n } \\sum _{ i=1 }&#94;{ n }{( X_i - \\mu)&#94;2} $$ 显示效果就是： $$ {\\sigma }&#94;{2 } =\\frac { 1 }{n } \\sum _{ i=1 }&#94;{ n }{( X_i - \\mu)&#94;2} $$ 显示小分子 比如 $\\ce{H_2O}$ 将显示为 \\(\\ce{H_2O}\\) ，然后 $\\ce{AgCl_2&#94;-}$ 将显示为 \\(\\ce{AgCl_2&#94;-}\\) 。 此外还有一种简写写法：比如 $\\ce{H2O}$ 将显示为 \\(\\ce{H2O}\\) ，然后 $\\ce{AgCl2-}$ 将显示为 \\(\\ce{AgCl2-}\\) 。 我们可以看一下没有经过 ce 命令包装的纯数学环境表达的显示效果： \\(H_2O\\) 和 \\(AgCl_2&#94;-\\) 。区别还是有点的。 关于数字进入上标和加减号自动情况见这两个例子： $\\ce{Y&#94;{99}+}$ \\(\\ce{Y&#94;{99}+}\\) 和 $\\ce{Y&#94;{99+}}$ \\(\\ce{Y&#94;{99+}}\\) 。 配位化合物 数字就直接写上即可 $\\ce{0.5H2O}$ \\(\\ce{0.5H2O}\\) ，值得一提的是，前面的数字分数形式会自动处理： $\\ce{1/2 H2O}$ \\(\\ce{1/2 H2O}\\) 。 你会看到带上小数点的数字显示有点古怪。之前小数点会被解释成为配位化合物和结晶水中间的那个分隔点。如 $\\ce{KCr(SO4)2.12H2O}$ \\(\\ce{KCr(SO4)2.12H2O}\\) 。为了正确显示前面的例子，把这个0.5放入数学环境中即可： $\\ce{$0.5$H2O}$ $$ \\ce{$0.5$H2O} $$ 如上所示，mathjax目前是支持ce命令里面再加入数学环境 $ $ 的。 显示化学键 - = # 分别表示单键，双键和三键。 \\(\\ce{A-A B=B C#C}\\) 然后使用 \\bond 命令还可以加入其他一些额外的键，其中 $\\ce{\\bond{~}}$ 对应 \\(\\ce{\\bond{~}}\\) 然后 $\\ce{\\bond{~-}}$ 对应 \\(\\ce{\\bond{~-}}\\) ，其他类推。 显示化学反应式 $$ \\ce { CO2 + C <- 2 CO } $$ $$ \\ce{CO2 + C <- 2CO} $$ $$ \\ce{CO2 + C ->[\\text{加入text命令}] 2CO} \\ce{CO2 + C ->T[是支持][中文的] 2CO} $$ $$ \\ce{CO2 + C ->[\\text{加入text命令}] 2CO} $$ $$ \\ce{CO2 + C ->T[是支持][中文的] 2CO} $$ 如果不使用text命令，那么中文是不会正常显示。上面例子第二个没有使用text命令，是因为前面加上了T，然后箭头上下文字都不需要了。 显示上下箭头 $$ \\ce{SO4&#94;2- + Ba&#94;2+ -> BaSO4 v &#94;} $$ $$ \\ce{SO4&#94;2- + Ba&#94;2+ -> BaSO4 v &#94;} $$ 下降箭头是 v ，上式箭头是 &#94; ，需要和前面的内容有一个空格。 推荐一个markdown编辑器 typora 这个markdown编辑器，可以实时预览和修改markdown，包括化学公式和数学公式哦。 if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js','mhchem.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"chemistry","url":"articles/how-to-show-small-molecule-on-web.html"},{"title":"gitbook工具","text":"请读者主要阅读 http://www.chengweiyang.cn/gitbook/index.html 这篇教程。 下面我主要就我遇到的一些问题做一些补充说明。 安装 推荐安装的是 gitbook-cli ，gitbook安装之后会提示你应该安装 gitbook-cli ，推荐是全局安装。 安装插件 运行 gitbook serve 其会使用本地的插件，所以比如说要安装插件 simple-page-toc ，应该将其装在本地。 npm install gitbook-plugin-simple-page-toc gitbook build 虽然gitbook serve也会输出一些内容，但更正式的做法是 gitbook build the_foler 来编译出你的gitbook内容供你的 webserver来服务。输出还是在 _book 那里，挂上 index.html 文件即可。 比如apache的话推荐用 Alias 语句来加载。 gitbook和github的同步 首先是gitbook那边的配置要配置好，github那边也要新建一个对应的仓库。github的 settings 那里有个 Application 设置，里面也要设置好gitbook那边具体那些仓库对gitbook开放，否则你在gitbook那边是找不到这个仓库的。 然后就是第一次gitbook sync github是需要force 的，点下面两个大图标的左边，我还没有遇到过不需要force的情况，包括github那边新建一个空白仓库也不行。 一些特殊的文件的含义 主目录下 book.json ，插件配置就是在这里写的。 assets 文件夹一般放着图片，当然这个随意的，是参考了前gitbook图形界面的输出。 README.md 书在gitbook上一开始就显示这个文件。 SUMMARY.md 重要，控制书的目录，基本上你都可以将其看作gitbook对书处理的主入口。 中文文件名到底可不可以 gitbook那边自动生成的文件夹和文件名都不带中文的，那么通过github这边同步的内容，中文文件名到底可不可以。 经过测试中文文件夹和中文文件名都是 可以的 ，在 SUMMARY.md 那边写好对应的路径就是了。","tags":"others","url":"articles/gitbook-tools.html"},{"title":"化学信息学研究中英文属性词对照","text":"简介 早期编程不会考虑中文化的问题，一切化学物质的属性都将是英文表示，后面在网页显示的时候才考虑怎么将其中文化显示。 这里将详细这些关键的属性名词，这可以看作这一编程领域的特定领域语言，或者用计算机语言的角度来说是： cheminfo-keyword。 列表 标准名字 id类：各个不同的化学数据库对于相同的化学物质都有不同的id表达，这个id属性并没有特别的含义，不能作为化学物质的唯一性标识。 分子式 molecular_formular 分子量 molecular_weight InChi 国际化合物标识 IUPAC推荐将其作为化合物的唯一性标识 （我在开发中将以InChi为判断纯物质唯一性的标准） inchi_key inchi运行SHA-256哈希算法之后得到的哈希值。（在开发时可以作为实际检索key来使用） smiles 类似于InChi的标记体系，更具有可读性。实际上学过有机化学的人几乎可以毫不费力的写出某个化合物的smiles式，不作为判断纯物质的唯一性表示 isomeric_smiles 也就是人们说的 unique SMILES 唯一smiles表示。加上了对同位素和手性的表示。 iupac_name IUPAC 系统命名法的名字 名字转换 在其他数据库或者地方获得的关于化学物质的属性，名字有各种形式。 建议写一个名字转换小函数。 模型设计 substance -> mixture substance将有一个type属性：指明物质是单质，原子，离子，分子等。substance里面都是纯物质 后面的一切讨论都基于上面的substance类。 在substance类的基础上决定建立一种行为-属性的机制。 除了化学物质最基本的属性直接写在substance模型里面外，其他的额外的属性都将单独写模型。后面的所有的属性模型将加入一个字段，行为字段。正式基于这种行为，我们获得了额外的这个属性。 比如： mixture 混合物，混合物表示物理混合没有化学反应，行为的描述就是什么什么纯物质以多少比例，这个行为决定了混合物的生成也决定了混合物的存在。 同样后面的化学反应也将作为这样的进一步额外属性描述引入。 比如说溶解度的属性，具体溶解度 由 behave_condition= '在20度下溶解于水' propery='' behave_condition behave_condition 是描述了一种行为，我们约定某种behave_condition 下物质测的的property应该是具有唯一性的。 这首先需要我们建立一种行为描述方法，这种行为描述方法将是一系列可能的条件集 [a1,a2,a3,a4,a5.....] 然后由此获得property。 这样的描述系统已经足够的表达充分了，比如说今天做的实验记录各个测试条件加入，甚至把在那个实验室等也加入，甚至是测试时间，最后填入property。 实际设计数据库，可能会将条件集的数值和单位还有关于单位的进入描述分开。其中数值和单位才是完整的behave_condition描述。","tags":"chemistry","url":"articles/cheminfo-keyword-refrence.html"},{"title":"数据绘图","text":"在jupyter notebook 下首先推荐输入 %matplotlib notebook 。 In [1]: % matplotlib notebook In [2]: import matplotlib.pyplot as plt 配置中文字体支持 In [3]: from matplotlib import rcParams rcParams [ 'font.family' ] = 'sans-serif' rcParams [ 'font.sans-serif' ] . insert ( 0 , 'SimHei' ) # 插入中文字体 print ( rcParams [ 'font.sans-serif' ]) rcParams [ 'axes.unicode_minus' ] = False #用来正常显示负号 ['SimHei', 'DejaVu Sans', 'Bitstream Vera Sans', 'Computer Modern Sans Serif', 'Lucida Grande', 'Verdana', 'Geneva', 'Lucid', 'Arial', 'Helvetica', 'Avant Garde', 'sans-serif'] 折线图 折线图是最简单的图形，直接调用plot函数即可，主要是其他一些图形显示上的微调。 In [5]: import numpy as np x = np . arange ( 6 ) y = [ 2 , 2.1 , 2.2 , 2.1 , 2.3 , 2.4 ] plt . ylabel ( \"利润\" ) # 设置y标签 plt . xlabel ( \"月份\" ) # 设置x标签 plt . xticks ( x , [ '七月' , '八月' , '九月' , '十月' , '十一月' , '十二月' ]) # 设置x标记 plt . ylim ( 0 , 2.8 ) # 设置y轴范围 plt . plot ( y ) var element = $('#e81ef26d-6eb3-431f-b233-39e33b6c9fc8'); /* Put everything inside the global mpl namespace */ window.mpl = {}; mpl.get_websocket_type = function() { if (typeof(WebSocket) !== 'undefined') { return WebSocket; } else if (typeof(MozWebSocket) !== 'undefined') { return MozWebSocket; } else { alert('Your browser does not have WebSocket support.' + 'Please try Chrome, Safari or Firefox ≥ 6. ' + 'Firefox 4 and 5 are also supported but you ' + 'have to enable WebSockets in about:config.'); }; } mpl.figure = function(figure_id, websocket, ondownload, parent_element) { this.id = figure_id; this.ws = websocket; this.supports_binary = (this.ws.binaryType != undefined); if (!this.supports_binary) { var warnings = document.getElementById(\"mpl-warnings\"); if (warnings) { warnings.style.display = 'block'; warnings.textContent = ( \"This browser does not support binary websocket messages. \" + \"Performance may be slow.\"); } } this.imageObj = new Image(); this.context = undefined; this.message = undefined; this.canvas = undefined; this.rubberband_canvas = undefined; this.rubberband_context = undefined; this.format_dropdown = undefined; this.image_mode = 'full'; this.root = $('<div/>'); this._root_extra_style(this.root) this.root.attr('style', 'display: inline-block'); $(parent_element).append(this.root); this._init_header(this); this._init_canvas(this); this._init_toolbar(this); var fig = this; this.waiting = false; this.ws.onopen = function () { fig.send_message(\"supports_binary\", {value: fig.supports_binary}); fig.send_message(\"send_image_mode\", {}); if (mpl.ratio != 1) { fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio}); } fig.send_message(\"refresh\", {}); } this.imageObj.onload = function() { if (fig.image_mode == 'full') { // Full images could contain transparency (where diff images // almost always do), so we need to clear the canvas so that // there is no ghosting. fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height); } fig.context.drawImage(fig.imageObj, 0, 0); }; this.imageObj.onunload = function() { fig.ws.close(); } this.ws.onmessage = this._make_on_message_function(this); this.ondownload = ondownload; } mpl.figure.prototype._init_header = function() { var titlebar = $( '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' + 'ui-helper-clearfix\"/>'); var titletext = $( '<div class=\"ui-dialog-title\" style=\"width: 100%; ' + 'text-align: center; padding: 3px;\"/>'); titlebar.append(titletext) this.root.append(titlebar); this.header = titletext[0]; } mpl.figure.prototype._canvas_extra_style = function(canvas_div) { } mpl.figure.prototype._root_extra_style = function(canvas_div) { } mpl.figure.prototype._init_canvas = function() { var fig = this; var canvas_div = $('<div/>'); canvas_div.attr('style', 'position: relative; clear: both; outline: 0'); function canvas_keyboard_event(event) { return fig.key_event(event, event['data']); } canvas_div.keydown('key_press', canvas_keyboard_event); canvas_div.keyup('key_release', canvas_keyboard_event); this.canvas_div = canvas_div this._canvas_extra_style(canvas_div) this.root.append(canvas_div); var canvas = $('<canvas/>'); canvas.addClass('mpl-canvas'); canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\") this.canvas = canvas[0]; this.context = canvas[0].getContext(\"2d\"); var backingStore = this.context.backingStorePixelRatio || this.context.webkitBackingStorePixelRatio || this.context.mozBackingStorePixelRatio || this.context.msBackingStorePixelRatio || this.context.oBackingStorePixelRatio || this.context.backingStorePixelRatio || 1; mpl.ratio = (window.devicePixelRatio || 1) / backingStore; var rubberband = $('<canvas/>'); rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\") var pass_mouse_events = true; canvas_div.resizable({ start: function(event, ui) { pass_mouse_events = false; }, resize: function(event, ui) { fig.request_resize(ui.size.width, ui.size.height); }, stop: function(event, ui) { pass_mouse_events = true; fig.request_resize(ui.size.width, ui.size.height); }, }); function mouse_event_fn(event) { if (pass_mouse_events) return fig.mouse_event(event, event['data']); } rubberband.mousedown('button_press', mouse_event_fn); rubberband.mouseup('button_release', mouse_event_fn); // Throttle sequential mouse events to 1 every 20ms. rubberband.mousemove('motion_notify', mouse_event_fn); rubberband.mouseenter('figure_enter', mouse_event_fn); rubberband.mouseleave('figure_leave', mouse_event_fn); canvas_div.on(\"wheel\", function (event) { event = event.originalEvent; event['data'] = 'scroll' if (event.deltaY < 0) { event.step = 1; } else { event.step = -1; } mouse_event_fn(event); }); canvas_div.append(canvas); canvas_div.append(rubberband); this.rubberband = rubberband; this.rubberband_canvas = rubberband[0]; this.rubberband_context = rubberband[0].getContext(\"2d\"); this.rubberband_context.strokeStyle = \"#000000\"; this._resize_canvas = function(width, height) { // Keep the size of the canvas, canvas container, and rubber band // canvas in synch. canvas_div.css('width', width) canvas_div.css('height', height) canvas.attr('width', width * mpl.ratio); canvas.attr('height', height * mpl.ratio); canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;'); rubberband.attr('width', width); rubberband.attr('height', height); } // Set the figure to an initial 600x600px, this will subsequently be updated // upon first draw. this._resize_canvas(600, 600); // Disable right mouse context menu. $(this.rubberband_canvas).bind(\"contextmenu\",function(e){ return false; }); function set_focus () { canvas.focus(); canvas_div.focus(); } window.setTimeout(set_focus, 100); } mpl.figure.prototype._init_toolbar = function() { var fig = this; var nav_element = $('<div/>') nav_element.attr('style', 'width: 100%'); this.root.append(nav_element); // Define a callback function for later on. function toolbar_event(event) { return fig.toolbar_button_onclick(event['data']); } function toolbar_mouse_event(event) { return fig.toolbar_button_onmouseover(event['data']); } for(var toolbar_ind in mpl.toolbar_items) { var name = mpl.toolbar_items[toolbar_ind][0]; var tooltip = mpl.toolbar_items[toolbar_ind][1]; var image = mpl.toolbar_items[toolbar_ind][2]; var method_name = mpl.toolbar_items[toolbar_ind][3]; if (!name) { // put a spacer in here. continue; } var button = $('<button/>'); button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' + 'ui-button-icon-only'); button.attr('role', 'button'); button.attr('aria-disabled', 'false'); button.click(method_name, toolbar_event); button.mouseover(tooltip, toolbar_mouse_event); var icon_img = $('<span/>'); icon_img.addClass('ui-button-icon-primary ui-icon'); icon_img.addClass(image); icon_img.addClass('ui-corner-all'); var tooltip_span = $('<span/>'); tooltip_span.addClass('ui-button-text'); tooltip_span.html(tooltip); button.append(icon_img); button.append(tooltip_span); nav_element.append(button); } var fmt_picker_span = $('<span/>'); var fmt_picker = $('<select/>'); fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content'); fmt_picker_span.append(fmt_picker); nav_element.append(fmt_picker_span); this.format_dropdown = fmt_picker[0]; for (var ind in mpl.extensions) { var fmt = mpl.extensions[ind]; var option = $( '<option/>', {selected: fmt === mpl.default_extension}).html(fmt); fmt_picker.append(option) } // Add hover states to the ui-buttons $( \".ui-button\" ).hover( function() { $(this).addClass(\"ui-state-hover\");}, function() { $(this).removeClass(\"ui-state-hover\");} ); var status_bar = $('<span class=\"mpl-message\"/>'); nav_element.append(status_bar); this.message = status_bar[0]; } mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) { // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client, // which will in turn request a refresh of the image. this.send_message('resize', {'width': x_pixels, 'height': y_pixels}); } mpl.figure.prototype.send_message = function(type, properties) { properties['type'] = type; properties['figure_id'] = this.id; this.ws.send(JSON.stringify(properties)); } mpl.figure.prototype.send_draw_message = function() { if (!this.waiting) { this.waiting = true; this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id})); } } mpl.figure.prototype.handle_save = function(fig, msg) { var format_dropdown = fig.format_dropdown; var format = format_dropdown.options[format_dropdown.selectedIndex].value; fig.ondownload(fig, format); } mpl.figure.prototype.handle_resize = function(fig, msg) { var size = msg['size']; if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) { fig._resize_canvas(size[0], size[1]); fig.send_message(\"refresh\", {}); }; } mpl.figure.prototype.handle_rubberband = function(fig, msg) { var x0 = msg['x0'] / mpl.ratio; var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio; var x1 = msg['x1'] / mpl.ratio; var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio; x0 = Math.floor(x0) + 0.5; y0 = Math.floor(y0) + 0.5; x1 = Math.floor(x1) + 0.5; y1 = Math.floor(y1) + 0.5; var min_x = Math.min(x0, x1); var min_y = Math.min(y0, y1); var width = Math.abs(x1 - x0); var height = Math.abs(y1 - y0); fig.rubberband_context.clearRect( 0, 0, fig.canvas.width, fig.canvas.height); fig.rubberband_context.strokeRect(min_x, min_y, width, height); } mpl.figure.prototype.handle_figure_label = function(fig, msg) { // Updates the figure title. fig.header.textContent = msg['label']; } mpl.figure.prototype.handle_cursor = function(fig, msg) { var cursor = msg['cursor']; switch(cursor) { case 0: cursor = 'pointer'; break; case 1: cursor = 'default'; break; case 2: cursor = 'crosshair'; break; case 3: cursor = 'move'; break; } fig.rubberband_canvas.style.cursor = cursor; } mpl.figure.prototype.handle_message = function(fig, msg) { fig.message.textContent = msg['message']; } mpl.figure.prototype.handle_draw = function(fig, msg) { // Request the server to send over a new figure. fig.send_draw_message(); } mpl.figure.prototype.handle_image_mode = function(fig, msg) { fig.image_mode = msg['mode']; } mpl.figure.prototype.updated_canvas_event = function() { // Called whenever the canvas gets updated. this.send_message(\"ack\", {}); } // A function to construct a web socket function for onmessage handling. // Called in the figure constructor. mpl.figure.prototype._make_on_message_function = function(fig) { return function socket_on_message(evt) { if (evt.data instanceof Blob) { /* FIXME: We get \"Resource interpreted as Image but * transferred with MIME type text/plain:\" errors on * Chrome. But how to set the MIME type? It doesn't seem * to be part of the websocket stream */ evt.data.type = \"image/png\"; /* Free the memory for the previous frames */ if (fig.imageObj.src) { (window.URL || window.webkitURL).revokeObjectURL( fig.imageObj.src); } fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL( evt.data); fig.updated_canvas_event(); fig.waiting = false; return; } else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") { fig.imageObj.src = evt.data; fig.updated_canvas_event(); fig.waiting = false; return; } var msg = JSON.parse(evt.data); var msg_type = msg['type']; // Call the \"handle_{type}\" callback, which takes // the figure and JSON message as its only arguments. try { var callback = fig[\"handle_\" + msg_type]; } catch (e) { console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg); return; } if (callback) { try { // console.log(\"Handling '\" + msg_type + \"' message: \", msg); callback(fig, msg); } catch (e) { console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg); } } }; } // from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas mpl.findpos = function(e) { //this section is from http://www.quirksmode.org/js/events_properties.html var targ; if (!e) e = window.event; if (e.target) targ = e.target; else if (e.srcElement) targ = e.srcElement; if (targ.nodeType == 3) // defeat Safari bug targ = targ.parentNode; // jQuery normalizes the pageX and pageY // pageX,Y are the mouse positions relative to the document // offset() returns the position of the element relative to the document var x = e.pageX - $(targ).offset().left; var y = e.pageY - $(targ).offset().top; return {\"x\": x, \"y\": y}; }; /* * return a copy of an object with only non-object keys * we need this to avoid circular references * http://stackoverflow.com/a/24161582/3208463 */ function simpleKeys (original) { return Object.keys(original).reduce(function (obj, key) { if (typeof original[key] !== 'object') obj[key] = original[key] return obj; }, {}); } mpl.figure.prototype.mouse_event = function(event, name) { var canvas_pos = mpl.findpos(event) if (name === 'button_press') { this.canvas.focus(); this.canvas_div.focus(); } var x = canvas_pos.x * mpl.ratio; var y = canvas_pos.y * mpl.ratio; this.send_message(name, {x: x, y: y, button: event.button, step: event.step, guiEvent: simpleKeys(event)}); /* This prevents the web browser from automatically changing to * the text insertion cursor when the button is pressed. We want * to control all of the cursor setting manually through the * 'cursor' event from matplotlib */ event.preventDefault(); return false; } mpl.figure.prototype._key_event_extra = function(event, name) { // Handle any extra behaviour associated with a key event } mpl.figure.prototype.key_event = function(event, name) { // Prevent repeat events if (name == 'key_press') { if (event.which === this._key) return; else this._key = event.which; } if (name == 'key_release') this._key = null; var value = ''; if (event.ctrlKey && event.which != 17) value += \"ctrl+\"; if (event.altKey && event.which != 18) value += \"alt+\"; if (event.shiftKey && event.which != 16) value += \"shift+\"; value += 'k'; value += event.which.toString(); this._key_event_extra(event, name); this.send_message(name, {key: value, guiEvent: simpleKeys(event)}); return false; } mpl.figure.prototype.toolbar_button_onclick = function(name) { if (name == 'download') { this.handle_save(this, null); } else { this.send_message(\"toolbar_button\", {name: name}); } }; mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) { this.message.textContent = tooltip; }; mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]]; mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"]; mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) { // Create a \"websocket\"-like object which calls the given IPython comm // object with the appropriate methods. Currently this is a non binary // socket, so there is still some room for performance tuning. var ws = {}; ws.close = function() { comm.close() }; ws.send = function(m) { //console.log('sending', m); comm.send(m); }; // Register the callback with on_msg. comm.on_msg(function(msg) { //console.log('receiving', msg['content']['data'], msg); // Pass the mpl event to the overridden (by mpl) onmessage function. ws.onmessage(msg['content']['data']) }); return ws; } mpl.mpl_figure_comm = function(comm, msg) { // This is the function which gets called when the mpl process // starts-up an IPython Comm through the \"matplotlib\" channel. var id = msg.content.data.id; // Get hold of the div created by the display call when the Comm // socket was opened in Python. var element = $(\"#\" + id); var ws_proxy = comm_websocket_adapter(comm) function ondownload(figure, format) { window.open(figure.imageObj.src); } var fig = new mpl.figure(id, ws_proxy, ondownload, element.get(0)); // Call onopen now - mpl needs it, as it is assuming we've passed it a real // web socket which is closed, not our websocket->open comm proxy. ws_proxy.onopen(); fig.parent_element = element.get(0); fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\"); if (!fig.cell_info) { console.error(\"Failed to find cell for figure\", id, fig); return; } var output_index = fig.cell_info[2] var cell = fig.cell_info[0]; }; mpl.figure.prototype.handle_close = function(fig, msg) { var width = fig.canvas.width/mpl.ratio fig.root.unbind('remove') // Update the output cell to use the data from the current canvas. fig.push_to_output(); var dataURL = fig.canvas.toDataURL(); // Re-enable the keyboard manager in IPython - without this line, in FF, // the notebook keyboard shortcuts fail. IPython.keyboard_manager.enable() $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">'); fig.close_ws(fig, msg); } mpl.figure.prototype.close_ws = function(fig, msg){ fig.send_message('closing', msg); // fig.ws.close() } mpl.figure.prototype.push_to_output = function(remove_interactive) { // Turn the data on the canvas into data in the output cell. var width = this.canvas.width/mpl.ratio var dataURL = this.canvas.toDataURL(); this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">'; } mpl.figure.prototype.updated_canvas_event = function() { // Tell IPython that the notebook contents must change. IPython.notebook.set_dirty(true); this.send_message(\"ack\", {}); var fig = this; // Wait a second, then push the new image to the DOM so // that it is saved nicely (might be nice to debounce this). setTimeout(function () { fig.push_to_output() }, 1000); } mpl.figure.prototype._init_toolbar = function() { var fig = this; var nav_element = $('<div/>') nav_element.attr('style', 'width: 100%'); this.root.append(nav_element); // Define a callback function for later on. function toolbar_event(event) { return fig.toolbar_button_onclick(event['data']); } function toolbar_mouse_event(event) { return fig.toolbar_button_onmouseover(event['data']); } for(var toolbar_ind in mpl.toolbar_items){ var name = mpl.toolbar_items[toolbar_ind][0]; var tooltip = mpl.toolbar_items[toolbar_ind][1]; var image = mpl.toolbar_items[toolbar_ind][2]; var method_name = mpl.toolbar_items[toolbar_ind][3]; if (!name) { continue; }; var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>'); button.click(method_name, toolbar_event); button.mouseover(tooltip, toolbar_mouse_event); nav_element.append(button); } // Add the status bar. var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>'); nav_element.append(status_bar); this.message = status_bar[0]; // Add the close button to the window. var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>'); var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>'); button.click(function (evt) { fig.handle_close(fig, {}); } ); button.mouseover('Stop Interaction', toolbar_mouse_event); buttongrp.append(button); var titlebar = this.root.find($('.ui-dialog-titlebar')); titlebar.prepend(buttongrp); } mpl.figure.prototype._root_extra_style = function(el){ var fig = this el.on(\"remove\", function(){ fig.close_ws(fig, {}); }); } mpl.figure.prototype._canvas_extra_style = function(el){ // this is important to make the div 'focusable el.attr('tabindex', 0) // reach out to IPython and tell the keyboard manager to turn it's self // off when our div gets focus // location in version 3 if (IPython.notebook.keyboard_manager) { IPython.notebook.keyboard_manager.register_events(el); } else { // location in version 2 IPython.keyboard_manager.register_events(el); } } mpl.figure.prototype._key_event_extra = function(event, name) { var manager = IPython.notebook.keyboard_manager; if (!manager) manager = IPython.keyboard_manager; // Check for shift+enter if (event.shiftKey && event.which == 13) { this.canvas_div.blur(); event.shiftKey = false; // Send a \"J\" for go to next cell event.which = 74; event.keyCode = 74; manager.command_mode(); manager.handle_keydown(event); } } mpl.figure.prototype.handle_save = function(fig, msg) { fig.ondownload(fig, null); } mpl.find_output_cell = function(html_output) { // Return the cell and output element which can be found *uniquely* in the notebook. // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\" // IPython event is triggered only after the cells have been serialised, which for // our purposes (turning an active figure into a static one), is too late. var cells = IPython.notebook.get_cells(); var ncells = cells.length; for (var i=0; i<ncells; i++) { var cell = cells[i]; if (cell.cell_type === 'code'){ for (var j=0; j<cell.output_area.outputs.length; j++) { var data = cell.output_area.outputs[j]; if (data.data) { // IPython >= 3 moved mimebundle to data attribute of output data = data.data; } if (data['text/html'] == html_output) { return [cell, data, j]; } } } } } // Register the function which deals with the matplotlib target/channel. // The kernel may be null if the page has been refreshed. if (IPython.notebook.kernel != null) { IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm); } Out[5]: [<matplotlib.lines.Line2D at 0x20cb5fbebe0>] 饼图 使用pie函数，注意这里使用了子图: fig1, ax1 = plt.subplots() autopct 的格式 '%2.0f%%' 含义是 有效数字位数和小数点位数。 In [6]: labels = [ '其他' , '射击' , '动作' , '策略' , '体育' ] sizes = [ 1500 , 3500 , 6000 , 11500 , 27500 ] # explode = (0, 0, 0, 0, 0.1) fig1 , ax1 = plt . subplots () ax1 . pie ( sizes , labels = labels , autopct = ' %2.0f%% ' , startangle = 90 ) ax1 . axis ( 'equal' ) # 确保画成一个圆 plt . show () var element = $('#32491884-1e0a-4ac1-a32b-5c3870ff8535'); /* Put everything inside the global mpl namespace */ window.mpl = {}; mpl.get_websocket_type = function() { if (typeof(WebSocket) !== 'undefined') { return WebSocket; } else if (typeof(MozWebSocket) !== 'undefined') { return MozWebSocket; } else { alert('Your browser does not have WebSocket support.' + 'Please try Chrome, Safari or Firefox ≥ 6. ' + 'Firefox 4 and 5 are also supported but you ' + 'have to enable WebSockets in about:config.'); }; } mpl.figure = function(figure_id, websocket, ondownload, parent_element) { this.id = figure_id; this.ws = websocket; this.supports_binary = (this.ws.binaryType != undefined); if (!this.supports_binary) { var warnings = document.getElementById(\"mpl-warnings\"); if (warnings) { warnings.style.display = 'block'; warnings.textContent = ( \"This browser does not support binary websocket messages. \" + \"Performance may be slow.\"); } } this.imageObj = new Image(); this.context = undefined; this.message = undefined; this.canvas = undefined; this.rubberband_canvas = undefined; this.rubberband_context = undefined; this.format_dropdown = undefined; this.image_mode = 'full'; this.root = $('<div/>'); this._root_extra_style(this.root) this.root.attr('style', 'display: inline-block'); $(parent_element).append(this.root); this._init_header(this); this._init_canvas(this); this._init_toolbar(this); var fig = this; this.waiting = false; this.ws.onopen = function () { fig.send_message(\"supports_binary\", {value: fig.supports_binary}); fig.send_message(\"send_image_mode\", {}); if (mpl.ratio != 1) { fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio}); } fig.send_message(\"refresh\", {}); } this.imageObj.onload = function() { if (fig.image_mode == 'full') { // Full images could contain transparency (where diff images // almost always do), so we need to clear the canvas so that // there is no ghosting. fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height); } fig.context.drawImage(fig.imageObj, 0, 0); }; this.imageObj.onunload = function() { fig.ws.close(); } this.ws.onmessage = this._make_on_message_function(this); this.ondownload = ondownload; } mpl.figure.prototype._init_header = function() { var titlebar = $( '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' + 'ui-helper-clearfix\"/>'); var titletext = $( '<div class=\"ui-dialog-title\" style=\"width: 100%; ' + 'text-align: center; padding: 3px;\"/>'); titlebar.append(titletext) this.root.append(titlebar); this.header = titletext[0]; } mpl.figure.prototype._canvas_extra_style = function(canvas_div) { } mpl.figure.prototype._root_extra_style = function(canvas_div) { } mpl.figure.prototype._init_canvas = function() { var fig = this; var canvas_div = $('<div/>'); canvas_div.attr('style', 'position: relative; clear: both; outline: 0'); function canvas_keyboard_event(event) { return fig.key_event(event, event['data']); } canvas_div.keydown('key_press', canvas_keyboard_event); canvas_div.keyup('key_release', canvas_keyboard_event); this.canvas_div = canvas_div this._canvas_extra_style(canvas_div) this.root.append(canvas_div); var canvas = $('<canvas/>'); canvas.addClass('mpl-canvas'); canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\") this.canvas = canvas[0]; this.context = canvas[0].getContext(\"2d\"); var backingStore = this.context.backingStorePixelRatio || this.context.webkitBackingStorePixelRatio || this.context.mozBackingStorePixelRatio || this.context.msBackingStorePixelRatio || this.context.oBackingStorePixelRatio || this.context.backingStorePixelRatio || 1; mpl.ratio = (window.devicePixelRatio || 1) / backingStore; var rubberband = $('<canvas/>'); rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\") var pass_mouse_events = true; canvas_div.resizable({ start: function(event, ui) { pass_mouse_events = false; }, resize: function(event, ui) { fig.request_resize(ui.size.width, ui.size.height); }, stop: function(event, ui) { pass_mouse_events = true; fig.request_resize(ui.size.width, ui.size.height); }, }); function mouse_event_fn(event) { if (pass_mouse_events) return fig.mouse_event(event, event['data']); } rubberband.mousedown('button_press', mouse_event_fn); rubberband.mouseup('button_release', mouse_event_fn); // Throttle sequential mouse events to 1 every 20ms. rubberband.mousemove('motion_notify', mouse_event_fn); rubberband.mouseenter('figure_enter', mouse_event_fn); rubberband.mouseleave('figure_leave', mouse_event_fn); canvas_div.on(\"wheel\", function (event) { event = event.originalEvent; event['data'] = 'scroll' if (event.deltaY < 0) { event.step = 1; } else { event.step = -1; } mouse_event_fn(event); }); canvas_div.append(canvas); canvas_div.append(rubberband); this.rubberband = rubberband; this.rubberband_canvas = rubberband[0]; this.rubberband_context = rubberband[0].getContext(\"2d\"); this.rubberband_context.strokeStyle = \"#000000\"; this._resize_canvas = function(width, height) { // Keep the size of the canvas, canvas container, and rubber band // canvas in synch. canvas_div.css('width', width) canvas_div.css('height', height) canvas.attr('width', width * mpl.ratio); canvas.attr('height', height * mpl.ratio); canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;'); rubberband.attr('width', width); rubberband.attr('height', height); } // Set the figure to an initial 600x600px, this will subsequently be updated // upon first draw. this._resize_canvas(600, 600); // Disable right mouse context menu. $(this.rubberband_canvas).bind(\"contextmenu\",function(e){ return false; }); function set_focus () { canvas.focus(); canvas_div.focus(); } window.setTimeout(set_focus, 100); } mpl.figure.prototype._init_toolbar = function() { var fig = this; var nav_element = $('<div/>') nav_element.attr('style', 'width: 100%'); this.root.append(nav_element); // Define a callback function for later on. function toolbar_event(event) { return fig.toolbar_button_onclick(event['data']); } function toolbar_mouse_event(event) { return fig.toolbar_button_onmouseover(event['data']); } for(var toolbar_ind in mpl.toolbar_items) { var name = mpl.toolbar_items[toolbar_ind][0]; var tooltip = mpl.toolbar_items[toolbar_ind][1]; var image = mpl.toolbar_items[toolbar_ind][2]; var method_name = mpl.toolbar_items[toolbar_ind][3]; if (!name) { // put a spacer in here. continue; } var button = $('<button/>'); button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' + 'ui-button-icon-only'); button.attr('role', 'button'); button.attr('aria-disabled', 'false'); button.click(method_name, toolbar_event); button.mouseover(tooltip, toolbar_mouse_event); var icon_img = $('<span/>'); icon_img.addClass('ui-button-icon-primary ui-icon'); icon_img.addClass(image); icon_img.addClass('ui-corner-all'); var tooltip_span = $('<span/>'); tooltip_span.addClass('ui-button-text'); tooltip_span.html(tooltip); button.append(icon_img); button.append(tooltip_span); nav_element.append(button); } var fmt_picker_span = $('<span/>'); var fmt_picker = $('<select/>'); fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content'); fmt_picker_span.append(fmt_picker); nav_element.append(fmt_picker_span); this.format_dropdown = fmt_picker[0]; for (var ind in mpl.extensions) { var fmt = mpl.extensions[ind]; var option = $( '<option/>', {selected: fmt === mpl.default_extension}).html(fmt); fmt_picker.append(option) } // Add hover states to the ui-buttons $( \".ui-button\" ).hover( function() { $(this).addClass(\"ui-state-hover\");}, function() { $(this).removeClass(\"ui-state-hover\");} ); var status_bar = $('<span class=\"mpl-message\"/>'); nav_element.append(status_bar); this.message = status_bar[0]; } mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) { // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client, // which will in turn request a refresh of the image. this.send_message('resize', {'width': x_pixels, 'height': y_pixels}); } mpl.figure.prototype.send_message = function(type, properties) { properties['type'] = type; properties['figure_id'] = this.id; this.ws.send(JSON.stringify(properties)); } mpl.figure.prototype.send_draw_message = function() { if (!this.waiting) { this.waiting = true; this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id})); } } mpl.figure.prototype.handle_save = function(fig, msg) { var format_dropdown = fig.format_dropdown; var format = format_dropdown.options[format_dropdown.selectedIndex].value; fig.ondownload(fig, format); } mpl.figure.prototype.handle_resize = function(fig, msg) { var size = msg['size']; if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) { fig._resize_canvas(size[0], size[1]); fig.send_message(\"refresh\", {}); }; } mpl.figure.prototype.handle_rubberband = function(fig, msg) { var x0 = msg['x0'] / mpl.ratio; var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio; var x1 = msg['x1'] / mpl.ratio; var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio; x0 = Math.floor(x0) + 0.5; y0 = Math.floor(y0) + 0.5; x1 = Math.floor(x1) + 0.5; y1 = Math.floor(y1) + 0.5; var min_x = Math.min(x0, x1); var min_y = Math.min(y0, y1); var width = Math.abs(x1 - x0); var height = Math.abs(y1 - y0); fig.rubberband_context.clearRect( 0, 0, fig.canvas.width, fig.canvas.height); fig.rubberband_context.strokeRect(min_x, min_y, width, height); } mpl.figure.prototype.handle_figure_label = function(fig, msg) { // Updates the figure title. fig.header.textContent = msg['label']; } mpl.figure.prototype.handle_cursor = function(fig, msg) { var cursor = msg['cursor']; switch(cursor) { case 0: cursor = 'pointer'; break; case 1: cursor = 'default'; break; case 2: cursor = 'crosshair'; break; case 3: cursor = 'move'; break; } fig.rubberband_canvas.style.cursor = cursor; } mpl.figure.prototype.handle_message = function(fig, msg) { fig.message.textContent = msg['message']; } mpl.figure.prototype.handle_draw = function(fig, msg) { // Request the server to send over a new figure. fig.send_draw_message(); } mpl.figure.prototype.handle_image_mode = function(fig, msg) { fig.image_mode = msg['mode']; } mpl.figure.prototype.updated_canvas_event = function() { // Called whenever the canvas gets updated. this.send_message(\"ack\", {}); } // A function to construct a web socket function for onmessage handling. // Called in the figure constructor. mpl.figure.prototype._make_on_message_function = function(fig) { return function socket_on_message(evt) { if (evt.data instanceof Blob) { /* FIXME: We get \"Resource interpreted as Image but * transferred with MIME type text/plain:\" errors on * Chrome. But how to set the MIME type? It doesn't seem * to be part of the websocket stream */ evt.data.type = \"image/png\"; /* Free the memory for the previous frames */ if (fig.imageObj.src) { (window.URL || window.webkitURL).revokeObjectURL( fig.imageObj.src); } fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL( evt.data); fig.updated_canvas_event(); fig.waiting = false; return; } else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") { fig.imageObj.src = evt.data; fig.updated_canvas_event(); fig.waiting = false; return; } var msg = JSON.parse(evt.data); var msg_type = msg['type']; // Call the \"handle_{type}\" callback, which takes // the figure and JSON message as its only arguments. try { var callback = fig[\"handle_\" + msg_type]; } catch (e) { console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg); return; } if (callback) { try { // console.log(\"Handling '\" + msg_type + \"' message: \", msg); callback(fig, msg); } catch (e) { console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg); } } }; } // from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas mpl.findpos = function(e) { //this section is from http://www.quirksmode.org/js/events_properties.html var targ; if (!e) e = window.event; if (e.target) targ = e.target; else if (e.srcElement) targ = e.srcElement; if (targ.nodeType == 3) // defeat Safari bug targ = targ.parentNode; // jQuery normalizes the pageX and pageY // pageX,Y are the mouse positions relative to the document // offset() returns the position of the element relative to the document var x = e.pageX - $(targ).offset().left; var y = e.pageY - $(targ).offset().top; return {\"x\": x, \"y\": y}; }; /* * return a copy of an object with only non-object keys * we need this to avoid circular references * http://stackoverflow.com/a/24161582/3208463 */ function simpleKeys (original) { return Object.keys(original).reduce(function (obj, key) { if (typeof original[key] !== 'object') obj[key] = original[key] return obj; }, {}); } mpl.figure.prototype.mouse_event = function(event, name) { var canvas_pos = mpl.findpos(event) if (name === 'button_press') { this.canvas.focus(); this.canvas_div.focus(); } var x = canvas_pos.x * mpl.ratio; var y = canvas_pos.y * mpl.ratio; this.send_message(name, {x: x, y: y, button: event.button, step: event.step, guiEvent: simpleKeys(event)}); /* This prevents the web browser from automatically changing to * the text insertion cursor when the button is pressed. We want * to control all of the cursor setting manually through the * 'cursor' event from matplotlib */ event.preventDefault(); return false; } mpl.figure.prototype._key_event_extra = function(event, name) { // Handle any extra behaviour associated with a key event } mpl.figure.prototype.key_event = function(event, name) { // Prevent repeat events if (name == 'key_press') { if (event.which === this._key) return; else this._key = event.which; } if (name == 'key_release') this._key = null; var value = ''; if (event.ctrlKey && event.which != 17) value += \"ctrl+\"; if (event.altKey && event.which != 18) value += \"alt+\"; if (event.shiftKey && event.which != 16) value += \"shift+\"; value += 'k'; value += event.which.toString(); this._key_event_extra(event, name); this.send_message(name, {key: value, guiEvent: simpleKeys(event)}); return false; } mpl.figure.prototype.toolbar_button_onclick = function(name) { if (name == 'download') { this.handle_save(this, null); } else { this.send_message(\"toolbar_button\", {name: name}); } }; mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) { this.message.textContent = tooltip; }; mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]]; mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"]; mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) { // Create a \"websocket\"-like object which calls the given IPython comm // object with the appropriate methods. Currently this is a non binary // socket, so there is still some room for performance tuning. var ws = {}; ws.close = function() { comm.close() }; ws.send = function(m) { //console.log('sending', m); comm.send(m); }; // Register the callback with on_msg. comm.on_msg(function(msg) { //console.log('receiving', msg['content']['data'], msg); // Pass the mpl event to the overridden (by mpl) onmessage function. ws.onmessage(msg['content']['data']) }); return ws; } mpl.mpl_figure_comm = function(comm, msg) { // This is the function which gets called when the mpl process // starts-up an IPython Comm through the \"matplotlib\" channel. var id = msg.content.data.id; // Get hold of the div created by the display call when the Comm // socket was opened in Python. var element = $(\"#\" + id); var ws_proxy = comm_websocket_adapter(comm) function ondownload(figure, format) { window.open(figure.imageObj.src); } var fig = new mpl.figure(id, ws_proxy, ondownload, element.get(0)); // Call onopen now - mpl needs it, as it is assuming we've passed it a real // web socket which is closed, not our websocket->open comm proxy. ws_proxy.onopen(); fig.parent_element = element.get(0); fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\"); if (!fig.cell_info) { console.error(\"Failed to find cell for figure\", id, fig); return; } var output_index = fig.cell_info[2] var cell = fig.cell_info[0]; }; mpl.figure.prototype.handle_close = function(fig, msg) { var width = fig.canvas.width/mpl.ratio fig.root.unbind('remove') // Update the output cell to use the data from the current canvas. fig.push_to_output(); var dataURL = fig.canvas.toDataURL(); // Re-enable the keyboard manager in IPython - without this line, in FF, // the notebook keyboard shortcuts fail. IPython.keyboard_manager.enable() $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">'); fig.close_ws(fig, msg); } mpl.figure.prototype.close_ws = function(fig, msg){ fig.send_message('closing', msg); // fig.ws.close() } mpl.figure.prototype.push_to_output = function(remove_interactive) { // Turn the data on the canvas into data in the output cell. var width = this.canvas.width/mpl.ratio var dataURL = this.canvas.toDataURL(); this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">'; } mpl.figure.prototype.updated_canvas_event = function() { // Tell IPython that the notebook contents must change. IPython.notebook.set_dirty(true); this.send_message(\"ack\", {}); var fig = this; // Wait a second, then push the new image to the DOM so // that it is saved nicely (might be nice to debounce this). setTimeout(function () { fig.push_to_output() }, 1000); } mpl.figure.prototype._init_toolbar = function() { var fig = this; var nav_element = $('<div/>') nav_element.attr('style', 'width: 100%'); this.root.append(nav_element); // Define a callback function for later on. function toolbar_event(event) { return fig.toolbar_button_onclick(event['data']); } function toolbar_mouse_event(event) { return fig.toolbar_button_onmouseover(event['data']); } for(var toolbar_ind in mpl.toolbar_items){ var name = mpl.toolbar_items[toolbar_ind][0]; var tooltip = mpl.toolbar_items[toolbar_ind][1]; var image = mpl.toolbar_items[toolbar_ind][2]; var method_name = mpl.toolbar_items[toolbar_ind][3]; if (!name) { continue; }; var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>'); button.click(method_name, toolbar_event); button.mouseover(tooltip, toolbar_mouse_event); nav_element.append(button); } // Add the status bar. var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>'); nav_element.append(status_bar); this.message = status_bar[0]; // Add the close button to the window. var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>'); var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>'); button.click(function (evt) { fig.handle_close(fig, {}); } ); button.mouseover('Stop Interaction', toolbar_mouse_event); buttongrp.append(button); var titlebar = this.root.find($('.ui-dialog-titlebar')); titlebar.prepend(buttongrp); } mpl.figure.prototype._root_extra_style = function(el){ var fig = this el.on(\"remove\", function(){ fig.close_ws(fig, {}); }); } mpl.figure.prototype._canvas_extra_style = function(el){ // this is important to make the div 'focusable el.attr('tabindex', 0) // reach out to IPython and tell the keyboard manager to turn it's self // off when our div gets focus // location in version 3 if (IPython.notebook.keyboard_manager) { IPython.notebook.keyboard_manager.register_events(el); } else { // location in version 2 IPython.keyboard_manager.register_events(el); } } mpl.figure.prototype._key_event_extra = function(event, name) { var manager = IPython.notebook.keyboard_manager; if (!manager) manager = IPython.keyboard_manager; // Check for shift+enter if (event.shiftKey && event.which == 13) { this.canvas_div.blur(); event.shiftKey = false; // Send a \"J\" for go to next cell event.which = 74; event.keyCode = 74; manager.command_mode(); manager.handle_keydown(event); } } mpl.figure.prototype.handle_save = function(fig, msg) { fig.ondownload(fig, null); } mpl.find_output_cell = function(html_output) { // Return the cell and output element which can be found *uniquely* in the notebook. // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\" // IPython event is triggered only after the cells have been serialised, which for // our purposes (turning an active figure into a static one), is too late. var cells = IPython.notebook.get_cells(); var ncells = cells.length; for (var i=0; i<ncells; i++) { var cell = cells[i]; if (cell.cell_type === 'code'){ for (var j=0; j<cell.output_area.outputs.length; j++) { var data = cell.output_area.outputs[j]; if (data.data) { // IPython >= 3 moved mimebundle to data attribute of output data = data.data; } if (data['text/html'] == html_output) { return [cell, data, j]; } } } } } // Register the function which deals with the matplotlib target/channel. // The kernel may be null if the page has been refreshed. if (IPython.notebook.kernel != null) { IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm); } 条形图 一般使用垂直条形图，如果类别很多则使用水平条形图。条形图用于处理定性数据。 垂直条形图 使用barh函数来绘制垂直条形图。 In [7]: import numpy as np fig , ax = plt . subplots () x = [ '北美洲' , '南美洲' , '欧洲' , '亚洲' , '大洋洲' , '非洲' , '南极洲' ] y = np . arange ( len ( x )) y_value = [ 1500 , 500 , 1500 , 2000 , 1000 , 500 , 1 ] ax . barh ( y , y_value , align = 'center' ) ax . set_yticks ( y ) ax . set_yticklabels ( x ) ax . set_xlabel ( '销量' ) var element = $('#615e88b5-abe5-43d2-8f6d-16dd303eeac8'); /* Put everything inside the global mpl namespace */ window.mpl = {}; mpl.get_websocket_type = function() { if (typeof(WebSocket) !== 'undefined') { return WebSocket; } else if (typeof(MozWebSocket) !== 'undefined') { return MozWebSocket; } else { alert('Your browser does not have WebSocket support.' + 'Please try Chrome, Safari or Firefox ≥ 6. ' + 'Firefox 4 and 5 are also supported but you ' + 'have to enable WebSockets in about:config.'); }; } mpl.figure = function(figure_id, websocket, ondownload, parent_element) { this.id = figure_id; this.ws = websocket; this.supports_binary = (this.ws.binaryType != undefined); if (!this.supports_binary) { var warnings = document.getElementById(\"mpl-warnings\"); if (warnings) { warnings.style.display = 'block'; warnings.textContent = ( \"This browser does not support binary websocket messages. \" + \"Performance may be slow.\"); } } this.imageObj = new Image(); this.context = undefined; this.message = undefined; this.canvas = undefined; this.rubberband_canvas = undefined; this.rubberband_context = undefined; this.format_dropdown = undefined; this.image_mode = 'full'; this.root = $('<div/>'); this._root_extra_style(this.root) this.root.attr('style', 'display: inline-block'); $(parent_element).append(this.root); this._init_header(this); this._init_canvas(this); this._init_toolbar(this); var fig = this; this.waiting = false; this.ws.onopen = function () { fig.send_message(\"supports_binary\", {value: fig.supports_binary}); fig.send_message(\"send_image_mode\", {}); if (mpl.ratio != 1) { fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio}); } fig.send_message(\"refresh\", {}); } this.imageObj.onload = function() { if (fig.image_mode == 'full') { // Full images could contain transparency (where diff images // almost always do), so we need to clear the canvas so that // there is no ghosting. fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height); } fig.context.drawImage(fig.imageObj, 0, 0); }; this.imageObj.onunload = function() { fig.ws.close(); } this.ws.onmessage = this._make_on_message_function(this); this.ondownload = ondownload; } mpl.figure.prototype._init_header = function() { var titlebar = $( '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' + 'ui-helper-clearfix\"/>'); var titletext = $( '<div class=\"ui-dialog-title\" style=\"width: 100%; ' + 'text-align: center; padding: 3px;\"/>'); titlebar.append(titletext) this.root.append(titlebar); this.header = titletext[0]; } mpl.figure.prototype._canvas_extra_style = function(canvas_div) { } mpl.figure.prototype._root_extra_style = function(canvas_div) { } mpl.figure.prototype._init_canvas = function() { var fig = this; var canvas_div = $('<div/>'); canvas_div.attr('style', 'position: relative; clear: both; outline: 0'); function canvas_keyboard_event(event) { return fig.key_event(event, event['data']); } canvas_div.keydown('key_press', canvas_keyboard_event); canvas_div.keyup('key_release', canvas_keyboard_event); this.canvas_div = canvas_div this._canvas_extra_style(canvas_div) this.root.append(canvas_div); var canvas = $('<canvas/>'); canvas.addClass('mpl-canvas'); canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\") this.canvas = canvas[0]; this.context = canvas[0].getContext(\"2d\"); var backingStore = this.context.backingStorePixelRatio || this.context.webkitBackingStorePixelRatio || this.context.mozBackingStorePixelRatio || this.context.msBackingStorePixelRatio || this.context.oBackingStorePixelRatio || this.context.backingStorePixelRatio || 1; mpl.ratio = (window.devicePixelRatio || 1) / backingStore; var rubberband = $('<canvas/>'); rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\") var pass_mouse_events = true; canvas_div.resizable({ start: function(event, ui) { pass_mouse_events = false; }, resize: function(event, ui) { fig.request_resize(ui.size.width, ui.size.height); }, stop: function(event, ui) { pass_mouse_events = true; fig.request_resize(ui.size.width, ui.size.height); }, }); function mouse_event_fn(event) { if (pass_mouse_events) return fig.mouse_event(event, event['data']); } rubberband.mousedown('button_press', mouse_event_fn); rubberband.mouseup('button_release', mouse_event_fn); // Throttle sequential mouse events to 1 every 20ms. rubberband.mousemove('motion_notify', mouse_event_fn); rubberband.mouseenter('figure_enter', mouse_event_fn); rubberband.mouseleave('figure_leave', mouse_event_fn); canvas_div.on(\"wheel\", function (event) { event = event.originalEvent; event['data'] = 'scroll' if (event.deltaY < 0) { event.step = 1; } else { event.step = -1; } mouse_event_fn(event); }); canvas_div.append(canvas); canvas_div.append(rubberband); this.rubberband = rubberband; this.rubberband_canvas = rubberband[0]; this.rubberband_context = rubberband[0].getContext(\"2d\"); this.rubberband_context.strokeStyle = \"#000000\"; this._resize_canvas = function(width, height) { // Keep the size of the canvas, canvas container, and rubber band // canvas in synch. canvas_div.css('width', width) canvas_div.css('height', height) canvas.attr('width', width * mpl.ratio); canvas.attr('height', height * mpl.ratio); canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;'); rubberband.attr('width', width); rubberband.attr('height', height); } // Set the figure to an initial 600x600px, this will subsequently be updated // upon first draw. this._resize_canvas(600, 600); // Disable right mouse context menu. $(this.rubberband_canvas).bind(\"contextmenu\",function(e){ return false; }); function set_focus () { canvas.focus(); canvas_div.focus(); } window.setTimeout(set_focus, 100); } mpl.figure.prototype._init_toolbar = function() { var fig = this; var nav_element = $('<div/>') nav_element.attr('style', 'width: 100%'); this.root.append(nav_element); // Define a callback function for later on. function toolbar_event(event) { return fig.toolbar_button_onclick(event['data']); } function toolbar_mouse_event(event) { return fig.toolbar_button_onmouseover(event['data']); } for(var toolbar_ind in mpl.toolbar_items) { var name = mpl.toolbar_items[toolbar_ind][0]; var tooltip = mpl.toolbar_items[toolbar_ind][1]; var image = mpl.toolbar_items[toolbar_ind][2]; var method_name = mpl.toolbar_items[toolbar_ind][3]; if (!name) { // put a spacer in here. continue; } var button = $('<button/>'); button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' + 'ui-button-icon-only'); button.attr('role', 'button'); button.attr('aria-disabled', 'false'); button.click(method_name, toolbar_event); button.mouseover(tooltip, toolbar_mouse_event); var icon_img = $('<span/>'); icon_img.addClass('ui-button-icon-primary ui-icon'); icon_img.addClass(image); icon_img.addClass('ui-corner-all'); var tooltip_span = $('<span/>'); tooltip_span.addClass('ui-button-text'); tooltip_span.html(tooltip); button.append(icon_img); button.append(tooltip_span); nav_element.append(button); } var fmt_picker_span = $('<span/>'); var fmt_picker = $('<select/>'); fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content'); fmt_picker_span.append(fmt_picker); nav_element.append(fmt_picker_span); this.format_dropdown = fmt_picker[0]; for (var ind in mpl.extensions) { var fmt = mpl.extensions[ind]; var option = $( '<option/>', {selected: fmt === mpl.default_extension}).html(fmt); fmt_picker.append(option) } // Add hover states to the ui-buttons $( \".ui-button\" ).hover( function() { $(this).addClass(\"ui-state-hover\");}, function() { $(this).removeClass(\"ui-state-hover\");} ); var status_bar = $('<span class=\"mpl-message\"/>'); nav_element.append(status_bar); this.message = status_bar[0]; } mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) { // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client, // which will in turn request a refresh of the image. this.send_message('resize', {'width': x_pixels, 'height': y_pixels}); } mpl.figure.prototype.send_message = function(type, properties) { properties['type'] = type; properties['figure_id'] = this.id; this.ws.send(JSON.stringify(properties)); } mpl.figure.prototype.send_draw_message = function() { if (!this.waiting) { this.waiting = true; this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id})); } } mpl.figure.prototype.handle_save = function(fig, msg) { var format_dropdown = fig.format_dropdown; var format = format_dropdown.options[format_dropdown.selectedIndex].value; fig.ondownload(fig, format); } mpl.figure.prototype.handle_resize = function(fig, msg) { var size = msg['size']; if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) { fig._resize_canvas(size[0], size[1]); fig.send_message(\"refresh\", {}); }; } mpl.figure.prototype.handle_rubberband = function(fig, msg) { var x0 = msg['x0'] / mpl.ratio; var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio; var x1 = msg['x1'] / mpl.ratio; var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio; x0 = Math.floor(x0) + 0.5; y0 = Math.floor(y0) + 0.5; x1 = Math.floor(x1) + 0.5; y1 = Math.floor(y1) + 0.5; var min_x = Math.min(x0, x1); var min_y = Math.min(y0, y1); var width = Math.abs(x1 - x0); var height = Math.abs(y1 - y0); fig.rubberband_context.clearRect( 0, 0, fig.canvas.width, fig.canvas.height); fig.rubberband_context.strokeRect(min_x, min_y, width, height); } mpl.figure.prototype.handle_figure_label = function(fig, msg) { // Updates the figure title. fig.header.textContent = msg['label']; } mpl.figure.prototype.handle_cursor = function(fig, msg) { var cursor = msg['cursor']; switch(cursor) { case 0: cursor = 'pointer'; break; case 1: cursor = 'default'; break; case 2: cursor = 'crosshair'; break; case 3: cursor = 'move'; break; } fig.rubberband_canvas.style.cursor = cursor; } mpl.figure.prototype.handle_message = function(fig, msg) { fig.message.textContent = msg['message']; } mpl.figure.prototype.handle_draw = function(fig, msg) { // Request the server to send over a new figure. fig.send_draw_message(); } mpl.figure.prototype.handle_image_mode = function(fig, msg) { fig.image_mode = msg['mode']; } mpl.figure.prototype.updated_canvas_event = function() { // Called whenever the canvas gets updated. this.send_message(\"ack\", {}); } // A function to construct a web socket function for onmessage handling. // Called in the figure constructor. mpl.figure.prototype._make_on_message_function = function(fig) { return function socket_on_message(evt) { if (evt.data instanceof Blob) { /* FIXME: We get \"Resource interpreted as Image but * transferred with MIME type text/plain:\" errors on * Chrome. But how to set the MIME type? It doesn't seem * to be part of the websocket stream */ evt.data.type = \"image/png\"; /* Free the memory for the previous frames */ if (fig.imageObj.src) { (window.URL || window.webkitURL).revokeObjectURL( fig.imageObj.src); } fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL( evt.data); fig.updated_canvas_event(); fig.waiting = false; return; } else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") { fig.imageObj.src = evt.data; fig.updated_canvas_event(); fig.waiting = false; return; } var msg = JSON.parse(evt.data); var msg_type = msg['type']; // Call the \"handle_{type}\" callback, which takes // the figure and JSON message as its only arguments. try { var callback = fig[\"handle_\" + msg_type]; } catch (e) { console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg); return; } if (callback) { try { // console.log(\"Handling '\" + msg_type + \"' message: \", msg); callback(fig, msg); } catch (e) { console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg); } } }; } // from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas mpl.findpos = function(e) { //this section is from http://www.quirksmode.org/js/events_properties.html var targ; if (!e) e = window.event; if (e.target) targ = e.target; else if (e.srcElement) targ = e.srcElement; if (targ.nodeType == 3) // defeat Safari bug targ = targ.parentNode; // jQuery normalizes the pageX and pageY // pageX,Y are the mouse positions relative to the document // offset() returns the position of the element relative to the document var x = e.pageX - $(targ).offset().left; var y = e.pageY - $(targ).offset().top; return {\"x\": x, \"y\": y}; }; /* * return a copy of an object with only non-object keys * we need this to avoid circular references * http://stackoverflow.com/a/24161582/3208463 */ function simpleKeys (original) { return Object.keys(original).reduce(function (obj, key) { if (typeof original[key] !== 'object') obj[key] = original[key] return obj; }, {}); } mpl.figure.prototype.mouse_event = function(event, name) { var canvas_pos = mpl.findpos(event) if (name === 'button_press') { this.canvas.focus(); this.canvas_div.focus(); } var x = canvas_pos.x * mpl.ratio; var y = canvas_pos.y * mpl.ratio; this.send_message(name, {x: x, y: y, button: event.button, step: event.step, guiEvent: simpleKeys(event)}); /* This prevents the web browser from automatically changing to * the text insertion cursor when the button is pressed. We want * to control all of the cursor setting manually through the * 'cursor' event from matplotlib */ event.preventDefault(); return false; } mpl.figure.prototype._key_event_extra = function(event, name) { // Handle any extra behaviour associated with a key event } mpl.figure.prototype.key_event = function(event, name) { // Prevent repeat events if (name == 'key_press') { if (event.which === this._key) return; else this._key = event.which; } if (name == 'key_release') this._key = null; var value = ''; if (event.ctrlKey && event.which != 17) value += \"ctrl+\"; if (event.altKey && event.which != 18) value += \"alt+\"; if (event.shiftKey && event.which != 16) value += \"shift+\"; value += 'k'; value += event.which.toString(); this._key_event_extra(event, name); this.send_message(name, {key: value, guiEvent: simpleKeys(event)}); return false; } mpl.figure.prototype.toolbar_button_onclick = function(name) { if (name == 'download') { this.handle_save(this, null); } else { this.send_message(\"toolbar_button\", {name: name}); } }; mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) { this.message.textContent = tooltip; }; mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]]; mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"]; mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) { // Create a \"websocket\"-like object which calls the given IPython comm // object with the appropriate methods. Currently this is a non binary // socket, so there is still some room for performance tuning. var ws = {}; ws.close = function() { comm.close() }; ws.send = function(m) { //console.log('sending', m); comm.send(m); }; // Register the callback with on_msg. comm.on_msg(function(msg) { //console.log('receiving', msg['content']['data'], msg); // Pass the mpl event to the overridden (by mpl) onmessage function. ws.onmessage(msg['content']['data']) }); return ws; } mpl.mpl_figure_comm = function(comm, msg) { // This is the function which gets called when the mpl process // starts-up an IPython Comm through the \"matplotlib\" channel. var id = msg.content.data.id; // Get hold of the div created by the display call when the Comm // socket was opened in Python. var element = $(\"#\" + id); var ws_proxy = comm_websocket_adapter(comm) function ondownload(figure, format) { window.open(figure.imageObj.src); } var fig = new mpl.figure(id, ws_proxy, ondownload, element.get(0)); // Call onopen now - mpl needs it, as it is assuming we've passed it a real // web socket which is closed, not our websocket->open comm proxy. ws_proxy.onopen(); fig.parent_element = element.get(0); fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\"); if (!fig.cell_info) { console.error(\"Failed to find cell for figure\", id, fig); return; } var output_index = fig.cell_info[2] var cell = fig.cell_info[0]; }; mpl.figure.prototype.handle_close = function(fig, msg) { var width = fig.canvas.width/mpl.ratio fig.root.unbind('remove') // Update the output cell to use the data from the current canvas. fig.push_to_output(); var dataURL = fig.canvas.toDataURL(); // Re-enable the keyboard manager in IPython - without this line, in FF, // the notebook keyboard shortcuts fail. IPython.keyboard_manager.enable() $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">'); fig.close_ws(fig, msg); } mpl.figure.prototype.close_ws = function(fig, msg){ fig.send_message('closing', msg); // fig.ws.close() } mpl.figure.prototype.push_to_output = function(remove_interactive) { // Turn the data on the canvas into data in the output cell. var width = this.canvas.width/mpl.ratio var dataURL = this.canvas.toDataURL(); this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">'; } mpl.figure.prototype.updated_canvas_event = function() { // Tell IPython that the notebook contents must change. IPython.notebook.set_dirty(true); this.send_message(\"ack\", {}); var fig = this; // Wait a second, then push the new image to the DOM so // that it is saved nicely (might be nice to debounce this). setTimeout(function () { fig.push_to_output() }, 1000); } mpl.figure.prototype._init_toolbar = function() { var fig = this; var nav_element = $('<div/>') nav_element.attr('style', 'width: 100%'); this.root.append(nav_element); // Define a callback function for later on. function toolbar_event(event) { return fig.toolbar_button_onclick(event['data']); } function toolbar_mouse_event(event) { return fig.toolbar_button_onmouseover(event['data']); } for(var toolbar_ind in mpl.toolbar_items){ var name = mpl.toolbar_items[toolbar_ind][0]; var tooltip = mpl.toolbar_items[toolbar_ind][1]; var image = mpl.toolbar_items[toolbar_ind][2]; var method_name = mpl.toolbar_items[toolbar_ind][3]; if (!name) { continue; }; var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>'); button.click(method_name, toolbar_event); button.mouseover(tooltip, toolbar_mouse_event); nav_element.append(button); } // Add the status bar. var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>'); nav_element.append(status_bar); this.message = status_bar[0]; // Add the close button to the window. var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>'); var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>'); button.click(function (evt) { fig.handle_close(fig, {}); } ); button.mouseover('Stop Interaction', toolbar_mouse_event); buttongrp.append(button); var titlebar = this.root.find($('.ui-dialog-titlebar')); titlebar.prepend(buttongrp); } mpl.figure.prototype._root_extra_style = function(el){ var fig = this el.on(\"remove\", function(){ fig.close_ws(fig, {}); }); } mpl.figure.prototype._canvas_extra_style = function(el){ // this is important to make the div 'focusable el.attr('tabindex', 0) // reach out to IPython and tell the keyboard manager to turn it's self // off when our div gets focus // location in version 3 if (IPython.notebook.keyboard_manager) { IPython.notebook.keyboard_manager.register_events(el); } else { // location in version 2 IPython.keyboard_manager.register_events(el); } } mpl.figure.prototype._key_event_extra = function(event, name) { var manager = IPython.notebook.keyboard_manager; if (!manager) manager = IPython.keyboard_manager; // Check for shift+enter if (event.shiftKey && event.which == 13) { this.canvas_div.blur(); event.shiftKey = false; // Send a \"J\" for go to next cell event.which = 74; event.keyCode = 74; manager.command_mode(); manager.handle_keydown(event); } } mpl.figure.prototype.handle_save = function(fig, msg) { fig.ondownload(fig, null); } mpl.find_output_cell = function(html_output) { // Return the cell and output element which can be found *uniquely* in the notebook. // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\" // IPython event is triggered only after the cells have been serialised, which for // our purposes (turning an active figure into a static one), is too late. var cells = IPython.notebook.get_cells(); var ncells = cells.length; for (var i=0; i<ncells; i++) { var cell = cells[i]; if (cell.cell_type === 'code'){ for (var j=0; j<cell.output_area.outputs.length; j++) { var data = cell.output_area.outputs[j]; if (data.data) { // IPython >= 3 moved mimebundle to data attribute of output data = data.data; } if (data['text/html'] == html_output) { return [cell, data, j]; } } } } } // Register the function which deals with the matplotlib target/channel. // The kernel may be null if the page has been refreshed. if (IPython.notebook.kernel != null) { IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm); } Out[7]: Text(0.5,0,'销量') In [62]: import pandas as pd import numpy as np fig , ax = plt . subplots () x = [ '北美洲' , '南美洲' , '欧洲' , '亚洲' , '大洋洲' , '非洲' , '南极洲' ] y_value = [ 1500 , 500 , 1500 , 2000 , 1000 , 500 , 1 ] data = pd . Series ( y_value , index = x ) data . plot . barh ( ax = ax ) var element = $('#cb4901c1-0895-44c8-a2bb-1e685d1647b7'); /* Put everything inside the global mpl namespace */ window.mpl = {}; mpl.get_websocket_type = function() { if (typeof(WebSocket) !== 'undefined') { return WebSocket; } else if (typeof(MozWebSocket) !== 'undefined') { return MozWebSocket; } else { alert('Your browser does not have WebSocket support.' + 'Please try Chrome, Safari or Firefox ≥ 6. ' + 'Firefox 4 and 5 are also supported but you ' + 'have to enable WebSockets in about:config.'); }; } mpl.figure = function(figure_id, websocket, ondownload, parent_element) { this.id = figure_id; this.ws = websocket; this.supports_binary = (this.ws.binaryType != undefined); if (!this.supports_binary) { var warnings = document.getElementById(\"mpl-warnings\"); if (warnings) { warnings.style.display = 'block'; warnings.textContent = ( \"This browser does not support binary websocket messages. \" + \"Performance may be slow.\"); } } this.imageObj = new Image(); this.context = undefined; this.message = undefined; this.canvas = undefined; this.rubberband_canvas = undefined; this.rubberband_context = undefined; this.format_dropdown = undefined; this.image_mode = 'full'; this.root = $('<div/>'); this._root_extra_style(this.root) this.root.attr('style', 'display: inline-block'); $(parent_element).append(this.root); this._init_header(this); this._init_canvas(this); this._init_toolbar(this); var fig = this; this.waiting = false; this.ws.onopen = function () { fig.send_message(\"supports_binary\", {value: fig.supports_binary}); fig.send_message(\"send_image_mode\", {}); if (mpl.ratio != 1) { fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio}); } fig.send_message(\"refresh\", {}); } this.imageObj.onload = function() { if (fig.image_mode == 'full') { // Full images could contain transparency (where diff images // almost always do), so we need to clear the canvas so that // there is no ghosting. fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height); } fig.context.drawImage(fig.imageObj, 0, 0); }; this.imageObj.onunload = function() { fig.ws.close(); } this.ws.onmessage = this._make_on_message_function(this); this.ondownload = ondownload; } mpl.figure.prototype._init_header = function() { var titlebar = $( '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' + 'ui-helper-clearfix\"/>'); var titletext = $( '<div class=\"ui-dialog-title\" style=\"width: 100%; ' + 'text-align: center; padding: 3px;\"/>'); titlebar.append(titletext) this.root.append(titlebar); this.header = titletext[0]; } mpl.figure.prototype._canvas_extra_style = function(canvas_div) { } mpl.figure.prototype._root_extra_style = function(canvas_div) { } mpl.figure.prototype._init_canvas = function() { var fig = this; var canvas_div = $('<div/>'); canvas_div.attr('style', 'position: relative; clear: both; outline: 0'); function canvas_keyboard_event(event) { return fig.key_event(event, event['data']); } canvas_div.keydown('key_press', canvas_keyboard_event); canvas_div.keyup('key_release', canvas_keyboard_event); this.canvas_div = canvas_div this._canvas_extra_style(canvas_div) this.root.append(canvas_div); var canvas = $('<canvas/>'); canvas.addClass('mpl-canvas'); canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\") this.canvas = canvas[0]; this.context = canvas[0].getContext(\"2d\"); var backingStore = this.context.backingStorePixelRatio || this.context.webkitBackingStorePixelRatio || this.context.mozBackingStorePixelRatio || this.context.msBackingStorePixelRatio || this.context.oBackingStorePixelRatio || this.context.backingStorePixelRatio || 1; mpl.ratio = (window.devicePixelRatio || 1) / backingStore; var rubberband = $('<canvas/>'); rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\") var pass_mouse_events = true; canvas_div.resizable({ start: function(event, ui) { pass_mouse_events = false; }, resize: function(event, ui) { fig.request_resize(ui.size.width, ui.size.height); }, stop: function(event, ui) { pass_mouse_events = true; fig.request_resize(ui.size.width, ui.size.height); }, }); function mouse_event_fn(event) { if (pass_mouse_events) return fig.mouse_event(event, event['data']); } rubberband.mousedown('button_press', mouse_event_fn); rubberband.mouseup('button_release', mouse_event_fn); // Throttle sequential mouse events to 1 every 20ms. rubberband.mousemove('motion_notify', mouse_event_fn); rubberband.mouseenter('figure_enter', mouse_event_fn); rubberband.mouseleave('figure_leave', mouse_event_fn); canvas_div.on(\"wheel\", function (event) { event = event.originalEvent; event['data'] = 'scroll' if (event.deltaY < 0) { event.step = 1; } else { event.step = -1; } mouse_event_fn(event); }); canvas_div.append(canvas); canvas_div.append(rubberband); this.rubberband = rubberband; this.rubberband_canvas = rubberband[0]; this.rubberband_context = rubberband[0].getContext(\"2d\"); this.rubberband_context.strokeStyle = \"#000000\"; this._resize_canvas = function(width, height) { // Keep the size of the canvas, canvas container, and rubber band // canvas in synch. canvas_div.css('width', width) canvas_div.css('height', height) canvas.attr('width', width * mpl.ratio); canvas.attr('height', height * mpl.ratio); canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;'); rubberband.attr('width', width); rubberband.attr('height', height); } // Set the figure to an initial 600x600px, this will subsequently be updated // upon first draw. this._resize_canvas(600, 600); // Disable right mouse context menu. $(this.rubberband_canvas).bind(\"contextmenu\",function(e){ return false; }); function set_focus () { canvas.focus(); canvas_div.focus(); } window.setTimeout(set_focus, 100); } mpl.figure.prototype._init_toolbar = function() { var fig = this; var nav_element = $('<div/>') nav_element.attr('style', 'width: 100%'); this.root.append(nav_element); // Define a callback function for later on. function toolbar_event(event) { return fig.toolbar_button_onclick(event['data']); } function toolbar_mouse_event(event) { return fig.toolbar_button_onmouseover(event['data']); } for(var toolbar_ind in mpl.toolbar_items) { var name = mpl.toolbar_items[toolbar_ind][0]; var tooltip = mpl.toolbar_items[toolbar_ind][1]; var image = mpl.toolbar_items[toolbar_ind][2]; var method_name = mpl.toolbar_items[toolbar_ind][3]; if (!name) { // put a spacer in here. continue; } var button = $('<button/>'); button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' + 'ui-button-icon-only'); button.attr('role', 'button'); button.attr('aria-disabled', 'false'); button.click(method_name, toolbar_event); button.mouseover(tooltip, toolbar_mouse_event); var icon_img = $('<span/>'); icon_img.addClass('ui-button-icon-primary ui-icon'); icon_img.addClass(image); icon_img.addClass('ui-corner-all'); var tooltip_span = $('<span/>'); tooltip_span.addClass('ui-button-text'); tooltip_span.html(tooltip); button.append(icon_img); button.append(tooltip_span); nav_element.append(button); } var fmt_picker_span = $('<span/>'); var fmt_picker = $('<select/>'); fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content'); fmt_picker_span.append(fmt_picker); nav_element.append(fmt_picker_span); this.format_dropdown = fmt_picker[0]; for (var ind in mpl.extensions) { var fmt = mpl.extensions[ind]; var option = $( '<option/>', {selected: fmt === mpl.default_extension}).html(fmt); fmt_picker.append(option) } // Add hover states to the ui-buttons $( \".ui-button\" ).hover( function() { $(this).addClass(\"ui-state-hover\");}, function() { $(this).removeClass(\"ui-state-hover\");} ); var status_bar = $('<span class=\"mpl-message\"/>'); nav_element.append(status_bar); this.message = status_bar[0]; } mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) { // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client, // which will in turn request a refresh of the image. this.send_message('resize', {'width': x_pixels, 'height': y_pixels}); } mpl.figure.prototype.send_message = function(type, properties) { properties['type'] = type; properties['figure_id'] = this.id; this.ws.send(JSON.stringify(properties)); } mpl.figure.prototype.send_draw_message = function() { if (!this.waiting) { this.waiting = true; this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id})); } } mpl.figure.prototype.handle_save = function(fig, msg) { var format_dropdown = fig.format_dropdown; var format = format_dropdown.options[format_dropdown.selectedIndex].value; fig.ondownload(fig, format); } mpl.figure.prototype.handle_resize = function(fig, msg) { var size = msg['size']; if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) { fig._resize_canvas(size[0], size[1]); fig.send_message(\"refresh\", {}); }; } mpl.figure.prototype.handle_rubberband = function(fig, msg) { var x0 = msg['x0'] / mpl.ratio; var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio; var x1 = msg['x1'] / mpl.ratio; var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio; x0 = Math.floor(x0) + 0.5; y0 = Math.floor(y0) + 0.5; x1 = Math.floor(x1) + 0.5; y1 = Math.floor(y1) + 0.5; var min_x = Math.min(x0, x1); var min_y = Math.min(y0, y1); var width = Math.abs(x1 - x0); var height = Math.abs(y1 - y0); fig.rubberband_context.clearRect( 0, 0, fig.canvas.width, fig.canvas.height); fig.rubberband_context.strokeRect(min_x, min_y, width, height); } mpl.figure.prototype.handle_figure_label = function(fig, msg) { // Updates the figure title. fig.header.textContent = msg['label']; } mpl.figure.prototype.handle_cursor = function(fig, msg) { var cursor = msg['cursor']; switch(cursor) { case 0: cursor = 'pointer'; break; case 1: cursor = 'default'; break; case 2: cursor = 'crosshair'; break; case 3: cursor = 'move'; break; } fig.rubberband_canvas.style.cursor = cursor; } mpl.figure.prototype.handle_message = function(fig, msg) { fig.message.textContent = msg['message']; } mpl.figure.prototype.handle_draw = function(fig, msg) { // Request the server to send over a new figure. fig.send_draw_message(); } mpl.figure.prototype.handle_image_mode = function(fig, msg) { fig.image_mode = msg['mode']; } mpl.figure.prototype.updated_canvas_event = function() { // Called whenever the canvas gets updated. this.send_message(\"ack\", {}); } // A function to construct a web socket function for onmessage handling. // Called in the figure constructor. mpl.figure.prototype._make_on_message_function = function(fig) { return function socket_on_message(evt) { if (evt.data instanceof Blob) { /* FIXME: We get \"Resource interpreted as Image but * transferred with MIME type text/plain:\" errors on * Chrome. But how to set the MIME type? It doesn't seem * to be part of the websocket stream */ evt.data.type = \"image/png\"; /* Free the memory for the previous frames */ if (fig.imageObj.src) { (window.URL || window.webkitURL).revokeObjectURL( fig.imageObj.src); } fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL( evt.data); fig.updated_canvas_event(); fig.waiting = false; return; } else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") { fig.imageObj.src = evt.data; fig.updated_canvas_event(); fig.waiting = false; return; } var msg = JSON.parse(evt.data); var msg_type = msg['type']; // Call the \"handle_{type}\" callback, which takes // the figure and JSON message as its only arguments. try { var callback = fig[\"handle_\" + msg_type]; } catch (e) { console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg); return; } if (callback) { try { // console.log(\"Handling '\" + msg_type + \"' message: \", msg); callback(fig, msg); } catch (e) { console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg); } } }; } // from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas mpl.findpos = function(e) { //this section is from http://www.quirksmode.org/js/events_properties.html var targ; if (!e) e = window.event; if (e.target) targ = e.target; else if (e.srcElement) targ = e.srcElement; if (targ.nodeType == 3) // defeat Safari bug targ = targ.parentNode; // jQuery normalizes the pageX and pageY // pageX,Y are the mouse positions relative to the document // offset() returns the position of the element relative to the document var x = e.pageX - $(targ).offset().left; var y = e.pageY - $(targ).offset().top; return {\"x\": x, \"y\": y}; }; /* * return a copy of an object with only non-object keys * we need this to avoid circular references * http://stackoverflow.com/a/24161582/3208463 */ function simpleKeys (original) { return Object.keys(original).reduce(function (obj, key) { if (typeof original[key] !== 'object') obj[key] = original[key] return obj; }, {}); } mpl.figure.prototype.mouse_event = function(event, name) { var canvas_pos = mpl.findpos(event) if (name === 'button_press') { this.canvas.focus(); this.canvas_div.focus(); } var x = canvas_pos.x * mpl.ratio; var y = canvas_pos.y * mpl.ratio; this.send_message(name, {x: x, y: y, button: event.button, step: event.step, guiEvent: simpleKeys(event)}); /* This prevents the web browser from automatically changing to * the text insertion cursor when the button is pressed. We want * to control all of the cursor setting manually through the * 'cursor' event from matplotlib */ event.preventDefault(); return false; } mpl.figure.prototype._key_event_extra = function(event, name) { // Handle any extra behaviour associated with a key event } mpl.figure.prototype.key_event = function(event, name) { // Prevent repeat events if (name == 'key_press') { if (event.which === this._key) return; else this._key = event.which; } if (name == 'key_release') this._key = null; var value = ''; if (event.ctrlKey && event.which != 17) value += \"ctrl+\"; if (event.altKey && event.which != 18) value += \"alt+\"; if (event.shiftKey && event.which != 16) value += \"shift+\"; value += 'k'; value += event.which.toString(); this._key_event_extra(event, name); this.send_message(name, {key: value, guiEvent: simpleKeys(event)}); return false; } mpl.figure.prototype.toolbar_button_onclick = function(name) { if (name == 'download') { this.handle_save(this, null); } else { this.send_message(\"toolbar_button\", {name: name}); } }; mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) { this.message.textContent = tooltip; }; mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]]; mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"]; mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) { // Create a \"websocket\"-like object which calls the given IPython comm // object with the appropriate methods. Currently this is a non binary // socket, so there is still some room for performance tuning. var ws = {}; ws.close = function() { comm.close() }; ws.send = function(m) { //console.log('sending', m); comm.send(m); }; // Register the callback with on_msg. comm.on_msg(function(msg) { //console.log('receiving', msg['content']['data'], msg); // Pass the mpl event to the overriden (by mpl) onmessage function. ws.onmessage(msg['content']['data']) }); return ws; } mpl.mpl_figure_comm = function(comm, msg) { // This is the function which gets called when the mpl process // starts-up an IPython Comm through the \"matplotlib\" channel. var id = msg.content.data.id; // Get hold of the div created by the display call when the Comm // socket was opened in Python. var element = $(\"#\" + id); var ws_proxy = comm_websocket_adapter(comm) function ondownload(figure, format) { window.open(figure.imageObj.src); } var fig = new mpl.figure(id, ws_proxy, ondownload, element.get(0)); // Call onopen now - mpl needs it, as it is assuming we've passed it a real // web socket which is closed, not our websocket->open comm proxy. ws_proxy.onopen(); fig.parent_element = element.get(0); fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\"); if (!fig.cell_info) { console.error(\"Failed to find cell for figure\", id, fig); return; } var output_index = fig.cell_info[2] var cell = fig.cell_info[0]; }; mpl.figure.prototype.handle_close = function(fig, msg) { var width = fig.canvas.width/mpl.ratio fig.root.unbind('remove') // Update the output cell to use the data from the current canvas. fig.push_to_output(); var dataURL = fig.canvas.toDataURL(); // Re-enable the keyboard manager in IPython - without this line, in FF, // the notebook keyboard shortcuts fail. IPython.keyboard_manager.enable() $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">'); fig.close_ws(fig, msg); } mpl.figure.prototype.close_ws = function(fig, msg){ fig.send_message('closing', msg); // fig.ws.close() } mpl.figure.prototype.push_to_output = function(remove_interactive) { // Turn the data on the canvas into data in the output cell. var width = this.canvas.width/mpl.ratio var dataURL = this.canvas.toDataURL(); this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">'; } mpl.figure.prototype.updated_canvas_event = function() { // Tell IPython that the notebook contents must change. IPython.notebook.set_dirty(true); this.send_message(\"ack\", {}); var fig = this; // Wait a second, then push the new image to the DOM so // that it is saved nicely (might be nice to debounce this). setTimeout(function () { fig.push_to_output() }, 1000); } mpl.figure.prototype._init_toolbar = function() { var fig = this; var nav_element = $('<div/>') nav_element.attr('style', 'width: 100%'); this.root.append(nav_element); // Define a callback function for later on. function toolbar_event(event) { return fig.toolbar_button_onclick(event['data']); } function toolbar_mouse_event(event) { return fig.toolbar_button_onmouseover(event['data']); } for(var toolbar_ind in mpl.toolbar_items){ var name = mpl.toolbar_items[toolbar_ind][0]; var tooltip = mpl.toolbar_items[toolbar_ind][1]; var image = mpl.toolbar_items[toolbar_ind][2]; var method_name = mpl.toolbar_items[toolbar_ind][3]; if (!name) { continue; }; var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>'); button.click(method_name, toolbar_event); button.mouseover(tooltip, toolbar_mouse_event); nav_element.append(button); } // Add the status bar. var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>'); nav_element.append(status_bar); this.message = status_bar[0]; // Add the close button to the window. var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>'); var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>'); button.click(function (evt) { fig.handle_close(fig, {}); } ); button.mouseover('Stop Interaction', toolbar_mouse_event); buttongrp.append(button); var titlebar = this.root.find($('.ui-dialog-titlebar')); titlebar.prepend(buttongrp); } mpl.figure.prototype._root_extra_style = function(el){ var fig = this el.on(\"remove\", function(){ fig.close_ws(fig, {}); }); } mpl.figure.prototype._canvas_extra_style = function(el){ // this is important to make the div 'focusable el.attr('tabindex', 0) // reach out to IPython and tell the keyboard manager to turn it's self // off when our div gets focus // location in version 3 if (IPython.notebook.keyboard_manager) { IPython.notebook.keyboard_manager.register_events(el); } else { // location in version 2 IPython.keyboard_manager.register_events(el); } } mpl.figure.prototype._key_event_extra = function(event, name) { var manager = IPython.notebook.keyboard_manager; if (!manager) manager = IPython.keyboard_manager; // Check for shift+enter if (event.shiftKey && event.which == 13) { this.canvas_div.blur(); event.shiftKey = false; // Send a \"J\" for go to next cell event.which = 74; event.keyCode = 74; manager.command_mode(); manager.handle_keydown(event); } } mpl.figure.prototype.handle_save = function(fig, msg) { fig.ondownload(fig, null); } mpl.find_output_cell = function(html_output) { // Return the cell and output element which can be found *uniquely* in the notebook. // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\" // IPython event is triggered only after the cells have been serialised, which for // our purposes (turning an active figure into a static one), is too late. var cells = IPython.notebook.get_cells(); var ncells = cells.length; for (var i=0; i<ncells; i++) { var cell = cells[i]; if (cell.cell_type === 'code'){ for (var j=0; j<cell.output_area.outputs.length; j++) { var data = cell.output_area.outputs[j]; if (data.data) { // IPython >= 3 moved mimebundle to data attribute of output data = data.data; } if (data['text/html'] == html_output) { return [cell, data, j]; } } } } } // Register the function which deals with the matplotlib target/channel. // The kernel may be null if the page has been refreshed. if (IPython.notebook.kernel != null) { IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm); } Out[62]: <matplotlib.axes._subplots.AxesSubplot at 0x237ffb46048> 直方图 直方图用于处理定量数据的分组显示需求。直方图各长方形之间没有间隔。 In [8]: x = [ 5 , 29 , 56 , 17 , 3 ] fig , ax = plt . subplots () bins = [ 0 , 200 , 400 , 600 , 800 , 1000 ] n , bins , patches = ax . hist ( bins [: - 1 ], bins = bins , weights = x ) ax . set_xlabel ( '得分' ) ax . set_ylabel ( '频数' ) plt . title ( '各种游戏得分' ) plt . show () var element = $('#5686c131-6f49-481f-ab1f-8a2f2c3ef3b1'); /* Put everything inside the global mpl namespace */ window.mpl = {}; mpl.get_websocket_type = function() { if (typeof(WebSocket) !== 'undefined') { return WebSocket; } else if (typeof(MozWebSocket) !== 'undefined') { return MozWebSocket; } else { alert('Your browser does not have WebSocket support.' + 'Please try Chrome, Safari or Firefox ≥ 6. ' + 'Firefox 4 and 5 are also supported but you ' + 'have to enable WebSockets in about:config.'); }; } mpl.figure = function(figure_id, websocket, ondownload, parent_element) { this.id = figure_id; this.ws = websocket; this.supports_binary = (this.ws.binaryType != undefined); if (!this.supports_binary) { var warnings = document.getElementById(\"mpl-warnings\"); if (warnings) { warnings.style.display = 'block'; warnings.textContent = ( \"This browser does not support binary websocket messages. \" + \"Performance may be slow.\"); } } this.imageObj = new Image(); this.context = undefined; this.message = undefined; this.canvas = undefined; this.rubberband_canvas = undefined; this.rubberband_context = undefined; this.format_dropdown = undefined; this.image_mode = 'full'; this.root = $('<div/>'); this._root_extra_style(this.root) this.root.attr('style', 'display: inline-block'); $(parent_element).append(this.root); this._init_header(this); this._init_canvas(this); this._init_toolbar(this); var fig = this; this.waiting = false; this.ws.onopen = function () { fig.send_message(\"supports_binary\", {value: fig.supports_binary}); fig.send_message(\"send_image_mode\", {}); if (mpl.ratio != 1) { fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio}); } fig.send_message(\"refresh\", {}); } this.imageObj.onload = function() { if (fig.image_mode == 'full') { // Full images could contain transparency (where diff images // almost always do), so we need to clear the canvas so that // there is no ghosting. fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height); } fig.context.drawImage(fig.imageObj, 0, 0); }; this.imageObj.onunload = function() { fig.ws.close(); } this.ws.onmessage = this._make_on_message_function(this); this.ondownload = ondownload; } mpl.figure.prototype._init_header = function() { var titlebar = $( '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' + 'ui-helper-clearfix\"/>'); var titletext = $( '<div class=\"ui-dialog-title\" style=\"width: 100%; ' + 'text-align: center; padding: 3px;\"/>'); titlebar.append(titletext) this.root.append(titlebar); this.header = titletext[0]; } mpl.figure.prototype._canvas_extra_style = function(canvas_div) { } mpl.figure.prototype._root_extra_style = function(canvas_div) { } mpl.figure.prototype._init_canvas = function() { var fig = this; var canvas_div = $('<div/>'); canvas_div.attr('style', 'position: relative; clear: both; outline: 0'); function canvas_keyboard_event(event) { return fig.key_event(event, event['data']); } canvas_div.keydown('key_press', canvas_keyboard_event); canvas_div.keyup('key_release', canvas_keyboard_event); this.canvas_div = canvas_div this._canvas_extra_style(canvas_div) this.root.append(canvas_div); var canvas = $('<canvas/>'); canvas.addClass('mpl-canvas'); canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\") this.canvas = canvas[0]; this.context = canvas[0].getContext(\"2d\"); var backingStore = this.context.backingStorePixelRatio || this.context.webkitBackingStorePixelRatio || this.context.mozBackingStorePixelRatio || this.context.msBackingStorePixelRatio || this.context.oBackingStorePixelRatio || this.context.backingStorePixelRatio || 1; mpl.ratio = (window.devicePixelRatio || 1) / backingStore; var rubberband = $('<canvas/>'); rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\") var pass_mouse_events = true; canvas_div.resizable({ start: function(event, ui) { pass_mouse_events = false; }, resize: function(event, ui) { fig.request_resize(ui.size.width, ui.size.height); }, stop: function(event, ui) { pass_mouse_events = true; fig.request_resize(ui.size.width, ui.size.height); }, }); function mouse_event_fn(event) { if (pass_mouse_events) return fig.mouse_event(event, event['data']); } rubberband.mousedown('button_press', mouse_event_fn); rubberband.mouseup('button_release', mouse_event_fn); // Throttle sequential mouse events to 1 every 20ms. rubberband.mousemove('motion_notify', mouse_event_fn); rubberband.mouseenter('figure_enter', mouse_event_fn); rubberband.mouseleave('figure_leave', mouse_event_fn); canvas_div.on(\"wheel\", function (event) { event = event.originalEvent; event['data'] = 'scroll' if (event.deltaY < 0) { event.step = 1; } else { event.step = -1; } mouse_event_fn(event); }); canvas_div.append(canvas); canvas_div.append(rubberband); this.rubberband = rubberband; this.rubberband_canvas = rubberband[0]; this.rubberband_context = rubberband[0].getContext(\"2d\"); this.rubberband_context.strokeStyle = \"#000000\"; this._resize_canvas = function(width, height) { // Keep the size of the canvas, canvas container, and rubber band // canvas in synch. canvas_div.css('width', width) canvas_div.css('height', height) canvas.attr('width', width * mpl.ratio); canvas.attr('height', height * mpl.ratio); canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;'); rubberband.attr('width', width); rubberband.attr('height', height); } // Set the figure to an initial 600x600px, this will subsequently be updated // upon first draw. this._resize_canvas(600, 600); // Disable right mouse context menu. $(this.rubberband_canvas).bind(\"contextmenu\",function(e){ return false; }); function set_focus () { canvas.focus(); canvas_div.focus(); } window.setTimeout(set_focus, 100); } mpl.figure.prototype._init_toolbar = function() { var fig = this; var nav_element = $('<div/>') nav_element.attr('style', 'width: 100%'); this.root.append(nav_element); // Define a callback function for later on. function toolbar_event(event) { return fig.toolbar_button_onclick(event['data']); } function toolbar_mouse_event(event) { return fig.toolbar_button_onmouseover(event['data']); } for(var toolbar_ind in mpl.toolbar_items) { var name = mpl.toolbar_items[toolbar_ind][0]; var tooltip = mpl.toolbar_items[toolbar_ind][1]; var image = mpl.toolbar_items[toolbar_ind][2]; var method_name = mpl.toolbar_items[toolbar_ind][3]; if (!name) { // put a spacer in here. continue; } var button = $('<button/>'); button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' + 'ui-button-icon-only'); button.attr('role', 'button'); button.attr('aria-disabled', 'false'); button.click(method_name, toolbar_event); button.mouseover(tooltip, toolbar_mouse_event); var icon_img = $('<span/>'); icon_img.addClass('ui-button-icon-primary ui-icon'); icon_img.addClass(image); icon_img.addClass('ui-corner-all'); var tooltip_span = $('<span/>'); tooltip_span.addClass('ui-button-text'); tooltip_span.html(tooltip); button.append(icon_img); button.append(tooltip_span); nav_element.append(button); } var fmt_picker_span = $('<span/>'); var fmt_picker = $('<select/>'); fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content'); fmt_picker_span.append(fmt_picker); nav_element.append(fmt_picker_span); this.format_dropdown = fmt_picker[0]; for (var ind in mpl.extensions) { var fmt = mpl.extensions[ind]; var option = $( '<option/>', {selected: fmt === mpl.default_extension}).html(fmt); fmt_picker.append(option) } // Add hover states to the ui-buttons $( \".ui-button\" ).hover( function() { $(this).addClass(\"ui-state-hover\");}, function() { $(this).removeClass(\"ui-state-hover\");} ); var status_bar = $('<span class=\"mpl-message\"/>'); nav_element.append(status_bar); this.message = status_bar[0]; } mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) { // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client, // which will in turn request a refresh of the image. this.send_message('resize', {'width': x_pixels, 'height': y_pixels}); } mpl.figure.prototype.send_message = function(type, properties) { properties['type'] = type; properties['figure_id'] = this.id; this.ws.send(JSON.stringify(properties)); } mpl.figure.prototype.send_draw_message = function() { if (!this.waiting) { this.waiting = true; this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id})); } } mpl.figure.prototype.handle_save = function(fig, msg) { var format_dropdown = fig.format_dropdown; var format = format_dropdown.options[format_dropdown.selectedIndex].value; fig.ondownload(fig, format); } mpl.figure.prototype.handle_resize = function(fig, msg) { var size = msg['size']; if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) { fig._resize_canvas(size[0], size[1]); fig.send_message(\"refresh\", {}); }; } mpl.figure.prototype.handle_rubberband = function(fig, msg) { var x0 = msg['x0'] / mpl.ratio; var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio; var x1 = msg['x1'] / mpl.ratio; var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio; x0 = Math.floor(x0) + 0.5; y0 = Math.floor(y0) + 0.5; x1 = Math.floor(x1) + 0.5; y1 = Math.floor(y1) + 0.5; var min_x = Math.min(x0, x1); var min_y = Math.min(y0, y1); var width = Math.abs(x1 - x0); var height = Math.abs(y1 - y0); fig.rubberband_context.clearRect( 0, 0, fig.canvas.width, fig.canvas.height); fig.rubberband_context.strokeRect(min_x, min_y, width, height); } mpl.figure.prototype.handle_figure_label = function(fig, msg) { // Updates the figure title. fig.header.textContent = msg['label']; } mpl.figure.prototype.handle_cursor = function(fig, msg) { var cursor = msg['cursor']; switch(cursor) { case 0: cursor = 'pointer'; break; case 1: cursor = 'default'; break; case 2: cursor = 'crosshair'; break; case 3: cursor = 'move'; break; } fig.rubberband_canvas.style.cursor = cursor; } mpl.figure.prototype.handle_message = function(fig, msg) { fig.message.textContent = msg['message']; } mpl.figure.prototype.handle_draw = function(fig, msg) { // Request the server to send over a new figure. fig.send_draw_message(); } mpl.figure.prototype.handle_image_mode = function(fig, msg) { fig.image_mode = msg['mode']; } mpl.figure.prototype.updated_canvas_event = function() { // Called whenever the canvas gets updated. this.send_message(\"ack\", {}); } // A function to construct a web socket function for onmessage handling. // Called in the figure constructor. mpl.figure.prototype._make_on_message_function = function(fig) { return function socket_on_message(evt) { if (evt.data instanceof Blob) { /* FIXME: We get \"Resource interpreted as Image but * transferred with MIME type text/plain:\" errors on * Chrome. But how to set the MIME type? It doesn't seem * to be part of the websocket stream */ evt.data.type = \"image/png\"; /* Free the memory for the previous frames */ if (fig.imageObj.src) { (window.URL || window.webkitURL).revokeObjectURL( fig.imageObj.src); } fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL( evt.data); fig.updated_canvas_event(); fig.waiting = false; return; } else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") { fig.imageObj.src = evt.data; fig.updated_canvas_event(); fig.waiting = false; return; } var msg = JSON.parse(evt.data); var msg_type = msg['type']; // Call the \"handle_{type}\" callback, which takes // the figure and JSON message as its only arguments. try { var callback = fig[\"handle_\" + msg_type]; } catch (e) { console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg); return; } if (callback) { try { // console.log(\"Handling '\" + msg_type + \"' message: \", msg); callback(fig, msg); } catch (e) { console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg); } } }; } // from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas mpl.findpos = function(e) { //this section is from http://www.quirksmode.org/js/events_properties.html var targ; if (!e) e = window.event; if (e.target) targ = e.target; else if (e.srcElement) targ = e.srcElement; if (targ.nodeType == 3) // defeat Safari bug targ = targ.parentNode; // jQuery normalizes the pageX and pageY // pageX,Y are the mouse positions relative to the document // offset() returns the position of the element relative to the document var x = e.pageX - $(targ).offset().left; var y = e.pageY - $(targ).offset().top; return {\"x\": x, \"y\": y}; }; /* * return a copy of an object with only non-object keys * we need this to avoid circular references * http://stackoverflow.com/a/24161582/3208463 */ function simpleKeys (original) { return Object.keys(original).reduce(function (obj, key) { if (typeof original[key] !== 'object') obj[key] = original[key] return obj; }, {}); } mpl.figure.prototype.mouse_event = function(event, name) { var canvas_pos = mpl.findpos(event) if (name === 'button_press') { this.canvas.focus(); this.canvas_div.focus(); } var x = canvas_pos.x * mpl.ratio; var y = canvas_pos.y * mpl.ratio; this.send_message(name, {x: x, y: y, button: event.button, step: event.step, guiEvent: simpleKeys(event)}); /* This prevents the web browser from automatically changing to * the text insertion cursor when the button is pressed. We want * to control all of the cursor setting manually through the * 'cursor' event from matplotlib */ event.preventDefault(); return false; } mpl.figure.prototype._key_event_extra = function(event, name) { // Handle any extra behaviour associated with a key event } mpl.figure.prototype.key_event = function(event, name) { // Prevent repeat events if (name == 'key_press') { if (event.which === this._key) return; else this._key = event.which; } if (name == 'key_release') this._key = null; var value = ''; if (event.ctrlKey && event.which != 17) value += \"ctrl+\"; if (event.altKey && event.which != 18) value += \"alt+\"; if (event.shiftKey && event.which != 16) value += \"shift+\"; value += 'k'; value += event.which.toString(); this._key_event_extra(event, name); this.send_message(name, {key: value, guiEvent: simpleKeys(event)}); return false; } mpl.figure.prototype.toolbar_button_onclick = function(name) { if (name == 'download') { this.handle_save(this, null); } else { this.send_message(\"toolbar_button\", {name: name}); } }; mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) { this.message.textContent = tooltip; }; mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]]; mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"]; mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) { // Create a \"websocket\"-like object which calls the given IPython comm // object with the appropriate methods. Currently this is a non binary // socket, so there is still some room for performance tuning. var ws = {}; ws.close = function() { comm.close() }; ws.send = function(m) { //console.log('sending', m); comm.send(m); }; // Register the callback with on_msg. comm.on_msg(function(msg) { //console.log('receiving', msg['content']['data'], msg); // Pass the mpl event to the overridden (by mpl) onmessage function. ws.onmessage(msg['content']['data']) }); return ws; } mpl.mpl_figure_comm = function(comm, msg) { // This is the function which gets called when the mpl process // starts-up an IPython Comm through the \"matplotlib\" channel. var id = msg.content.data.id; // Get hold of the div created by the display call when the Comm // socket was opened in Python. var element = $(\"#\" + id); var ws_proxy = comm_websocket_adapter(comm) function ondownload(figure, format) { window.open(figure.imageObj.src); } var fig = new mpl.figure(id, ws_proxy, ondownload, element.get(0)); // Call onopen now - mpl needs it, as it is assuming we've passed it a real // web socket which is closed, not our websocket->open comm proxy. ws_proxy.onopen(); fig.parent_element = element.get(0); fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\"); if (!fig.cell_info) { console.error(\"Failed to find cell for figure\", id, fig); return; } var output_index = fig.cell_info[2] var cell = fig.cell_info[0]; }; mpl.figure.prototype.handle_close = function(fig, msg) { var width = fig.canvas.width/mpl.ratio fig.root.unbind('remove') // Update the output cell to use the data from the current canvas. fig.push_to_output(); var dataURL = fig.canvas.toDataURL(); // Re-enable the keyboard manager in IPython - without this line, in FF, // the notebook keyboard shortcuts fail. IPython.keyboard_manager.enable() $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">'); fig.close_ws(fig, msg); } mpl.figure.prototype.close_ws = function(fig, msg){ fig.send_message('closing', msg); // fig.ws.close() } mpl.figure.prototype.push_to_output = function(remove_interactive) { // Turn the data on the canvas into data in the output cell. var width = this.canvas.width/mpl.ratio var dataURL = this.canvas.toDataURL(); this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">'; } mpl.figure.prototype.updated_canvas_event = function() { // Tell IPython that the notebook contents must change. IPython.notebook.set_dirty(true); this.send_message(\"ack\", {}); var fig = this; // Wait a second, then push the new image to the DOM so // that it is saved nicely (might be nice to debounce this). setTimeout(function () { fig.push_to_output() }, 1000); } mpl.figure.prototype._init_toolbar = function() { var fig = this; var nav_element = $('<div/>') nav_element.attr('style', 'width: 100%'); this.root.append(nav_element); // Define a callback function for later on. function toolbar_event(event) { return fig.toolbar_button_onclick(event['data']); } function toolbar_mouse_event(event) { return fig.toolbar_button_onmouseover(event['data']); } for(var toolbar_ind in mpl.toolbar_items){ var name = mpl.toolbar_items[toolbar_ind][0]; var tooltip = mpl.toolbar_items[toolbar_ind][1]; var image = mpl.toolbar_items[toolbar_ind][2]; var method_name = mpl.toolbar_items[toolbar_ind][3]; if (!name) { continue; }; var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>'); button.click(method_name, toolbar_event); button.mouseover(tooltip, toolbar_mouse_event); nav_element.append(button); } // Add the status bar. var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>'); nav_element.append(status_bar); this.message = status_bar[0]; // Add the close button to the window. var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>'); var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>'); button.click(function (evt) { fig.handle_close(fig, {}); } ); button.mouseover('Stop Interaction', toolbar_mouse_event); buttongrp.append(button); var titlebar = this.root.find($('.ui-dialog-titlebar')); titlebar.prepend(buttongrp); } mpl.figure.prototype._root_extra_style = function(el){ var fig = this el.on(\"remove\", function(){ fig.close_ws(fig, {}); }); } mpl.figure.prototype._canvas_extra_style = function(el){ // this is important to make the div 'focusable el.attr('tabindex', 0) // reach out to IPython and tell the keyboard manager to turn it's self // off when our div gets focus // location in version 3 if (IPython.notebook.keyboard_manager) { IPython.notebook.keyboard_manager.register_events(el); } else { // location in version 2 IPython.keyboard_manager.register_events(el); } } mpl.figure.prototype._key_event_extra = function(event, name) { var manager = IPython.notebook.keyboard_manager; if (!manager) manager = IPython.keyboard_manager; // Check for shift+enter if (event.shiftKey && event.which == 13) { this.canvas_div.blur(); event.shiftKey = false; // Send a \"J\" for go to next cell event.which = 74; event.keyCode = 74; manager.command_mode(); manager.handle_keydown(event); } } mpl.figure.prototype.handle_save = function(fig, msg) { fig.ondownload(fig, null); } mpl.find_output_cell = function(html_output) { // Return the cell and output element which can be found *uniquely* in the notebook. // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\" // IPython event is triggered only after the cells have been serialised, which for // our purposes (turning an active figure into a static one), is too late. var cells = IPython.notebook.get_cells(); var ncells = cells.length; for (var i=0; i<ncells; i++) { var cell = cells[i]; if (cell.cell_type === 'code'){ for (var j=0; j<cell.output_area.outputs.length; j++) { var data = cell.output_area.outputs[j]; if (data.data) { // IPython >= 3 moved mimebundle to data attribute of output data = data.data; } if (data['text/html'] == html_output) { return [cell, data, j]; } } } } } // Register the function which deals with the matplotlib target/channel. // The kernel may be null if the page has been refreshed. if (IPython.notebook.kernel != null) { IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm); } 散点图 在机器学习中，散点图是一种很常见的图形，来表现大量的数据点分布。 In [10]: import numpy as np import matplotlib.pyplot as plt group = np . array ([[ 1.0 , 1.1 ], [ 1.0 , 1.0 ], [ 0 , 0 ], [ 0 , 0.1 ]]) x_group = [] y_group = [] for x , y in group : x_group . append ( x ) y_group . append ( y ) fig , ax = plt . subplots () ax . set_xlabel ( 'x' ) ax . set_ylabel ( 'y' ) ax . scatter ( x_group , y_group ) ax . set_title ( '散点图' ) plt . show () var element = $('#d1a2862f-cf27-4bf5-8cd1-9f0f3a4918f7'); /* Put everything inside the global mpl namespace */ window.mpl = {}; mpl.get_websocket_type = function() { if (typeof(WebSocket) !== 'undefined') { return WebSocket; } else if (typeof(MozWebSocket) !== 'undefined') { return MozWebSocket; } else { alert('Your browser does not have WebSocket support.' + 'Please try Chrome, Safari or Firefox ≥ 6. ' + 'Firefox 4 and 5 are also supported but you ' + 'have to enable WebSockets in about:config.'); }; } mpl.figure = function(figure_id, websocket, ondownload, parent_element) { this.id = figure_id; this.ws = websocket; this.supports_binary = (this.ws.binaryType != undefined); if (!this.supports_binary) { var warnings = document.getElementById(\"mpl-warnings\"); if (warnings) { warnings.style.display = 'block'; warnings.textContent = ( \"This browser does not support binary websocket messages. \" + \"Performance may be slow.\"); } } this.imageObj = new Image(); this.context = undefined; this.message = undefined; this.canvas = undefined; this.rubberband_canvas = undefined; this.rubberband_context = undefined; this.format_dropdown = undefined; this.image_mode = 'full'; this.root = $('<div/>'); this._root_extra_style(this.root) this.root.attr('style', 'display: inline-block'); $(parent_element).append(this.root); this._init_header(this); this._init_canvas(this); this._init_toolbar(this); var fig = this; this.waiting = false; this.ws.onopen = function () { fig.send_message(\"supports_binary\", {value: fig.supports_binary}); fig.send_message(\"send_image_mode\", {}); if (mpl.ratio != 1) { fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio}); } fig.send_message(\"refresh\", {}); } this.imageObj.onload = function() { if (fig.image_mode == 'full') { // Full images could contain transparency (where diff images // almost always do), so we need to clear the canvas so that // there is no ghosting. fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height); } fig.context.drawImage(fig.imageObj, 0, 0); }; this.imageObj.onunload = function() { fig.ws.close(); } this.ws.onmessage = this._make_on_message_function(this); this.ondownload = ondownload; } mpl.figure.prototype._init_header = function() { var titlebar = $( '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' + 'ui-helper-clearfix\"/>'); var titletext = $( '<div class=\"ui-dialog-title\" style=\"width: 100%; ' + 'text-align: center; padding: 3px;\"/>'); titlebar.append(titletext) this.root.append(titlebar); this.header = titletext[0]; } mpl.figure.prototype._canvas_extra_style = function(canvas_div) { } mpl.figure.prototype._root_extra_style = function(canvas_div) { } mpl.figure.prototype._init_canvas = function() { var fig = this; var canvas_div = $('<div/>'); canvas_div.attr('style', 'position: relative; clear: both; outline: 0'); function canvas_keyboard_event(event) { return fig.key_event(event, event['data']); } canvas_div.keydown('key_press', canvas_keyboard_event); canvas_div.keyup('key_release', canvas_keyboard_event); this.canvas_div = canvas_div this._canvas_extra_style(canvas_div) this.root.append(canvas_div); var canvas = $('<canvas/>'); canvas.addClass('mpl-canvas'); canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\") this.canvas = canvas[0]; this.context = canvas[0].getContext(\"2d\"); var backingStore = this.context.backingStorePixelRatio || this.context.webkitBackingStorePixelRatio || this.context.mozBackingStorePixelRatio || this.context.msBackingStorePixelRatio || this.context.oBackingStorePixelRatio || this.context.backingStorePixelRatio || 1; mpl.ratio = (window.devicePixelRatio || 1) / backingStore; var rubberband = $('<canvas/>'); rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\") var pass_mouse_events = true; canvas_div.resizable({ start: function(event, ui) { pass_mouse_events = false; }, resize: function(event, ui) { fig.request_resize(ui.size.width, ui.size.height); }, stop: function(event, ui) { pass_mouse_events = true; fig.request_resize(ui.size.width, ui.size.height); }, }); function mouse_event_fn(event) { if (pass_mouse_events) return fig.mouse_event(event, event['data']); } rubberband.mousedown('button_press', mouse_event_fn); rubberband.mouseup('button_release', mouse_event_fn); // Throttle sequential mouse events to 1 every 20ms. rubberband.mousemove('motion_notify', mouse_event_fn); rubberband.mouseenter('figure_enter', mouse_event_fn); rubberband.mouseleave('figure_leave', mouse_event_fn); canvas_div.on(\"wheel\", function (event) { event = event.originalEvent; event['data'] = 'scroll' if (event.deltaY < 0) { event.step = 1; } else { event.step = -1; } mouse_event_fn(event); }); canvas_div.append(canvas); canvas_div.append(rubberband); this.rubberband = rubberband; this.rubberband_canvas = rubberband[0]; this.rubberband_context = rubberband[0].getContext(\"2d\"); this.rubberband_context.strokeStyle = \"#000000\"; this._resize_canvas = function(width, height) { // Keep the size of the canvas, canvas container, and rubber band // canvas in synch. canvas_div.css('width', width) canvas_div.css('height', height) canvas.attr('width', width * mpl.ratio); canvas.attr('height', height * mpl.ratio); canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;'); rubberband.attr('width', width); rubberband.attr('height', height); } // Set the figure to an initial 600x600px, this will subsequently be updated // upon first draw. this._resize_canvas(600, 600); // Disable right mouse context menu. $(this.rubberband_canvas).bind(\"contextmenu\",function(e){ return false; }); function set_focus () { canvas.focus(); canvas_div.focus(); } window.setTimeout(set_focus, 100); } mpl.figure.prototype._init_toolbar = function() { var fig = this; var nav_element = $('<div/>') nav_element.attr('style', 'width: 100%'); this.root.append(nav_element); // Define a callback function for later on. function toolbar_event(event) { return fig.toolbar_button_onclick(event['data']); } function toolbar_mouse_event(event) { return fig.toolbar_button_onmouseover(event['data']); } for(var toolbar_ind in mpl.toolbar_items) { var name = mpl.toolbar_items[toolbar_ind][0]; var tooltip = mpl.toolbar_items[toolbar_ind][1]; var image = mpl.toolbar_items[toolbar_ind][2]; var method_name = mpl.toolbar_items[toolbar_ind][3]; if (!name) { // put a spacer in here. continue; } var button = $('<button/>'); button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' + 'ui-button-icon-only'); button.attr('role', 'button'); button.attr('aria-disabled', 'false'); button.click(method_name, toolbar_event); button.mouseover(tooltip, toolbar_mouse_event); var icon_img = $('<span/>'); icon_img.addClass('ui-button-icon-primary ui-icon'); icon_img.addClass(image); icon_img.addClass('ui-corner-all'); var tooltip_span = $('<span/>'); tooltip_span.addClass('ui-button-text'); tooltip_span.html(tooltip); button.append(icon_img); button.append(tooltip_span); nav_element.append(button); } var fmt_picker_span = $('<span/>'); var fmt_picker = $('<select/>'); fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content'); fmt_picker_span.append(fmt_picker); nav_element.append(fmt_picker_span); this.format_dropdown = fmt_picker[0]; for (var ind in mpl.extensions) { var fmt = mpl.extensions[ind]; var option = $( '<option/>', {selected: fmt === mpl.default_extension}).html(fmt); fmt_picker.append(option) } // Add hover states to the ui-buttons $( \".ui-button\" ).hover( function() { $(this).addClass(\"ui-state-hover\");}, function() { $(this).removeClass(\"ui-state-hover\");} ); var status_bar = $('<span class=\"mpl-message\"/>'); nav_element.append(status_bar); this.message = status_bar[0]; } mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) { // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client, // which will in turn request a refresh of the image. this.send_message('resize', {'width': x_pixels, 'height': y_pixels}); } mpl.figure.prototype.send_message = function(type, properties) { properties['type'] = type; properties['figure_id'] = this.id; this.ws.send(JSON.stringify(properties)); } mpl.figure.prototype.send_draw_message = function() { if (!this.waiting) { this.waiting = true; this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id})); } } mpl.figure.prototype.handle_save = function(fig, msg) { var format_dropdown = fig.format_dropdown; var format = format_dropdown.options[format_dropdown.selectedIndex].value; fig.ondownload(fig, format); } mpl.figure.prototype.handle_resize = function(fig, msg) { var size = msg['size']; if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) { fig._resize_canvas(size[0], size[1]); fig.send_message(\"refresh\", {}); }; } mpl.figure.prototype.handle_rubberband = function(fig, msg) { var x0 = msg['x0'] / mpl.ratio; var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio; var x1 = msg['x1'] / mpl.ratio; var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio; x0 = Math.floor(x0) + 0.5; y0 = Math.floor(y0) + 0.5; x1 = Math.floor(x1) + 0.5; y1 = Math.floor(y1) + 0.5; var min_x = Math.min(x0, x1); var min_y = Math.min(y0, y1); var width = Math.abs(x1 - x0); var height = Math.abs(y1 - y0); fig.rubberband_context.clearRect( 0, 0, fig.canvas.width, fig.canvas.height); fig.rubberband_context.strokeRect(min_x, min_y, width, height); } mpl.figure.prototype.handle_figure_label = function(fig, msg) { // Updates the figure title. fig.header.textContent = msg['label']; } mpl.figure.prototype.handle_cursor = function(fig, msg) { var cursor = msg['cursor']; switch(cursor) { case 0: cursor = 'pointer'; break; case 1: cursor = 'default'; break; case 2: cursor = 'crosshair'; break; case 3: cursor = 'move'; break; } fig.rubberband_canvas.style.cursor = cursor; } mpl.figure.prototype.handle_message = function(fig, msg) { fig.message.textContent = msg['message']; } mpl.figure.prototype.handle_draw = function(fig, msg) { // Request the server to send over a new figure. fig.send_draw_message(); } mpl.figure.prototype.handle_image_mode = function(fig, msg) { fig.image_mode = msg['mode']; } mpl.figure.prototype.updated_canvas_event = function() { // Called whenever the canvas gets updated. this.send_message(\"ack\", {}); } // A function to construct a web socket function for onmessage handling. // Called in the figure constructor. mpl.figure.prototype._make_on_message_function = function(fig) { return function socket_on_message(evt) { if (evt.data instanceof Blob) { /* FIXME: We get \"Resource interpreted as Image but * transferred with MIME type text/plain:\" errors on * Chrome. But how to set the MIME type? It doesn't seem * to be part of the websocket stream */ evt.data.type = \"image/png\"; /* Free the memory for the previous frames */ if (fig.imageObj.src) { (window.URL || window.webkitURL).revokeObjectURL( fig.imageObj.src); } fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL( evt.data); fig.updated_canvas_event(); fig.waiting = false; return; } else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") { fig.imageObj.src = evt.data; fig.updated_canvas_event(); fig.waiting = false; return; } var msg = JSON.parse(evt.data); var msg_type = msg['type']; // Call the \"handle_{type}\" callback, which takes // the figure and JSON message as its only arguments. try { var callback = fig[\"handle_\" + msg_type]; } catch (e) { console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg); return; } if (callback) { try { // console.log(\"Handling '\" + msg_type + \"' message: \", msg); callback(fig, msg); } catch (e) { console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg); } } }; } // from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas mpl.findpos = function(e) { //this section is from http://www.quirksmode.org/js/events_properties.html var targ; if (!e) e = window.event; if (e.target) targ = e.target; else if (e.srcElement) targ = e.srcElement; if (targ.nodeType == 3) // defeat Safari bug targ = targ.parentNode; // jQuery normalizes the pageX and pageY // pageX,Y are the mouse positions relative to the document // offset() returns the position of the element relative to the document var x = e.pageX - $(targ).offset().left; var y = e.pageY - $(targ).offset().top; return {\"x\": x, \"y\": y}; }; /* * return a copy of an object with only non-object keys * we need this to avoid circular references * http://stackoverflow.com/a/24161582/3208463 */ function simpleKeys (original) { return Object.keys(original).reduce(function (obj, key) { if (typeof original[key] !== 'object') obj[key] = original[key] return obj; }, {}); } mpl.figure.prototype.mouse_event = function(event, name) { var canvas_pos = mpl.findpos(event) if (name === 'button_press') { this.canvas.focus(); this.canvas_div.focus(); } var x = canvas_pos.x * mpl.ratio; var y = canvas_pos.y * mpl.ratio; this.send_message(name, {x: x, y: y, button: event.button, step: event.step, guiEvent: simpleKeys(event)}); /* This prevents the web browser from automatically changing to * the text insertion cursor when the button is pressed. We want * to control all of the cursor setting manually through the * 'cursor' event from matplotlib */ event.preventDefault(); return false; } mpl.figure.prototype._key_event_extra = function(event, name) { // Handle any extra behaviour associated with a key event } mpl.figure.prototype.key_event = function(event, name) { // Prevent repeat events if (name == 'key_press') { if (event.which === this._key) return; else this._key = event.which; } if (name == 'key_release') this._key = null; var value = ''; if (event.ctrlKey && event.which != 17) value += \"ctrl+\"; if (event.altKey && event.which != 18) value += \"alt+\"; if (event.shiftKey && event.which != 16) value += \"shift+\"; value += 'k'; value += event.which.toString(); this._key_event_extra(event, name); this.send_message(name, {key: value, guiEvent: simpleKeys(event)}); return false; } mpl.figure.prototype.toolbar_button_onclick = function(name) { if (name == 'download') { this.handle_save(this, null); } else { this.send_message(\"toolbar_button\", {name: name}); } }; mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) { this.message.textContent = tooltip; }; mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]]; mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"]; mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) { // Create a \"websocket\"-like object which calls the given IPython comm // object with the appropriate methods. Currently this is a non binary // socket, so there is still some room for performance tuning. var ws = {}; ws.close = function() { comm.close() }; ws.send = function(m) { //console.log('sending', m); comm.send(m); }; // Register the callback with on_msg. comm.on_msg(function(msg) { //console.log('receiving', msg['content']['data'], msg); // Pass the mpl event to the overridden (by mpl) onmessage function. ws.onmessage(msg['content']['data']) }); return ws; } mpl.mpl_figure_comm = function(comm, msg) { // This is the function which gets called when the mpl process // starts-up an IPython Comm through the \"matplotlib\" channel. var id = msg.content.data.id; // Get hold of the div created by the display call when the Comm // socket was opened in Python. var element = $(\"#\" + id); var ws_proxy = comm_websocket_adapter(comm) function ondownload(figure, format) { window.open(figure.imageObj.src); } var fig = new mpl.figure(id, ws_proxy, ondownload, element.get(0)); // Call onopen now - mpl needs it, as it is assuming we've passed it a real // web socket which is closed, not our websocket->open comm proxy. ws_proxy.onopen(); fig.parent_element = element.get(0); fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\"); if (!fig.cell_info) { console.error(\"Failed to find cell for figure\", id, fig); return; } var output_index = fig.cell_info[2] var cell = fig.cell_info[0]; }; mpl.figure.prototype.handle_close = function(fig, msg) { var width = fig.canvas.width/mpl.ratio fig.root.unbind('remove') // Update the output cell to use the data from the current canvas. fig.push_to_output(); var dataURL = fig.canvas.toDataURL(); // Re-enable the keyboard manager in IPython - without this line, in FF, // the notebook keyboard shortcuts fail. IPython.keyboard_manager.enable() $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">'); fig.close_ws(fig, msg); } mpl.figure.prototype.close_ws = function(fig, msg){ fig.send_message('closing', msg); // fig.ws.close() } mpl.figure.prototype.push_to_output = function(remove_interactive) { // Turn the data on the canvas into data in the output cell. var width = this.canvas.width/mpl.ratio var dataURL = this.canvas.toDataURL(); this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">'; } mpl.figure.prototype.updated_canvas_event = function() { // Tell IPython that the notebook contents must change. IPython.notebook.set_dirty(true); this.send_message(\"ack\", {}); var fig = this; // Wait a second, then push the new image to the DOM so // that it is saved nicely (might be nice to debounce this). setTimeout(function () { fig.push_to_output() }, 1000); } mpl.figure.prototype._init_toolbar = function() { var fig = this; var nav_element = $('<div/>') nav_element.attr('style', 'width: 100%'); this.root.append(nav_element); // Define a callback function for later on. function toolbar_event(event) { return fig.toolbar_button_onclick(event['data']); } function toolbar_mouse_event(event) { return fig.toolbar_button_onmouseover(event['data']); } for(var toolbar_ind in mpl.toolbar_items){ var name = mpl.toolbar_items[toolbar_ind][0]; var tooltip = mpl.toolbar_items[toolbar_ind][1]; var image = mpl.toolbar_items[toolbar_ind][2]; var method_name = mpl.toolbar_items[toolbar_ind][3]; if (!name) { continue; }; var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>'); button.click(method_name, toolbar_event); button.mouseover(tooltip, toolbar_mouse_event); nav_element.append(button); } // Add the status bar. var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>'); nav_element.append(status_bar); this.message = status_bar[0]; // Add the close button to the window. var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>'); var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>'); button.click(function (evt) { fig.handle_close(fig, {}); } ); button.mouseover('Stop Interaction', toolbar_mouse_event); buttongrp.append(button); var titlebar = this.root.find($('.ui-dialog-titlebar')); titlebar.prepend(buttongrp); } mpl.figure.prototype._root_extra_style = function(el){ var fig = this el.on(\"remove\", function(){ fig.close_ws(fig, {}); }); } mpl.figure.prototype._canvas_extra_style = function(el){ // this is important to make the div 'focusable el.attr('tabindex', 0) // reach out to IPython and tell the keyboard manager to turn it's self // off when our div gets focus // location in version 3 if (IPython.notebook.keyboard_manager) { IPython.notebook.keyboard_manager.register_events(el); } else { // location in version 2 IPython.keyboard_manager.register_events(el); } } mpl.figure.prototype._key_event_extra = function(event, name) { var manager = IPython.notebook.keyboard_manager; if (!manager) manager = IPython.keyboard_manager; // Check for shift+enter if (event.shiftKey && event.which == 13) { this.canvas_div.blur(); event.shiftKey = false; // Send a \"J\" for go to next cell event.which = 74; event.keyCode = 74; manager.command_mode(); manager.handle_keydown(event); } } mpl.figure.prototype.handle_save = function(fig, msg) { fig.ondownload(fig, null); } mpl.find_output_cell = function(html_output) { // Return the cell and output element which can be found *uniquely* in the notebook. // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\" // IPython event is triggered only after the cells have been serialised, which for // our purposes (turning an active figure into a static one), is too late. var cells = IPython.notebook.get_cells(); var ncells = cells.length; for (var i=0; i<ncells; i++) { var cell = cells[i]; if (cell.cell_type === 'code'){ for (var j=0; j<cell.output_area.outputs.length; j++) { var data = cell.output_area.outputs[j]; if (data.data) { // IPython >= 3 moved mimebundle to data attribute of output data = data.data; } if (data['text/html'] == html_output) { return [cell, data, j]; } } } } } // Register the function which deals with the matplotlib target/channel. // The kernel may be null if the page has been refreshed. if (IPython.notebook.kernel != null) { IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm); } In [19]: import pandas as pd import numpy as np import matplotlib.pyplot as plt fig , ( ax1 , ax2 ) = plt . subplots ( ncols = 2 ) group = np . array ([[ 1.0 , 1.1 ], [ 1.0 , 1.0 ], [ 0 , 0 ], [ 0 , 0.1 ]]) ### ax1 x_group = [] y_group = [] for x , y in group : x_group . append ( x ) y_group . append ( y ) ax1 . set_xlabel ( 'x' ) ax1 . set_ylabel ( 'y' ) ax1 . scatter ( x_group , y_group ) ax1 . set_title ( '散点图-matplotlib' ) ### ax2 看得出来pandas非常好用，几乎是数据处理的标配数据中转层了。 data = pd . DataFrame ( group , columns = [ 'x' , 'y' ]) ax2 . set_title ( '散点图-pandas' ) data . plot . scatter ( x = 'x' , y = 'y' , ax = ax2 ) var element = $('#e55d8d21-c0e6-4a61-90cc-d4dc4fcd2789'); /* Put everything inside the global mpl namespace */ window.mpl = {}; mpl.get_websocket_type = function() { if (typeof(WebSocket) !== 'undefined') { return WebSocket; } else if (typeof(MozWebSocket) !== 'undefined') { return MozWebSocket; } else { alert('Your browser does not have WebSocket support.' + 'Please try Chrome, Safari or Firefox ≥ 6. ' + 'Firefox 4 and 5 are also supported but you ' + 'have to enable WebSockets in about:config.'); }; } mpl.figure = function(figure_id, websocket, ondownload, parent_element) { this.id = figure_id; this.ws = websocket; this.supports_binary = (this.ws.binaryType != undefined); if (!this.supports_binary) { var warnings = document.getElementById(\"mpl-warnings\"); if (warnings) { warnings.style.display = 'block'; warnings.textContent = ( \"This browser does not support binary websocket messages. \" + \"Performance may be slow.\"); } } this.imageObj = new Image(); this.context = undefined; this.message = undefined; this.canvas = undefined; this.rubberband_canvas = undefined; this.rubberband_context = undefined; this.format_dropdown = undefined; this.image_mode = 'full'; this.root = $('<div/>'); this._root_extra_style(this.root) this.root.attr('style', 'display: inline-block'); $(parent_element).append(this.root); this._init_header(this); this._init_canvas(this); this._init_toolbar(this); var fig = this; this.waiting = false; this.ws.onopen = function () { fig.send_message(\"supports_binary\", {value: fig.supports_binary}); fig.send_message(\"send_image_mode\", {}); if (mpl.ratio != 1) { fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio}); } fig.send_message(\"refresh\", {}); } this.imageObj.onload = function() { if (fig.image_mode == 'full') { // Full images could contain transparency (where diff images // almost always do), so we need to clear the canvas so that // there is no ghosting. fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height); } fig.context.drawImage(fig.imageObj, 0, 0); }; this.imageObj.onunload = function() { fig.ws.close(); } this.ws.onmessage = this._make_on_message_function(this); this.ondownload = ondownload; } mpl.figure.prototype._init_header = function() { var titlebar = $( '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' + 'ui-helper-clearfix\"/>'); var titletext = $( '<div class=\"ui-dialog-title\" style=\"width: 100%; ' + 'text-align: center; padding: 3px;\"/>'); titlebar.append(titletext) this.root.append(titlebar); this.header = titletext[0]; } mpl.figure.prototype._canvas_extra_style = function(canvas_div) { } mpl.figure.prototype._root_extra_style = function(canvas_div) { } mpl.figure.prototype._init_canvas = function() { var fig = this; var canvas_div = $('<div/>'); canvas_div.attr('style', 'position: relative; clear: both; outline: 0'); function canvas_keyboard_event(event) { return fig.key_event(event, event['data']); } canvas_div.keydown('key_press', canvas_keyboard_event); canvas_div.keyup('key_release', canvas_keyboard_event); this.canvas_div = canvas_div this._canvas_extra_style(canvas_div) this.root.append(canvas_div); var canvas = $('<canvas/>'); canvas.addClass('mpl-canvas'); canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\") this.canvas = canvas[0]; this.context = canvas[0].getContext(\"2d\"); var backingStore = this.context.backingStorePixelRatio || this.context.webkitBackingStorePixelRatio || this.context.mozBackingStorePixelRatio || this.context.msBackingStorePixelRatio || this.context.oBackingStorePixelRatio || this.context.backingStorePixelRatio || 1; mpl.ratio = (window.devicePixelRatio || 1) / backingStore; var rubberband = $('<canvas/>'); rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\") var pass_mouse_events = true; canvas_div.resizable({ start: function(event, ui) { pass_mouse_events = false; }, resize: function(event, ui) { fig.request_resize(ui.size.width, ui.size.height); }, stop: function(event, ui) { pass_mouse_events = true; fig.request_resize(ui.size.width, ui.size.height); }, }); function mouse_event_fn(event) { if (pass_mouse_events) return fig.mouse_event(event, event['data']); } rubberband.mousedown('button_press', mouse_event_fn); rubberband.mouseup('button_release', mouse_event_fn); // Throttle sequential mouse events to 1 every 20ms. rubberband.mousemove('motion_notify', mouse_event_fn); rubberband.mouseenter('figure_enter', mouse_event_fn); rubberband.mouseleave('figure_leave', mouse_event_fn); canvas_div.on(\"wheel\", function (event) { event = event.originalEvent; event['data'] = 'scroll' if (event.deltaY < 0) { event.step = 1; } else { event.step = -1; } mouse_event_fn(event); }); canvas_div.append(canvas); canvas_div.append(rubberband); this.rubberband = rubberband; this.rubberband_canvas = rubberband[0]; this.rubberband_context = rubberband[0].getContext(\"2d\"); this.rubberband_context.strokeStyle = \"#000000\"; this._resize_canvas = function(width, height) { // Keep the size of the canvas, canvas container, and rubber band // canvas in synch. canvas_div.css('width', width) canvas_div.css('height', height) canvas.attr('width', width * mpl.ratio); canvas.attr('height', height * mpl.ratio); canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;'); rubberband.attr('width', width); rubberband.attr('height', height); } // Set the figure to an initial 600x600px, this will subsequently be updated // upon first draw. this._resize_canvas(600, 600); // Disable right mouse context menu. $(this.rubberband_canvas).bind(\"contextmenu\",function(e){ return false; }); function set_focus () { canvas.focus(); canvas_div.focus(); } window.setTimeout(set_focus, 100); } mpl.figure.prototype._init_toolbar = function() { var fig = this; var nav_element = $('<div/>') nav_element.attr('style', 'width: 100%'); this.root.append(nav_element); // Define a callback function for later on. function toolbar_event(event) { return fig.toolbar_button_onclick(event['data']); } function toolbar_mouse_event(event) { return fig.toolbar_button_onmouseover(event['data']); } for(var toolbar_ind in mpl.toolbar_items) { var name = mpl.toolbar_items[toolbar_ind][0]; var tooltip = mpl.toolbar_items[toolbar_ind][1]; var image = mpl.toolbar_items[toolbar_ind][2]; var method_name = mpl.toolbar_items[toolbar_ind][3]; if (!name) { // put a spacer in here. continue; } var button = $('<button/>'); button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' + 'ui-button-icon-only'); button.attr('role', 'button'); button.attr('aria-disabled', 'false'); button.click(method_name, toolbar_event); button.mouseover(tooltip, toolbar_mouse_event); var icon_img = $('<span/>'); icon_img.addClass('ui-button-icon-primary ui-icon'); icon_img.addClass(image); icon_img.addClass('ui-corner-all'); var tooltip_span = $('<span/>'); tooltip_span.addClass('ui-button-text'); tooltip_span.html(tooltip); button.append(icon_img); button.append(tooltip_span); nav_element.append(button); } var fmt_picker_span = $('<span/>'); var fmt_picker = $('<select/>'); fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content'); fmt_picker_span.append(fmt_picker); nav_element.append(fmt_picker_span); this.format_dropdown = fmt_picker[0]; for (var ind in mpl.extensions) { var fmt = mpl.extensions[ind]; var option = $( '<option/>', {selected: fmt === mpl.default_extension}).html(fmt); fmt_picker.append(option) } // Add hover states to the ui-buttons $( \".ui-button\" ).hover( function() { $(this).addClass(\"ui-state-hover\");}, function() { $(this).removeClass(\"ui-state-hover\");} ); var status_bar = $('<span class=\"mpl-message\"/>'); nav_element.append(status_bar); this.message = status_bar[0]; } mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) { // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client, // which will in turn request a refresh of the image. this.send_message('resize', {'width': x_pixels, 'height': y_pixels}); } mpl.figure.prototype.send_message = function(type, properties) { properties['type'] = type; properties['figure_id'] = this.id; this.ws.send(JSON.stringify(properties)); } mpl.figure.prototype.send_draw_message = function() { if (!this.waiting) { this.waiting = true; this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id})); } } mpl.figure.prototype.handle_save = function(fig, msg) { var format_dropdown = fig.format_dropdown; var format = format_dropdown.options[format_dropdown.selectedIndex].value; fig.ondownload(fig, format); } mpl.figure.prototype.handle_resize = function(fig, msg) { var size = msg['size']; if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) { fig._resize_canvas(size[0], size[1]); fig.send_message(\"refresh\", {}); }; } mpl.figure.prototype.handle_rubberband = function(fig, msg) { var x0 = msg['x0'] / mpl.ratio; var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio; var x1 = msg['x1'] / mpl.ratio; var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio; x0 = Math.floor(x0) + 0.5; y0 = Math.floor(y0) + 0.5; x1 = Math.floor(x1) + 0.5; y1 = Math.floor(y1) + 0.5; var min_x = Math.min(x0, x1); var min_y = Math.min(y0, y1); var width = Math.abs(x1 - x0); var height = Math.abs(y1 - y0); fig.rubberband_context.clearRect( 0, 0, fig.canvas.width, fig.canvas.height); fig.rubberband_context.strokeRect(min_x, min_y, width, height); } mpl.figure.prototype.handle_figure_label = function(fig, msg) { // Updates the figure title. fig.header.textContent = msg['label']; } mpl.figure.prototype.handle_cursor = function(fig, msg) { var cursor = msg['cursor']; switch(cursor) { case 0: cursor = 'pointer'; break; case 1: cursor = 'default'; break; case 2: cursor = 'crosshair'; break; case 3: cursor = 'move'; break; } fig.rubberband_canvas.style.cursor = cursor; } mpl.figure.prototype.handle_message = function(fig, msg) { fig.message.textContent = msg['message']; } mpl.figure.prototype.handle_draw = function(fig, msg) { // Request the server to send over a new figure. fig.send_draw_message(); } mpl.figure.prototype.handle_image_mode = function(fig, msg) { fig.image_mode = msg['mode']; } mpl.figure.prototype.updated_canvas_event = function() { // Called whenever the canvas gets updated. this.send_message(\"ack\", {}); } // A function to construct a web socket function for onmessage handling. // Called in the figure constructor. mpl.figure.prototype._make_on_message_function = function(fig) { return function socket_on_message(evt) { if (evt.data instanceof Blob) { /* FIXME: We get \"Resource interpreted as Image but * transferred with MIME type text/plain:\" errors on * Chrome. But how to set the MIME type? It doesn't seem * to be part of the websocket stream */ evt.data.type = \"image/png\"; /* Free the memory for the previous frames */ if (fig.imageObj.src) { (window.URL || window.webkitURL).revokeObjectURL( fig.imageObj.src); } fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL( evt.data); fig.updated_canvas_event(); fig.waiting = false; return; } else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") { fig.imageObj.src = evt.data; fig.updated_canvas_event(); fig.waiting = false; return; } var msg = JSON.parse(evt.data); var msg_type = msg['type']; // Call the \"handle_{type}\" callback, which takes // the figure and JSON message as its only arguments. try { var callback = fig[\"handle_\" + msg_type]; } catch (e) { console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg); return; } if (callback) { try { // console.log(\"Handling '\" + msg_type + \"' message: \", msg); callback(fig, msg); } catch (e) { console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg); } } }; } // from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas mpl.findpos = function(e) { //this section is from http://www.quirksmode.org/js/events_properties.html var targ; if (!e) e = window.event; if (e.target) targ = e.target; else if (e.srcElement) targ = e.srcElement; if (targ.nodeType == 3) // defeat Safari bug targ = targ.parentNode; // jQuery normalizes the pageX and pageY // pageX,Y are the mouse positions relative to the document // offset() returns the position of the element relative to the document var x = e.pageX - $(targ).offset().left; var y = e.pageY - $(targ).offset().top; return {\"x\": x, \"y\": y}; }; /* * return a copy of an object with only non-object keys * we need this to avoid circular references * http://stackoverflow.com/a/24161582/3208463 */ function simpleKeys (original) { return Object.keys(original).reduce(function (obj, key) { if (typeof original[key] !== 'object') obj[key] = original[key] return obj; }, {}); } mpl.figure.prototype.mouse_event = function(event, name) { var canvas_pos = mpl.findpos(event) if (name === 'button_press') { this.canvas.focus(); this.canvas_div.focus(); } var x = canvas_pos.x * mpl.ratio; var y = canvas_pos.y * mpl.ratio; this.send_message(name, {x: x, y: y, button: event.button, step: event.step, guiEvent: simpleKeys(event)}); /* This prevents the web browser from automatically changing to * the text insertion cursor when the button is pressed. We want * to control all of the cursor setting manually through the * 'cursor' event from matplotlib */ event.preventDefault(); return false; } mpl.figure.prototype._key_event_extra = function(event, name) { // Handle any extra behaviour associated with a key event } mpl.figure.prototype.key_event = function(event, name) { // Prevent repeat events if (name == 'key_press') { if (event.which === this._key) return; else this._key = event.which; } if (name == 'key_release') this._key = null; var value = ''; if (event.ctrlKey && event.which != 17) value += \"ctrl+\"; if (event.altKey && event.which != 18) value += \"alt+\"; if (event.shiftKey && event.which != 16) value += \"shift+\"; value += 'k'; value += event.which.toString(); this._key_event_extra(event, name); this.send_message(name, {key: value, guiEvent: simpleKeys(event)}); return false; } mpl.figure.prototype.toolbar_button_onclick = function(name) { if (name == 'download') { this.handle_save(this, null); } else { this.send_message(\"toolbar_button\", {name: name}); } }; mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) { this.message.textContent = tooltip; }; mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]]; mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"]; mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) { // Create a \"websocket\"-like object which calls the given IPython comm // object with the appropriate methods. Currently this is a non binary // socket, so there is still some room for performance tuning. var ws = {}; ws.close = function() { comm.close() }; ws.send = function(m) { //console.log('sending', m); comm.send(m); }; // Register the callback with on_msg. comm.on_msg(function(msg) { //console.log('receiving', msg['content']['data'], msg); // Pass the mpl event to the overridden (by mpl) onmessage function. ws.onmessage(msg['content']['data']) }); return ws; } mpl.mpl_figure_comm = function(comm, msg) { // This is the function which gets called when the mpl process // starts-up an IPython Comm through the \"matplotlib\" channel. var id = msg.content.data.id; // Get hold of the div created by the display call when the Comm // socket was opened in Python. var element = $(\"#\" + id); var ws_proxy = comm_websocket_adapter(comm) function ondownload(figure, format) { window.open(figure.imageObj.src); } var fig = new mpl.figure(id, ws_proxy, ondownload, element.get(0)); // Call onopen now - mpl needs it, as it is assuming we've passed it a real // web socket which is closed, not our websocket->open comm proxy. ws_proxy.onopen(); fig.parent_element = element.get(0); fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\"); if (!fig.cell_info) { console.error(\"Failed to find cell for figure\", id, fig); return; } var output_index = fig.cell_info[2] var cell = fig.cell_info[0]; }; mpl.figure.prototype.handle_close = function(fig, msg) { var width = fig.canvas.width/mpl.ratio fig.root.unbind('remove') // Update the output cell to use the data from the current canvas. fig.push_to_output(); var dataURL = fig.canvas.toDataURL(); // Re-enable the keyboard manager in IPython - without this line, in FF, // the notebook keyboard shortcuts fail. IPython.keyboard_manager.enable() $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">'); fig.close_ws(fig, msg); } mpl.figure.prototype.close_ws = function(fig, msg){ fig.send_message('closing', msg); // fig.ws.close() } mpl.figure.prototype.push_to_output = function(remove_interactive) { // Turn the data on the canvas into data in the output cell. var width = this.canvas.width/mpl.ratio var dataURL = this.canvas.toDataURL(); this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">'; } mpl.figure.prototype.updated_canvas_event = function() { // Tell IPython that the notebook contents must change. IPython.notebook.set_dirty(true); this.send_message(\"ack\", {}); var fig = this; // Wait a second, then push the new image to the DOM so // that it is saved nicely (might be nice to debounce this). setTimeout(function () { fig.push_to_output() }, 1000); } mpl.figure.prototype._init_toolbar = function() { var fig = this; var nav_element = $('<div/>') nav_element.attr('style', 'width: 100%'); this.root.append(nav_element); // Define a callback function for later on. function toolbar_event(event) { return fig.toolbar_button_onclick(event['data']); } function toolbar_mouse_event(event) { return fig.toolbar_button_onmouseover(event['data']); } for(var toolbar_ind in mpl.toolbar_items){ var name = mpl.toolbar_items[toolbar_ind][0]; var tooltip = mpl.toolbar_items[toolbar_ind][1]; var image = mpl.toolbar_items[toolbar_ind][2]; var method_name = mpl.toolbar_items[toolbar_ind][3]; if (!name) { continue; }; var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>'); button.click(method_name, toolbar_event); button.mouseover(tooltip, toolbar_mouse_event); nav_element.append(button); } // Add the status bar. var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>'); nav_element.append(status_bar); this.message = status_bar[0]; // Add the close button to the window. var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>'); var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>'); button.click(function (evt) { fig.handle_close(fig, {}); } ); button.mouseover('Stop Interaction', toolbar_mouse_event); buttongrp.append(button); var titlebar = this.root.find($('.ui-dialog-titlebar')); titlebar.prepend(buttongrp); } mpl.figure.prototype._root_extra_style = function(el){ var fig = this el.on(\"remove\", function(){ fig.close_ws(fig, {}); }); } mpl.figure.prototype._canvas_extra_style = function(el){ // this is important to make the div 'focusable el.attr('tabindex', 0) // reach out to IPython and tell the keyboard manager to turn it's self // off when our div gets focus // location in version 3 if (IPython.notebook.keyboard_manager) { IPython.notebook.keyboard_manager.register_events(el); } else { // location in version 2 IPython.keyboard_manager.register_events(el); } } mpl.figure.prototype._key_event_extra = function(event, name) { var manager = IPython.notebook.keyboard_manager; if (!manager) manager = IPython.keyboard_manager; // Check for shift+enter if (event.shiftKey && event.which == 13) { this.canvas_div.blur(); event.shiftKey = false; // Send a \"J\" for go to next cell event.which = 74; event.keyCode = 74; manager.command_mode(); manager.handle_keydown(event); } } mpl.figure.prototype.handle_save = function(fig, msg) { fig.ondownload(fig, null); } mpl.find_output_cell = function(html_output) { // Return the cell and output element which can be found *uniquely* in the notebook. // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\" // IPython event is triggered only after the cells have been serialised, which for // our purposes (turning an active figure into a static one), is too late. var cells = IPython.notebook.get_cells(); var ncells = cells.length; for (var i=0; i<ncells; i++) { var cell = cells[i]; if (cell.cell_type === 'code'){ for (var j=0; j<cell.output_area.outputs.length; j++) { var data = cell.output_area.outputs[j]; if (data.data) { // IPython >= 3 moved mimebundle to data attribute of output data = data.data; } if (data['text/html'] == html_output) { return [cell, data, j]; } } } } } // Register the function which deals with the matplotlib target/channel. // The kernel may be null if the page has been refreshed. if (IPython.notebook.kernel != null) { IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm); } Out[19]: <matplotlib.axes._subplots.AxesSubplot at 0x20cbadc0828>","tags":"机器学习","url":"articles/shu-ju-hui-tu.html"},{"title":"读取数据","text":"In [1]: import numpy as np import pandas as pd 从文本读取数据 in linux use !cat the.txt in windows use !type the.txt In [5]: test_csv = './examples/test.csv' print ( * open ( test_csv )) a,b,c,d,message 1,2,3,4,hello 5,6,7,8,world 9,10,11,12,foo In [6]: df = pd . read_csv ( test_csv ) In [7]: df Out[7]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } a b c d message 0 1 2 3 4 hello 1 5 6 7 8 world 2 9 10 11 12 foo 处理没有header的情况 如果指定 header=None ，那么将会自动分配0, 1, 2等为header，或者通过 names=['a','b'] 来指定之,如果原来csv数据源有header，那么可以通过 skiprows 来跳过这个你不想要的header。 In [10]: df2 = pd . read_csv ( test_csv , names = [ 'd' , 'c' , 'b' , 'a' , 'info' ], skiprows = [ 0 ]) df2 Out[10]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } d c b a info 0 1 2 3 4 hello 1 5 6 7 8 world 2 9 10 11 12 foo In [15]: with open ( 'examples/test.json' , 'w' ) as f : print ( df2 . to_json (), file = f ) 读入excel 读入微软的excel文件,这需要你安装 xlrd 模块。 In [20]: pd3 = pd . read_excel ( 'examples/test.xlsx' ) pd3 Out[20]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } a b c d message 0 1 2 3 4 hello 1 5 6 7 8 world 2 9 10 11 12 foo 读取html文件 是的，pandas还可以直接读取分析html文件 In [56]: pd4 = pd . read_html ( 'examples/benzene.html' ) for index , i in enumerate ( pd4 [ 2 ][ 0 ]): if i == '化学式' : print ( pd4 [ 2 ][ 1 ][ index ]) C6H6","tags":"机器学习","url":"articles/du-qu-shu-ju.html"},{"title":"nginx web服务器","text":"前言 nginx的官方文档在 这里 ，有问题主要还是参看官方文档吧。 安装 debian系安装: sudo apt-get install nginx rpm系统安装: sudo yum install nginx nginx配置基础 nginx的配置就是在 /etc/nginx/sites-available 那里新建一个配置文件，然后这样创建一个符号链接到 sites-enabled 那里。 sudo ln -s /etc/nginx/sites-available/cdwanze.work /etc/nginx/sites-enabled/cdwanze.work 然后重启nginx即可。 sudo service nginx restart nginx配置文件的基本格式是: <section> { <directive> <parameters>; } nginx命令行 nginx -t 测试 nginx -s stop 快速停用nginx nginx -s quit 温和的退出nginx nginx -s reload 重载配置文件 ​ 通用配置 这里的所谓通用的配置也就是所谓的 global section ，这些配置将影响整个server，我们常在 nginx.conf 中看到这些配置。 user 当前工作进程下的user用户名。 worker_processes 工作进程数，在 server-configs-nginx 项目中的推荐设置如下: # Sets the worker threads to the number of CPU cores available in the system for best performance. # Should be > the number of CPU cores. # Maximum number of connections = worker_processes * worker_connections worker_processes auto; error_log 其他地方没设置的话，默认的错误日志输出路径。 推荐将 /etc/nginx/logs 和 /var/log/nginx 用ln命令统一起来： ln -s /var/log/nginx /etc/nginx/logs http部分配置 http部分也就是所谓的 http section部分配置，其是基于http module。http section部分后面有这么一句: include sites-enabled/*; } 这是把额外的站点配置放在 sites-enabled 文件夹下管理，同时也说明了后面提到的server 部分应该放入http 部分中，在实践中人们会创建一个 sites-available 文件夹，在下面创建一些站点配置，实际启用就用ln 命令来创建一个符号链接。 keepalive_timeout 设置响应头 KeepAlive 的时间。 server_tokens 默认on 推荐off。把nginx的版本信息隐藏起来。 常常有些需求最后要到这里来配置。比如说 client_max_body_size ，如果你遇到nginx请求实体过大错误信息: Nginx 413 Request Entity Too Large 参考了 这个网页 ，你需要在http section里面如下配置: # set client body size to 2M # client_max_body_size 2M; server部分配置 listen和server_name 的配置很基本和关键，具体请参看附录介绍的nginx分配请求逻辑。 location部分配置 location部分配置是放在 server部分里面的。 location部分描述了 遇到什么url 该做什么动作。 对于url的匹配，nginx认为没有正则表达式的最长匹配为最佳匹配，然后再开始按照正则表达式进行匹配。 一般的静态文件服务如下： location /static { root /whrer/your/static; } 或者反向代理服务： location / { proxy_pass http : // 127.0.0.1 : 5000 ; } 这种反向代理，一个很重要的知识点就是uri的改写规则。这里面东西也很多，比如下面的这个: location / socket . io { proxy_pass http : // 127.0.0.1 : 5000 / socket . io ; } 匹配到的部分会被改写为 http://127.0.0.1:5000/socket.io 但是也有些例外的情况，以后再详细讨论之。 root和alias的区别 比如说想要服务一些静态文件： location /static/ { root /home/cdwanze/project/tinyblog; autoindex off; } root在这里的意思是，我们从root开始找， /static/??? 根据 url 传过来的 full path。注意如果用root，就不要再指定static文件夹名了。 而 alias的意思是： location /static/ { alias /home/cdwanze/project/tinyblog/static; autoindex off; } /static/ 将被替换为 /home/cdwanze/project/tinyblog/static/??? 去找那个文件。 本小节参考了 这个网页 。 附录 nginx分配请求逻辑 这部分内容很关键，慢慢看下吧。 根据请求的ip和端口号来核对 listen 信息。 根据请求Host字段来核对 server_name 信息。 核对由继续分为 通配符前 核对 通配符后 核对 正则表达式 核对 以上listen和server_name的核对最后若都没有匹配最后都会回滚到默认的 default_server 中。(实践中推荐default_server return 444，来提升服务器的安全访问级别。) server { listen 80 default_server; return 444; } 以上核对若匹配则进一步根据相应的配置来进行请求处理。 403没有权限访问错误 我需要在本用户的主文件夹下的随便某个文件夹来写一些网页，然后nginx的server的 root 配置好后可能会出现 403错误，这很有可能是你 nginx.conf 文件的 user 配置，没有设置为本用户，所以才无权限操作。ubuntu下那个user好像默认的是var-www这个。将其改为你的用户名即可。参看了 这个网页 。 参考资料 mastering nginx nginx 官方手册","tags":"linux","url":"articles/nginx-web-server.html"},{"title":"jinja2模板","text":"前言 jinja2模板在flask和pelican中都有使用，而且就是在django框架中，模版语法也大体类似，所以jinja2模板还是很值得一学的。 注释 这里面的内容是模板文件的注释内容。 {# ... #} 变量 这里算是jinja2模板的主体内容了，里面的变量可以直接使用，在render的时候传进去即可。然后 object.a 这样的dot法引用，或者 object['a'] 这样的利用对象 __getitem__ 内置方法来调用值的形式也支持。 {{ ... }} 变量的值在jinja2模板系统中调用之后将会变成字符串然后插入在文档中，这就不多说了。 for语句 for语句结构如下所示: <ul> {% for user in users %} <li> {{ user.username }} </li> {% endfor %} </ul> 条件分支 条件分支主要用于有条件的显示某些内容。 {% if user %} Hello, {{ user }} ! {% else %} Hello , stranger! {% endif %} html特殊符号问题 如果你的变量有这些html的特殊符号: < > & \" 假设你没有在flask中使用jinja2模板系统，那么这些字符是没有经过特殊处理的，那么比如说 <b>test</b> 这段字符串到了html文档中就将以粗体的形式显示。如果你希望显示这些符号，那么可以使用 escape 过滤器来做到这点: {{ test | escape }} 或者: {{ test | e }} 都是一样的。 这里的过滤器有点类似bash的管道的意思，意思是将输出的字符串经过额外的操作。 但一般推荐的风格是html标签都放在jinja2模板系统的外面，jinja2模板系统只处理最核心的那些字符串。所以flask是设置为全局auto escape的，这是正确的思路。如果你确实有某些html标签就希望是html标签的形式显示出来，而不经过escape，那么可以采用 safe 过滤器 1 。 {{ \"<b>test</b>\" | safe }} 模板文件继承机制 jinja2的模板文件有一种继承机制，可以让你基于某个模板文件来建构出另外一个模板文件，前面那个模板文件大概可以称作模板文件的模板文件吧。具体使用是在父模板（模板文件的模板文件）构建一些block区块，如下所示: <title> {% block title %} {% endblock %} </title> 这里构建了一个title区块。 然后子模板首先继承父模板所有的内容: {% extends \"base.html\" %} 然后一些需要定制的部分，比如说这里的title部分，做成block之后，子模板文件可以重新定义这个title block: {% extends \"base.html\" %} {% block title } books - the classic books of which you want to collected { % endblock %} 此外子模块在block重载的时候，你还可以用 {{ super () }} 来加载父模块在该block中的一些定义。 上面title block的内容你可以如下引用之: {{ self.title () }} 过滤器filters 过滤器就是一些额外的字符串操作函数，一般推荐还是在python代码中把要输出显示的字符串处理好吧，下面列出一些函数简单了解下即可。 safe 渲染值不转义 capitalize 值首字母大写 其他字母小写 lower 字母都小写 upper 字母都大写 title 值每个单词首字母大写 trim 值首尾空格去除 striptags 渲染之前把所有HTML标签去掉 宏 宏 和python的函数类似，遇到即将其展开。 {% macro render_comment ( comment ) %} <li> {{ comment }} </li> {% endmacro %} <ul> {% for comment in comments %} {{ render_comment ( comment ) }} {% endfor %} </ul> 外部宏文件 引入 { % import 'macros.html' as macros % } { % import 'macros.html' as macros % } < ul > { % for comment in comments % } {{ macros . render_comment ( comment ) }} { % endfor % } </ ul > 引入 {% include 'common.html' %} Footnotes: 1 参考了 [这个网页](http://stackoverflow.com/questions/3206344/passing-html-to-template-using-flask-jinja2) 。","tags":"python好伙伴","url":"articles/jinja2-template.html"},{"title":"beautifulsoup模块","text":"简介 BeautifulSoup模块在python网页分析这一块是很有名的一个模块，其确实让网页分析任务变得轻松而easy了。本文将对bs4模块进行简单的介绍，更多细节请参看 官方文档 。 安装 安装就简单用pip命令安装之: sudo pip install beautifulsoup 第一个例子 然后在使用上因为python2和python3的urllib相关改动很大，加上urllib在使用上不是很友好，强烈推荐大家直接用requests模块来进行相关操作。然后beautifulsoup的引入语句一般如下所示: from bs4 import BeautifulSoup 最简单的和requests的组合使用如下所示: import requests from bs4 import BeautifulSoup res = requests . get ( \"http://www.pythonscraping.com/exercises/exercise1.html\" ) soup = BeautifulSoup ( res . text ) print ( soup . title ) 在上面soup.title返回的是一个标签对象。然后标签对象里面如果有标签的话又可以继续点号索引标签: >>> soup.body.h1 <h1> An Interesting Title </h1> 这时读者一定在想，文档里面相同的p标签有很多，soup会返回什么呢？ import requests from bs4 import BeautifulSoup res = requests . get ( \"http://www.crummy.com/software/BeautifulSoup/bs4/doc/\" ) soup = BeautifulSoup ( res . text ) print ( soup . p ) 我们看到soup返回的是第一个p标签，这可以看作下面要讲的find方法的简化css索引形式。 find方法 如下所示最简单的find定位实际上就类似于 soup.p 的用法。但find方法里面有更丰富的内容。 >>> soup.find('p') <p><a class= \"reference external\" href= \"http://www.crummy.com/software/BeautifulSoup/\" > Beautiful Soup </a> is a Python library for pulling data out of HTML and XML files. It works with your favorite parser to provide idiomatic ways of navigating, searching, and modifying the parse tree. It commonly saves programmers hours or days of work. </p> find方法如果找不到就返回None，找到则返回目标标签元素。 >>> soup.test is None True 过滤器 find方法最常用的形式是接受一个参数，这个参数叫做什么过滤器参数。过滤器可以是字符串或正则表达式或列表组成，其中列表里面的元素基于前面谈及的字符串或正则表达式，然后组成或逻辑，只要符合一个匹配条件就认为是匹配的。 第一个参量也就是name参量是针对tag的操作，通常简单的字符串就够用了，如果是正则表达式的话，则是 re.compile(\"&#94;b\") 这样的形式，然后其内是通过正则表达式的 match 方法来完成的（稍作测试，我觉得应该对应的re.search。）。 最后要额外一提的就是过滤器 True ，其会匹配任何值，比如说 id=True ，将会匹配所有有id属性的标签。 class_参量 你可以通过 class_= 来过滤标签的class属性，注意为了和python的class关键词区分，后面加上了一个下划线，同样是接受一个过滤器。 id参量 你可以通过 id= 来具体定位网页中的某个id，也是接受一个过滤器。 text参量 对网页各个标签内的字符串进行过滤操作，前面提及的过滤器一样都可以用，不过字符串是精确匹配的我估计用得会比较少。尽可能地用正则表达式。然后如果单独使用text参量 soup.find_all(text=re.compile('name')) 标签里面的字符串也会被搜索，而且返回也不一定是标准的标签元素对象，这很不好。推荐采用如下形式: soup.find_all(True,text=re.compile('name')) 这样返回的必定是标签元素，而且text里面必定只搜索标签的text字符串内容，这更易于人们的理解。 然后搜索完之后你可能定位到的是某个小标签，比如 <b> 之类的，然后你可以对目标标签元素使用 .parent ，则将返回更高一级的标签元素，这有时会很有用的: soup.find_all(True,text=re.compile('name'))[-1].parent 其他keywords 其他标签的各个属性都可以类似上面的作为关键词加上过滤器来搜索。比如 oup.find_all(href=re.compile(\"elsie\")) recursive参量 recursive默认是True，也就是检索当前tag的所有子孙节点，如果只想搜索当前tag的第一级子节点，则使用 recursive=False 。 limit参量 这个只对find_all才有意义，确定返回几个元素。 find_all方法 find_all和find方法API类似，除了find_all返回的是一系列匹配的标签元素的列表。在这里顺便提一下，find方法和find_all方法可以接受多个参数作为限定，这些限定条件可以看作逻辑与关系。 标签元素对象 具体标签元素的使用见下面例子: >>> import re >>> soup . find ( True , text = re . compile ( \"sister\" )) < span class = \"s\" >& lt ; p class = \"story\" & gt ; Once upon a time there were three little sisters ; and their names were </ span > >>> thetag = soup . find ( True , text = re . compile ( \"sister\" )) >>> thetag . name 'span' >>> thetag . text '<p class=\"story\">Once upon a time there were three little sisters; and their names were' >>> thetag . string '<p class=\"story\">Once upon a time there were three little sisters; and their names were' >>> type ( thetag . string ) < class ' bs4 . element . NavigableString '> >>> type ( thetag . text ) < class ' str '> >>> thetag [ 'class' ] [ 's' ] name: 标签对象的标签名字 string: 返回NavigableString对象，这里暂时先略过讨论。 text: 返回标签所包含的文本对象。 get_text(): 从最新的bs4文档来看，官方文档推荐tag获取其内文本内容都用 get_text 方法，而不要使用上面的 thetag.text 这种形式了。 ['class']: 属性值索引，上面的\"class\"属性具体返回的是一个列表，叫做什么多值属性。 基于某个标签的附加查找 我们通过 find 或 find_all 能够找到某个或某些标签对象了，然后bs4还给标签对象加上了一些辅助查找方法，基于这个标签对象来进一步查找，从而返回其他某个或某些标签对象。 平行级别上下标签 这里所谓的平行级别上下标签是指如下面这个例子: <html> <body> <a> <b> text1 </b> <c> text2 </c> </a> <d> test3 </d> </body> </html> 标签和 标签就是一个html文档缩进深度，它们就属于一个层次的平行标签。而 和 也是属于平行标签，但 和 则不是。 平行级别下标签 find_next_sibling(name, attrs, string, **kwargs) 才外还有返回一些标签对象（对应find_all方法）的方法: find_next_siblings(name, attrs, string, limit, **kwargs) 比如上面的例子我们有: >>> [ i for i in soup.a.next_siblings] ['\\n', <d> test3 </d> , '\\n'] >>> [ i for i in soup.b.next_siblings] ['\\n', <c> text2 </c> , '\\n'] >>> 这些方法的用法和前面谈及的 find 还有 find_all 类似，但多少有点令人沮丧的是，beautifulsoup受到换行符的干扰，在 这篇网页 中提到预处理网页将换行符都换成空格，然后将标签之间的各个空格符号都删除的解决方案，虽然不是很完美，但作为解决也是可以接受的，因为网络抓取实际上进来的网页简化预处理是必须要做的一步工作。 平行级别上标签 平行级别上标签类似上面的描述，不过是往上走，这里就不赘述了。 find_previous_sibling(name, attrs, string, **kwargs) 此外还有返回一些标签对象（对应find_all方法）的方法: find_previous_siblings(name, attrs, string, limit, **kwargs) 非平行级别上下标签 find_parents(name, attrs, string, limit, **kwargs) find_parent(name, attrs, string, **kwargs) find_all_next(name, attrs, string, limit, **kwargs) find_next(name, attrs, string, **kwargs) find_all_previous(name, attrs, string, limit, **kwargs) find_previous(name, attrs, string, **kwargs) .contents and .children select方法 select方法通过CSS选择器来进行标签元素的选择。原则上上面谈论的那些方法已经能够满足我们大部分的需求了，再加上专门针对某个个别网站的个别网页的css布局而进行抓取，这种抓取方法是很不灵活很有局限性的，所以select方法应该作为用户的最后备选方案。 移除某个标签 s = soup.find('sup') s.extract() 解析部分文档来提升效率 请看到下面这个函数，其用途是将整个webpage的所有a连接有href属性的链接收集起来。 def get_webpage_links ( html , baseurl ): ''' 刷本网页 a标签 有 href 属性的所有 links 绝对化路径 去除fragment 返回字典值去重 ''' soup = BeautifulSoup ( html , 'lxml' , parse_only = SoupStrainer ( 'a' )) links = [ link . get ( 'href' ) for link in soup . find_all ( 'a' , href = True )] links = [ to_absolute_url ( baseurl , link ) for link in links ] links = [ remove_url_fragment ( link ) for link in links ] return set ( links ) 其中: soup = BeautifulSoup(html, 'lxml', parse_only=SoupStrainer('a')) parse_only 参数用于控制BeautifulSoup一开始刷文档时创建标签元素对象的时候，就只刷某些标签而进行了过滤操作，从而大大节省了工作量。具体参数是创建一个 SoupStrainer 对象，其接受的过滤器语法和前面叙述的一样。","tags":"python爬虫","url":"articles/beautifulsoup-module.html"},{"title":"scrapy模块","text":"简介 老实说Scrapy模块和Django模块在实用上包括在内容目录结构上都很相似，当然这两个项目干的完全是两个不同的事情，我想这种相似性更多的可以描述为类似于大多数GUI界面的那种类似。 我之前尝试过写过一个小的Spider网络爬虫程序，其实网络爬取大体过程都是类似的，因此我学习Scrapy项目大体只是一些基本配置的了解，对于其内部原理已经很熟悉了，所以本文不会在这些地方赘述了。 scrapy就是一个python模块，可以通过 pip 安装之，所以安装这块也不多说了。 新建一个项目 scrapy startproject project_name [path] 因为我喜欢创建python的venv虚拟环境，所以上面最后path设置为 . 当前目录下的意思。 然后接下来就是编写爬虫Spider脚本还有等等其他一些配置了。 第一个例子 下面是一个简单的例子： class MySpider ( scrapy . Spider ): user_agent = get_random_user_agent () name = \"7yrt\" start_urls = [ 'http://7yrt.com/html/rhrt/' ] allowed_domains = [ 'http://7yrt.com/' ] def parse ( self , response ): url = response . url html = response . text ## do something if re . match ( 'http://7yrt.com/html/rhrt/[\\d]+/[\\d]+/[\\d_]+.html' , url ): images = parse_webpage_images ( url , html , name = 'div' , class_ = 'imgview' ) title = response . xpath ( '//h1/text()' ) . extract_first () for index , image in enumerate ( images ): yield MyItem ( uuid = get_item_uuid ( url , str ( index )), image_url = [ image ], name = title ) ##### get next page links = parse_webpage_links ( url , html ) for next_page in links : yield scrapy . Request ( next_page , callback = self . parse ) user_agent 属性改变你爬虫情况的USER_AGENT HTTP头，这通常需要设置一下，防止你的爬虫被ban。 name 你的爬虫的名字，等下你要具体运行某个爬虫的名字是 scrapy crawl spider_name ，用的就是这里定义的名字。然后 scrapy list 显示的也是这些爬虫名字。 start_urls 你的爬虫起始开爬点，官方教程提到过 start_requests 这个方法，一般就定义 start_urls 还是很简便的。 allowed_domains 你可以在 parse 方法获取 next_page 的时候自己定义过滤行为，更简单的就是定义站点内这个行为，这个熟悉点网络爬虫基本编写原理的都会了解这个概念，不过记得你还需要在 settings.py 那边设置： SPIDER_MIDDLEWARES = { 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware': None, } parse方法 parse方法类似于Django也有request请求和response的概念，简单来说每一个URL（按照基本网络爬虫模型）最后都会送入到这个方法，其要完成的工作有： 针对某些特定的url获取数据 添加next page行为（其内暗含的行为有去重，舍弃，过滤等） response对象 response对象可以获取 response.text 然后送给beautifulsoup来处理，比如上面的 parse_webpage_images 和 parse_webpage_links 就是这样做的，主要是这两个以前写的函数还是很简便的，所以就没考虑效率问题了，有的时候真的不在乎那么一点，因为后面还会讨论减缓爬虫爬取速度的问题。 然后官方教程提到的response对象可以调用 css 或 xpath 方法来进行一些信息提取工作，这个简单了解下xpath语法，还是很便捷的。 MyItem对象 MyItem对象是在 items.py 哪里定义的，很简单，没啥好说的，就是一个简单的python对象罢了，方便存储数据用。你若不喜欢，就临时定义一个字典值也是可以的。 settings.py里面的配置 减缓访问速度 在网络爬取中，防止被ban（一般403错误就是由此而来）一直是个大问题。开代理换IP要求挺高的，不过下面这些手段一般还是能够实现的，这些都在settings.py里面就有了，只需要去注释就是了。大体有下面这些： DOWNLOAD_DELAY = 3 CONCURRENT_REQUESTS_PER_DOMAIN = 16 #CONCURRENT_REQUESTS_PER_IP = 16 # Disable cookies (enabled by default) COOKIES_ENABLED = False 就是设置下载访问停顿时间和并行请求数还有禁用cookies。除了禁用cookies之外，上面这几个设置可以不用，请看到官方文档的 这里 。 这个在 settings.py 文件的后面些也有，这是一种自动节流机制，它是利用下载延迟还有并行数来自动调节DELAY时间， AUTOTHROTTLE_ENABLED = True # The initial download delay AUTOTHROTTLE_START_DELAY = 5 # The maximum download delay to be set in case of high latencies AUTOTHROTTLE_MAX_DELAY = 60 # The average number of requests Scrapy should be sending in parallel to # each remote server AUTOTHROTTLE_TARGET_CONCURRENCY = 1.0 最后要说的是自动节流和前面的 DOWNLOAD_DELAY 和 CONCURRENT_REQUESTS_PER_DOMAIN 是协作关系。自动节流最小不会小过 DOWNLOAD_DELAY ，最大不会大过 AUTOTHROTTLE_MAX_DELAY 。 然后 AUTOTHROTTLE_TARGET_CONCURRENCY 也只是一个节流建议，并不是最大极限，对于单个域名的最大并行请求数是由 CONCURRENT_REQUESTS_PER_DOMAIN 定义的。 JsonPipeline pipelines.py 文件里面就定义了一些你自己写的Pipeline类，比如下面这个是JsonPipeline类： class JsonPipeline ( object ): def __init__ ( self ): self . file = codecs . open ( 'test.json' , 'w' , encoding = 'utf-8' ) def process_item ( self , item , spider ): line = json . dumps ( dict ( item ), ensure_ascii = False , indent = 4 ) + \" \\n \" self . file . write ( line ) return item def spider_closed ( self , spider ): self . file . close () 大体就是一个简单的类，其中一些特别的方法有特别的用处。这个jsonpipelie并不具有实用价值，简单了解下即可。 ImagesPipeline 想要自动下载图片，没问题，scrapy已经内置有这个功能了！你需要做的就是收集好图片连接就是了。设置里要加上这样一行： ITEM_PIPELINES = { 'scrapy.pipelines.images.ImagesPipeline': 1, } 然后设置里还有如下相关配置: IMAGES_STORE = '/path/to/download_images' IMAGES_URLS_FIELD = 'image_url' IMAGES_RESULT_FIELD = 'image' 这里 IMAGES_URLS_FIELD 的默认值是 image_urls ，你需要在你的items对象加上这一属性，其是一个列表值。然后 IMAGES_RESULT_FIELD 默认值是 images ， 这个值ImagesPipeline会自动填充，不需要管的。这里改名字是因为我不喜欢很多图片混在一起，所以做了一些处理分开了。 MongoDBPipeline 想要把数据直接实时填入到mongodb里面去？用 MongoDBPipeline 即可，你需要 pip install scrapy-mongodb 然后配置加上 ITEM_PIPELINES = { 'scrapy_mongodb.MongoDBPipeline': 400, } 这后面的数字只是执行优先级，没什么特别的含义。 然后还有配置： MONGODB_URI = 'mongodb://localhost:27017' MONGODB_DATABASE = 'myscrapy' MONGODB_UNIQUE_KEY = 'uuid' 这个插件的 MONGODB_COLLECTION 值默认是 items 是个死的，我还不是很满意。然后 MONGODB_UNIQUE_KEY 我还不清楚是什么，后面有时间继续。 测试抓取 scrapy shell url 然后进入shell之后，有个 response 对象，其对应于之前写爬虫 parse函数时候的那个response对象。进一步可以做一些前期测试抓取的工作。 settings的传递 爬虫初始化后， self.settings 就可以使用了，通过它你就可以调用一些在 settings.py 文件里面的配置变量了。然后你在写pipeline的时候，如下： def open_spider ( self , spider ): self . client = MongoClient ( self . mongo_uri ) self . mongodb = self . client [ self . mongo_dbname ] spider . mongodb = self . mongodb open_spider 是打开爬虫后的动作，定义 self.mongodb 是将目标mongodb 数据库对象挂载本 pipeline上，而 spider.mongodb 是将这个变量挂在本爬虫上，这样后面你的爬虫类那里都是可以直接用 self.mongodb 来调用目标变量的，但说到爬虫类 __init__ 方法里面还不大确定。然后你写pipeline的时候通过 crawler.settings 也可以或者配置变量： @classmethod def from_crawler ( cls , crawler ): return cls ( mongo_uri = crawler . settings . get ( 'MONGODB_URI' ), mongo_dbname = crawler . settings . get ( 'MONGODB_DATABASE' ) ) xpath语法 下面主要通过各个例子简要介绍xpath语法之，参考了 阮一峰的这篇文章 和菜鸟教程的xpath教程。 选择title //title 这是选择到了文档中任意位置的 title 标签， / 开头的话会选择根节点，这不太好用。 选择title包含的文本 //title/text() 按照id选择 //div[@id='post-date']/text() 上面例子的意思是选择一个div标签，其有id属性 post-date ，如果div改为 * 则为随便什么标签名字。 继续往下选 //*[@id='js_profile_qrcode']/div/p[1]/span/text() 选择目标标签的属性 ////*[@id='js_profile_qrcode']//a/@href user agent 设置 你可以设置middlesware来设置useragent： class MyUserAgentMiddleware ( UserAgentMiddleware ): def __init__ ( self , user_agent = 'Scrapy' ): super ( MyUserAgentMiddleware , self ) . __init__ () self . user_agent = get_random_user_agent () def process_request ( self , request , spider ): if self . user_agent : request . headers . setdefault ( 'User-Agent' , self . user_agent ) logger . debug ( 'Using User-Agent:{0}' . format ( request . headers [ 'User-Agent' ])) 因为middleware是在你的爬虫开始之前就运行了，所以你的爬虫一开始就有一个 user_agent 属性了。 可能你还有其他需求，需要临时改变user agent，那么在你的爬虫类的属性设置那里可以直接设置： user_agent = what 这样将覆写原来middleware指定的self.user_agent，实际上在middleware之前你的settings那里还可以设置user_agent，而那是最先的scrapy默认的useragentMiddleware的行为，本小节的讨论参考了 这个网页 eLRuLL 的回答和自己的一点小小的print。 模拟用户登录 import scrapy class LoginSpider ( scrapy . Spider ): name = 'example.com' start_urls = [ 'http://www.example.com/users/login.php' ] def parse ( self , response ): return scrapy . FormRequest . from_response ( response , formdata = { 'username' : 'john' , 'password' : 'secret' }, callback = self . after_login ) def after_login ( self , response ): # check login succeed before going on if \"authentication failed\" in response . body : self . logger . error ( \"Login failed\" ) return # continue scraping with authenticated session... 防止被封的策略 设置随机的user agent策略 禁用cookie COOKIES_ENABLED = True 设置下载停顿 DOWNLOAD_DELAY = n 使用代理池","tags":"python爬虫","url":"articles/scrapy-module.html"},{"title":"python语言学习之-编码风格推荐","text":"PEP8代码风格规范是每个python程序员都应该了解的内容，其具体内容官方文档在 这里 。 关于空白和其他一些格式现在的编辑器加上插件都可以做到自动pep8格式调整，比如 autopep8 模块等，这一块就不多说了。 这里主要简单地说一下变量名的命名规范 【高质量python代码】： 字母都大写的变量，我们一般认为它是模块文件级别的常量，各单词用下划线隔开。 首字母大写的我们一般认为它是类或者异常名字，多个单词的用驼峰写法表示。 其他一律是小写字母，用下划线隔开。 一般开发者不应该命名下划线开头的变量，你若这样写你必须知道自己在干什么。 其他编码风格推荐 不要使用带两个以上for语句的列表解析。 用生成器表达式改写数据量较大的列表解析。 it = (len(x) for x in open('/tmp/myfile.txt')) 不要在for和while循环后面写上else语句。这个建议有利于程序的简洁直观，可以接受。 函数的返回值是你需要的返回值才有意义，如果不是，而只是某些特殊的情况，那么最好抛出异常。 python哲学 参考了 这个网页的翻译 。 美优于丑。 直白优于隐晦。 简单优于复杂。 复杂优于纠结。 扁平优于嵌套。 稀疏优于稠密。 可读性是有重要价值的。 特例可以有，但不能特例到打破规则。 尽管在纯粹性和实用性之间倾向的是实用性。 出错决不能无声无息地忽略。 除非明确地说明了是无声无息的。 面对二义性情况时，要拒绝任何猜的诱惑。 一件事应该一种做法 —— 并且宁愿只有一种做法 —— 一种显而易见的做法。 尽管在刚开始的时候这个做法可能不是那么显而易见，毕竟你不是荷兰人。 『现在』优于『决不』。 尽管『决不』常常优于『 马上 』。 如果一个实现难于解释清楚，那它是个差的想法。 如果一个实现很容易解释清楚，那它可能是个好的想法。 命名空间是个拍案叫绝的想法 — 放手多多用起来吧！","tags":"python语言","url":"articles/python-style-guide.html"},{"title":"python语言学习之-测试开发","text":"测试开发风格是如此重要，下面进一步讨论之来提高我们的测试驱动型开发。首先推荐使用pytest。 pytest简介 pytest模块是站在unittest基础上的，就简单的应用如下，通过pip安装pytest，然后你之前通过 unittest 写的测试案例，全部都不用更改照样有用，接下来你要写一个新的测试，不需要再新建一个 unittest.TestCase 类了（如果你希望多个测试在一个类里面，就新建一个类即可，这个类不需要继承自任何类了。），直接如下写测试函数就是了，然后也不确认就是最简单的 assert 确认返回为 True 即可。 def test_prime(): assert prime(4) == 7 确认抛出某个异常 把官方的例子copy过来了，看一下就懂了。 import pytest def f (): raise SystemExit ( 1 ) def test_mytest (): with pytest . raises ( SystemExit ): f () 完了，如果你赶时间的话，这就足够了。下面说一些让你更加优雅地进行测试工作的技巧。 实时修改代码实时测试 推荐安装的有： pytest 和 pytest-runner 。然后新建 setup.cfg 文件，里面的内容是： [aliases] test = pytest 这样当你输入 python setup.py test 实际等于输入 python setup.py pytest 。 以后你要测试就输入： python setup.py test 这样做的好处是，其是直接利用本地修改的源码，也就是一边修改源码一边实时测试。 这样写的话记得要给pytest传递参数需要加上 --addopts= 选项，比如打印更多的信息： python setup.py test --addopts=\"-v\" 可能每次写 --addopts=\"-v\" 有点麻烦，在 setup.cfg 上加上这样一句吧： [tool:pytest] addopts = --verbose 好了，就是： python setup.py test 然后专心一边测试一边写代码吧。 只单独测试某个文件 还是跟着上面的 --addopts= 选项来，把具体某个测试py文件相对路径写上即可。 自动发现测试文件 pytest是支持自动发现测试文件的，所有的 test_*.py 和 *_test.py 文件都被认为是测试文件。 一般是推荐统一管理测试文件，如这样设置：新建一个 pytest.ini 文件，里面的内容是： [pytest] testpaths = tests 这样pytest就只处理这个tests文件夹下的测试文件了。 可能有某些情况你希望你的测试文件和代码文件在一起（请确定你必须这样做，毕竟将测试代码和模块源码放在一起很不美观），没问题，写上就是了，pytest会自动发现它的。记得将上面的那个 pytest.ini 文件的 testpaths 配置删除掉算了。 fixture功能 pytest里面比较高级一点的功能大概就是fixture功能了，这个等下再讲。TODO。 测试过一次下次不测试了 函数上加上这个装饰器。 @pytest.mark.skip(reason=\"i have test it\") mock模块的使用 在大型框架中写单元测试，在涉及到网络，套接字等编程问题是，必然有这个需求，那就是你希望伪造一些数据，拦截某些函数或类的返回值，从而将整个测试从大型软件框架中抽离出来，这个时候就必须要了解mock模块了。python3自带的有mock模块，直接用就是了： from unittest import mock 使用mock模块最关键性的问题是理解mock在做什么。mock模块里面最核心的概念是 Mock 类 ，我们看到官方文档的这个例子： from unittest import mock class Test (): pass t = Test () t . method = Mock ( return_value = 3 ) t . method = mock . Mock ( return_value = 3 ) t . method () 3 t . method ( 1 , 2 , 3 ) 3 一开始的话我们还是不要管那个 MagicMock 是个什么东西吧，暂时 Mock够用了。然后Mock也可以通过 side_effect 来定制抛出异常。 在来个定制函数返回的例子： test = mock.Mock(return_value='hello world.') test() 'hello world.' just patch it 实际编码中我们更多的是和现有的代码或者现有的第三方库的代码来交互，而不是凭空创造个Mock对象进行测试。我们看下面这个例子： @mock.patch('users.views.WXAPPAPI.jscode2session', \\ return_value={\"openid\": \"o1ZL90Blemh5ylei7sBfQotG7PLM\", \"session_key\": \"4XXDVTc0e4nuDVp20CIcOg==\", \"expires_in\": 7200}) def test_login(self, mock_jscode2session): data = {'js_code': '003xXUd30hnknF1gLeg30ua5e30xXUdr'} response = self.client.get(reverse('mini-login'), data) # for next testcase self.our_session_key = response.data.get('our_session_key') self.assertEqual(response.status_code, status.HTTP_200_OK) 如何理解上面的代码？当这段测试代码运行的时候，它的变量名字空间被patch给污染了，比如上面的 users.views.WXAPPAPI.jscode2session 这个函数，被污染成为一个 Mock 对象了，这个Mock对象传递给了这个函数的第二个参数（额外的的这个参数哪怕你后面不用也必须写上） mock_jscode2session 。 然后代码在运行的时候遇到 jscode2session 总会返回上面给出的值，这样你就不用考虑数据库啊，网络情况之类的问题了。上面还有一些小技巧和django框架相关，比如 self.client.get(reverse('mini-login'), data) 是直接利用自己django，然后自己请求自己的url获得什么响应，这个和django相关，在这里就不多说了。","tags":"python语言","url":"articles/pythonyu-yan-xue-xi-zhi-ce-shi-kai-fa.html"},{"title":"python语言学习之-官方模块第三谈","text":"re模块 re模块提供了python对于正则表达式的支持，对于字符串操作，如果之前在介绍字符串类型的一些方法（比如split，replace等等），能够用它们解决问题就用它们，因为更快更简单。实在需要动用正则表达式理念才考虑使用re模块，而且你要克制写很多或者很复杂的（除非某些特殊情况）正则表达式的冲动，因为正则表达式的引入将会使得整个程序都更加难懂和不可捉摸。 更多内容请参见 官方文档 。 re模块中的元字符集 . 表示一行内的任意字符，如果如果通过re.compile指定 re.DOTALL ，则表示多行内的任意字符，即包括了换行符。此外还可以通过字符串模板在它的前面加上 (?s) 来获得同样的效果。 * 对之前的字符匹配或者多次。 + 对之前的字符匹配或者多次。 ? 对之前的字符匹配或者。 {m} 对之前的字符匹配()m次。 {m,n} 对之前的字符匹配m次到n次，其中n次可能省略，视作默认值是无穷大。 \\&#94; 表示字符串的开始，如果加上 re.MULTILINE 选项，则表示行首。此外字符串模板加上 (?m) 可以获得同样的效果。 \\$ 表示字符串的结束，同\\&#94;类似，如果加上 re.MULTILINE 选项，则表示行尾，可以简单理解为 \\n 换行符。此外字符串模板加上 (?m) 可以获得同样的效果。 \\ \\(符号在re.sub函数中可以被替换为另外一个字符串，其具体效果就是原字符串尾加上了这个字符串，类似的\\&#94;被替换成某个字符串，其具体效果就是原字符串头加上了这个字符串。这里显然\\&#94;和\\\\) 在字符串中都不是真实存在的字符，而没有这个所谓的标记，所以这种替换总给人怪怪的感觉。 [] [abc]字符组匹配一个字符，这个字符是a或者b或者c。类似的[a-z]匹配所有的小写字母， [\\w] 匹配任意的字母或数字，具体请看下面的特殊字符类。 | 相当于正则表达式内的匹配或逻辑。 () 圆括号包围的部分将会记忆起来，方便后面调用。这个后面在谈及。 re模块中的特殊字符类 \\w 任意的字母或数字 [a-zA-Z0-9_] (meaning word) \\W 匹配任何非字母非数字 [&#94;a-zA-Z0-9_] \\d [0-9] (digit) 数字 \\D [&#94;0-9] 非数字 \\s 匹配任何空白字符 [ \\t\\n\\r\\f\\v] 。 \\S 匹配任何非空白字符 匹配中文:[\\u4e00-\\u9fa5] \\b 文档说严格的定义是\\w 和\\W 之间的边界，反之亦然。粗略的理解可以看作是英文单词头或者尾。 其中\\&#94;在方括号[]里面，只有在最前面，才表示排除型字符组的意思。 转义问题 正则表达式的转义问题有时会比较纠结。一个简单的原则是以上谈及的有特殊作用的字符有转义问题，如果python中的字符都写成 r'' 这种形式，也就是所谓的raw string形式，这样 \\n 在里面就可以直接写成 \\n ，而 \\section 可以简单写为 \\\\section 即可，也就是 \\ 字符需要转义一次。 然后字符组的方括号内[]有些字符有时是不需要转义的，这个实在不确定就转义吧，要不就用正则表达式工具测试一下。 re模块的使用 compile方法生成regular expression object这一条线这里略过了，接下来的讨论全部基于（原始的）字符串模板。 字符串模板前面提及(?m)和(?s)的用法了，然后 (?i) 表示忽略大小写。 匹配和查找 search，match方法简单地用法就是： re.search(字符串模板, 待匹配字符串) re.match(pattern, string) 它们将会返回一个match object或者none，其中match object在逻辑上就是真值的意思。match对字符串的匹配是必须从一开始就精确匹配，这对于正则表达式多少0有点突兀。推荐使用search方法，如果一定要限定行首，或者字符串开始可以用前面讨论的正则表达式各个符号来表达。请看下面的例子。 import re string = '''this is test line. this is the second line. today is sunday.''' match = re . search ( '(?m)&#94;today' , string ) if match : print ( '所使用的正则表达式是：' , match . re ) print ( '所输入的字符串是：' , match . string ) print ( '匹配的结果是：' , match . group ( 0 )) print ( '匹配的字符串index' , match . span ()) else : print ( 'return the none value' ) 前面说道圆括号的部分将会记忆起来，作为匹配的结果，默认整个正则表达式所匹配的全部是group中的第0个元素，然后从左到右，子group编号依次是1，2，3......。 所使用的正则表达式是： re.compile('(?m)&#94;today', re.MULTILINE) 所输入的字符串是： this is test line. this is the second line. today is sunday. 匹配的结果是： today 匹配的字符串index (44, 49) 具体这些信息是为了说明情况，实际最简单的情况可能就需要判断一下是不是真值，字符串模板是不是匹配到了即可。 分割操作 re模块的split函数可以看作字符串的split方法的升级版本，对于所描述的任何正则表达式，匹配成功之后都将成为一个分隔符，从而将原输入字符串分割开来。 下面是我写的zwc小脚本的最核心的部分，用途是统计中英文文档的具体英文单词和中文字符的个数。其中最核心的部分就是用的re的split函数进行正则表达式分割，如果不用那个圆括号的话，那么分隔符是不会包含进去的，这里就是具体匹配的中文字和各个标点符号等等。用了圆括号，那么圆括号匹配的内容也会进去列表。这里就是具体的各个分隔符。 import re def zwc ( string ): #中英文常用标点符号 lst = re . split ( '([ \\u4e00 - \\u9fa5 \\s，。；])' , string ) #去除 空白 #去除\\s 中英文常用标点符号 lst = [ i for i in lst if not i in [ \"\" , \" \" , \" \\n \" , \" \\t \" , \" \\r \" , \" \\f \" , \" \\v \" , \"；\" , \"，\" , \"。\" ]] print ( lst ) if __name__ == '__main__' : string = '''道可道，非常道。名可名，非常名。無名天地之始，有名萬物之母。 故常無欲，以觀其妙；常有欲，以觀其徼。此兩者同出而異名， 同謂之玄，玄之又玄，眾妙之門。 ''' zwc ( string ) 字符分割之后后面做了一个小修正，将匹配到的空白字符和中英文标点符号等都删除了，这些是不应该统计入字数的。 具体这个github项目链接在这里： zwc项目 。 替换操作 基于正则表达式的替换操作非常的有用，其实前面的search方法，再加上具体匹配字符串的索引值，然后修改原字符串，然后再search这样循环操作下去，就是一个替换操作了。re模块有sub方法来专门解决这个问题。 非最长匹配 本小节参考了 python cookbook 的 2.7 小节，比如说： re.compile(r'\"(.*)\"') 这将匹配两个双引号之间的内容，其默认是最长匹配，也就是多个双引号组成的句子都会匹配进去，你可以如下要要求最短匹配： re.compile(r'\"(.*?)\"') 非捕获组 看下面的正则表达式， (?:...) 这个括号的组是非捕获组，也就是不会进入 .group 里面去。 re.search(r'((?:.|\\n)*)',text2) 然后默认 . 是不会匹配换行符号的，如果要引入换行符则要如上所示加上。 abc模块 abc模块帮助你实现抽象基类，有点类似于java中抽象类的概念。 具体实现如下所示： from abc import abstractmethod from abc import ABC class Graph ( ABC ): \"\"\" 一般图 \"\"\" DIRECTED = None @abstractmethod def nodes ( self ): \"\"\" :return: \"\"\" raise NotImplementedError ( \"Not Implement nodes methods\" ) 抽象类不可实例化，实例化将会报错。继承于它的类，如果如上定义了抽象方法，那么继承它的类必须定义好对应方法的实现，否则将会报错。 抽象类里面也可以定义不是抽象方法的其他实际动作的方法。 抽象类里面还可以定义抽象属性。 argparse模块 下面简要介绍了python3的官方文档argparse模块的用法，用于快速制作一个可以刷参数的python脚本。 首先看下面这个简单的情况: import argparse usage = ''' this is a example to show argparse usage ''' parser = argparse . ArgumentParser ( usage = usage ) args = parser . parse_args () 这是简单的一个例子了，现在脚本还不可以接受任何参数，只可以用 -h 或 --help 来查看一些信息，如下所示。 wanze@wanze-ubuntu64:~/桌面$ python3 hello.py -h usage: this is a example to show argparse usage [-h] optional arguments: -h, --help show this help message and exit 其首先是新建一个parser，上面ArgumentParser的usage是可选参数，就是命令行的一些描述信息。然后需要调用parser的 parse_args 方法，其就是具体将命令行接受的一些参数刷进去。 简单添加一个参数 上面的例子太简单了，现在开始简单添加一个参数。 import argparse usage = ''' this is a example to show argparse usage ''' parser = argparse . ArgumentParser ( usage = usage ) parser . add_argument ( '--config' , help = \"the config file path\" ) args = parser . parse_args () print ( args ) 这样命令行的帮助信息就变成如下所示了: wanze@wanze-ubuntu64:~/桌面$ python3 hello.py -h usage: this is a example to show argparse usage optional arguments: -h, --help show this help message and exit --config CONFIG the config file path 如果我们如下输入则有: wanze@wanze - ubuntu64 : ~ / 桌面$ python3 hello . py -- config = 'config.cfg' Namespace ( config = 'config.cfg') 我们看到 parse_args 方法返回的是Namespace对象，推荐用 vars 函数来将其处理成为字典值，这样会更好地方便后面的使用。 import argparse usage = ''' this is a example to show argparse usage ''' parser = argparse . ArgumentParser ( usage = usage ) parser . add_argument ( '-c' , '--config' , help = \"the config file path\" ) args = vars ( parser . parse_args ()) print ( args ) wanze @wanze - ubuntu64 : ~/ 桌面$ python3 hello . py - h usage : this is a example to show argparse usage python3 hello . py optional arguments : - h , -- help show this help message and exit - c CONFIG , -- config CONFIG the config file path wanze @wanze - ubuntu64 : ~/ 桌面$ python3 hello . py -- config = 'config.cfg' { 'config' : 'config.cfg' } 上面代码稍作修改，在长名字可选参数前面还可以加上短名字可选参数支持，然后我们看到 parse_args 方法经过 vars 处理之后返回的是字典值。该字典的key默认对应的是长名字可选参数。你还可以自己设置目标参数名: 添加参数的其他选项设置 下面演示了如何设置目标参数在脚本中具体对应的变量名: import argparse usage = ''' this is a example to show argparse usage ''' parser = argparse . ArgumentParser ( usage = usage ) parser . add_argument ( '-c' , '--config' , dest = \"configpath\" , help = \"the config file path\" ) args = vars ( parser . parse_args ()) print ( args ) 然后我们看到字典输入如下: wanze@wanze-ubuntu64:~/桌面$ python3 hello.py --config='config.cfg' {'configpath': 'config.cfg'} 当然一般就默认设置成为和长名字可选参数一致，没必要这么折腾。类似的你还可以继续用 add_argument 方法来添加其他的可选参数，然后 add_argument 还有如下一些选项配置: required=True 该参数一定要输入值，否则报错 help 描述信息，前面已经看到了。 default 该参数的默认值，默认是None，你可以选择设置成另外一个值。 type 目标参数的数据类型，默认是字符串，可以设置为int或float。注意设置格式如下，不是字符串的那种设置形式: ​ parser.add_argument('--delay',type=int) 必填参数的添加如下所示，除了这个\\\"target\\\"名字前面没有 -- 之外，和可选参数用法大致类似，其刷入args字典之后的key就是\\\"target\\\"这个名字。 parser.add_argument('target',help=\"必填参数\") 不过必填参数和可选参数在某些细节上还是有点差异的，后面会提及。 nargs选项设置 nargs设置之后该参数在脚本中具体对应的变量将是一个列表。其中nargs可以设置为一个数字，比如 nargs=4 ，则脚本对该参数将接受4个输入值，然后将其收集进一个列表里面。 此外还有: nargs='*' 这通常是对可选参数进行设置，当然也可以作用于必填参数，但这让必填参数失去意义了。其将收集任意多的输入参数值，而如果多个可选参数之间这样使用星号是可以的，具体请参看官方文档。 nargs='+' 这通常作用于必填参数，其意义有点类似于正则表达式里面的'+'号，和上面的'*'号比起来其必须有一个输入值，否则将报错。 nargs='?' 这个'?'号具体使用情况挺复杂的，我不太喜欢，而且其和nargs其他的一些设置比较起来显得有点格格不入。首先其对应的变量值不是列表而是单个值！其次其改变了默认值的行为。如果该参数不输入，比如 ​ --foo ​ 这个东西完全不输入在命令行里面，那么foo默认取default的值，如果加入了 ​ --foo 这个东西但是后面又不跟值，则foo取 const ​ 选项赋的值。不太喜欢这个东西。 一个完整的例子 下面给出一个完整的例子: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 #!/usr/bin/env python3 # -*- coding: utf-8 -*- import argparse usage = ''' resize the image ''' def main (): parser = argparse . ArgumentParser ( usage = usage ) parser . add_argument ( '-c' , '--config' , dest = \"configpath\" , help = \"the config file path\" ) parser . add_argument ( 'inputimg' , help = \"the input image\" , nargs = '+' ) parser . add_argument ( '--width' , help = \"the input image\" , type = int ) args = vars ( parser . parse_args ()) configpath = args [ 'configpath' ] width = args [ 'width' ] inputimg = args [ 'inputimg' ] for inputimg in args [ 'inputimg' ]: print ( 'resize image' ) print ( 'the input image is {} ' . format ( inputimg )) print ( 'the target width is {} ' . format ( width )) if __name__ == '__main__' : main () 具体运行情况如下所示: wanze@wanze-ubuntu64:~/图片$ python3 resizeimg.py --help usage: resize the image positional arguments: inputimg the input image optional arguments: -h, --help show this help message and exit -c CONFIGPATH, --config CONFIGPATH the config file path --width WIDTH the input image wanze@wanze-ubuntu64:~/图片$ python3 resizeimg.py --width=300 *.png resize image the input image is 2015-01-27 13:16:46 的屏幕截图.png the target width is 300 resize image the input image is 2015-05-03 18:17:19屏幕截图.png the target width is 300 resize image the input image is 2015-05-03 18:20:45屏幕截图.png the target width is 300 .... 命令行选项关联其他动作 parser的 add_argument 方法的 action 参数就是用来控制命令行选项关联的动作的，一般都不需要设置，就是默认的 store ，也就是存储值。类似的有 store_const , store_true 和 store_false 。 store_const 如果是默认的store，则通常是需要指明具体值的，如果设置action为 store_const 了: parser.add_argument('--foo', action='store_const', const=42) 那么如下就会自动设置该值，这和default默认值的区别是这个选项的值要求是某个常量值。 >> python3 test2 . py -- foo Namespace ( foo = 42 ) store_true 和 store_false 如果写为: parser.add_argument('--foo', action='store_true') 则其存储的就是 True 值: >> python3 test2 . py -- foo Namespace ( foo = True ) 这里主要是要讲定义自己的动作，就是类似 --version 这样的用法，是一种影响程序整个工作流的选项，官方文档推荐通过子类化 argparse.Action 的方法，还是有点麻烦的。然后发现 click 模块非常好（一个解决创建命令行脚本工具问题推荐使用的第三方模块），处理这个问题也很容易: import click def print_version ( ctx , param , value ): if not value or ctx . resilient_parsing : return click . echo ( 'Version 1.0' ) ctx . exit () def quick ( ctx , param , value ): print ( ctx , param , value ) ctx . exit () @click.command () @click.option ( '--version' , is_flag = True , callback = print_version , expose_value = False , is_eager = True ) @click.option ( '--quick' , callback = quick , is_flag = True ) def hello (): while True : userinput = input ( 'input:' ) click . echo ( userinput ) if userinput == 'exit' : break if __name__ == '__main__' : hello () 这里的ctx和param到click模块那边再细讲吧，我们看到整个过程比argparse美观多了。 ast模块 更多信息请参看 官方文档 。 literal_eval函数 literal_eval 函数是一个非常有用的函数，其可用于将某个短小的python字符串转化成python object。如下所示: import ast def str2pyobj ( val ): '''str to python obj or not changed''' try : val = ast . literal_eval ( val ) except Exception : ### pass return val 支持的python object有: strings, bytes, numbers, tuples, lists, dicts, sets, booleans, and None. 所以一般的字符串如 \\\"1\\\" \\\"3.14\\\" \\\"[1,2,3]\\\" 将其分别转化成为integer float 和list是小菜一碟。当然最好建立异常捕捉，如果转化失败，则原样返回字符串即可。 collections模块 更多内容请参见 官方文档 。 namedtuple函数 collections模块里面的namedtuple函数将会产生一个有名字的数组的类（有名数组），通过这个类可以新建类似的实例。比如： from collections import namedtuple Point3d = namedtuple ( 'Point3d' ,[ 'x' , 'y' , 'z' ]) p1 = Point3d ( 0 , 1 , 2 ) print ( p1 ) print ( p1 [ 0 ], p1 . z ) Point3d ( x = 0 , y = 1 , z = 2 ) 0 2 Counter计数类 可以进行简单的输入数据统计频数计算。 OrderedDict对象 python中的字典对象默认各个key是没有顺序的，OrderdDict对象的概念就是在字典概念的基础上让各个key有顺序。 一个例子如下所示（来自官方文档）。简单的理解就是一个字典对象记住了各个key的插入顺序。 >>> d = {'banana': 3, 'apple':4, 'pear': 1, 'orange': 2} >>> # dictionary sorted by key >>> OrderedDict(sorted(d.items(), key=lambda t: t[0])) OrderedDict([('apple', 4), ('banana', 3), ('orange', 2), ('pear', 1)]) >>> # dictionary sorted by value >>> OrderedDict(sorted(d.items(), key=lambda t: t[1])) OrderedDict([('pear', 1), ('orange', 2), ('banana', 3), ('apple', 4)]) >>> # dictionary sorted by length of the key string >>> OrderedDict(sorted(d.items(), key=lambda t: len(t[0]))) OrderedDict([('pear', 1), ('apple', 4), ('orange', 2), ('banana', 3)]) configparser模块 简单的配置文件管理就用python的内置模块configparser。python2对应的模块名字叫 ConfigParser 。 python3之后configparser的使用更加简单了，具体就分为如下几步: 新建一个configparser对象 import configparser config = configparser . ConfigParser () 读取某个config文件 调用read方法具体读取某个config文件。 config.read('test.cfg') 如同字典一般操作configparser对象 然后接下来就是如同字典一般操作这个configparser对象。其中 'DEFAULT' 是特殊的section，大致如下这样表达: config['DEFAULT'] = {'ServerAliveInterval': '45', 'Compression': 'yes', 'CompressionLevel': '9'} config['bitbucket.org'] = {} config['bitbucket.org']['User'] = 'hg' config['topsecret.server.com'] = {} 调用write方法写入 with open('example.ini', 'w') as configfile: config.write(configfile) 不默认更改大小写 具体请参看 这个网页 ，configparser模块默认把 option name 也就是每个section的key name改成小写，我不太喜欢这种风格，因为将configparser刷成字典值时，我们通常认为字典的key大小写是区分的，可以如下改动，然后就不自动进行小写操作了: self.cfg = configparser.ConfigParser() self.cfg.optionxform = str## not auto make it lowercase csv模块 Title: csv模块 Slug: cvs-module Date: 2017-11-24 12:05 Modified: 2017-11-24 12:05 Tags: python re模块 re模块中的元字符集 re模块中的特殊字符类 转义问题 re模块的使用 匹配和查找 分割操作 替换操作 非最长匹配 非捕获组 abc模块 argparse模块 简单添加一个参数 添加参数的其他选项设置 nargs选项设置 一个完整的例子 命令行选项关联其他动作 store_const store_true 和 store_false ast模块 literal_eval函数 collections模块 namedtuple函数 Counter计数类 OrderedDict对象 configparser模块 新建一个configparser对象 读取某个config文件 如同字典一般操作configparser对象 调用write方法写入 不默认更改大小写 csv模块 自定义csv方言 对应的Reader编写 对应的Writer编写 tempfile模块 mkstemp 本文主要讨论python内置模块csv略显高级的知识，也就是自定义csv的方言。 自定义csv方言 首先我们看到最通用的excel格式的csv方言写法： class excel ( Dialect ): \"\"\"Describe the usual properties of Excel-generated CSV files.\"\"\" delimiter = ',' quotechar = '\"' doublequote = True skipinitialspace = False lineterminator = ' \\r\\n ' quoting = QUOTE_MINIMAL register_dialect ( \"excel\" , excel ) 下面就这些字段的含义作出说明： delimiter 分隔符，这个意义很明显。 lineterminator 换行符，这个意义也很明显，目前主要就两种： \\r\\n 和 \\n 。 skipinitialspace 默认是False，其主要是对于如果你将空格设置为分隔符时有意义，这样后面字符开始的空格将会被忽略，其他情况设置为True或者False区别不大。 quoting 设置quote规则 csv.QUOTE_MINIMAL 意思是只有在需要的情况下才加上双引号，比如逗号在字符串里面，双引号在字符串里面，换行符号在字符串里面等等。 csv.QUOTE_ALL 意思是都加上双引号，即使是数字。 csv.QUOTE_NONNUMERIC 数字不加，字符串都加上双引号。（只有在这种情况下csv模块才会正确将数字解析为float类型） csv.QUOTE_NONE 都不加（此时需要设置好escapechar选项） quotechar 设置quote具体的字符，一般设置为双引号。 doublequote 用来处理双引号在字符串中的情况，默认是True，字符串将会双引号之外再加上双引号，如果设置为False，会前面加上一个 escapechar 。 自己定义csv方言就是类似的写上这样一个方言类，然后如下注册好即可： import csv class MindMapCSV ( csv . Dialect ): delimiter = ',' # 分隔符 quotechar = '\"' # quote符号 doublequote = True # 双引号在字符中的情况 skipinitialspace = True # 分隔符后空白忽略 lineterminator = ' \\n ' # 换行符 quoting = csv . QUOTE_MINIMAL # 最小quote csv . register_dialect ( \"MindMapCSV\" , MindMapCSV ) 对应的Reader编写 下面贴出一个样例，具体要看你设计的csv方言来的。 class Reader (): def __init__ ( self , f , dialect = 'sv' ): self . lines = [] for line in csv . reader ( f , dialect ): line = [ self . to_float ( e ) for e in line ] self . lines . append ( line ) def getrow ( self , num ): return self . lines [ num - 1 ] def getcol ( self , head ): index = self . getrow ( 1 ) . index ( head ) lst = [] for line in self . lines : lst . append ( line [ index ]) return lst def getdata ( self ): return self . lines @staticmethod def to_float ( e ): try : return float ( e ) except ValueError : return e 其中有： getrow 取某一行的值 getcol 取某一列的值 getdata 取整个表格的数据值 对应的Writer编写 同样也要根据你的csv方言设计来的，下面只是贴出一个样例： class Writer (): def __init__ ( self , f , dialect = 'sv' ): self . lines = [] self . writer = csv . writer ( f , dialect ) def addrow ( self , row ): self . lines . append ( row ) def addcol ( self , col ): for index in range ( len ( self . lines )): self . lines [ index ] . append ( col [ index ]) def setrow ( self , num , row ): self . lines [ num - 1 ] = row def setcol ( self , num , col ): for index in range ( len ( self . lines )): self . lines [ index ][ num - 1 ] = col [ index ] def set ( self , row , col , e ): self . lines [ row - 1 ][ col - 1 ] = e def setdata ( self , data ): self . lines = data def write ( self ): for line in self . lines : self . writer . writerow ( line ) 提供的方法有： addrow 添加一行值 addcol 添加一列值 set 设置某行某列的某个值为什么 setdata 设置整个数据 write 实际写入到文件中去。 tempfile模块 tempfile模块用于创建临时文件或者临时文件夹，这个模块在所有系统平台上都能正常工作，有时还是很有用的。 比如windows系统下的临时文件夹所在： >>> import os >>> os . name 'nt' >>> import tempfile >>> tempfile . gettempdir () 'C: \\\\ Users \\\\ a3580 \\\\ AppData \\\\ Local \\\\ Temp' 最核心的两个函数是 mkstemp 和 mkdtemp 。 mkstemp mkstemp函数用于新建一个临时文件 fd , fpath = tempfile . mkstemp ( dir = tmpdir ) with os . fdopen ( fd , 'wb' ) as temp_cache_file : marshal . dump (( self . FREQ , self . total ), temp_cache_file ) 返回的第二个参数就是目标临时文件的路径名，第一个文件参数比较特殊，是操作系统级别的文件句柄（应该是C语言那边的文件句柄吧），要转成一般使用的python文件对象如上所示，使用 os.fdopen 来打开。 if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js','mhchem.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"python语言","url":"articles/python-modules-three.html"},{"title":"python语言学习之-官方模块第二谈","text":"shelve模块 shelve模块是基于pickle模块的，也就是只有pickle模块支持的对象它才支持。 之前提及pickle模块只能针对一个对象，如果你有多个对象要处理，可以考虑使用shelve模块，而shelve模块就好像是自动将这些对象用字典的形式包装起来了。除此之外shelve模块的使用更加简便了。 存入多个对象 我们根据类的操作第三版中定义的类（ 12.5 {reference-type=\"ref\" reference=\"sec:类的操作第三版\"}）建立了一个Hero.py文件，就是将那些类的定义复制进去。然后我们新建了几个实例来存入test.db文件中。 import shelve from Hero import Garen if __name__ == '__main__' : garen1 = Garen () garen2 = Garen ( 'red' ) garen3 = Garen ( 'yellow' ) db = shelve . open ( 'test.db' ) for ( key , item ) in [( 'garen1' , garen1 ),( 'garen2' , garen2 ),( 'garen3' , garen3 )]: db [ key ] = item db . close () 我们看到整个过程的代码变得非常的简洁了，然后一个个对象是以字典的形式存入进去的。 读取这些对象 读取这些对象的代码也很简洁，就是用shelve模块的open函数打开数据库文件，open函数会自动返回一个字典对象，这个字典对象里面的数据就对应着之前存入的键值和对象。 同时通过这个例子我发现，如果自己定义的类，将他们提取出来放入另外一个文件，那么shelve模块读取文件时候是不需要再引入之前的定义。这一点值得我们注意，因为shelve模块内部也采用的是pickle的机制，所以可以猜测之前pickle的那个例子类的定义写在写入文件代码的里面，所以不能载入数据库；而如果将这些类的定义放入一个文件，然后这些类以模块或说模块载入的形式引入，那么读取这些对象就可以以一种更优雅的形式实现。如下所示： import shelve if __name__ == '__main__' : db = shelve . open ( 'test.db' ) for key in sorted ( db ): print ( db [ key ]) db . close () 我们看到就作为简单的程序或者原型程序的数据库，shelve模块已经很好用而且够用了。 更多内容请参见 官方文档 。 pickle模块 pickle模块可以将某复杂的对象永久存入文件中，以后再导入这个文件，这样自动将这个复杂的对象导入进来了。 将对象存入文件 import pickle class Test : def __init__ ( self ): self . a = 0 self . b = 0 self . c = 1 self . d = 1 def __str__ ( self ): return str ( self . __dict__ ) if __name__ == '__main__' : test001 = Test () print ( test001 ) testfile = open ( 'data.pkl' , 'wb' ) pickle . dump ( test001 , testfile ) testfile . close () 从文件中取出对象 值得一提的是从文件中取出对象，原来的类的定义还是必须存在，也就是声明一次在内存中的，否则会出错。 import pickle class Test : def __init__ ( self ): self . a = 0 self . b = 0 self . c = 1 self . d = 1 def __str__ ( self ): return str ( self . __dict__ ) if __name__ == '__main__' : testfile = open ( 'data.pkl' , 'rb' ) test001 = pickle . load ( testfile ) print ( test001 ) testfile . close () pickle模块的基本使用就是用dump函数将某个对象存入某个文件中，然后这个文件以后可以用load函数来加载，然后之前的那个对象会自动返回出来。 更多内容请参见 官方文档 。 pathlib模块 自python3.4以后起，python3就内置了pathlib模块了。之前的python版本，需要通过pip安装pathlib，后面的使用也差不了太多了。下面的讨论主要参考了python3.4的pathlib模块的官方文档，以其为准。 这个模块主要让我们对系统的路径更加灵活的操作，python取代bash进行系统运维的时候，有大量的对文件名，路径等的操作，pathlib将大大简化我们在这一块的工作量。首先来看一个例子： from pathlib import Path import os p1 = Path ( os . path . expanduser ( '~' )) p2 = Path ( '.' ) print ([ x for x in p1 . glob ( \"*.pdf\" ) if x . is_file ()]) print ([ x for x in p2 . iterdir () if x . is_dir ()]) 这里Path是可以接受相对路径语法的，所以\\\".\\\"和\\\"..\\\"都是可用的。然后Path对象有方法glob和iterdir方法，其中glob就是类似linux的glob命令；然后iterdir将遍历当前目录。遍历之后返回了一个可迭代对象（读者可以看一下，是一个生成器对象），展开之后仍然是一个Path对象。然后Path对象有 is_file 方法和 is_dir 方法来判断该Path对象是不是文件夹或者文件路径。 Path对象有很多便捷的方法，很是好用，比如： iterdir ， exists ， is_file ， is_dir ， parents ， cwd 等等。更多信息请参看官方文档。 marshal模块可以将python的一些变量以二进制的形式读写入文件中，比如jieba分词的词典缓存就是这么做的。 官方文档推荐如果确实有类似的简单存储需求，推荐是使用pickle或者shelve模块，不管怎么说，这个模块简单的使用我们了解下吧。 其支持的对象类型有： The following types are supported: booleans, integers, floating point numbers, complex numbers, strings, bytes, bytearrays, tuples, lists, sets, frozensets, dictionaries 简单的使用如下： with open ( cache_file , 'rb' ) as cf : self . FREQ , self . total = marshal . load ( cf ) with open ( cache_file , 'wb' ) as temp_cache_file : marshal . dump (( self . FREQ , self . total ), temp_cache_file ) load方法加载目标文件对象，返回值是你之前送入的对象。 dump方法是把你想要送进去的对象，送入到某个文件中去。 logging模块 在软件开发中，两个东西最易被初学者忽视，但实际上却是最有用的工具: 一个是单元测试；一个是日志输出管理。python的官方内置模块logging可以帮助你更好地管理自己的日志汇报系统。一个好的日志汇报系统不仅能够帮助程序员调试debug，用户向专业人员汇报发生错误时候的信息，还可以帮助人们理解程序具体是如何运行的和运行到了那里，在干些什么，这些都是非常有用的。 什么时候使用logging 有的时候一些简单的函数调试就可以使用print函数来进行一些输出信息，这在编程早期还是有用的。而后续不管是调试还是编程都推荐使用单元测试的方法。而在大型软件项目中，print函数则是更应该少出现，只有那些程序员希望用户看到的信息才能使用print函数（当然某些经过io重定向的print函数不在这里的讨论范围之内）。 程序员有时想要看看某个大型软件内部具体是如何运作的，丑陋的做法是print，然后注释掉。这样也不是不可以，只是最好程序员做的一切工作都能保存起来拿到台面上，毕竟这都是劳动。logging模块的第一个用途就出来了: 我们可以使用 logging.info() 这个函数，来输出某些信息，这些信息只有在你调低了logging等级之后（默认的是 WARNING ），才会显示出来。低于 WARNING 等级的还有一个函数 logging.debug() 。info函数的信息通常是程序员用来确认程序是按照预期运行的，debug函数的信息通常是出现某个bug了，程序员希望有助于他debug的输出信息。 logging.warn() 函数用来发出警告信息，并且程序员应该修改程序来避免这个信息出现； logging.warning 函数用来发出警告信息，这种情况程序员表示在我的预料之中，是用户不应该这样做，程序不需要修改，但信息应该被记录。 然后特别重大的错误或异常捕捉，这个使用python的 try... except... 语句，或者raise抛出异常，这自不必多说。只是有某些情况，程序员不愿抛出这个异常，而是希望压抑这个错误，则可以使用logging模块的 error() 函数或者 exception() 函数或者 critical() 函数。 具体这些函数的严重等级是: 最简单的一个使用例子如下所示: import logging logging . basicConfig ( level = logging . DEBUG ) logging . debug ( 'debug' ) logging . info ( 'info' ) logging . warning ( 'warning' ) 这里的basicConfig函数对整个日志系统进行一些配置。比如这里设置日志报告等级 level=logging.DEBUG ，这样我们将会看到 DEBUG 以及 DEBUG 以上等级的日志信息；然后如果设置为 logging.INFO ，则就只看到 INFO 和 INFO 以上等级的信息了。 将日志信息输出到文件 更专业的做法是将日志输出到文件中去，即使是自己调试，对于大型软件项目来说，日志信息是很多的，将其保存到文件，然后用编辑器或者shell工具或者其他工具查看会更便捷一些。要将这些日志信息都输出到某个文件中很简单，在 basicConfig 设置 filename 参数即可: import logging logging . basicConfig ( filename = 'test.log' , level = logging . DEBUG ) logging . debug ( 'debug' ) logging . info ( 'info' ) logging . warning ( 'warning' ) 默认的 filemode 是 \\\"a\\\" ，也就是日志信息一直累积在那里。你可以多运行几次这个小py脚本，来看看具体的效果。 filemode 也可以设置为 \\\"w\\\" ，则只保存最后那次运行的日志信息。 logging模块中级教程 logging模块的中级使用需要了解如下几个词汇：loggers, handlers, filters, and formatters。 loggers 记录器 之前我们运行logging.info，就是调用的默认的记录器，然后一般我们会针对每个python的模块文件创建一个记录器。 logger = logging.getLogger(__name__) 这个 __name__ 只是一种简便的命名方法，如果你勤快或者某种情况下有需要的话完全可以自己手工给记录器取个名字。 然后这个 getLogger 函数如果你后面指定的名字之前已经定义了（这通常是指在其他第三方模块下定义了），那么你通过这个 getLogger 然后指定目标名字就会得到对应的该记录器。这通常对于DIY某个第三方模块的日志记录器有用。 记录器可以挂载或者卸载某个处理器对象或过滤器对象： logger.addHandler() logger.removeHandler() logger.addFilter() logger.removeFilter() 记录器通过 setLevel() 方法来设置最小记录级别，这个和后面的Handler级别是协作关系。 记录器的propagate参数这里值得详细说下，记录器的名字自己定义也好，还是用 __name__ 这样python自带的模块结构语法也好，其有个上层和下层的关系，比如说 main.test 这个记录器是属于 main 这个记录器的。而这里讨论的 propagate 参数，默认是True，也就是发送给 main.test 记录器的信息也会传递给其上层 main 记录器上去。如果设置为False则不会往上传递了。 handlers 处理器 负责分发日志信息到目标地去。这里主要介绍这几个Handler类： StreamHandler 将信息以流的形式输出，这通常指输出到终端 FileHandler 将信息写入到某个文件中去 RotatingFileHandler 将信息写入某个文件，如果文件大小超过某个值，则另外新建一个文件继续写。 TimeRotatingFileHandler 将信息写入某个文件，每隔一段时间，比如说一天，就会自动再新建一个文件再往里面写。 处理器对象也有 setLevel 方法，这个前面也提及了，和记录器的 setLevel 是协作关系，更详细的描述是，信息先记录器处理并分发给对应的处理器对象，然后再处理器处理再分发到目的地。 处理器可以挂载 格式器 对象和 过滤器 对象。 handler.setFormatter() handler.addFilter() handler.removeFilter() filters 过滤器 formatters 格式器 ，具体信息的格式定义。 这里的format涉及到的一些参数设置如下所示: - %(levelname)s 类似'DEBUG'这样的logging level - %(message)s 具体输出的信息 - %(asctime)s 具体时间，默认是'2003-07-08 16:49:45,896'，你可以通过 **datefmt** 选项来进一步设置格式，格式设置和strftime命令类似。 - %(filename)s 文件名，更简洁的表达是模块名。 - %(module)s 模块名 - %(funcName)s 函数名 - %(lineno)d 具体logging代码在第几行 - %(name)s logger的名字，默认是'root'。 - %(process)d 进程号 - %(processName)s 进程名 - %(thread)d 线程号 - %(threadName)s 线程名 字典统一配置 django的setting.py就会有这样的配置，具体含义还是很明显的，就是定义处理器，格式器，记录器等。 LOGGING = { 'version': 1, 'disable_existing_loggers': False, 'formatters': { 'simple': { 'format': \"%(asctime)s %(name)s [%(levelname)s] %(thread)d %(module)s %(funcName)s %(lineno)s: %(message)s\" } }, 'handlers': { 'log_file': { 'class': 'sdsom.common.log.DedupeRotatingAndTimedRotatingFileHandler', 'filename': config.get('web', 'log_path'), 'when': 'midnight', 'maxBytes': int(config.get('web', 'log_max_bytes')), 'interval': 1, 'backupDay': int(config.get('web', 'log_backup_days')), 'dedupetime': int(config.get('web', 'log_dedupe_time')), 'formatter': 'simple' }, }, 'loggers': { 'django.request': { 'handlers': ['log_file'], 'level': config.get('web', 'log_level'), 'propagate': True, }, } } json模块 什么是json json全称是JavaScript Object Notation，也就是JavaScript对象表示法。json是一种基于文本的，人类易读的数据存储交互格式。json文件保存使用后缀 .json 。虽然json是从javascript语言衍生出来，不过其作为数据存储和交互是独立于语言的。json和xml作为数据存储和交互方案相比有更易读和读写速度更快的特点。 json存储格式语法 json存储格式的语法很简单，首先是最基本的数字开始，其支持两种数字类型，整数型和浮点型，其对应于python的int和float；字符串在双引号里面，其对应于python的字符串概念；布尔值true和false，其对应于python的True和False，然后还有一个null对应于python的None；json数据用 [] 表示，里面的元素用逗号分隔，其对应的正是python的列表概念；然后json的object对象用 {} 包围，其内是key:value这样的形式，其正对应于python的字典概念。 json就可以存储如上描述的这些数据类型，当然可以无限组合下去。这相比较于sql那样单纯的用table表格的形式来描述所有数据已经很灵活了。下面开始实际讲解如何利用python的json模块来读写数据。 python语言已经内置了json模块，所以要读写json文件只需要简单 import json 即可。 首先让我们小试牛刀，把[1,2,3,4,5]这组数存( dump )进test.json文件里面去。 import json lst = [ 1 , 2 , 3 , 4 , 5 ] with open ( 'test.json' , mode = 'w' , encoding = 'utf-8' ) as f : json . dump ( lst , f ) json不支持元组(tuple)和字节(bytes)类型，bytes类型一般不会去惊扰它，如果有tuple元组你需要存储，那么将其转换成列表即可。 简单的读取是使用的json的 load 函数，如下所示： with open('test.json', mode='r', encoding='utf-8') as f: lst2 = json.load(f) 这样lst2就被赋值[1,2,3,4,5]了，方便后面的运算。 存储字典值 上面的例子稍作修改即可以存储字典值了： import json dict01 = { 'a' : 1 , 'b' : 2 , 'c' :[ 1 , 2 , 3 ]} with open ( 'test.json' , mode = 'w' , encoding = 'utf-8' ) as f : json . dump ( dict01 , f ) with open ( 'test.json' , mode = 'r' , encoding = 'utf-8' ) as f : dict02 = json . load ( f ) print ( dict02 ) 上面的dump函数那句读者可以考虑加入 indent 选项： json.dump(dict01,f,indent=4) 这样我们的test.json文件里面的数据会更好看一些了。此外 sort_keys 选项有时会很有用，默认是False，如果设置为True，则输出的文件的key是排序了的 。 定义自己的数据类型支持 下面是关于一个关于复数类型的演示： def to_json ( obj ): if isinstance ( obj , complex ): return { '__class__' : 'complex' , '__value__' : [ obj . real , obj . imag ]} raise TypeError ( repr ( obj ) + ' is not JSON serializable' ) def from_json ( obj ): if '__class__' in obj : if obj [ '__class__' ] == 'complex' : return complex ( obj [ '__value__' ][ 0 ], obj [ '__value__' ][ 1 ]) return obj import json ​ ​ lst = [{'a':1,'f':7+8j,'c':[1,2,3]},1+1,3+5j] ​ with open('test.json', mode='w', encoding='utf-8') as f: json.dump(lst,f,indent=4,sort_keys=True, default=to_json) with open('test.json', mode='r', encoding='utf-8') as f: lst2 = json.load(f,object_hook=from_json) print(lst2) default 选项连接前面定义的函数，这个函数对额外的对象类型进行转变------变成json可以支持的类型。比如这里的复数类型变成了列表输出，然后读取用 object_hook 函数连接的函数对obj进行额外的处理，这里的 __class__ 还是你自己加上去的标记，然后return成某个python的值，如果不是则直接 return obj ，估计json模块还会有进一步的操作。 然后自定义对象按照上面的方法加入额外的条件判断语句即可，经过测试是可行的，目前还没有实用需求，最默认的这些数据类型觉得就挺不错了。 dumps和loads函数 此外json模块还有dumps函数其对应dump函数不过没有文件操作，然后loads函数对应load函数不过没有文件操作。 dumps和loads函数可以简单理解为：dumps函数能够简单将python对象字符串化，而loads函数可以简单理解为将某一字符串python对象化。和dump还有load函数比较，其对应的文本数据风格更偏向一行行的相似数据，这些一行行的数据之间彼此并无什么关系（包括简单的顺序关系）；而dump和load函数其对应的文本数据风格更倾向于整个文本数据是一个整体，包括[1,2,3...]这样的列表风格数据，其内都暗含顺序关系。 对于上面谈论的一行行独立数据的json文件，推荐使用dumps和loads函数来管理。写入json文件如下所示： import json data1 = { 'color' : 'red' , 'count' : 200 } data2 = { 'color' : 'yellow' , 'count' : 100 } data3 = { 'color' : 'blue' , 'count' : 500 } with open ( 'test.json' , 'w' ) as f : for data in [ data1 , data2 , data3 ]: print ( json . dumps ( data ), file = f ) 然后一行行读取如下所示： with open('test.json','r') as f: data = [json.loads(line) for line in f] print(data) 之后你可以使用列表解析来单独对每一行的每个元素执行某种操作。 itertools模块 repeat函数 其定义函数如下： def repeat(object, times=None): # repeat(10, 3) --> 10 10 10 if times is None: while True: yield object else: for i in range(times): yield object 也就是返回一个可迭代对象，这么封装最大的一个用处是用于填充map函数或者zip函数的某个常数值。因为你填写repeat(5)之后将一个返回一个可迭代对象，不停的返回数字5而不需要你考虑长度问题。 starmap函数 starmap函数具体定义如下所示： def starmap(function, iterable): # starmap(pow, [(2,5), (3,2), (10,3)]) --> 32 9 1000 for args in iterable: yield function(*args) 其接受一个可迭代对象，然后逐个将可迭代对象中的元素解包之后送入函数当参数（最后当然函数也执行了）。 inspect模块 更多信息请参看 官方文档]( 。 getfile函数 传入python object，返回定义该object具体是在那个文件中的。可以如下获取该文件的系统绝对路径地址: os.path.abspath(inspect.getfile(func)) 值得一提的是，如果该模块被安装进入系统了，那么实际该文件的地址应该是类似这样的形式: /usr/local/lib/python3.4/dist-packages/infome-15.10.30-py3.4.egg/infome/web/youdao.py 。 getcallargs函数 如下所示: params = inspect.getcallargs(func,*args,**kargs) 相当于模拟执行了func函数，然后返回如果执行func函数时其接受的参数字典值（包括必填参数和可选参数）。 functools模块 partial类 functools模块定义了一个partial类，其输入参数如下所示: functools.partial(func, *args, **keywords) 其将返回一个partial对象，其有 __call__ 方法，也就是其可以类似函数进行调用。然后其有 func 属性，作为未来函数的调用； args 属性，作为未来函数的参数； keywords 属性，作为未来函数的可选参数。 简单来说就是partial对原函数对象func进行了封装（所以其特别适合做装饰器）， newfun=partial(func,args,keywords) ，使得调用这个newfun对象就好像调用原func一样，只是加上了额外的参数，其中args非可选参数是类似列表append形式，而keywords可选参数或说关键字参数是类似字典update形式。 下面是一个简单的演示例子: import functools def fun1 ( a , b = 2 ): print ( 'called fun1 with' , a , b ) def show_details ( name , f , is_partial = False ): print ( name ) print ( f ) if is_partial : print ( f . func ) print ( f . args ) print ( f . keywords ) else : print ( f . __name__ ) show_details ( 'fun1' , fun1 ) fun1 ( 'fun1 a' ) p1 = functools . partial ( fun1 , 'p1 a' , b = 99 ) show_details ( 'p1' , p1 , True ) p1 () 其输出如下: fun1 <function fun1 at 0xb705880c> fun1 called fun1 with fun1 a 2 p1 functools.partial(<function fun1 at 0xb705880c>, 'p1 a', b=99) <function fun1 at 0xb705880c> ('p1 a',) {'b': 99} called fun1 with p1 a 99 这里的逻辑是首先正常执行fun1，然后将fun用partial封装成p1，新增参数字符串'p1 a'和b=4，后面我们可以看到这个p1的参数都加进去了。然后执行这个p1我们看到了参数的变化。 datetime模块 简单的日期时间操作用time模块里面的一些函数即可，datetime模块是用类的方式来处理的，适合大量处理日期时间的任务。然后值得一提的是mongodb的python接口 pymongo 里面（连接mongodb的python第三方模块），日期时间的输入输出都是 datetime 对象的，这很是方便。 下面简要介绍之，更多内容请参看 官方文档 。 timedelta对象 通过timedelta函数返回一个timedelta对象，也就是一个表示时间间隔的对象。函数参数情况如下所示: class datetime . timedelta ([ days [, seconds [, microseconds [, milliseconds [, minutes [, hours [, weeks ]]]]]]]) 其没有必填参数，简单控制的话第一个整数就是多少天的间隔的意思: datetime.timedelta(10) 两个时间间隔对象可以彼此之间相加或相减，返回的仍是一个时间间隔对象。而更方便的是一个datetime对象如果减去一个时间间隔对象，那么返回的对应减去之后的datetime对象，然后两个datetime对象如果相减返回的是一个时间间隔对象。这很是方便。 datetime对象 通过datetime函数可以创建一个datetime对象: class datetime . datetime ( year , month , day [, hour [, minute [, second [, microsecond [, tzinfo ]]]]]) 其中year，month和day是必填参数。下面是一个简单的例子: >>> db_t = { ... \"date\": datetime.datetime(1777,07,07) ... } >>> db_t {'date': datetime.datetime(1777, 7, 7, 0, 0)} 其通过pymongo存入mongodb之后是这样的形式: ISODate(\"1777-07-07T00:00:00.000Z\") now和utcnow方法 datetime对象有 now 和 utcnow 这两个 类方法 （classmethod）来返回当前日期时间的datetime对象。utcnow不可以接受参数，now方法可以接受一个tz指定时区的参数，我们可以通过 pytz 模块（一个处理时区推荐的第三方模块）来具体指明某个时区。 查看pytz的所有时区 参看 这个网页 。 >>> pytz.all_timezones ['Africa/Abidjan', 'Africa/Accra', 'Africa/Addis_Ababa', 'Africa/Algiers', ...... 具体给now方法指定一个时区 参看 这个网页 。 import pytz datetime . datetime . now ( tz = pytz . timezone ( \"Asia/Hong_Kong\" )) now方法和utcnow方法区别 我们看下面这个例子: >>> datetime.now(tz = pytz.timezone(\"UTC\")),datetime.utcnow() (datetime.datetime(2015, 7, 11, 9, 25, 20, 266863, tzinfo=<UTC>), datetime.datetime(2015, 7, 11, 9, 25, 20, 266888)) 如果我们给now方法指定默认的时区是\\\"UTC\\\"，那么我们看到其返回的datetime对象和utcnow返回的datetime对象基本上没什么区别，后面的微秒（ \\(10&#94;{-6}\\) 秒）有点区别完全可以理解。然后我们再看now方法如果不加任何参数会如何: >>> now datetime.datetime(2015, 7, 11, 16, 34, 43, 144018) >>> utcnow datetime.datetime(2015, 7, 11, 8, 34, 56, 319108) 这里now显示的时间和本地的时间是一致的，说明now默认的时区是本地的时区参数。谈到这里大家应该就明白了，如果是后台数据库有日期时间输入需求，为了保持时间戳的一致性，推荐都使用utcnow方法来生成时间戳，也就是实际上都以UTC格林威治时区为准。如果到前端需要显示给用户具体的日期时间了，如果要引用前端数据库的日期时间，才需要引入时区的考虑进行必要的转换。然后如果前端需要用python生成实时的时间，那么就用now方法再引入pytz的时区控制。 datetime对象的属性 >>> from datetime import datetime >>> d = datetime . now () >>> d . year 2015 >>> d . month 11 >>> d . day 3 >>> d . hour 18 >>> d . minute 42 >>> d . second 57 >>> d . tzinfo >>> d datetime . datetime ( 2015 , 11 , 3 , 18 , 42 , 57 , 919613 ) 具体含义如下所示: year 年 month 月 day 日 hour 时 minute 分 second 秒 microsecond 微秒 strftime方法 datetime对象可以如下调用 strftime 方法或者 __format__ 方法来得到一个好看的你想要的日期时间字符串格式: >>> from datetime import datetime >>> d = datetime . now () >>> d . strftime ( '%T' ) '18:52:39' >>> d . __format__ ( ' %F ' ) '2015-11-03' 这里的格式符号python官方文档有所述及，而更实际上是和linux系统下的 date 命令的格式符一致的，读者可以用 date --help 来看一下，就可以看到如下信息: %% 一个文字的 % %a 当前 locale 的星期名缩写 ( 例如： 日，代表星期日 ) % A 当前 locale 的星期名全称 ( 如：星期日 ) %b 当前 locale 的月名缩写 ( 如：一，代表一月 ) % B 当前 locale 的月名全称 ( 如：一月 ) %c 当前 locale 的日期和时间 ( 如： 2005 年 3 月 3 日 星期四 23 : 05 : 25 ) % C 世纪；比如 % Y ，通常为省略当前年份的后两位数字 ( 例如： 20 ) %d 按月计的日期 ( 例如： 01 ) % D 按月计的日期；等于 %m / %d / %y %e 按月计的日期，添加空格，等于 %_d % F 完整日期格式，等价于 % Y - %m - %d %g ISO - 8601 格式年份的最后两位 ( 参见 % G ) % G ISO - 8601 格式年份 ( 参见 % V ) ，一般只和 % V 结合使用 %h 等于 %b % H 小时 ( 00 - 23 ) % I 小时 ( 00 - 12 ) %j 按年计的日期 ( 001 - 366 ) %k hour , space padded ( 0..23 ); same as %_ H %l hour , space padded ( 1..12 ); same as %_ I %m month ( 01..12 ) % M minute ( 00..59 ) %n 换行 % N 纳秒 ( 000000000 - 999999999 ) %p 当前 locale 下的 \"上午\" 或者 \"下午\" ，未知时输出为空 % P 与 %p 类似，但是输出小写字母 %r 当前 locale 下的 12 小时时钟时间 ( 如： 11 : 11 : 04 下午 ) % R 24 小时时间的时和分，等价于 % H : % M %s 自 UTC 时间 1970 - 01 - 01 00 : 00 : 00 以来所经过的秒数 % S 秒 ( 00 - 60 ) %t 输出制表符 Tab % T 时间，等于 % H : % M : % S %u 星期， 1 代表星期一 % U 一年中的第几周，以周日为每星期第一天 ( 00 - 53 ) % V ISO - 8601 格式规范下的一年中第几周，以周一为每星期第一天 ( 01 - 53 ) %w 一星期中的第几日 ( 0 - 6 ) ， 0 代表周一 % W 一年中的第几周，以周一为每星期第一天 ( 00 - 53 ) %x 当前 locale 下的日期描述 ( 如： 12 / 31 / 99 ) % X 当前 locale 下的时间描述 ( 如： 23 : 13 : 48 ) %y 年份最后两位数位 ( 00 - 99 ) % Y 年份 %z + hhmm 数字时区 ( 例如， - 0400 ) %: z + hh : mm 数字时区 ( 例如， - 04 : 00 ) %:: z + hh : mm : ss 数字时区 ( 例如， - 04 : 00 : 00 ) %::: z 数字时区带有必要的精度 ( 例如， - 04 ， + 05 : 30 ) % Z 按字母表排序的时区缩写 ( 例如， EDT ) 其中的 %F 和 %T 在python官方文档中并无说明，可见其内部API是和这个 date 命令一致的。 支持的时间间隔运算 前面提到了一个datetime对象减去一个timedelta对象返回一个datetime对象，然后一个datetime对象减去一个datetime对象返回一个时间间隔对象。比如此时之前一年的时间可以这样表达 datetime.datetime.utcnow() - datetime.timedelta(365) 。然后此时和爱因斯坦的生日时间间隔可以这样表达: datetime.datetime.utcnow() - datetime.datetime(1879,03,14) 然后我们可以利用这个时间间隔来进行一些操作和判断。 >>> delta = datetime.datetime.utcnow() - datetime.datetime(1879,03,14) >>> delta datetime.timedelta(49792, 35970, 903285) >>> delta > datetime.timedelta(120*365) True >>> delta.days // 365 136 struct_time 对象转化成为 datetime 对象 参看 这个网页 from time import mktime mktime函数接受time模块的 struct_time object，其可以来自time模块的 gmtime 、 localtime 、 strptime 这些函数，mktime函数将返回一个时间戳，然后用datetime模块的 fromtimestamp 函数可以接受这个时间戳。 总的过程即: from time import mktime from datetime import datetime dt = datetime . fromtimestamp ( mktime ( struct )) datetime 对象转化为 time_struct 对象 参考了 这个网页 >>> t = datetime.datetime.now() >>> t datetime.datetime(2011, 11, 5, 11, 26, 15, 37496) >>> time.mktime(t.timetuple()) + t.microsecond / 1E6 1320517575.037496 if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js','mhchem.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"python语言","url":"articles/python-modules-two.html"},{"title":"mysql数据库","text":"简介 本文已经假设读者对sql有一个初步的认识了，然后更加具体的讨论mysql的相关细节。安装在ubuntu下就简单用apt-get安装之，如下所示，不赘述了。 sudo apt-get install mysql-server mysql-client mysql入门 本小节的代码依次演示了第一个例子，好让读者对mysql有个初步的认识。 登录 以root用户登录 mysql -u root -p 具体密码是多少要根据你安装mysql时的情况来，若没有设置密码则直接按Enter。 mysql数据库配置 mysql除了在 /etc 那边 my.conf 的一些配置外，很多和自身相关的配置在一个名叫mysql的数据库里面。 列出数据库 show databases ; 切换数据库 我们先切换到那个mysql数据库看一下。 use mysql ; 列出表格 show tables ; 上面描述的这些过程你也可以用GUI程序（比如 emma 等）来点开看一下。我们先看到user这个表格，这个表格里面存储着mysql用户的一些信息。 简单检索某个表格 select * from user ; 因为内容较多，可能显示效果不太好。 创建用户 给user表格插入一条记录实际上就是新建一个新的mysql用户，如下所示: insert into user ( host , user , password , select_priv , insert_priv ) values ( 'localhost' , 'wanze' , password ( '123456' ), 'Y' , 'Y' ); 删除用户 给user表格删除一条记录就是删除某个mysql用户，让我们把前面创建的这个用户删除了: delete from user where user = 'wanze' ; 好吧，继续再把那个用户加进去，然后我们注意到之前只给了那个用户select和insert的权限的，现在让我们再多给他几个权限。 更新记录 mysql > update user -> set update_priv = 'Y' , -> delete_priv = 'Y' , -> create_priv = 'Y' , -> drop_priv = 'Y' -> where user = 'wanze' ; 现在这个用户又新加上了update，delete，create和drop权限了。然后我们看到用户还有很多其他权限设置， 用户访问权限管理 除了上面直接修改mysql的user数据库方法之外，推荐用户访问权限管理用下面的语句： GRANT ALL PRIVILEGES ON test . * to 'username' @ 'localhost' ; 这里的test是具体的database name，后面带个 * 表示所有表格，如果你想要用户可以访问所有的database，那么可以写 *.* 。 第二个username是用户名，然后localhost是本地连接。然后我们再来看下面这个例子： GRANT ALL PRIVILEGES ON *.* to wanze@'%' IDENTIFIED BY '123455'; 这里 % 表示所有远程连接，你也可以写只是某个host。然后后面跟上 IDENTIFIED BY 来设置用户的登录密码。 ​ 创建数据库 我们先创建一个新的数据库: create database test ; 创建数据库指定字符集 create database database_name character set utf8 collate utf8_unicode_ci; 创建表格 mysql > create table test ( x int , y integer , z integer ); 这里就简单创建了一个名叫test的表格，然后定义表头为三个整数，integer和int是一个意思。 插入数据 插入数据和其他sql数据库一样还是insert into这样的语句格式。 mysql & gt ; insert into test ( x , y , z ) values ( 1 , 2 , 3 ) ; 第一个例子就到这里了，简单了解了一下mysql的情况，下面继续详细的讨论。 删除table drop table test ; 删除database drop database test ; 至此我们新建的那个数据库的所有信息都被删除了，下面进入第二个例子，我们将建立更具有现实意义的数据库。 mysql进阶 首先创建learning_example database。然后创建一个student用户，其对learning_example database拥有所有的权限。 mysql - u root mysql > create database learning_example ; mysql > grant all privileges on learning_example . * to 'student' @ 'localhost' ; 创建表格 写好sql语句文件然后刷进去，如下所示: mysql -u student learning_example < mysql_learning_example.sql 这里的 -u 接用户名，然后后面跟要操作的database名字。 现在这个文件就简单写上这么一句: create table department ( dept_id smallint unsigned not null auto_increment , name varchar ( 20 ) not null , constraint pk_department primary key ( dept_id ) ); 这里前面的意思是很明显的，就是新建department这个table，然后定义一列dept_id ，其为 smallint ， unsigned （就是从0到65535），然后 not null 说这列不能为空，然后 auto_increment 说这列的数值自动增加（主要是主键id需要这个）；然后name这一列是 varchar(20) ，是变长字符串，最大长度20，类似的还有 char(20) ，其为定长字符串，后面都会 自动填充空格 ，同样not null限定非空。然后后面的约束语句需要额外说一下。 constraint 是约束的意思，然后后面跟pk_department（这个名字貌似是随意的）指约束department这个table的primary key，后面跟上primary key (dept_id) ，即约束table department的主键值为 dept_id 这一列。 create table if not exists department ( dept_id smallint unsigned not null auto_increment , name varchar ( 20 ) not null , constraint pk_department primary key ( dept_id ) ); create table if not exists branch ( branch_id smallint unsigned not null auto_increment , name varchar ( 20 ) not null , address varchar ( 30 ), city varchar ( 20 ), state varchar ( 2 ), zip varchar ( 12 ), constraint pk_branch primary key ( branch_id ) ); 注意前面的创建department表格语句那里加上了 if not exists ，这样如果表格不存在才会新建该table，从而避免了sql文件重复刷的时候出错。下面那个新建branch表格的sql语句并没有增加新的东西，所以我们继续往下看。 值得一提的是mysql的date类型只能存储公元前1000年到公元9999年之间的date。 接下来重点讲一下 foreign key 约束的写法。 constraint fk_e_emp_id foreign key (superior_emp_id) references employee (emp_id), 这里fk_e_emp_id这个名字带有一定的随意性，大致表达出fk_然后某个table下的某一列即可。然后 foreign key 外键值 (superior_emp_id) 即这一列是外键值，具体references 引用自 employee 这个表格的(emp_id) 这一列。总的意思就是superiro_emp_id这一列是一个外键值约束列，其值只可能取自employee表格的emp_id这一列，因为这里具体的逻辑含义就是其值引用自它。比如说雇员张三在这里的id是3，张三的上司是张三丰，其id是4。那么张三如果要修改自己的上司值，就必须是本雇员列表已经有了的id号的其他雇员。（外键引用主要用于SQL表格中所谓的one to many 或者 many to one 的情况，具体就是用内连接查询，这样该外键值约束列的可能对应取值是另外一个表格的很多列，这个后面再详细讨论。） 继续刷下去，强烈推荐读者用emma或者其他什么GUI程序来实时查看一下: create table if not exists customer ( cust_id integer unsigned not null auto_increment , fed_id varchar ( 12 ) not null , cust_type_cd enum ( 'I' , 'B' ) not null , address varchar ( 30 ), city varchar ( 20 ), state varchar ( 20 ), postal_code varchar ( 10 ), constraint pk_customer primary key ( cust_id ) ); 这里值得一讲的有: cust_type_cd enum('I','B') not null, mysql的枚举类型，在这里cust_type_cd这一列只能取'I'和'B'这两个值。 插入数据 现在我们加入如下代码: insert into department ( dept_id , name ) values ( null , 'Operations' ); insert into department ( dept_id , name ) values ( null , 'Loans' ); insert into department ( dept_id , name ) values ( null , 'Administration' ); department的dept_id已经打开了auto_increment特性，那么简单的给这一列赋值 null 即可，其会自动添加一个主键数字。 在前面创建表格的时候有if not exists逻辑，这样sql脚本可以重复刷都没有问题，那么插入数据也有这样的if not exists逻辑吗？请参看 这个网页 。我们可以使用 insert ignore 语句来避免重复插入，这是插入语句改成这个样子了: insert ignore into department ( dept_id , name ) values ( 1 , 'Operations' ); insert ignore into department ( dept_id , name ) values ( 2 , 'Loans' ); insert ignore into department ( dept_id , name ) values ( 3 , 'Administration' ); 注意这里id直接赋值了，因为其为primarykey，如果设置为null这里的语句还是会重复插入，只有primarykey重复了，这个insert语句才不会继续插入了。 然后我们看到下面这句: insert ignore into employee ( emp_id , fname , lname , start_date , dept_id , title , assigned_branch_id ) values ( 1 , 'Michael' , 'Smith' , '2001-06-22' , ( select dept_id from department where name = 'Administration' ), 'President' , ( select branch_id from branch where name = 'Headquarters' )); 子查询 SQL有三种类型的表: 一种是大家常见的实际存储的那种SQL表格；第二种是临时表格，也就是子查询返回的表格；还有一种就是虚拟表，比如视图。 所谓的子查询实际上就是一个select语句其将返回一个临时的SQL表格，最简单的应用就是直接跟在另一个select语句的from语句后面，然后还有一种用法常用于表格多列值的复制转移操作，也就是所谓的 insert select 语句，其是由一个insert语句和一个select语句组合而成。如下所示 1 : INSERT INTO Customers (CustomerName, Country) SELECT SupplierName, Country FROM Suppliers; 这个SQL语句将把Suppliers表格里面的SupplierName和Country这两列的值都复制到Customers这个表格中去，具体是对应的CustomerName和Country这两列。 而上面的例子就是第三种用法，其是一个select语句然后 用括号()括起来了 。其需要返回一列值，然后像上面的情况必须是只有一个值，而这个值将提取出来被insert into语句作为value使用，然后也有返回多个值的情况，比如过滤条件where what in (select …) ，这种子查询就可以返回多个值。 我们继续往下看: create temporary table emp_tmp as select emp_id , fname , lname from employee ; update employee set superior_emp_id = ( select emp_id from emp_tmp where lname = 'Smith' and fname = 'Michael' ) where (( lname = 'Barker' and fname = 'Susan' ) or ( lname = 'Tyler' and fname = 'Robert' )); 这里的 create temporary table 语句是根据某个select语句创建了一个临时表格，临时表格只有当前的session看得到，退出session之后该临时表格会自动drop掉。 update语句基本格式我们是熟悉的，关键是理解where字句这个过滤条件。该SQL语句的意思是:将employee表格中Barker Susan和Tyler Robert这两个伙计的上司设置为Michael Smith的emp_id。这里的过滤条件or逻辑还有and逻辑我想熟悉编程的都很清楚了，这里就不赘述了。 交叉连接 接下来的这个语句显得更加复杂了: insert ignore into account ( account_id , product_cd , cust_id , open_date , last_activity_date , status , open_branch_id , open_emp_id , avail_balance , pending_balance ) select 1 , a . prod_cd , c . cust_id , a . open_date , a . last_date , 'ACTIVE' , e . branch_id , e . emp_id , a . avail , a . pend from customer c cross join ( select b . branch_id , e . emp_id from branch b inner join employee e on e . assigned_branch_id = b . branch_id where b . city = 'Woburn' limit 1 ) e cross join ( select 'CHK' prod_cd , '2000-01-15' open_date , '2005-01-04' last_date , 1057 . 75 avail , 1057 . 75 pend union all select 'SAV' prod_cd , '2000-01-15' open_date , '2004-12-19' last_date , 500 . 00 avail , 500 . 00 pend union all select 'CD' prod_cd , '2004-06-30' open_date , '2004-06-30' last_date , 3000 . 00 avail , 3000 . 00 pend ) a where c . fed_id = '111-11-1111' ; 该SQL语句主体是insert select语句，然后显得复杂的部分就是那个select语句是有customer（别名c）和一个子查询语句生成的表格（别名e）和另外一个子查询语句生成的表格（别名a）的 cross join 而成的一个复杂的表格。 这里我们需要理解cross join这个概念，不知道读者之前接触过inner join，内连接的概念没有，如果接触过那么一定了解了SQL表格在join的时候不加任何过滤条件其生成的表格就是所谓的这两个SQL表格的笛卡尔积。所谓的笛卡尔积就是，假设一个表格有三行，a行b行c行，然后假设另外一个表格有两行，1行和2行，那么这两个表格的笛卡尔积就是生成一个大表格，具体是(a1行a2行b1行b2行c1行c2行)，一共3*2=6行。 而所谓的cross join交叉连接实际上就是多个表格之间进行笛卡尔积运算之后组合成为一个更大的表格。 内连接 我们又看到上面的例子中第一个子查询语句里面还有 inner join 关键词，其是所谓的内连接。内连接可以看作是在交叉连接生成的表格的基础上进一步加上了某些过滤条件从而将某些行给删除掉了。 我们首先来看一下: select b.branch_id, e.emp_id, e.assigned_branch_id from branch b cross join employee e ; branch表格有4条记录，branch有18条记录，所以cross join之后将组合出72条记录。 然后我们再来看这个查询: select b.branch_id, e.emp_id from branch b inner join employee e on e.assigned_branch_id = b.branch_id; 通常两个SQL表格cross join之后出来的大SQL表格里面有些数据组合是实际可能并不存在的，而上面inner join通过on关键词过滤将使得生成的大SQL表格更具有现实意义。比如这里每一个雇员只可能在某一个分公司，而cross join让每个雇员都有可能在四个分公司了，这里的inner join加上on主要就是控制雇员具体分配的那个分公司正是连接的那个分公司号。这样实现更有现实意义的连接。我们也可以这样理解，雇员的分公司属性id为1，那么在连接分公司表格的时候，只有确定了这个，才能保证分公司表格的其他属性也是属于该雇员的。 现在我们进行到这里了: mysql> select b.branch_id, e.emp_id,b.city from branch b inner join employee e on e.assigned_branch_id = b.branch_id; +-----------+--------+---------+ | branch_id | emp_id | city | +-----------+--------+---------+ | 1 | 1 | Waltham | | 1 | 2 | Waltham | | 1 | 3 | Waltham | | 1 | 4 | Waltham | | 1 | 5 | Waltham | | 1 | 6 | Waltham | | 1 | 7 | Waltham | | 1 | 8 | Waltham | | 1 | 9 | Waltham | | 2 | 10 | Woburn | | 2 | 11 | Woburn | | 2 | 12 | Woburn | | 3 | 13 | Quincy | | 3 | 14 | Quincy | | 3 | 15 | Quincy | | 4 | 16 | Salem | | 4 | 17 | Salem | | 4 | 18 | Salem | +-----------+--------+---------+ 18 rows in set (0.00 sec) 然后通过 where b.city = 'Woburn' 这实际上就限定为具体某一个分公司了。 mysql> select b.branch_id, e.emp_id,b.city from branch b inner join employee e on e.assigned_branch_id = b.branch_id where b.city='Woburn'; +-----------+--------+--------+ | branch_id | emp_id | city | +-----------+--------+--------+ | 2 | 10 | Woburn | | 2 | 11 | Woburn | | 2 | 12 | Woburn | +-----------+--------+--------+ 3 rows in set (0.00 sec) 然后后面跟了 limit 1 这样将只返回一条记录了。然后我们注意到最终cross join生成的大表格还加上了过滤条件 where c.fed_id = '111-11-1111'; 由于每一个顾客的fed_id都是唯一的，所以实际上custom表格真正交叉连接的也只有一条记录，这样这个三个表格cross join这个复杂的情况就等同于前面两个表格一条记录属性都加上，再cross 第三个表格，第三个表格有三条记录，这样最终的大表格有三条记录。 union all union all 将多个数据集进行合并。此外还有一种 union 的用法，其中 union 会删除重复项，而union all只是单纯的合并。如下所示: mysql> select 'CHK' prod_cd, '2000-01-15' open_date, '2005-01-04' last_date, -> 1057.75 avail, 1057.75 pend union all -> select 'SAV' prod_cd, '2000-01-15' open_date, '2004-12-19' last_date, -> 500.00 avail, 500.00 pend union all -> select 'CD' prod_cd, '2004-06-30' open_date, '2004-06-30' last_date, -> 3000.00 avail, 3000.00 pend; +---------+------------+------------+---------+---------+ | prod_cd | open_date | last_date | avail | pend | +---------+------------+------------+---------+---------+ | CHK | 2000-01-15 | 2005-01-04 | 1057.75 | 1057.75 | | SAV | 2000-01-15 | 2004-12-19 | 500.00 | 500.00 | | CD | 2004-06-30 | 2004-06-30 | 3000.00 | 3000.00 | +---------+------------+------------+---------+---------+ 3 rows in set (0.01 sec) 别名 前面说了select字句是不仅可以运算列，还可以重新构建一个列，这些列mysql会自动为其创建默认名字，你也可以明确指定该名字，用如下 as 关键词，如下所示: select emp_id, 'ACTIVE' as status, emp_id * 3.1415926 as empid_x_pi, upper(lname) as last_name_upper from employee; as 关键词可以省略，表达仍然有效，但还是推荐加上 as 关键词，这样SQL语句可读性更高。 去除重复的行 如下所示加入 distinct 关键词来让select字句过滤掉重复的行。 select distinct cust_id from account; 备份和还原 mysql的备份操作就是使用 mysqldump 命令，其将生成一个sql文件，然后还原实际上就是加载这个sql文件即可。 还原 过程如下所示: mysql -u root -p newdatabase < dump.sql 备份 使用 mysqldump 命令： mysqldump -u user -h 127.0.0.1 -P 8888 -p -v olddatabase > dump.sql -u : 设置登录用户名 -h : 要连接的数据库服务器地址 -P : 要连接的数据库服务器端口 -v : 显示聒噪信息 -p : 和mysql命令类似，等下输入密码 其后必填参数是你想要dump的某个database名字。 备份还加上查询语句 mysqldump --tables article --where=\"created_at > '2017-11-19';\" --databases wxarticles -u root -p123456 重命名数据库 将备份和还原过程组合起来就是重命名数据库了。然后按照 hendrasaputra 介绍，如下做可以降低I/O。 mysqladmin -u username -p create newdatabase mysqldump -u username -v olddatabase -p | mysql -u username -p -D newdatabase 推荐扩展略读这篇文章，关于mysqlworkbench的相关备份还原和重命名操作： mysqlworkbench实现数据库的重命名 python连接 django连接mysql默认是用的 mysql-python，我更喜欢使用pymysql，你需要在你的 manage.py 前面加上这样两句： import pymysql pymysql . install_as_MySQLdb () 参考了 这个网页 。 附录 server has gone away错误 这个错误可能原因很多，我遇到的情况是mysql的可允许包大小设定得太小了： max_allowed_packet = 16M 参考资料 本网页主要参考了《SQL学习指南》一书，第二版，Alan Beaulieu著，张伟超，林青松译。 Footnotes: 1 参考了[这个网页](http://www.w3schools.com/sql/sql_insert_into_select.asp)。","tags":"数据库","url":"articles/mysql-database.html"},{"title":"python语言学习之-官方模块第一谈","text":"unittest模块 在编程中有一个概念TDD，其和具体的编程语言无关，其全称叫做test-driven development。也就是人们常说的测试驱动型开发。不说这么大的概念，但在python编程开发中有一块内容是你必须要了解的，那就是单元测试开发。具体python中内置模块unittest就是做这个工作的。 基本的使用就简单用下面这个例子来说明了： import unittest import math class TooBigError ( Exception ): pass def hello ( n ): if n > 2 : raise TooBigError ( 'too big input error' ) else : print ( 'hello' * n ) class FirstTest ( unittest . TestCase ): def setUp ( self ): '''setUp函数在每个测试单元执行前被执行，其通常用于预先配置 一些后面测试单元会用到的参数''' pass def tearDown ( self ): '''tearDown函数在每个测试单元执行之后再执行。''' pass def test_bool ( self ): '''具体的测试单元，名字需要以test字符开始''' self . assertTrue ( True ) self . assertFalse ( False ) def test_equal ( self ): self . assertEqual ( 1 , 1 ) self . assertNotEqual ( 1 , 2 ) self . assertAlmostEqual ( math . pi , 3.1416 , 4 ) self . assertNotAlmostEqual ( math . pi , 3.1415 , 4 ) def test_raises ( self ): self . assertRaises ( TooBigError , hello , 3 ) if __name__ == '__main__' : unittest . main () unittest模块的main函数具体实际执行各个测试单元类，这些测试单元类继承自unittest的TestCase类。在这些继承自TestCase的类中，setUp函数和tearDown函数有特殊的用途，具体见上面代码的说明。然后里面定义的函数test字符串开头的都是所谓的测试单元，其将被逐个执行。 TestCase有很多方法，比如assertTrue，assertFalse用于断言某个bool值是真或假，然后assertEqual用来断言某两个值是相等的(==)，类似的还有assertNotEqual用来断言两个值不相等。这里值得一提的assertAlmostEqual方法是用来断言某两个float值在多少小数位上是大致相等的，比如上面的例子， \\(\\pi\\) 值具体到小数点4位是3.1416。上面这些方法后面还可以额外接受一个提示字符串参数（Msg参数），用来具体没有断言成功的时的补充信息。 assertRaises方法用来断言某个函数在接受某些参数之后必然返回某个异常。该方法第一个参数是期望捕捉到的异常，第二个参数是具体调用的函数，后面的参数将送给这个函数，所以就不能跟之前谈及的Msg参数了。 更多信息请参看该模块的官方文档。 time模块 time模块提供了一些和时间相关的函数，更加的底层，不过有些函数可能在某些平台并不适用。类似的模块还有datetime模块，datetime是以类的框架来解决一些时间问题的。所以如果只是需要简单的调用一下时间，那么用time模块，如果是大量和时间相关的问题，推荐使用datetime模块。 time函数 >>> import time >>> time . time () 1404348227.07554 time函数返回一个数值，这个数值表示从1970年1月1号0时0分0秒到现在的时间过了多少秒。 gmtime函数 这个函数可以接受一个参数，这个参数是多少秒，然后返回一个特定格式的时间数组 struct_time 。如果不接受参数，那么默认接受的秒数由time函数返回，也就是从那个特定时间到现在过了多少秒，这样这个特定格式的时间数组对应的就是当前时间。 >>> time.gmtime() time.struct_time(tm_year=2014, tm_mon=7, tm_mday=3, tm_hour=0, tm_min=53, tm_sec=0, tm_wday=3, tm_yday=184, tm_isdst=0) >>> time.gmtime(0) time.struct_time(tm_year=1970, tm_mon=1, tm_mday=1, tm_hour=0, tm_min=0, tm_sec=0, tm_wday=3, tm_yday=1, tm_isdst=0) localtime函数 此外类似的还有 localtime 函数，和gmtime用法和返回完全一模一样，唯一的区别就是返回的是当地的时间。 >>> time.strftime('%Y-%m-%d %H:%M:%S',time.localtime()) '2014-07-03 09:19:40' >>> time.strftime('%Y-%m-%d %H:%M:%S',time.gmtime()) '2014-07-03 01:19:49' ctime函数 >>> time.ctime() 'Thu Jul 3 08:54:54 2014' >>> time.ctime(0) 'Thu Jan 1 07:00:00 1970' 和gmtime类似，不过返回的是字符串格式的时间。我们看到ctime默认设置的时间是根据localtime函数来的。 strftime函数 接受那个特定格式的时间数组 struct_time 作为参数，然后返回一定字符串格式的时间。具体例子请参看前面的例子。 其中最常用的格式符有： %Y，多少年；%m，多少月；%d，多少日； %H，多少小时；%M，多少分；%S，多少秒。 \\%X直接输出09:27:19这样的格式，也就是前面的多少小时多少分多少秒可以用一个%X表示即可。 还有一些，比如：%I表示多少小时，不过是[0-12]的形式；%y表示多少年，不过是[00-99]的格式，比如2014年就输出14；%p，本地的AM或PM文字。等等。 sleep函数 sleep函数有时需要用到，将程序休眠个几秒的意思。需要接受一个数值参数，单位是秒，可以是零点几秒。但sleep函数只是大概休眠几秒的意思，最好不去用来计时，因为它不大精确。 更多内容请参见 官方文档 。 sys模块 sys模块有一些功能很常用，其实在前面我们就看到过一些了。 sys.argv 在刚开始说明python执行脚本参数传递的问题时就已经讲了sys.argv这个变量。这是一个由字符串组成的列表。 import sys print ( sys . argv ) for i in range ( len ( sys . argv )): print ( sys . argv [ i ]) 比如新建上面的一个test.py文件，然后执行： python3 test.py test1 test2 ['test.py', 'test1', 'test2'] test.py test1 test2 我们可以看到sys.argv[0]就是这个脚本的文件名，然后后面依次是各个参数。 exit函数 这个我们在编写GUI程序的时候经常看到，在其他脚本程序中也很常用。如果不带参数的话那么直接退出程序，还可以带一个字符串参数，返回错误提示信息，或者带一个数字，这里的详细讨论略过。 >>> import sys >>> sys . exit ( '出错了' ) 出错了 wanze @wanze - ubuntu : ~ $ sys.platform 返回当前脚本执行的操作系统环境。 Linux 返回字符串值：linux；Windows返回win32；Mac OS X 返回darwin。 sys.path 一连串字符串列表，是python脚本模块的搜索路径，所以我们自定义的python模块，只需要在sys.path这个列表上新加一个字符串路径即可。 标准输入输出错误输出文件 sys.stdin，sys.stdout，sys.stderr这三个文件对象对应的就是linux系统所谓的标准输入标准输出和错误输出文件流对象。 sys.version sys.version输出当前python的版本信息和编译环境的详细信息。 sys.version_info[0] 返回当前python主版本的标识，比如python3就返回数字3。 sys.maxsize 返回当前计算环境下整数(int)类型的最大值，32位系统是 \\(2**31-1\\) 。 >>> 2 ** 31 - 1 2147483647 >>> import sys >>> sys . maxsize 2147483647 sys.stdin.isatty() 测试输入流是不是终端。如果是终端，则返回True。 更多内容请参见 官方文档 。 subprocess模块 我想大家都注意到了现在的计算机都是多任务的，这种多任务的实现机制就是所谓的多个进程同时运行，因为计算机只有一个CPU（现在多核的越来越普及了。）所有计算机一次只能处理一个进程，而这种多进程的实现有点类似你人脑（当然不排除某些极个别现象），你不能一边看电影一边写作业，但是可以写一会作业然后再看一会电影（当然不推荐这么做、），计算机的多进程实现机制也和这个类似，就是一会干这个进程，一会儿做那个进程。 计算机的一个进程里面还可以分为很多个线程，这个较为复杂，就不谈了。比如你编写的一个脚本程序，系统就会给它分配一个进程号之类的，然后cpu有时就会转过头来执行它一下（计算机各个进程之间的切换很快的，所以才会给我们一种多任务的错觉。）而你的脚本程序里面还可以再开出其他的子进程出来， python的subprocess模块主要负责这方面的工作。 call函数 import subprocess # Command with shell expansion subprocess . call ([ \"echo\" , \"hello world\" ]) subprocess . call ([ \"echo\" , \"$HOME\" ]) subprocess . call ( 'echo $HOME' , shell = True ) hello world $ HOME / home / wanze 其中使用shell=True选项后用法较简单较直观，但网上提及安全性和兼容性可能有问题，他们推荐一般不适用shell=True这个选项。 如果不使用shell=True这个选项的，比如这里 $HOME 这个系统变量就无法正确翻译过来，如果实在需要home路径，需要使用os.path的expanduser函数。 getoutput函数 取出某个进程命令的输出，返回的是字符串形式。 import subprocess name = subprocess . getoutput ( 'whoami' ) print ( name ) getstatusoutput函数 某个进程执行的状态。 Popen类 根据Popen类创建一个进程管理实例，可以进行进程的沟通，暂停，关闭等等操作。前面的函数的实现是基于Popen类的，这是较高级的课题，这里暂时略过。 更多内容请参见 官方文档 。 shutil模块 相当于os模块的补充，shutil模块进一步提供了一些系统级别的文件或文件夹的复制，删除，移动等等操作。 复制文件 shutil.copyfile(src, dst) shutil.copy(src, dst) shutil.copy2(src, dst) 其中 copyfile 的src和dst两个参量都是完整文件路径名，第一个参量是待复制的文件，第二个参量是复制后的文件名；而 copy 函数的第一个参量是待复制的文件，但是第二个参量是目标文件夹路径； copy2 函数和copy函数类似，不同的是它能尝试保留文件的所有元信息metadata（模块开头有说明是理论上但不尽然）。 复制文件夹 shutil.copytree(src, dst) copytree 函数第一个参量是待复制的文件夹路径名，第二个参量是目标文件夹路径名，其将被创建不应该存在。 删除整个目录 shutil.rmtree(path) rmtree 函数用于删除整个文件夹，path就是目标文件夹的路径名。 移动文件夹 shutil.move(src,dst) move 函数把一个文件或者一个文件夹移动到一个文件夹内。 chown函数 shutil.chown(path, user=None, group=None) chown 函数类似的linux系统下的chown函数，这个函数基于os.chown函数，不过接口更友好。 which函数 shutil.which(cmd) which 函数类似的linux系统下的which函数。 更多shutil模块内容请参见 官方文档 。 os模块 getcwd函数 不管你在终端运行python还是运行某个python脚本，总有一个变量存储着当前工作目录的位置。你可以通过getcwd命令来查看当前工作目录。 import os print ( os . getcwd ()) 上面是通过LaTeX文件运行的python小脚本，当你以python命令来运行某个脚本的时候，你调用python命令的地方就是当前的工作目录。然后加载的其他模块的各个py文件运行时的当前工作目录和主py文件脚本的当前目录是一样的，都是你运行python命令的地方。 如果是终端调用python就是你终端的当前工作目录所在，你可以用pwd命令来查看。如下所示： => pwd / home / wanze => python3 >>> import os >>> print ( os . getcwd ()) / home / wanze mkdir函数 新建一个文件夹。 os.mkdir(str) chdir函数 os模块里有一个chdir函数来更改当前工作目录所在地。 可以使用 . 和 .. 语法，也可以使用简单的\\\"test\\\"调转到test文件夹。 >>> os.chdir('/home/wanze/pymf') >>> print(os.getcwd()) /home/wanze/pymf 删除文件 os.remove(path) 支持相对路径表达。如果路径是目录将会抛出一个OSError异常。 os.rename os.rename(src, dst) 第一个参数是目标文件或目录，第二个参数是要替换成为的名字。这个命令一方面可以重命名文件，此外可以移动文件。 支持相对路径语法表达，rename在windows下不一定替换原文件，repalce一定替换文件。 os.repalce os.replace(src, dst) rename在windows下不一定替换原文件，repalce一定替换文件。 支持相对路径语法表达。 删除空目录 os.rmdir(path) 支持相对路径语法表达，只能删除空目录。如果要删除整个目录，请使用shutil.rmtree(path)。 listdir命令 os.listdir(path='.') 相当于简单的ls命令，将返回一个字符串列表，其内包含本path下所有的文件和文件夹名（包括链接文件）。 可以结合前面介绍的os.path模块的isfile等函数新建一个函数listdir_file，listdir_dir和listdir_link，将普通文件，目录和链接文件区分开来。 import os def listdir_dir ( path = '.' ): '''os的listdir函数加强，只返回文件夹。''' return [ dir for dir in os . listdir ( path ) if os . path . isdir ( dir ) ] def listdir_file ( path = '.' ): '''os的listdir函数加强，只返回普通文件''' return [ file for file in os . listdir ( path ) if os . path . isfile ( file ) and not os . path . islink ( file )] def listdir_link ( path = '.' ): '''os的listdir函数加强，只返回链接文件''' return [ link for link in os . listdir ( path ) if os . path . islink ( link ) ] 遍历目录树 os.walk('.') 产生一个生成器对象，具体数值含义如下：（dirpath, dirnames, filenames），其中dirpath和filenames可以合并出本目录下所有文件的具体文件名路径，而dirpath和dirnames可以合并出本目录下所有目录的具体路径名。 根据这个os.walk函数我写了一个 gen_file 函数，其是一个生成器函数，会遍历目录树，并返回本目录下的文件信息。具体代码如下所示: def gen_file(startpath='.',filetype=\"\"): '''利用os.walk 遍历某个目录，收集其内的文件，返回 (文件路径列表, 本路径下的文件列表) 比如: (['shortly'], ['shortly.py']) (['shortly', 'templates'], ['shortly.py']) (['shortly', 'static'], ['shortly.py']) 第一个可选参数 startpath 默认值 '.' 第二个参数 filetype 正则表达式模板 默认值是\"\" 其作用是只选择某些文件 如果是空值，则所有的文件都将被选中。比如 \"html$|pdf$\" 将只选中 html和pdf文件。 ''' for root, dirs, files in os.walk(startpath): filelist = [] for f in files: fileName,fileExt = os.path.splitext(f) if filetype: if re.search(filetype,fileExt): filelist.append(f) else: filelist = files if filelist:#空文件夹不加入 dirlist = root.split(os.path.sep) dirlist = dirlist[1:] if dirlist: yield (dirlist, filelist) else: yield (['.'], filelist) 这个函数可以帮助你管理本目录下（可以通过正则表达式过滤）你感兴趣的文件，都刷一边。然后继续必要的操作，比如查找等等之类的。 environ函数 os.environ，返回一个字典值，这个字典值里面存储着当前shell的一些变量和值。比如系统中\"HOME\"所具体的路径名是： import os print ( os . environ [ 'HOME' ]) / home / wanze >>> getpid函数 os.getpid函数，返回当前运行的进程的pid。 stat函数 返回文件的一些信息。比如st_size是文件的大小，单位是字节。 st_size属性 import os import glob print ([ os . path . abspath ( f ) for f in glob . glob ( '*.py' )]) print ([ f for f in glob . glob ( '*.py' ) if os . stat ( f ) . st_size > 400 ]) [ '/home/wanze/桌面/test.py' , '/home/wanze/桌面/flatten.py' ] [ 'flatten.py' ] 下面这个例子进行了文件大小输出单位的优化: import os import sys filename = sys . argv [ 1 ] filesize = os . stat ( filename ) . st_size for unit in [ '字节' , 'KB' , 'MB' , 'GB' , 'TB' ]: if filesize > 1024 : filesize = filesize / 1024 else : break print ( filename + '大小是' + str ( int ( filesize )) + unit ) 这个python小脚本自动输出合适的单位，具体程序逻辑还是很简单的。 st_mtime属性 最后文件修改的时间。 st_ctime属性 最后文件创建的时间，在windows下是严格的最初文件创建时间，在unix下是最后文件metadata的改变时间。 给进程发送信号 可以通过os模块的kill函数来给某个进程发送某个信号。 os.kill(pid, sig) 函数第一个参数是进程的pid，第二个参数是具体发送的信号。比如: os.kill(pid, signal.SIGSTOP) 就是暂停某个进程，然后 os.kill(pid, signal.SIGCONT) 是继续某个进程。 然后 killpg 函数能够对某个进程包括其子进程发送某个信号，参考了 这个网页 。 除此之外还有 SIGINT （正常终止进程信号）和 SIGKILL （强制终止进程信号） 等等，更多信号请参看关于unix信号那块，比如 这个wiki页面 。 更多os模块内容请参见 官方文档 。 os.path模块 前面提到sys.argv只能返回当前python脚本的文件名，而我们常常需要这个python脚本在系统中的具体位置。前面如os.getcwd等也能获得当前python脚本的所在目录，不过os.path模块的一个优点就是跨平台特性支持很好，也就是一般我们通过其他方式获得的path路径都会用这个模块的函数辅助处理一下。 我们来看下面的例子： import os print ( os . path . abspath ( __file__ )) print ( os . path . dirname ( os . path . abspath ( __file__ ))) print ( os . path . basename ( __file__ )) print ( os . path . basename ( os . environ [ 'HOME' ])) / home / wanze / 桌面 / test . py / home / wanze / 桌面 test . py wanze 其中 __file__ 表示当前脚本文件所在的路径。 abspath函数 abspath函数接受一个path路径值然后返回一个正规的普适的路径地址。具体效果类似于执行了: normpath(join(os.getcwd(), path)) 。 再看下面的例子演示了空字符串默认当前工作目录，然后也接受绝对路径等。 >>> import os >>> os . path . abspath ( '' ) '/home/wanze' >>> os . path . abspath ( 'test' ) '/home/wanze/test' >>> os . path . abspath ( '/test' ) '/test' >>> os . path . abspath ( 'test/' ) '/home/wanze/test' 我们看到如果abspath接收的是空字符串，其定位是当前脚本的工作目录，那么是引用的模块里面的 os.path.abspath('') ，具体对应的也是当前脚本的工作目录。然后os.path.abspath(\\\".\\\")返回的是当前脚本工作目录。 dirname函数 dirname函数接受一个路径值然后返回这个路径除开最后一个元素的前面的路径值。比如上面的例子，路径指向文件，那么dirname函数返回的是除开这个文件名的前面的路径；而如果接受的路径指向目录，那么返回的是除开最后一个文件夹名的前面的路径值。 basename函数 如上面例子所示，basename函数接受一个路径值然后返回路径的最后一个元素，如果路径指向文件，那么返回的是文件名；如果路径指向目录，那么返回的是最后那个目录的文件夹名。比如下面实现了从绝对路径提取出文件名的功能。 >>> import os.path >>> string = '/home/wanze/test.txt' >>> fileName , fileExtension = os . path . splitext ( os . path . basename ( string )) >>> fileName 'test' split函数 将路径path字符串分割，可以视作dirname和basename的组合。 >>> os.path.split('/usr/local/bin/test.txt') ('/usr/local/bin', 'test.txt') >>> os.path.dirname('/usr/local/bin/test.txt') '/usr/local/bin' >>> os.path.basename('/usr/local/bin/test.txt') 'test.txt' splitext函数 将某个路径path的后缀分开，这里主要是针对文件名为输入的时候，那么第一个为该文件的名字，输出数组的第二个值是该文件的后缀。这个函数在提取文件名后缀和前面的名字的时候很有用，方便组合出新的文件名。 >>> import os >>> fileName , fileExtension = os . path . splitext ( '/path/to/somefile.ext' ) >>> fileName '/path/to/somefile' >>> fileExtension '.ext' join函数 用于连接多个路径值合并成一个新的路径值，同样相对于简单的字符串拼接，用这个函数处理路径组合具有操作系统普适性和灵活性。 >>> os.path.join(os.path.expanduser('~'),'test','lib') '/home/wanze/test/lib' 上面join函数多个参数生成的新path在windows下又是不同的输出的。 expanduser函数 >>> import os >>> os . path . expanduser ( '~' ) '/home/wanze' >>> os . path . expanduser ( '~/pymf' ) '/home/wanze/pymf' >>> os . path . join ( os . path . expanduser ( '~' ), 'pymf' , 'mymodule' ) '/home/wanze/pymf/mymodule' ~ 这个符号可以在这里使用，从而展开为以/home/wanze为基础的绝对路径，兼容大部分系统（在windows下也可以使用。） 同时我们看到join函数可以接受很多不定量的参数，然后将他们组合成为一个新的路径，而且不用你费心是 / 还是 \\ ，你不需要写这些了，用join函数自然料理好一切。 exists函数 os.path.exists(path)：测试路径或文件等是否存在。如果存在返回True，否则返回False。 isfile和isdir还有islink os.path.isfile(path)：接受一个字符串路径变量，如果是文件那么返回True，否则返回False（也就是文件不存在或者不是文件是文件夹等情况都会返回False）。 类似的有isdir和islink函数。 samefile函数 os.path.samefile(path1,path2)：如果两个文件或路径相同则返回True\\ ，否则返回False。 getmtime函数 os.path.getmtime(path) 返回文件的最后修改时间，返回值是多少多少秒，可用time模块的ctime或localtime函数将其转换成time.struct_time 对象，然后使用strftime来进行更好的格式输出。 getctime函数 类似getmtime，返回文件的最后创建时间。在unix系统中是指最后文件的元信息更改的时间。 更多内容请参见 官方文档 。 if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js','mhchem.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"python语言","url":"articles/python-modules.html"},{"title":"faker模块","text":"简介 faker模块是一个很有特色的模块，所以其在github上得到的star也较多。其可以用来生成一些伪数据，比如用来做测试用途等等。其github项目地址在 这里 。 该项目支持pip安装: sudo pip install fake-factory 其使用还是很简单的，大概如下所示: from faker import Factory faker = Factory . create () for i in range ( 50 ): print ( faker . name ()) 然后中文名字例子如下，就是在Factory的create方法那里指定语言locale（默认是\"en_EN\"）: from faker import Factory faker = Factory . create ( 'zh_CN' ) for i in range ( 100 ): print ( faker . name ()) faker所含方法清单 address(): 地址 text(): 显示一段随机文本，没有中文化。 mime_type(): model/x3d+xml chrome(): 随机的user_agent , 这个很有用。 firefox(): 火狐随机user_agent internet_explorer(): ie随意user_agent opera(): opera safari(): safari user_agent(): 更加浏览器随意的user_agent phone_number(): 随意的电话号码 boolean(): 随意的bool值 country_code(): 城市代码 language_code(): en locale(): zh_CN md5(): 随意的md5值 null_boolean(): None or True or False sha1(): sha1值 sha256(): 随意sha256值 此外还有: fake.linux_platform_token() # X11; Linux x86_64 fake.linux_processor() # x86_64 fake.mac_platform_token() # Macintosh; U; PPC Mac OS X 10_7_6 fake.mac_processor() # U; PPC fake.windows_platform_token() # Windows 98; Win 9x 4.90 fake.company_email() # ggreenfelder@ortizmedhurst.com fake.domain_name() # mayer.com fake.domain_word() # gusikowski fake.email() # gbrakus@johns.net fake.free_email() # abbey60@yahoo.com fake.free_email_domain() # hotmail.com fake.ipv4() # 81.132.249.71 fake.ipv6() # 4c55:8c8b:54b5:746d:44ed:c7ab:486a:a50e fake.safe_email() # amalia49@example.com fake.slug() # TypeError fake.tld() # net fake.uri() # http://www.parker.com/ fake.uri_extension() # .asp fake.uri_page() # terms fake.uri_path() # explore/list/app fake.url() # http://dubuque.info/ fake.user_name() # goodwin.edwin fake.bs() # maximize end-to-end infrastructures fake.catch_phrase() # Multi-tiered analyzing instructionset fake.company() # Stanton-Luettgen fake.company_suffix() # Group fake.am_pm() # AM fake.century() # IX fake.date() # 1985-02-17 fake.date_time() # 1995-06-08 14:46:50 fake.date_time_ad() # 1927-12-17 23:08:46 fake.date_time_between() # 1999-08-22 22:49:52 fake.date_time_this_century() # 1999-07-24 23:35:49 fake.date_time_this_decade() # 2008-01-27 01:08:37 fake.date_time_this_month() # 2012-11-12 14:13:04 fake.date_time_this_year() # 2012-05-19 00:40:00 fake.day_of_month() # 23 fake.day_of_week() # Friday fake.iso8601() # 2009-04-09T21:30:02 fake.month() # 03 fake.month_name() # April fake.time() # 06:16:50 fake.timezone() # America/Noronha fake.unix_time() # 275630166 fake.year() # 2002 fake.first_name() # Elton fake.last_name() # Schowalter fake.name() # Susan Pagac III fake.prefix() # Ms. fake.suffix() # V fake.address() # 044 Watsica Brooks West Cedrickfort, SC 35023-5157 fake.building_number() # 319 fake.city() # Kovacekfort fake.city_prefix() # New fake.city_suffix() # ville fake.country() # Monaco fake.geo_coordinate() # 148.031951 fake.latitude() # 154.248666 fake.longitude() # 109.920335 fake.postcode() # 82402-3206 fake.secondary_address() # Apt. 230 fake.state() # Nevada fake.state_abbr() # NC fake.street_address() # 793 Haskell Stravenue fake.street_name() # Arvilla Valley fake.street_suffix() # Crescent fake.paragraph() # Itaque quia harum est autem inventore quisquam eaque. Facere mollitia repudiandae qui et voluptas. Consequatur sunt ullam blanditiis aliquam veniam illum voluptatem. fake.paragraphs() # ['Alias porro soluta eum voluptate. Iste consequatur qui non nam.', 'Id eum sint eius earum veniam fugiat ipsum et. Et et occaecati at labore amet et. Rem velit inventore consequatur facilis. Eum consequatur consequatur quis nobis.', 'Harum autem autem totam ex rerum adipisci magnam adipisci. Qui modi eos eum vel quisquam. Tempora quas eos dolorum sint voluptatem tenetur cum. Recusandae ducimus deleniti magnam ullam adipisci ipsa.'] fake.sentence() # Eum magni soluta unde minus nobis. fake.sentences() # ['Ipsam eius aut veritatis iusto.', 'Occaecati libero a aut debitis sunt quas deserunt aut.', 'Culpa dolor voluptatum laborum at et enim.'] fake.text() # Dicta quo eius possimus quae eveniet cum nihil. Saepe sint non nostrum. Sequi est sit voluptate et eos eum et. Pariatur non sunt distinctio magnam. fake.word() # voluptas fake.words() # ['optio', 'et', 'voluptatem'] 设置随机种子 from faker import Faker fake = Faker () fake . seed ( 4321 ) print fake . name () # Margaret Boehm 语言locale代码 bg_BG - Bulgarian cs_CZ - Czech de_DE - German dk_DK - Danish el_GR - Greek en_CA - English (Canada) en_GB - English (Great Britain) en_US - English (United States) es_ES - Spanish (Spain) es_MX - Spanish (Mexico) fa_IR - Persian (Iran) fi_FI - Finnish fr_FR - French hi_IN - Hindi it_IT - Italian ja_JP - Japanese ko_KR - Korean lt_LT - Lithuanian lv_LV - Latvian ne_NP - Nepali nl_NL - Dutch (Netherlands) no_NO - Norwegian pl_PL - Polish pt_BR - Portuguese (Brazil) pt_PT - Portuguese (Portugal) ru_RU - Russian sl_SI - Slovene sv_SE - Swedish tr_TR - Turkish zh_CN - Chinese (China) zh_TW - Chinese (Taiwan)","tags":"python好伙伴","url":"articles/faker-module.html"},{"title":"python语言学习之-网络编程","text":"下面只讨论TCP套接字编程，UDP协议暂不讨论。整个TCP套接字编程的过程如下所述: 套接字编程 客户机负责发起连接，其将新建一个套接字对象（在python中是通过 socket 函数来创建的），就好比在一个封闭的黑箱子里开了一个门，在创建这个套接字对象的过程中，你需要指定具体要连接的那个服务器的IP地址和端口号（ connect 方法）。 接下来是进行TCP的三路握手过程，具体在传输层最底层的东西，客户机应用程序还是服务器应用程序都不用操心，其应该是是操作系统程序负责的。服务器程序需要关心的是在这三路握手期间，其类似于听到了敲门声，其需要开出一个门出来。服务器程序要听到这个敲门声，其应该处于监听该端口的状态。首先服务器程序需要创建一个套接字对象，然后 bind 某个端口号，然后调用 listen 方法开始监听这个端口。 然后服务器那边的监听套接字调用 accept 方法，并形成阻塞，接下来就是听到了敲门声，这个敲门声是TCP三路握手第一路信号发送过来了，这后面TCP三路握手还有两路，这我们暂时不需要太关心了。等到TCP三路握手完成了，服务器之前的那个accept方法将创建一个套接字对象。这个套接字对象称之为 连接套接字 。我们在这里把服务器那边的连接套接字调用accept方法可以理解为接受了客户机的敲门，如果一切顺利的话，其将为客户机新开一个套接字，也就是一个新门。 对于客户机那边只有一个套接字，情况稍微简单点，其往套接字里面塞信息（ sendall 方法）就是发送信息过去了，然后从套接字那里读（ recv 方法），就是读信息了。而服务器那边，实际上和客户机对等的来看的话，第二个新建的连接套接字可以看作看作类似客户机那边的第一个套接字，往里面读就是读信息，往里面写就是发送信息。之所以服务器那边要新开一个套接字，我们可以猜到，是因为服务器要同时处理多个客户机请求，可以把第一个监听套接字理解为总大门，然后后面开启的连接套接字理解为小门，其才是真正和具体那个客户机的一对一管道连接。 上面的简要描述太过于抽象，我们再来看一个最简单的实际代码，其就是python官方文档socket模块的第一个例子，可能有些地方稍作改动。 下面是服务器端 server.py 的代码: import socket HOST = 'localhost' PORT = 50007 s = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) s . bind (( HOST , PORT )) s . listen ( 1 ) conn , addr = s . accept () print ( 'Connected by' , addr ) while True : data = conn . recv ( 1024 ) if not data : break conn . sendall ( data ) conn . close () 首先我们运行server.py，如前所述，其首先需要根据socket函数来创建一个监听套接字，这个套接字具体监听的端口由bind方法指定，然后这个监听套接字开始监听（调用listen方法）。然后调用这个监听套接字的accept方法，其如果收到TCP连接请求，其将返回一个连接套接字，这里是conn。然后程序进入主循环，在这里连接套接字用recv方法来读，然后用sendall方法来写。最后是通过close方法来关闭本连接套接字。 下面是客户机端 client.py 的代码: import socket HOST = 'localhost' PORT = 50007 s = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) s . connect (( HOST , PORT )) s . sendall ( b 'Hello, world' ) data = s . recv ( 1024 ) s . close () print ( 'Received' , repr ( data )) 这里客户机那边首先新建一个套接字，这个套接字可以直接用connect方法来拨号某个服务器，然后用sendall方法来写，用recv方法来读。整个过程大抵如此。 最后以一副图画来加深对本小节的印象把。 tao-jie-zi-bian-cheng 下面我们将更深入讨论套接字编程，并用python的socket模块来介绍具体编码的细节问题。 socket模块 host主机名 host最简单就是人们熟知的IP地址，然后就是由本地hosts文件解析或者网络DNS系统解析的名字。比如 localhost 或者 python.org 等。socket模块里面有 gethostbyname 函数，可以获取该hostname具体对应的IP地址。 >>> socket.gethostbyname('python.org') '104.130.43.121' 不过gethostbyname函数只支持IPv4地址，现在推荐使用 getaddrinfo 函数，其同时支持IPv4和IPv6地址。其参数设置如下: socket.getaddrinfo(host, port, family=0, type=0, proto=0, flags=0) port可以填写80或者'http'这样的形式，或者设置为None。然后后面的family是地址族，type是套接字类型等，这些这里先暂时略过讨论。 这个函数的返回值是一个列表，其内元素有如下结构: (family, type, proto, canonname, sockaddr) 具体如下所示: >>> socket.getaddrinfo('www.github.com','https') [(<AddressFamily.AF_INET: 2>, <SocketType.SOCK_STREAM: 1>, 6, '', ('192.30.252.131', 443)), (<AddressFamily.AF_INET: 2>, <SocketType.SOCK_DGRAM: 2>, 17, '', ('192.30.252.131', 443)), (<AddressFamily.AF_INET: 2>, <SocketType.SOCK_STREAM: 1>, 6, '', ('192.30.252.128', 443)), (<AddressFamily.AF_INET: 2>, <SocketType.SOCK_DGRAM: 2>, 17, '', ('192.30.252.128', 443))] 这里的 AF_INET 地址族是创建socket套接字对象时的默认地址族，其就是对应的IPv4地址。然后套接字类型 SOCK_STREAM 也是创建套接字对象的默认值，其是字节流套接字。 getaddrinfo函数返回的 family,type,proto 这三个参数可以传递给socket函数用于具体创建一个套接字对象。canonname比较冷门，然后 sockaddr 可以传递给套接字对象的 connect 方法来具体进行套接字连接操作。 我们来用下面这个脚本试一下: import socket socket . setdefaulttimeout ( 10 ) addrinfos = socket . getaddrinfo ( 'www.baidu.com' , 'http' ) for addrinfo in addrinfos : socket_parameter = addrinfo [: 3 ] print ( socket_parameter ) addr = addrinfo [ - 1 ] print ( addr ) s = socket . socket ( * socket_parameter ) try : s . connect ( addr ) print ( 'connected' ) print ( 'peername' , s . getpeername ()) print ( 'hostname' , s . getsockname ()) #except socket.timeout: #print('socket timeout') except Exception as e : print ( e ) 读者还可以用其他域名来试一下。 地址族 AF_INET IPv4地址 AF_INET6 IPv6地址 此外还有一些冷门的地址族: AF_UNIX ， AF_NETLINK ， AF_TIPC 套接字类型 SOCK_STREAM 字节流套接字 SOCK_DGRAM 数据报套接字 上面这两个套接字类型是全平台适用的。此外还有一些冷门的套接字类型: SOCK_RAW ， SOCK_RDM ， SOCK_SEQPACKET 传输协议 传输协议 proto 一般设置为0。也可以明确指定某个传输协议: IPPROTO_CP TCP传输协议 IPPROTO_UDP UDP传输协议 IPPROTO_SCTP SCTP传输协议 timeout socket.settimeout(None) socket.settimeout(0) socket.settimeout(sec) 如果设置为None，则套接字为阻塞模式 如果设置为0，则套接字为非阻塞模式 如果设置具体某个sec秒，则套接字会等待多少sec秒，然后抛出 socket.timeout 异常。 此外还有 setdefaulttimeout 函数可以全局设置后面所有创建的socket对象的timeout。 socket.setdefaulttimeout(10) 阻塞模式还可以如下设置： socket.setblocking(True) socket.setblocking(False) listen方法 服务器端套接字具体开始监听。 socket.listen([backlog]) 从python3.5开始，backlog参数为可选参数了。这个backlog的意思是最大等待连接数（如果超过这个数，新的连接将被拒绝）。这个数以前一般设置为5，因为那个时候系统最大也才允许是5，但现在可能需要再提高一点了，现在python3.5起，这个数成为可选参数了，文档上说会自动设置一个合适的数，所以就不需要我们操心了。 更多细节请参看官方文档。 异步编程 常规的所谓同步(synchronous)编程就是大家平时编程一般使用的模型，顺序结构，阻塞式，多个函数逐个执行，一个执行完才能执行下一个，如下图所示: tong-bu-bian-cheng-mo-xing 此外还有一种线程并发模型: xian-cheng-bing-fa-mo-xing python有所谓的GIL概念，很多人对其有指责，而实际上那些支持多线程并发的语言，怕因为这个便利而带来的是更多的困扰吧。想一想我们人脑思考问题同一时间也只能做一件事，也许python的GIL限制并不是一种限制。实际上如果要用多线程并发，人们需要建立好模型，比如最终多个分支线路互不干扰，然后结果平行放入一个列表中等等约束，然后才能放心的使用多线程并发。而在这个约束模型下，python的 multiprocess 模块似乎也能很好地胜任这种类型的工作。 继续讨论异步编程模型: yi-bu-bian-cheng-mo-xing 异步编程 还有一个名字叫做 非阻塞编程 ，我们看到上面主程序建立事件循环之后，主事件循环过程并没有阻塞其他的程序过程，而是允许其插入其中来执行。实际上这有点类似于我们看到的GUI程序的主设计理念------事件驱动循环机制，所以异步编程还有一个名字叫做 事件驱动编程 。 下面开始通过一些例子来学习吧。 低效的诗歌服务器 本例子来自参考资料 [@twisted与异步编程入门] ，我将其改成了python3版本 slowpoetry.py 。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 #!/usr/bin/env python3 # -*- coding: utf-8 -*- import argparse , os , socket , time def parse_args (): usage = \"\"\"usage: %prog [options] poetry-file This is the Slow Poetry Server, blocking edition. Run it like this: python3 slowpoetry.py ecstasy.txt \"\"\" parser = argparse . ArgumentParser ( usage ) help = \"The port to listen on. Default to a random available port.\" parser . add_argument ( '-p' , '--port' , type = int , help = help ) help = \"The interface to listen on. Default is localhost.\" parser . add_argument ( '--iface' , help = help , default = 'localhost' ) help = \"The number of seconds between sending bytes.\" parser . add_argument ( '--delay' , type = float , help = help , default =. 1 ) help = \"The number of bytes to send at a time.\" parser . add_argument ( '--num-bytes' , type = int , help = help , default = 20 ) parser . add_argument ( 'poetry_file' ) args = vars ( parser . parse_args ()) poetry_file = args [ 'poetry_file' ] if not poetry_file : parser . error ( 'No such file: %s ' % poetry_file ) return args def send_poetry ( sock , poetry_file , num_bytes , delay ): \"\"\"Send some poetry slowly down the socket.\"\"\" inputf = open ( poetry_file ) while True : bytes = inputf . read ( num_bytes ) . encode () if not bytes : sock . close () inputf . close () return 'end' print ( 'Sending %d bytes' % len ( bytes )) try : sock . sendall ( bytes ) except socket . error : sock . close () inputf . close () return 'error' time . sleep ( delay ) def serve ( listen_socket , poetry_file , num_bytes , delay ): while True : sock , addr = listen_socket . accept () print ( 'Somebody at %s wants poetry!' % ( addr ,)) result = send_poetry ( sock , poetry_file , num_bytes , delay ) if result == 'end' : print ( 'sending complete' ) elif result == 'error' : print ( 'error, sending stopped' ) def main (): args = parse_args () poetry_file = args [ 'poetry_file' ] port = args [ 'port' ] iface = args [ 'iface' ] num_bytes = args [ 'num_bytes' ] delay = args [ 'delay' ] sock = socket . socket () sock . bind (( iface , port or 0 )) sock . listen ( 5 ) print ( 'Serving %s on port %s .' % ( poetry_file , sock . getsockname ()[ 1 ])) serve ( sock , poetry_file , num_bytes , delay ) sock . close () if __name__ == '__main__' : main () 下面是对应的获取诗歌的client端程序 get_poetry.py 。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 #!/usr/bin/env python3 # -*- coding: utf-8 -*- import datetime , argparse , socket def parse_args (): usage = \"\"\"usage: %prog [options] [hostname]:port ... This is the Get Poetry Now! client, blocking edition. Run it like this: python3 get_poetry.py port1 port2 port3 ... \"\"\" parser = argparse . ArgumentParser ( usage ) parser . add_argument ( 'port' , nargs = '+' ) args = vars ( parser . parse_args ()) addresses = args [ 'port' ] if not addresses : print ( parser . format_help ()) parser . exit () def parse_address ( addr ): if ':' not in addr : host = '127.0.0.1' port = addr else : host , port = addr . split ( ':' , 1 ) if not port . isdigit (): parser . error ( 'Ports must be integers.' ) return host , int ( port ) return map ( parse_address , addresses ) def get_poetry ( address ): \"\"\"Download a piece of poetry from the given address.\"\"\" sock = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) sock . connect ( address ) poem = b '' while True : data = sock . recv ( 1024 ) if not data : sock . close () break else : print ( data . decode ( 'utf-8' ), end = '' ) poem += data return poem def format_address ( address ): host , port = address return ' %s : %s ' % ( host or '127.0.0.1' , port ) def main (): addresses = parse_args () elapsed = datetime . timedelta () for i , address in enumerate ( addresses ): addr_fmt = format_address ( address ) print ( 'Task %d : get poetry from: %s ' % ( i + 1 , addr_fmt )) start = datetime . datetime . now () poem = get_poetry ( address ) time = datetime . datetime . now () - start msg = 'Task %d : got %d bytes of poetry from %s in %s ' print ( msg % ( i + 1 , len ( poem ), addr_fmt , time )) elapsed += time print ( 'Got %d poems in %s ' % ( len ( list ( addresses )), elapsed )) if __name__ == '__main__' : main () 读者可以利用上面的两个脚本来具体测试一下效果。上面的两个脚本，客户端和服务器端都是阻塞式的。我们先开一个服务器端: python3 slowpoetry.py -p 10000 ecstasy.txt 然后开两个终端，同时刷如下命令，我们就能看到其中后执行的那个终端的获取文本是被阻塞了的------这是服务器阻塞了。 python3 slowpoetry.py -p 10000 ecstasy.txt 然后我们在开一个服务器端: python3 slowpoetry.py -p 10001 fascination.txt 然后一个客户端运行如下: python3 get_poetry.py 10000 10001 然后我们看到这个客户端获取文本是一个个来的，这是客户端阻塞了。 这种一个个来，一个任务做完才能进行下一个的模式是很好理解的，但进程间的通信可以不是这样，请看下面的select风格I/O复用的讨论。 Select风格的诗歌服务器 Unix五种I/O模型 首先讨论一下Unix的五种I/O模型： 阻塞式I/O ，默认的就是阻塞式I/O。 非阻塞式I/O，应用程序持续轮询内核看看某个操作是否准备就绪。 I/O复用，通过select或poll这样的多文件描述符来管理I/O。 信号驱动式I/O 异步I/O 这五种I/O模型中，最直接的阻塞式I/O模型，而非阻塞I/O轮询机制太过于浪费资源，然后信号驱动I/O和异步I/O应用很少，真正用的最多就是这里的 I/O复用模型 。python中的twisted模块和python3.4之后新出来的 asyncio 模块里面的事件循环都是基于 然后再建立起来的类异步I/O概念。 下面将重点结合python的selectors模块来分析这种I/O复用模型。selectors模块从python3.4开始才有，其建构在select模块之上。其有如下五种内置的Selector: - SelectSelector - PollSelector - EpollSelector - DevpollSelector - KqueueSelector 不过我们实际使用就使用 DefaultSelector 即可，python会自动选择当前平台最好的Selector。 具体创建一个Selector对象如下所示: sel = selectors.DefaultSelector() 监控文件读写事件 Selector对象有个register方法，如下所示： register(fileobj, events, data=None) 其中fileobj为某文件对象（在Linux中一切皆文件，所以套接字也可以视为一个文件。）。 这里可以监控的事件有: EVENT_READ 可读事件，具体可读的定义按照参考资料 [@Unix网络编程卷1] 是这样描述的: 该套接字接受缓冲区中的数据字节数大于等于套接字接受缓冲区低水平标记的当前大小。对这样的套接字的读是不会阻塞的，其将返回一个大于0的值（也就是具体读入的字节数）。我们可以使用 SO_RCVLOWAT 套接字选项来设置该套接字低水平标记，TCP和UDP套接字的默认值是1。【这个很好理解，就是1个字节，如果接受了1个字节或者更多的字节那么就有了可读事件了。】 该连接的读半部关闭，这样的套接字的读操作将不阻塞并返回0（也就是返回EOF）。【这里就是套接字对面关闭了，那么也将是可读的，我们可以用 'if read' 这样的判断来进行读结束的后续处理。】 该套接字是一个监听套接字且已完成连接数不为0。【这主要是指服务器端一开始创建的那个监听套接字，其一般accept不会阻塞的， conn, addr = s.accept() ，也就是客户端那边有敲门了，就会有一个可读事件，就会批准自动创建一个监听套接字，除非已完成连接数为0------这个已完成连接数具体含义我还不清楚。】 上面的情况中，有一个套接字错误待处理，对这样的套接字读操作将不阻塞并返回-1。【这里细节暂时还不清楚。】 EVENT_WRITE 可写事件，具体可写的定义按照参考资料 [@Unix网络编程卷1] 是这样描述的: 该套接字发送缓冲区中的可用空间字节数大于等于套接字发送缓冲区低水平标记的当前大小，并且该套接字已连接（或者该套接字不需要连接，比如UDP套接字）。如果我们把这样的套接字设置为非阻塞，那么写操作将返回一个正值（具体传输层接受到的字节数）。我们可以使用 SO_SNDLOWAT 套接字选项来设置该套接字的可写低水平标记，TCP和UDP套接字默认值是2048。【如果套接字是阻塞的，那么写操作应该会因为套接字另一端recv的阻塞而阻塞，这是我的一个猜测。然后这里和上面可读实际上是个反的，可读是相当于数据量超过某个标记，也就是往里面送一点点数据是不行的，还需要送到一定的量，才可读；而可写是送一点点数据都是可写的，只有送的数据量很大之后， 可用的 缓冲区空间 小于 某个标记之后，就不可写了。】 该连接的写半部关闭。对这样的套接字进行写操作将产生SIGPIPE信息。【我试过，后续程序会出错。对于服务器主动发动数据的模式，都应该考虑这种情况和捕捉好这个可能的异常。】 非阻塞连接的套接字已连接或连接已失败。【非阻塞连接初次连接成功可写很好理解，但为什么连接失败也可写？可能这里非阻塞初次连接失败被处理为连接半部关闭的情况了，也就是上面的哪一条。】 上面的情况中，有一个套接字错误待处理，对这样的套接字写操作将不阻塞并返回-1。 更多的内容请参看 selectors 模块的官方文档。 下面的例子将之前那个诗歌服务器写成了Select风格的异步版本 select_slowpoetry.py : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 #!/usr/bin/env python3 # -*- coding: utf-8 -*- import argparse import os import socket import time import selectors sel = selectors . DefaultSelector () def parse_args (): usage = \"\"\"usage: %prog [options] poetry-file python3 select_slowpoetry.py ecstasy.txt \"\"\" parser = argparse . ArgumentParser ( usage ) help = \"The port to listen on. Default to a random available port.\" parser . add_argument ( '-p' , '--port' , type = int , help = help ) help = \"The interface to listen on. Default is localhost.\" parser . add_argument ( '--iface' , help = help , default = 'localhost' ) help = \"The number of seconds between sending bytes.\" parser . add_argument ( '--delay' , type = float , help = help , default =. 1 ) help = \"The number of bytes to send at a time.\" parser . add_argument ( '--num-bytes' , type = int , help = help , default = 20 ) parser . add_argument ( 'poetry_file' ) args = vars ( parser . parse_args ()) poetry_file = args [ 'poetry_file' ] if not poetry_file : parser . error ( 'No such file: %s ' % poetry_file ) return args def send_poetry ( sock , poetry_file , num_bytes , delay , inputf ): \"\"\"Send some poetry slowly down the socket.\"\"\" bytes = inputf . read ( num_bytes ) if not bytes : sel . unregister ( sock ) sock . close () inputf . close () print ( 'sending complete' ) return True try : sock . sendall ( bytes ) except socket . error : sel . unregister ( sock ) sock . close () inputf . close () print ( 'some error, sending stoped' ) return False time . sleep ( delay ) def serve ( listen_socket , poetry_file , num_bytes , delay ): sock , addr = listen_socket . accept () print ( 'Somebody at %s wants poetry!' % ( addr ,)) sock . setblocking ( False ) inputf = open ( poetry_file , 'rb' ) sel . register ( sock , selectors . EVENT_WRITE , data = { 'callback' : send_poetry , 'args' : [ poetry_file , num_bytes , delay , inputf ]}) def main (): args = parse_args () poetry_file = args [ 'poetry_file' ] port = args [ 'port' ] iface = args [ 'iface' ] num_bytes = args [ 'num_bytes' ] delay = args [ 'delay' ] sock = socket . socket () sock . bind (( iface , port or 0 )) sock . listen ( 100 ) sock . setblocking ( False ) print ( 'Serving %s on port %s .' % ( poetry_file , sock . getsockname ()[ 1 ])) sel . register ( sock , selectors . EVENT_READ , data = { 'callback' : serve , 'args' : [ poetry_file , num_bytes , delay ]}) while True : events = sel . select () for key , mask in events : callback = key . data [ 'callback' ] callback ( key . fileobj , * key . data [ 'args' ]) sock . close () if __name__ == '__main__' : main () 客户端的编写要更加简单一点，具体代码如下所示 select_get_poetry.py : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 #!/usr/bin/env python3 # -*- coding: utf-8 -*- import datetime import argparse import socket import selectors sel = selectors . DefaultSelector () def parse_args (): usage = \"\"\"usage: %prog [options] [hostname]:port ... python3 select_get_poetry.py port1 port2 port3 ... 通过select I/O复用来建立一个异步诗歌下载客户端，可以同时面向多个诗歌服务器来进行下载。 \"\"\" parser = argparse . ArgumentParser ( usage ) parser . add_argument ( 'port' , nargs = '+' ) args = vars ( parser . parse_args ()) addresses = args [ 'port' ] if not addresses : print ( parser . format_help ()) parser . exit () def parse_address ( addr ): if ':' not in addr : host = '127.0.0.1' port = addr else : host , port = addr . split ( ':' , 1 ) if not port . isdigit (): parser . error ( 'Ports must be integers.' ) return host , int ( port ) return map ( parse_address , addresses ) def download_poetry ( sock , infile ): \"\"\"Download a piece of poetry from the given address.\"\"\" bstring = sock . recv ( 1024 ) if not bstring : # end fo reading sel . unregister ( sock ) infile . close () print ( 'end of reading' ) return True else : print ( 'writing to {} ' . format ( infile . name )) infile . write ( bstring ) def connect ( address ): \"\"\"Connect to the given server and return a non-blocking socket.\"\"\" sock = socket . socket () sock . connect ( address ) sock . setblocking ( False ) return sock def format_address ( address ): host , port = address return ' %s : %s ' % ( host or '127.0.0.1' , port ) def main (): addresses = parse_args () elapsed = datetime . timedelta () sockets = map ( connect , addresses ) for sock in sockets : filename = str ( sock . getpeername ()[ 1 ]) + '.txt' infile = open ( filename , 'wb' ) sel . register ( sock , selectors . EVENT_READ , data = { 'callback' : download_poetry , 'args' : [ infile ]}) while True : events = sel . select () for key , mask in events : callback = key . data [ 'callback' ] callback ( key . fileobj , * key . data [ 'args' ]) if __name__ == '__main__' : main () 这里主要的改动有两点: 1. 客户端同时开启几个sock，然后这些sock和可读时间绑定了download_poetry方法，只要有数据可读了，那么就会执行该操作。 2. 具体下载行为就是对目标fileobj进行write，把接受到的字节流给写进去即可。 Asyncio风格的诗歌服务器 通过Selectors模块，不仅现在我们的程序是高效的异步模式了，而且之前代码中那几个丑陋的 while True 给压缩到只有一个了，对于追求代码美观的程序员来说他们会对这一进步会感到很满意。而程序刚开始那个 while True 人们也有点看不习惯它了。人们慢慢的构建出\\\" reactor \\\"这个术语来取代这个主循环，如下图所示: reactor 在twisted模块中实际上就有这么一个reactor变量，来对应这个主Selector事件驱动。而asyncio模块里面也有类似的eventloop概念: import asyncio eventloop = asyncio . get_event_loop () 在进行事件驱动编程之前还需要强调一点，上图这个 事件循环 的概念是事件驱动编程的核心概念，实际上在前面的select风格异步编程中，我们就已经看到这点影子了，那就是开启事件循环之后，剩下的工作就是挂载一些函数，这些函数里面会涉及到另外一些函数的挂载和取消挂载操作等，我们可以在脑海中想象中间一个事件循环大圈，然后四周八围挂载着各种函数各种操作，这就是事件驱动编程风格了。实际上事件驱动编程会让很多工作变得简单，其没有让事情变得复杂，关键是我们的头脑要习惯这种编程风格，脑海里还熟悉这种事件驱动模型。 常规eventloop版 下面是Asyncio风格的诗歌服务器第一版，关于asyncio模块有不懂的读者请参看该模块的官方文档。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 #!/usr/bin/env python3 # -*- coding: utf-8 -*- import argparse import os import socket import time import asyncio def parse_args (): usage = \"\"\"usage: %prog [options] poetry-file python3 asyncio_slowpoetry.py ecstasy.txt \"\"\" parser = argparse . ArgumentParser ( usage ) help = \"The port to listen on. Default to a random available port.\" parser . add_argument ( '-p' , '--port' , type = int , help = help ) help = \"The interface to listen on. Default is localhost.\" parser . add_argument ( '--iface' , help = help , default = 'localhost' ) help = \"The number of seconds between sending bytes.\" parser . add_argument ( '--delay' , type = float , help = help , default =. 1 ) help = \"The number of bytes to send at a time.\" parser . add_argument ( '--num-bytes' , type = int , help = help , default = 20 ) parser . add_argument ( 'poetry_file' ) args = vars ( parser . parse_args ()) poetry_file = args [ 'poetry_file' ] if not poetry_file : parser . error ( 'No such file: %s ' % poetry_file ) return args def send_poetry ( eventloop , sock , poetry_file , num_bytes , delay , inputf ): \"\"\"Send some poetry slowly down the socket.\"\"\" bytes = inputf . read ( num_bytes ) if not bytes : eventloop . remove_writer ( sock ) sock . close () inputf . close () print ( 'sending complete' ) return True try : sock . sendall ( bytes ) except socket . error : eventloop . remove_writer ( sock ) sock . close () inputf . close () print ( 'some error, sending stoped' ) return False time . sleep ( delay ) def serve ( eventloop , listen_socket , poetry_file , num_bytes , delay ): sock , addr = listen_socket . accept () print ( 'Somebody at %s wants poetry!' % ( addr ,)) sock . setblocking ( False ) inputf = open ( poetry_file , 'rb' ) eventloop . add_writer ( sock , send_poetry , eventloop , sock , poetry_file , num_bytes , delay , inputf ) def main (): args = parse_args () poetry_file = args [ 'poetry_file' ] port = args [ 'port' ] iface = args [ 'iface' ] num_bytes = args [ 'num_bytes' ] delay = args [ 'delay' ] sock = socket . socket () sock . bind (( iface , port or 0 )) sock . listen ( 100 ) sock . setblocking ( False ) print ( 'Serving %s on port %s .' % ( poetry_file , sock . getsockname ()[ 1 ])) eventloop = asyncio . get_event_loop () eventloop . add_reader ( sock , serve , eventloop , sock , poetry_file , num_bytes , delay ) try : eventloop . run_forever () finally : eventloop . close () sock . close () if __name__ == '__main__' : main () 这里也将之前的诗歌获取客户端写成asyncio版本。代码如下所示，改动不是很大。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 #!/usr/bin/env python3 # -*- coding: utf-8 -*- import datetime import argparse import socket import asyncio def parse_args (): usage = \"\"\"usage: %prog [options] [hostname]:port ... python3 select_get_poetry3.py port1 port2 port3 ... \"\"\" parser = argparse . ArgumentParser ( usage ) parser . add_argument ( 'port' , nargs = '+' ) args = vars ( parser . parse_args ()) addresses = args [ 'port' ] if not addresses : print ( parser . format_help ()) parser . exit () def parse_address ( addr ): if ':' not in addr : host = '127.0.0.1' port = addr else : host , port = addr . split ( ':' , 1 ) if not port . isdigit (): parser . error ( 'Ports must be integers.' ) return host , int ( port ) return map ( parse_address , addresses ) def download_poetry ( eventloop , sock , infile ): \"\"\"Download a piece of poetry from the given address.\"\"\" bstring = sock . recv ( 1024 ) if not bstring : # end fo reading eventloop . remove_reader ( sock ) sock . close () infile . close () print ( 'end of reading' ) return True else : print ( 'writing to {} ' . format ( infile . name )) infile . write ( bstring ) def connect ( address ): \"\"\"Connect to the given server and return a non-blocking socket.\"\"\" sock = socket . socket () sock . connect ( address ) sock . setblocking ( False ) return sock def format_address ( address ): host , port = address return ' %s : %s ' % ( host or '127.0.0.1' , port ) def main (): addresses = parse_args () sockets = map ( connect , addresses ) eventloop = asyncio . get_event_loop () for sock in sockets : filename = str ( sock . getpeername ()[ 1 ]) + '.txt' infile = open ( filename , 'wb' ) eventloop . add_reader ( sock , download_poetry , eventloop , sock , infile ) try : eventloop . run_forever () finally : eventloop . close () if __name__ == '__main__' : main () 值得一提的是这里的读完毕的判断逻辑: if not bstring:##end fo reading eventloop.remove_reader(sock) sock.close() infile.close() print('end of reading') return True 如果读半部关闭，则将返回0，所以可以如上来判断读操作是否完毕了。 自定义协议版 asyncio模块还提供了很多功能可以让读者不用使用socket模块，而直接更高层的基于协议来编写网络程序。下面是 诗歌服务器第二版，本例子参考了 这个网页 然后修改而成。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 #!/usr/bin/env python3 # -*- coding: utf-8 -*- import argparse import os import time import asyncio def parse_args (): usage = \"\"\"usage: %prog [options] poetry-file python3 asyncio_slowpoetry3.py ecstasy.txt \"\"\" parser = argparse . ArgumentParser ( usage ) help = \"The port to listen on. Default to a random available port.\" parser . add_argument ( '-p' , '--port' , type = int , help = help ) help = \"The interface to listen on. Default is localhost.\" parser . add_argument ( '--iface' , help = help , default = '127.0.0.1' ) help = \"The number of bytes to send at a time.\" parser . add_argument ( '--num-bytes' , type = int , help = help , default = 20 ) parser . add_argument ( 'poetry_file' ) args = vars ( parser . parse_args ()) poetry_file = args [ 'poetry_file' ] if not poetry_file : parser . error ( 'No such file: %s ' % poetry_file ) return args class PoetryServeProtocol ( asyncio . Protocol ): def __init__ ( self , inputf , num_bytes ): self . inputf = inputf self . num_bytes = num_bytes def connection_made ( self , transport ): self . transport = transport print ( self . transport ) def data_received ( self , data ): if data == b 'poems' : poem = self . inputf . read ( self . num_bytes ) if poem : self . transport . write ( poem ) else : self . transport . write_eof () def main (): args = parse_args () poetry_file = args [ 'poetry_file' ] num_bytes = args [ 'num_bytes' ] port = args [ 'port' ] iface = args [ 'iface' ] inputf = open ( poetry_file , 'rb' ) eventloop = asyncio . get_event_loop () print ( iface , port ) coro = eventloop . create_server ( lambda : PoetryServeProtocol ( inputf , num_bytes ), iface , port ) server = eventloop . run_until_complete ( coro ) print ( server ) try : eventloop . run_forever () finally : eventloop . close () if __name__ == '__main__' : main () 代码变得简单得可怕了。首先我们看到这个 create_server 方法。通过这个方法，我们可以基于自己定义的某个协议来创建一个TCP server（返回的是协程对象）。下面主要看到具体创建的那个协议对象。 自定义的协议继承自Protocol类，然后定义一些方法: connection_made 这个callback继承自Protocol类，逻辑是如果一个连接建好了，那么执行该函数。其接受一个参数transport。也就是具体协议的传输层。 data_received 这个callback继承自Protocol类，如果某个数据传进来了，那么该函数将被执行。其接受一个参数就是传进来的data。 eof_received 数据结束完毕是调用。你可以在另外一端用transport发送写入结束信号 write_eof() 。 配套的获取诗歌客户端如下所示: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 #!/usr/bin/env python3 # -*- coding: utf-8 -*- import datetime import argparse import asyncio def parse_args (): usage = \"\"\"usage: %prog [options] [hostname]:port ... python3 select_get_poetry3.py port1 port2 port3 ... \"\"\" parser = argparse . ArgumentParser ( usage ) parser . add_argument ( 'port' , nargs = '+' ) args = vars ( parser . parse_args ()) addresses = args [ 'port' ] if not addresses : print ( parser . format_help ()) parser . exit () def parse_address ( addr ): if ':' not in addr : host = '127.0.0.1' port = addr else : host , port = addr . split ( ':' , 1 ) if not port . isdigit (): parser . error ( 'Ports must be integers.' ) return host , int ( port ) return map ( parse_address , addresses ) class PoetryClientProtocol ( asyncio . Protocol ): def __init__ ( self , infile ): self . infile = infile def connection_made ( self , transport ): print ( transport . get_extra_info ( 'peername' )) self . transport = transport self . transport . write ( b 'poems' ) def data_received ( self , data ): if data : print ( data ) print ( 'writing to {} ' . format ( self . infile . name )) self . infile . write ( data ) self . transport . write ( b 'poems' ) def eof_received ( self ): print ( 'end of writing' ) self . infile . close () def main (): addresses = parse_args () eventloop = asyncio . get_event_loop () for address in addresses : host , port = address filename = str ( port ) + '.txt' infile = open ( filename , 'wb' ) coro = eventloop . create_connection ( lambda : PoetryClientProtocol ( infile ), host , port ) t , p = eventloop . run_until_complete ( coro ) print ( t , p ) try : eventloop . run_forever () finally : eventloop . close () if __name__ == '__main__' : main ()","tags":"python语言","url":"articles/pythonyu-yan-xue-xi-zhi-wang-luo-bian-cheng.html"},{"title":"python语言学习之-多进程多线程","text":"进程的定义是: 一个正在执行的程序实例。每个进程都有一个唯一的进程ID，也就是所谓的 PID 。使用 ps 命令的第一个列就是每个进程的PID属性。在python中你可以使用 os.getpid() 来查看当前进程的PID。 以前只有一个CPU的机器上，多任务操作系统实际上一次也只能运行一个进程，操作系统是通过不断切换各个进程给你一种多任务似乎同时在运行多个程序的感觉的。多CPU机器上是真的可以同时运行多个进程。 进程fork 进程fork简单来说就类似于git某个项目的fork，进行了一些基本代码信息和其他配置以及其他相关信息的复制或注册。这就相当于在当前代码环境下，你有两个分别单独运行的程序实例了。 下面是一个非常简单的小例子，你可以把os.fork()语句移到print('before fork')之前来看看变化。 import os , time print ( 'before fork ' ) os . fork () print ( 'say hello from' , os . getpid ()) time . sleep ( 1 ) print ( 'after fork' ) 对于这个程序简单的理解就是，本py文件编译成字节码进入内存经过某些成为一个程序实例了（其中还包含其他一些信息），然后程序具体运行的时候会通过os.fork来调用系统的fork函数，然后复制本程序实例（以本程序实例目前已经所处的状态），因为print('before fork')已经执行了，所以子进程就不会执行这一行代码了，而是继续os.fork()下面的代码继续执行。此时就相当于有两个程序在运行了，至于后面的打印顺序那是说不准的。 关于操作系统具体如何fork的我们可以暂时不考虑，这两个程序实例里面的变量和运行环境基本上是一模一样的，除了运行的状态有所不同之外。fork可以做出一种程序多任务处理方案吧，不过os模块的fork方法目前只支持unix环境。 子进程和父进程分开 请看下面的代码: import os , time print ( 'before fork ' ) pid = os . fork () if pid : print ( pid ) print ( 'say hello from parent' , os . getpid ()) else : print ( pid ) print ( 'say hello from child' , os . getpid ()) time . sleep ( 1 ) print ( 'after fork' ) 其运行结果大致如下: before fork 13762 say hello from parent 13761 0 say hello from child 13762 after fork after fork 我们看到在父进程那一边，pid是本父进程的子进程PID，而在子进程那一边，os.fork()返回的是0。可以利用这点将父进程的操作和子进程的操作分开。具体上面的代码if pid 那一块是父进程的，else那一块是子进程的。 线程入门 线程的内部实施细节其实比进程要更加复杂，一般通俗的说法就是线程是轻量级进程，这里不深入讨论具体线程的细节。 python操作线程的主要模块是 threading 模块，简单的使用就是新建一个线程对象(Thread)，然后调用 start 方法来启动它，具体线程要做些什么由本线程对象的 run 确定，你可以重定义它，如果是默认的就是调用本线程Thread类新建是输入的 target 参数，这个target参数具体指向某个函数。下面是一个简单的例子: import random , threading result = [] def randchar_number ( i ): number_list = list ( range ( 48 , 58 )) coden = random . choice ( number_list ) result . append ( chr ( coden )) print ( 'thread:' , i ) for i in range ( 8 ): t = threading . Thread ( target = randchar_number , args = ( i ,)) t . start () print ( '' . join ( result )) thread : 0 thread : 1 thread : 2 thread : 3 thread : 4 thread : 5 thread : 6 thread : 7 22972371 注意: 控制参数后面那个逗号必须加上。 我不太喜欢这种风格，因为线程对接的那个函数实际上并不能return 什么值，而且其保存的值也依赖于前面的定义，并不能称之为真正意义上的函数（一个定义很好的函数必须复用特性很强）。所以线程还是如下类的风格编写。下面代码参考了 这个网页 。 import random , threading threads = [] class MyThread ( threading . Thread ): def __init__ ( self ): threading . Thread . __init__ ( self ) self . result = '' def run ( self ): number_list = list ( range ( 48 , 58 )) coden = random . choice ( number_list ) self . result = chr ( coden ) def getvalue ( self ): return self . result for i in range ( 8 ): t = MyThread () t . start () t . join () threads . append ( t ) result = '' for t in threads : result += t . getvalue () print ( result ) 0564 9040 >>> 上面调用线程对象的 join 方法是确保该线程执行完了，其也可能返回异常。上面的做法不太标准，更标准的做法是单独写一行t.join代码: for t in threads: t.join() 来确保各个线程都执行完了，如之前的形式并不能达到多任务并行处理的效果。 上面的例子对线程的执行顺序没有特殊要求，如果有的话推荐使用python的queue模块，这里就略过了。 后台线程 下面的函数实现了一个后台警报线程，不会阻塞主程序。 def beep ( a , b ): '''make a sound , ref: http://stackoverflow.com/questions/16573051/ python-sound-alarm-when-code-finishes you need install ``apt-get install sox`` :param a: frenquency :param b: duration create a background thread,so this function does not block ''' def _beep ( a , b ): import os os . system ( 'play --no-show-progress --null --channels 1 \\ synth %s sine %f ' % ( b , a )) from threading import Thread thread = Thread ( target = _beep , args = ( a , b )) thread . daemon = True thread . start () 如上所示，原beep函数调用系统的play命令制造一个声音，其中b是声音持续的时间，所以其是阻塞的。我们将其作为一个线程调用之后，然后其就没有阻塞主程序了。这里的 daemon 的意思是让这个线程成为一个后台线程，请参看 这个网页 ，其说道后台线程可以不用管了，后面会随着主程序自动关闭。 多线程: 一个定时器 这个例子主要参考了 这个网页 。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 #!/usr/bin/env python3 # -*- coding: utf-8 -*- import time import threading class Timer ( threading . Thread ): def __init__ ( self , interval , action = lambda : print ( ' \\a ' )): threading . Thread . __init__ ( self ) self . interval = interval self . action = action def run ( self ): time . sleep ( self . interval ) self . action () def set_interval ( self , interval ): self . interval = interval #timer = Timer(5) #timer.start() class CountDownTimer ( Timer ): def run ( self ): counter = self . interval for sec in range ( self . interval ): print ( counter ) time . sleep ( 1.0 ) counter -= 1 ## self . action () #timer = CountDownTimer(5) #timer.start() def hello (): print ( 'hello \\a ' ) timer = CountDownTimer ( 5 , action = hello ) timer . start () 具体还是很简单的，这里之所以使用线程就是为了timer.sleep函数不冻结主程序。 多线程下载大文件 本小节参考了 这个网页 和 这个网页 。 下面的 get_content_tofile 函数在目标内容大小大于1M的时候将启动多线程下载方法。其中 guess_url_filename 函数是根据url来猜测可能的目标下载文件名字，还只是一个尝试版本。 注意下面使用requests.get函数的时候加上了 stream=True 参数，这样连接目标url的时候只是获得头文件信息而不会进一步下载content内容。这方便我们早期根据headers里面的信息做出一些判断。 接下来根据HTTP头文件的 content-length 来判断要下载内容的大小，如果没有这个属性，那么目标url是没有content内容的，本函数将不会对这一情况做出反应，这通常是单网页url，使用requests的get方法获取网页文本内容即可。 然后如果目标长度小于1M，那么就直接打开文件，使用requests模块里response对象的 iter_content 方法来不断迭代完content内容。 如果目标长度大于1M，则采用一种多线程下载方法。首先是 get_content_partly 这个函数，接受url和index，这个index是一个简单的索引，具体多少bytes后面还需要计算。关于多线程操作和具体多少bytes的计算细节这里略过讨论了。唯一值得一提的就是HTTP协议的Range属性，begin-end，对应具体的范围0-1024，还包括1024位，所以实际上有1025个bytes，为了获得和我们python中一致的体验，我们让其end为begin+1024-1。这样就有1024个bytes位，然后定位是(0, 1024)，即和python中的一样，不包括1024位。 然后还有一个小信息是，HTTP协议返回的头文件中的 content-range 属性，如果你请求Range越界了，那么将不会有这个属性。那么begin没有越界，end越界的请求如何呢？HTTP协议处理得很好，这种跨界情况都只返回最后那点content内容。 最后写文件那里降低内存消耗，使用了下面的语句来强制文件流写入文件中，好释放内存，否则你的下载程序内存使用率是剧增的。 f . flush () os . fsync ( f . fileno ()) import re def guess_url_filename ( url ): '''根据url来猜测可能的目标文件名，''' response = requests . get ( url , stream = True ) ##还有一个content-type信息可以利用 s = urlsplit ( url ) guess_element = s . path . split ( '/' )[ - 1 ] guess_pattern = re . compile ( r ''' (.png|.flv) $ # end of string ''' , re . VERBOSE | re . IGNORECASE ) if re . search ( guess_pattern , guess_element ): filename = guess_element else : filename = guess_element + '.html' return filename import threading import os class DownloadThread ( threading . Thread ): def __init__ ( self , url , begin , chunk_size = 1024 * 300 ): threading . Thread . __init__ ( self ) self . url = url self . begin = begin self . chunk_size = chunk_size self . result = b '' def run ( self ): headers = { 'Range' : 'bytes={begin}-{end}' . format ( begin = str ( self . begin ), end = str ( self . begin + self . chunk_size - 1 ))} response = requests . get ( url , stream = True , headers = headers ) if response . headers . get ( 'content-range' ) is None : self . result = 0 ##表示已经越界了 else : self . result = response . content print ( 'start download...' , self . begin / 1024 , 'KB' ) def getvalue ( self ): return self . result def get_content_partly ( url , index ): threads = [] content = b '' chunk_size = 1024 * 300 # 这个不能设置太大也不能设置太小 block_size = 10 * chunk_size # 具体线程数 for i in range ( 10 ): t = DownloadThread ( url , index * block_size + i * chunk_size ) t . start () threads . append ( t ) for i , t in enumerate ( threads ): t . join () for t in threads : if t . getvalue (): content += t . getvalue () return content import os def get_content_tofile ( url , filename = '' ): '''简单的根据url获取content，并将其存入内容存入某个文件中。 如果某个内容size 小于1M 1000000 byte ，则采用多线程下载法''' if not filename : filename = guess_url_filename ( url ) # NOTE the stream=True parameter response = requests . get ( url , stream = True ) if not response . headers . get ( 'content-length' ): print ( 'this url does not have a content .' ) return 0 elif response . headers . get ( 'content-length' ) < '1000000' : with open ( filename , 'wb' ) as f : for chunk in response . iter_content ( chunk_size = 1024 ): if chunk : # filter out keep-alive new chunks f . write ( chunk ) f . flush () os . fsync ( f . fileno ()) else : with open ( filename , 'wb' ) as f : for i in range ( 1000000 ): ##very huge content = get_content_partly ( url , i ) if content : f . write ( content ) f . flush () os . fsync ( f . fileno ()) else : print ( 'end...' ) break 线程锁 python有两种类型线程锁 Lock 和 RLock ，其都是通过 acquire 来获取锁和 release 来释放锁。当一个线程试着访问某个unlocked的锁， acquire 将立即返回；如果访问的是locked的锁，那么该线程将阻塞，直到一个 release 释放了该锁。 RLock和Lock的区别是RLock可以被相同的线程acquire多次，RLock人们也称之为递归锁，如果你的某个（递归）函数在某个线程中多次访问资源，而这时被允许的，那么你应该使用RLock。 RLock常和with语句一起使用： lock = threading.RLock() with lock: do something...","tags":"python语言","url":"articles/pythonyu-yan-xue-xi-zhi-duo-jin-cheng-duo-xian-cheng.html"},{"title":"python语言学习之-文件处理","text":"一行行的操作 因为文件对象本身是可迭代的，我们简单迭代文件对象就可以对文件的一行行内容进行一些操作。比如： f = open('removeduplicate.py') for line in f: print(line,end='') 这个代码就将打印这个文件，其中end=\"的意思是取消 \\n ，因为原来的行里面已经有 \\n 了。 然后代码稍作修改就可以在每一行之前加上 >>> 这个符号了。 f = open('removeduplicate.py') for line in f: print('>>>',line,end='') 什么？这个输出只是在终端，没有到某个文件里面去，行，加上file参数。然后代码变成如下： import sys f = open ( 'removeduplicate.py' ) pyout = open ( sys . argv [ 1 ] , \"w\" ) for line in f : print ( '>>>' , line , end = '' , file = pyout ) pyout . close () f . close () 这样我们就制作了一个小python脚本，接受一个文件名然后输出这个文件，这个文件的内容就是之前我们在终端中看到的。 整个文件的列表解析 python的列表解析（迭代）效率是很高的，我们应该多用列表解析模式。 readlines方法 文件对象有一个readlines方法，能够一次性把整个文件的所有行字符串装入到一个列表中。然后我们再对这个列表进行解析操作就可以直接对整个文件的内容做出一些修改了。不过不推荐使用readlines方法了，这样将整个文件装入内存的方法具有内存爆炸风险，而迭代版本更好一点。 文本所有某个单词的替换 这里举一个例子，将removeduplicate.py文件接受进来，然后进行列表解析，将文本中的newlist全部都替换为list2。 import sys pyout = open ( sys . argv [ 1 ] , \"w\" ) print ( '' . join ([ line . replace ( 'newlist' , 'list2' ) for line in open ( 'removeduplicate.py' )]), file = pyout ) pyout . close () 我们可以看到这种列表解析风格代码更加具有python风格和更加的简洁同时功能是异常的强大的。 从这里起我们看到如果需要更加复杂的文本处理技巧就需要学习正则表达式和re模块了。","tags":"python语言","url":"articles/pythonyu-yan-xue-xi-zhi-wen-jian-chu-li.html"},{"title":"python语言学习之-模块","text":"现在让我们进入模块基础知识的学习吧，建立编写自己的模块，这样不断积累自己的知识，不断变得更强。 实际上之前我们已经接触过很多python自身的标准模块或者其他作者写的第三方模块，而import和from语句就是加载模块用的。 from语句和import语句内部作用机制很类似，只是在变量名的处理方式上有点差异（from会把变量名复制过来）。这里重点就import的工作方式说明如下： 首先需要找到模块文件。 然后将模块文件编译成位码（需要时，根据文件的时间戳。），你会看到新多出来一个 __pycache__ 文件夹。 执行编译出来的位码，创建该py文件定义的对象。 这三个步骤是第一次import的时候会执行的，第二次import的时候会跳过去，而直接引用内存中已加载的对象。 import语句 import语句的一般使用方法之前已有接触，比如import math，然后要使用math模块里面的函数或者类等需要使用这样的带点的变量名结构：math.pi。 此外import语句还有一个常见的缩写名使用技巧，比如import numpy as np，那么后面就可以这样写了， np.array，而不是numpy.array。 from语句 from语句的使用有以下两种情况： from this import this from what import * 第一种形式是点名只导入某个变量，第二种形式是都导入进来。我想读者肯定知道这点，使用第二种导入形式的时候要小心变量名覆盖问题，这个自己心里有数即可。 reload函数 reload函数可以重新载入某个模块，reload函数的优点就是不需要重新启动应用程序，更加合理的动态重载一些模块。reload只能用于python编写的模块，在python3中，reload函数被移到imp模块里面去了，因此首先需要import imp才能使用了。比如说： from imp import reload reload ( somemodule )","tags":"python语言","url":"articles/pythonyu-yan-xue-xi-zhi-mo-kuai.html"},{"title":"python语言学习之-一切皆对象","text":"首先说下python2和python3的兼容性，如果读者在python2.7环境下，那么推荐定义class的时候都如下跟上object： class Test ( object ) : pass 本章节围绕着下面这些内容逐步展开，从而逐步实现对python类的各个行为的深度定制。 内省属性： __dict__ ， __class__ 进行某种运算符操作或调用某个常见的方法时的行为重载。 函数装饰器： 函数调用行为的定制 一般属性访问行为定制 特定属性访问时行为定制 类实例创建时行为定制------类装饰器 类对象创建时行为定制------metaclass __dict__ 参考了 这个网页 。 首先读者记住class是个类似于def一样的语句，其也管理一个名字空间，然后区块里面的语句逐步执行。然后我们看下面这个例子： class A () : def __init__ ( self , a ) : self . a = a def fun2 ( self , what ) : print ( 'fun' , what ) @property def x ( self ) : return 1 class B ( A ) : def __init__ ( self ) : self . d = 5 b = 2 def fun3 ( self ) : print ( 'fun3' ) b = B () b . __class__ => < class 'B' > B . __class__ => < class 'type' > b . __dict__ => { 'd' : 5 } B . __dict__ => mappingproxy ({ '__module__' : 'builtins' , '__init__' : < function B . __init__ at 0x7f13586057b8 > , 'b' : 2 , 'fun3' : < function B . fun3 at 0x7f1358605840 > , '__doc__' : None }) A . __dict__ => mappingproxy ({ '__module__' : 'builtins' , '__init__' : < function A . __init__ at 0x7f1358605620 > , 'fun2' : < function A . fun2 at 0x7f13586056a8 > , 'x' : < property object at 0x7f1358604188 > , '__dict__' : < attribute '__dict__' of 'A' objects > , '__weakref__' : < attribute '__weakref__' of 'A' objects > , '__doc__' : None }) 这个例子很有些东西，首先是 b.__class__ ，是查看实例b的类型，大体输出接近于 type(b)，然后我们看到类B的类型是type。后面在将metaclass会讲到这个，目前记住实例是根据类创建的，而类是根据元类也就是这个type创建的。 然后我们看到不管是实例b还是类B或者类A都记忆了一些自己的属性，至于继承来的属性是不需要重复记忆了。 然后类的 __dict__ 是 mappingproxy对象，其是只读的，也就是只有实例b的 __dict__ 是 dict类型，是可以读写的（参考了 这篇文章 ）。 最后通过 @property 装饰器修饰的函数，我们会得到一个 property object ，这个后面会谈到，这个特定的属性访问行为是可定制的，通过描述符对象。 __getitem__ __getitem__(self, key) 方法定义了实例的这种形式 Class['key'] 的行为。 class Test () : a = 1 def __getitem__ ( self , key ) : print ( 'i accpeted: {0}' . format ( key )) return self . a t = Test () >> t [ 'a' ] i accpeted : a => 1 类初步测试不支持这种 Test['x'] 的写法。 然后 __setitem__(self, key, value) 方法 对应 t['x']=3 这样的赋值形式； 还有 __delitem(self, key)__ 方法对应这样的运算符号表示： del t['x'] 就不罗嗦了。 数学运算符号重载 一般应用层面很少有需求去重载这些数学运算符号操作吧。这里稍微了解下即可。 一般加法 X + other , __add__(self,other) 右侧加法 所谓加法是X+other，如果是右侧加法，则为radd，然后公式是：other+X。一般不区分左右的就用上面的一般加法。other + ​ X , __radd__(self,other) 增强加法 X +=other ， __iadd__(self.other) 一般减法 X - other , __sub__(self,other) ​ 。同上面情况一样类似的还有rsub和isub。 * 乘法， __mul__(self,other) ，下面的类似的都有右侧运算和增强运算，不再赘述了。 // 整除， __floordiv__ ，下面类似的参数都是self和other，不再赘述了。 / 除法 ， __div__ % 取余， __mod__ ** 开方， __pow__ \\<\\< 左移运算， __lshift__ >> 右移运算， __rshift__ & 位与， __and__ | 位或， __or__ \\&#94; 位异或[&#94;12]， __xor__ 类似的右侧运算名字前面加上r，增强运算名字前面加上i，不赘述了。 逻辑运算 bool函数 bool(X) __bool__(self) __eq__ __eq__ 方法定义了两个对象之间A == B的行为。 比如下面： def __eq__(self,other): if self.__dict__.keys() == other.__dict__.keys(): for key in self.__dict__.keys(): if not self.__dict__.get(key)==other.__dict__.get(key): return False return True else: return False 定义了这样的 __eq__ 方法之后，我们运行==语句，如果两个对象之间内置字典键和值都是一样的，那么就返回True。 >>> test=GClass() >>> test.a=1 >>> test2=GClass() >>> test2.a=1 >>> test == test2 True >>> test is test2 False 如果我们不重定义 __eq__ 方法，似乎test和test2会从原始的object类继承 __eq__ 方法，然后它们比较返回的是False，我想可能是这两个实例内部某些值的差异吧，但应该不是基于id。 比较判断操作 类似上面的==比较操作，还有如下比较判断操作和对应的内置方法可以重定义。 X != Y ，行为由 __ne__(self,other) 定义。 X >= Y ，行为由 __ge__(self,other) 定义。 X \\<= Y ，行为由 __le__(self,other) 定义。 X > Y ，行为由 __gt__(self,other) 定义。 X \\< Y ，行为由 __lt__(self,other) 定义。 in语句 如下所示： def __in__(self,other): for key in self.__dict__.keys(): if not self.__dict__.get(key) == other.__dict__.get(key): return False return True 提供了what in X语句的支持，上面的例子是基于类其内字典的内容而做出的判断。 类之间的相等判断 参考网站 。 这里先总结下is语句和==判断和isinstance和id还有type函数，然后再提及python类的内置方法 __eq__ 。 python是一个彻头彻尾的面向对象的语言，python内部一切数据都是对象，对象就有类型type的区别。比如内置的那样对象类型： >>> type('abc') <class 'str'> >>> type(123) <class 'int'> >>> type([1,2,3]) <class 'list'> 对象除了有type类型之外，还有id属性，id就是这个对象具体在内存中的存储位置。 当我们说lst=[1,2,3]的时候，程序具体在内存中创建的对象是[1,2,3]，而lst这个变量名不过是一个引用。然后我们看下面的例子： >>> x=[1,2,3] >>> y=[1,2,3] >>> type(x) <class 'list'> >>> type(y) <class 'list'> >>> id(x) 3069975884 >>> id(y) 3062209708 >>> x==y True >>> x is y False type函数返回对象的类型，id函数返回对象具体在内存中的存储位置，而==判断只是确保值相等，is语句返回True则更加严格，需要对象在内存上（即id相等）完全是同一个东西。 对象之间的类型比较可以用如下语句来进行比较： >>> x=10 >>> type(x) == int True >>> type(x) == type(0) True 不过不是特别好用，比如假设fun是你自己定义的一个函数，用type(fun) == function就会出错，然后type比较还要小心NoneType和其他空列表类型不同，而且type比较并没有将类的继承考虑进去。 一般推荐isinstance函数来进行类型比较，请参考 这个网站 的说明。推荐使用types模块的特定名字来判断类型，具体如下： types.NoneType None这个值的类型 types.TypeType type对象。 types.BooleanType 还可以使用 bool 。 types.IntType 还可以使用 int ，类似的有 long ， float 。 types.ComplexType 复数类型 types.StringType 字符串类型，还可以使用 str 。 types.TupleType 元组，还可以使用 tuple ，类似的有 list ， dict 。 types.FunctionType 定义的函数类型，此外还有 types.LambdaType 。 值得一提的是print等内置函数不是FunctionType而是BuiltinFunctionType。 >>> import types >>> isinstance ( print , types . FunctionType ) False >>> isinstance ( print , types . BuiltinFunctionType ) True 更多内容请参见 types模块的官方文档 。 强制类型变换 所包含的内置方法有： __int__(self) 返回整型 __long__(self) 长整型 __float__(self) 浮点型 __complex__(self) 复数型 __str__(self) 字符型 __oct__(self) 八进制 __hex__(self) 十六进制 __index__(self) 切片操作 __len__ 由 __len__(self) 提供支持。 copy方法和deepcopy方法 X.copy() 由 ___copy__(self) 提供。 X.deepcopy() 由 ___deepcopy__(self) 提供。 with语句支持 在打开文件那里谈及的with open(...) as f的这类语句是由以下两个内置方法提供的： __enter__(self) 和 __exit__(self,...) ，exit的还有其他一些参数这里忽略了，enter的返回值会赋值给with中的as后面的变量。 __call__ 请看下面的例子： class Position () : def __init__ ( self , x = 0 , y = 0 ) : self . x = x self . y = y def __call__ ( self , x , y ) : self . x = x self . y = y def __repr__ ( self ) : return '(' + str ( self . x ) + ',' + str ( self . y ) + ')' >>> p1 = Position () >>> print ( p1 ) ( 0 , 0 ) >>> p1 ( 4 , 5 ) >>> print ( p1 ) ( 4 , 5 ) >>> 有了 __call__(self,args) 方法，你的实例就好像函数一样可以被调用了。 __new__ 一个类创造出一个实例出来首先是调用 __new__ 方法，然后才是调用 __init__ 方法。其一个应用就是所谓的单例模式，也就是一个类只能创造一个实例，请参看 这篇文章 。 class Singleton ( object ) : _instance = None def __new__ ( cls , * args , ** kw ) : if not cls._instance : cls._instance = super ( Singleton , cls ). __new__ ( cls , * args , ** kw ) return cls . _instance class MyClass ( Singleton ) : a = 1 >>> one = MyClass () >>> two = MyClass () >>> one == two True >>> one is two True >>> id ( one ), id ( two ) ( 4303862608 , 4303862608 ) 可迭代对象 前面说的可迭代对象就是（参考了廖雪峰的 这个网页 ）： from collections import Iterable isinstance ( obj , Iterable ) 从实用角度出发所谓的可迭代对象就是可以直接用for遍历的对象。而for遍历的过程如下所示： >>> list=[1,2,3] >>> iter=iter(list) >>> while True: ... try: ... x=next(iter) ... except StopIteration: ... break ... print(x) ... 1 2 3 这里的iter函数是调用的可迭代对象的 __iter__ 方法，其将返回一个迭代器对象（Iterator）------简单理解（且先不管工作是否正常）就是如果这个对象有 __iter__ 方法，那么其就是一个可迭代对象，如果一个对象有 __next__ 方法，那么其就是一个迭代器对象。 __next__方法 比如文件对象本身就是可迭代的，调用 __next__ 方法就返回文件中下一行的内容，到达文件尾也就是迭代越界了返回： StopIteration 异常。 next函数比如next(f)等价于 f.__next__() 。 >>> for line in open('removeduplicate.py'): ... print(line,end='') ... #!/usr/bin/env python3 #-*-coding:utf-8-*- #此处一些内容省略。 >>> f=open('removeduplicate.py') >>> next(f) '#!/usr/bin/env python3\\n' 所以你可以通过定义类的 __next__ 方法来获得这个类对于next函数时的反应。 __iter__方法 ，，，，自身已经带有了 __next__ 方法，所以可以直接用next函数。不过虽然序列（列表，元组，字典，ranges对象[&#94;13]）等是可迭代对象，但是没有 __next__ 方法。 这些序列经过iter函数处理就可以使用next函数了，或者说可以调用 __next__ 方法了，是因为它们有如下这种通用写法： def __iter__(self): return self 其返回自身，而这个自身对象已经定义了 __next__ 方法了。 >>> list=[1,2,3] >>> next(list) Traceback (most recent call last): File \"<stdin>\", line 1, in <module> TypeError: 'list' object is not an iterator >>> i=iter(list) >>> next(i) 1 >>> i.__next__() 2 如下所示，你也可以直接通过定义 __iter__ 方法返回一个生成器对象（generator object）------通过生成器函数或者return一个生成器表达式。 下面这个例子通过重新定义字典类的 __iter__ 方法来获得一个新类，这个类用iter函数处理之后的迭代器返回的是经过排序的字典的键。 class SortedDict ( dict ) : def __init__ ( self , dict = {}) : super (). __init__ ( dict ) def __iter__ ( self ) : self . _keys = sorted ( self . keys ()) for i in self._keys : yield i dict02 = SortedDict () dict02 [ 'a' ] = 1 dict02 [ 'b' ] = 1 dict02 [ 'c' ] = 1 dict02 [ 'd' ] = 1 x = iter ( dict02 ) __del__ 当对象内存存储被回收时，python最后将执行一个内置方法 __del__ ，这个一般不推荐使用。 __getattr__ 如果某个属性不在对象的 __dict__ 里面，然后python会调用 __getattr__(self,name) 方法（参考了 这篇文章 ）。如果没定义这个方法那么将抛出 AttributeError 。 然后还有 __setattr__(self,name,value) 和 __delattr__(self,name) ，这两个方法不管原属性在不在都会对其进行操作，谨慎使用！ 装饰器 装饰器的作用机制就是对接下来的函数（类class声明其实也类似于函数声明，所以后面会提到类装饰器的概念）进行进一步的封装，比如： @staticmethod def what(): pass # 其就等价于在类声明语句里写上了这样一句。 what = staticmethod(what) 可见装饰器并不是一个什么神秘的难懂的概念，同样你可以定义自己的函数，这个函数处理某个函数对象，并对其进行某种封装。 自定义装饰器 def print1(f): print('1',f) return f @print1 def print3(c): print(c) print3('c') # print1(print3)('c') 比如上面的print1函数就做成了一个装饰器函数，后面的print3函数可以理解为 print3=print1(print3) 。 多个装饰器 def print1(f): print('1',f) return f def print2(f): print('2',f) return f @print2 @print1 def print4(c): print(c) print4('c') # print2(print1(print4))(c) 类似上面的多个装饰器就可以简单理解为: print4 = print2(print1(print4)) 装饰器带上参数 在前面的例子中，我们就可以简单将装饰器函数理解为一个接受函数对象返回返回函数对象的函数，这很直观和简单。实际上装饰器也是可以带上自己的参数的，这需要通过什么函数的闭包结构才能完成，如下面的例子所示: def print1(f): print('1',f) return f def print2(b): def test(f): print('2',f,b) return f return test @print2('b') @print1 def print4(c): print(c) print4('c') # print2(print1(print4))('b')(c) 所谓闭包结构简单来说就是函数里面套函数的结构。前面在介绍nolocal关键词的时候说道，如果函数里面的嵌套函数的某个变量加上声明关键词nolocal，那么（如果嵌套函数内没有定义该本地变量），则该变量名是对应嵌套函数外面的自由变量的（自由变量在函数生存期具有记忆能力）。 上面例子可以理解为 print2(print1(print4))('b')(c) 这样一个过程。首先执行print1(print4)，然后返回print4，这很直观。然后表达式变为 print2(print4)('b')(c) ，然后print2返回test，同时消费掉一个参数，即获得自由变量 b='b' ，这样表达式变为 test(print4)(c) ，然后表达式继续规约为 print4(c) 。 静态方法装饰器 class Test : # @staticmethod def hello () : print ( 'aaa' ) test = Test () test . hello () 在上面的例子中，我们希望创造一个函数，这个函数和self实例没有关系（这里指这个函数将不接受self这个默认参数了）。如上所示，hello函数只是希望简单打印一小段字符，如 上面这样的代码是错误 的，如果我们在这个函数上面加上 \\@staticmethod ，那么上面这段代码就不会报错了， class Test : @staticmethod def hello () : print ( 'aaa' ) test = Test () test . hello () 这样在类里面定义出来的函数叫做这个类的静态方法，静态方法同样可以继承等等，而静态方法通常使用最大的特色就是不需要建立实例，即可以直接从类来调用，如下所示： class Test : @staticmethod def hello () : print ( 'aaa' ) Test . hello () 静态方法的使用比如pyqt中的 QtGui.QFileDialog.getOpenFileName(......) 就是一个静态方法，可以通过直接调用这个方法来弹出询问打开文件的窗口，并不需要先实例化一个对象，然后通过self.what等类似的形式来调用。 类方法装饰器 还有一个装饰器有时也会用到， @classmethod ，叫什么类方法装饰器。其和前面的静态方法一样也可以不新建实例，而直接通过类来调用。其和静态方法的区别就是静态方法在调用的时候没有任何默认的第一参数，而类方法在调用的时候默认第一参数就是调用的那个类[&#94;14]。 class Test : @classmethod def hello ( cls ) : print ( 'from class:' , cls , 'saying hello' ) Test . hello () from class : < class '__main__.Test' > saying hello 关于classmethod装饰器实际上东西就这么多，然后就是传进去的第一个参数cls看你有什么使用需要了，比如 cls(...) 将根据这个类来生成一个实例。 多重继承的顺序问题 我们来看下面这个例子： class B1 () : x = 'B1' class B2 () : x = 'B2' class B3 () : x = 'B3' class B ( B1 , B2 , B3 ) : x = 'B' class A1 () : x = 'A1' class A2 () : x = 'A2' class A ( A1 , A2 ) : x = 'A' class D ( B , A ) : x = 'D' test = D () print ( test . x ) duo-chong-ji-cheng 你可以测试一下上面这个例子，首先当然结果是D自己的x被先查找，然后返回 'D' ，如果你把类D的x定义语句换成pass，结果就是 'B' 。这说明这里程序的逻辑是如果test实例找不到x，那么再找D，D找不到再接下来找D继承自的父类，首先是B，到目前为止，没什么新鲜事发生。 然后我们再把B的x赋值语句换成pass，这时的结果是 'B1' ，也没什么好惊讶的。然后类似的一致操作下去，我们会发现python的值的查找顺序在这里是：D，B，B1，B2，B3，A，A1，A2。 于是我们可以总结道：恩，类的多重继承就是深度优先法则，先把子类或者子类的子类都查找完，确认没有值之后再继续从左到右的查找。 一般情况来说这么理解是没有问题的，但是在编程界多重继承中有个有名的问题------菱形难题。 菱形难题 参考资料： 维基百科菱形难题 ling-xing-nan-ti 菱形难题即在如上的类的继承中，如果C和A都有同名属性x，那么D会调用谁的呢？读者测试下面的例子： class E () : x = 'E' class F () : x = 'F' class G () : x = 'G' class A ( F , G ) : x = 'A' class B ( E , F ) : x = 'B' class D ( B , A ) : pass test = D () print ( test . x ) 此时运行结果到DBE都没有什么出奇的， 接下来要某是DBEF[&#94;15]，要某是DBEA，这里程序的结果是 'A' 。这里的情况确实比较纠结，如果没有这个F作为菱形难题的交叉点，似前面的层次分明，那么简单的理解为深度优先即可，这里python3的选择是 'A' ，不清楚为什么要这么选择。 我们再来看这个例子： class E () : x = 'E' class F () : x = 'F' class G () : x = 'G' class A ( F , G ) : x = 'A' class B ( F , E ) : pass class D ( B , A ) : pass test = D () print ( test . x ) 此时结果是 'A' ，连E都被跳过去了，变成了彻底的横向优先原则。 程序出现菱形难题之后，情况变得不可琢磨了。上面的三个情况 D(B(B1 B2 B3) A(A1 A2)) → D B B1 B2 B3 A A1 A2 D(B(E F) A(F G)) → D B E A F G D(B(F E) A(F G)) → D B A F E G 就是这样的，总之这是很冷门的领域了。。简单的理解就是深度搜索，类似flatten函数处理过，然后如果遇到某个子元在下一个平行级别的子元中也含有，那么本子元会被略过，做个记号，分叉跳过去跑到A那里，执行完那个子元之后，又会重新调到之前的操作点上。python怎么弄这么古怪的逻辑。。 super如何面对菱形难题 第一种情况是如果是单继承的类的系统，super()这种形式就直接表示父类的意思。然后用super().什么什么的来引用父类的某个变量或方法。 第二种情况是多重继承的，搜索顺序和多重继承的搜索顺序相同，也就是从左到右。请注意调试下面的例子，如果调用c.d就会返回错误，说明调用的是类A的构造函数。 class A () : def __init__ ( self , a ) : self . a = a def fun ( self ) : print ( 'fun' ) def fun2 ( self , what ) : print ( 'fun' , what ) class B () : def __init__ ( self ) : self . d = 5 b = 2 def fun3 ( self ) : print ( 'fun3' ) class C ( A , B ) : def __init__ ( self ) : super (). __init__ ( 3 ) super (). fun () super (). fun2 ( 'what' ) super (). fun3 () print ( super (). b ) c = C () print ( c . a , c . b ) fun fun what fun3 2 3 2 其中A类定义的fun函数在写的函数上通常有个self参数，而 super() 这种调用形式在意义上表示其的父类，同时默认第一个参数就是self。使用super()在类的编写中引用本类的父类的属性和方法是很便捷的， 。比如上面的例子中fun3能被调用是因为多重继承的机制在这里，所以它会逐个找父类。然后c.d会出错，因为这里初始化是用的A类的构造函数。 属性装饰器 其他编程语言的开发者可能会在类里定义一些针对某些属性的get和set之类的方法，这并不是Pythonic的风格，对于某些特定名字的属性，一般利用属性装饰器来构建，如下所示： class Apple () : def __init__ ( self ) : self . _color = 'red' @property def color ( self ) : return self . _color apple = Apple () 这样将给这个类定义个属性，具体调用这个属性就用这样的点号引用即可，然后实际执行的就是 @property 装饰的那个函数。 现在这个color属性只可读，不可更改。 >>> apple.color 'red' >>> apple.color = 'yellow' Traceback (most recent call last): File \"<stdin>\", line 1, in <module> AttributeError: can't set attribute 请参看 这个网页 ，这里讲到了 @color.setter 装饰器，来装饰某个函数之后，通过这个函数来修改color属性。然后还有 @color.deleter 装饰某个函数之后，来通过这个函数来删除某个属性。这里deleter的使用可能较少，一般 @property 就能满足大部分需求了，有的觉得需要修改某个属性则定义setter。 一个简单的setter例子如下所示： class Apple () : def __init__ ( self ) : self . _color = 'red' @property def color ( self ) : return self . _color @color . setter def color ( self , color ) : self . _color = color apple = Apple () print ( apple . color ) apple . color = 'yellow' print ( apple . color ) 描述器 本小节参考了 这个网页 。 上面谈及的属性装饰器，其实际上是调用的property函数， property(fget, fset, fdel, descrition) 而这个函数返回的是一个描述器对象（Desriptor）。那么什么是一个描述器对象呢，简单来说这个对象里面定义了三个方法（最基本的是必须把 __get__ 方法定义了）。 现在让我们把思路再理一下，首先是某个instance.a这个表达，python将视图从 __dict__ 里面去找这个属性，找得到那么一般 instance['a'] 这个表达也是可以获得值的（类的属性继承这里先不涉及），如果 __dict__ 里面没有这个属性，那么python会去找 __getattr__(self,name) 方法，如果找不到那么就会报错。 在上面找属性的过程中，查找描述器的行为是很靠前的。如果找到的属性是一个描述器，那么python会根据这个描述器对象来决定如何提取这个属性，如何修改这个属性等的行为。 然后理解property这个函数返回的是一个怎样的描述器，看下面的python代码等价实现是最直观的了： class Property ( object ) : \"Emulate PyProperty_Type() in Objects/descrobject.c\" def __init__ ( self , fget = None , fset = None , fdel = None , doc = None ) : self . fget = fget self . fset = fset self . fdel = fdel self . __doc__ = doc def __get__ ( self , obj , objtype = None ) : if obj is None : return self if self . fget is None : raise AttributeError , \"unreadable attribute\" return self . fget ( obj ) def __set__ ( self , obj , value ) : if self . fset is None : raise AttributeError , \"can't set attribute\" self . fset ( obj , value ) def __delete__ ( self , obj ) : if self . fdel is None : raise AttributeError , \"can't delete attribute\" self . fdel ( obj ) def getter ( self , fget ) : return type ( self )( fget , self . fset , self . fdel , self . __doc__ ) def setter ( self , fset ) : return type ( self )( self . fget , fset , self . fdel , self . __doc__ ) def deleter ( self , fdel ) : return type ( self )( self . fget , self . fset , fdel , self . __doc__ ) 缓存属性 下面这个例子灵感来自python官方装饰器 @property 的源码，稍作修改使得某个对象的属性具有记忆特性。 import time import logging class memorized_property ( property ): def __init__ ( self , * args , ** kwargs ): super ( memorized_property , self ) . __init__ ( * args , ** kwargs ) self . name = '_{}' . format ( self . fget . __name__ ) def __get__ ( self , obj , objtype = None ): if obj is None : return self if self . fget is None : raise AttributeError ( \"unreadable attribute\" ) if self . name in obj . __dict__ : logging . debug ( 'from memory--------------------' ) return obj . __dict__ [ self . name ] else : logging . debug ( 'from computing##########' ) value = obj . __dict__ [ self . name ] = self . fget ( obj ) return value def __set__ ( self , obj , value ): if self . fset is None : raise AttributeError ( \"can't set attribute\" ) obj . __dict__ [ self . name ] = value def __delete__ ( self , obj ): if self . fdel is None : raise AttributeError ( \"can't delete attribute\" ) del obj . __dict__ [ self . name ] class Test ( object ): def __init__ ( self ): pass @memorized_property def x ( self ): return time . time () @x.setter def x ( self , value ): pass @x.deleter def x ( self ): pass if __name__ == '__main__' : logging . basicConfig ( level = logging . DEBUG ) t = Test () print ( t . x ) print ( t . x ) 函数装饰器 本小节参考了 这个网页 。 前面简单介绍了python的装饰器的概念，然后已经接触了带参数的函数装饰器的概念，之前的例子是为了直白，下面再写个例子表示函数的这种通用形式： def mydecorator(arg1, arg2): def _mydecorator(func): print('i know you pass to decorator parameters:', arg1, arg2) return func return _mydecorator @mydecorator('a', 'b') def test(*args, **kwargs): print(args, kwargs) test('test', a=1) ('i know you pass to decorator parameters:', 'a', 'b') (('test',), {'a': 1}) 上面的这种函数装饰器写法是在理解了装饰器的具体原理之后写出来的这种形式，和网上的这种写法有所区别，其更加简洁明了一点，不过还是推荐和大家使用一致的风格写法吧： def mydecorator(arg1, arg2): def _mydecorator(func): def wraper_func(*args, **kwargs): print('i know you pass to decorator parameters:', arg1, arg2) return func(*args, **kwargs) return wraper_func return _mydecorator @mydecorator('a', 'b') def test(*args, **kwargs): print(args, kwargs) test('test', a=1) 具体运行效果都是一致的，然后我们看到这里用到了函数套函数的结构，从而将装饰器上的一些参数都变为自由变量了，理解这一点是关键。 更进一步的做法是利用functools模块的 wraps 函数来装饰最终实际执行的那个 wraper_func 函数。 from functools import wraps def mydecorator ( arg1 , arg2 ): def _mydecorator ( func ): @wraps ( func ) def wraper_func ( * args , ** kwargs ): print ( 'i know you pass to decorator parameters:' , arg1 , arg2 ) return func ( * args , ** kwargs ) return wraper_func return _mydecorator @mydecorator ( 'a' , 'b' ) def test ( * args , ** kwargs ): \"\"\" this is test function \"\"\" print ( args , kwargs ) test ( 'test' , a = 1 ) print ( test . __doc__ ) 这样做的好处就是目标函数的说明文档还保留着，目标函数的名字也保留着，目标函数的动作也保留着，只是经过装饰器之后需要经过一些额外的程序流程操作。 类作为装饰器 类作为装饰器就是利用类的 __call__ 内置方法，我把这段代码粘贴在下面了，有时可能看别人的源码有用吧，但装饰器这部分就到此为止吧，没必要弄得这么复杂了。 class MyDecorator ( object ) : \"\"\"Decorator example mixing class and function definitions.\"\"\" def __init__ ( self , func , param1 , param2 ) : self . func = func self . param1 , self . param2 = param1 , param2 def __call__ ( self , * args , ** kwargs ) : ... # use self . param1 result = self . func ( * args , ** kwargs ) # use self . param2 return result def my_dec_factory ( param1 , param2 ) : def decorator ( func ) : return MyDecorator ( func , param1 , param2 ) return decorator 类装饰器 前面讲到class声明语句和def语句很类似，def语句是利用缩进区块内的代码（简单理解就是执行编译了一遍，当然应该还有其他处理）构建出一个函数对象，然后将这个函数对象和某个名字绑定起来。class语句也是利用缩进区块内的代码构建出一个类对象，然后将这个类对象和某个名字绑定起来。 那么类装饰器，也就是类上面挂个装饰器，如下所示是什么意思呢： def decorator ( C ) : return ProcessedC @decorator class C : .... 这样我们得到的C是： C = decorator(C) 所以函数装饰器相当于函数对象创建过程的深度定制DIY，而类装饰器就相当于类对象创建过程的深度DIY。 什么是metaclass 所有类都是由元类（type类）创建的，其对应的语句如下： class = type ( classname , superclasses , attributedict ) type实际调用的是自身的 __call__ 方法，这个方法将运行type的两个方法： __new__ ， __call__ 。 这样就创造了一个类了，然后之前我们提到： 类还要调用自身的 __new__ ， __call__ ，这样就创造出一个实例来了。 之前提到type的type也是type，type大体可以看作python中类型的最底层的原子结构吧。元类创造类，然后是类创造实例。 定义一个元类 class Meta ( type ) : def __new__ ( meta , classname , supers , classdict ) : # do something return type . __new__ ( meta , classname , supers , classdict ) 使用一个元类 class Test ( Super , metaclass = Meta ) : pass 元类理解起来并不难，关键是如何把握在合适的时候合适的使用。 python的迭代进阶 在python中一般复杂的代码运算效率就会低一点，如果完成类似的工作但你可以用更简单的语句那么运算效率就会高一点。当然这只是python的一个设计理念，并不尽然，但确实很有意思。 程序结构中最有用的就是多个操作的重复，其中有迭代和递归还有一般的循环语句。递归函式感觉对于某些特殊的问题很有用，然后一般基于数据结构的不是特别复杂的操作重复用迭代语句即可，最后才考虑一般循环语句。 迭代语句中for语句运算效率最低，然后是map函数（不尽然），然后是列表解析。所以我们在处理问题的时候最pythonic的风格，运算效率最高的就是列表解析了，如果一个问题能够用列表解析解决那么就用列表解析解决，因为python的设计者的很多优化工作都是针对迭代操作进行的，然后python3进一步深化了迭代思想，最后python中的迭代是用c语言来实现的（你懂的）。 可是让我们反思一下为什么列表解析在问题处理的时候如此通用？比如说range函数或者文件对象或者列表字符串等等，他们都可以称之为可迭代对象。可迭代对象有内置方法 __next__ 这个我们之前有所谈及，可迭代对象最大的特色就是有一系列的元素，然后这一系列的元素可以通过上面的内置方法逐个调出来，而列表解析就是对这些调出来的元素进行了某个表达式操作，然后将其收集起来。这是什么？我们看下面这张图片： lie-biao-jie-xi 这张图片告诉我们列表解析和数学上所谓的集合还有函数的定义非常的类似，可迭代对象就好像是一个集合（有顺序或者没顺序都行），然后这些集合中的所有元素经过了某个操作，这个操作似乎就是我们数学中定义的函数，然后加上过滤条件，某些元素不参加运算，这样就生成了第二个可迭代对象（一般是列表也可以是字典什么的。） 有一个哲学上的假定，那就是我们的世界一切问题都可以用数学来描述，而一些数学问题都可以用函数即如上的信息操作过滤流来描述之。当然这不尽然，但我们可以看到列表解析在一般问题处理上是很通用的思想。 不过我们看到有限的元素的集合问题适合用迭代，但无限元素的集合问题也许用递归或者循环更适合一些。然后我们又想到集合的描述分为列举描述（有限个元素的列举）和定义描述。比如说1\\<x\\<10，x属于整数，这就定义了一个集合。那么我们就想到python存在这样的通过描述而不是列举（如列表一样）的集合吗？range函数似乎就是为了这样的目的而生的，比如说range(10)就定义了[0,10)这一系列的整数集合，range函数生成一个range对象，range对象是一个可迭代对象，我们可以把它看作可迭代对象中的描述集合类型吧。这时我们就问了，既然0\\<=x\\<10这样的整数集合可以通过描述来实现，那么更加复杂的函数描述可不可以实现呢？我们可不可以建立更加复杂的类似range对象的描述性可迭代对象呢？ map和filter函数 按照之前的迭代模式的描述，虽然使用常见的列表解析格式(for 语句)就可以完成对某个集合中各个元素的操作或者过滤，不过python中还有另外两个函数来实现类似的功能，map对应对集合中各个元素进行某个函数操作（可以接受lambda函式），而filter则实现如上所述的过滤功能。然后值得一提的是python3之后map函数和filter函数返回都是一个可迭代对象而不是列表，和range函数等其他可迭代对象一样可用于列表解析结构。 map函数 这里列出一些例子： >>> map(abs, [-2,-1,0,1,2]) <map object at 0xb707dccc> >>> [x for x in map(abs, [-2,-1,0,1,2])] [2, 1, 0, 1, 2] >>> [x for x in map(lambda x : x+2, [-2,-1,0,1,2])] [0, 1, 2, 3, 4] map函数还可以接受两个可迭代对象的协作参数模式，这个学过lisp语言的会觉得很眼熟，不过这里按照我们的理解也是很便捷的。具体就是第一个可迭代对象取出一个元素作为map的函数的第一个参数，然后第二个可迭代对象取出第二个参数，然后经过函数运算，得到一个结果，这个结果如果不列表解析的话就是一个map对象（可迭代对象），然后展开以此类推。值得一提的是两个可迭代对象的 深度由最短的那个决定 ，请看下面的例子： >>> [x for x in map(lambda x,y : x+y, [-2,-1,0,1,2],[-2,-1,0,1,2])] [-4, -2, 0, 2, 4] >>> [x for x in map(lambda x,y : x+y, [-2,-1,0,1,2],[-2,-1,0,1])] [-4, -2, 0, 2] filter函数 同样和上面的谈及的类似，filter函数过滤一个可迭代对象然后产生一个可迭代对象。类似的功能可以用列表解析的后的if语句来实现。前面谈到map函数的时候提及一般还是优先使用列表解析模式，但filter函数这里有点不同，因为列表解析后面跟个if可能有时会让人困惑，这时推荐还是用filter函数来进行可迭代对象的过滤操作。 filter函数的基本逻辑是只有return True（用lambda表达式就是这个表达式的值为真，具体请参看python的逻辑小知识和布尔值的一些规则 10.1 {reference-type=\"ref\" reference=\"sec:布尔值\"}）的时候元素才被收集起来，或者说是过滤出来。这里强调True是因为如果你的函数没有return值那么默认的是return None，这个时候元素也是不会过滤出来的。 请参看下面的例子来理解： >>> [x for x in filter(lambda x:x&1,[1,2,3,5,9,10,155,-20,-25])] [1, 3, 5, 9, 155, -25] >>> [x for x in filter(lambda x:not x&1,[1,2,3,5,9,10,155,-20,-25])] [2, 10, -20] 当然你也可以传统的编写函数： >>> def even(n): ... if n % 2 ==0: ... return True >>> [x for x in filter(even,[1,2,3,5,9,10,155,-25])] [2, 10] zip函数 这里就顺便把zip函数也一起提了，zip函数同样返回一个可迭代对象，它接受任意数目的可迭代对象，然后逐个取出可迭代对象元素构成一个元组成为自己的一个元素。和map函数类似 迭代深度由最短的那个可迭代对象决定 。 >>> zip(['a','b','c'],[1,2,3,4]) <zip object at 0xb7055e6c> >>> [x for x in zip(['a','b','c'],[1,2,3,4])] [('a', 1), ('b', 2), ('c', 3)] >>> list(zip(['a','b','c'],[1,2,3,4])) [('a', 1), ('b', 2), ('c', 3)] >>> dict(zip(['a','b','c'],[1,2,3,4])) {'c': 3, 'b': 2, 'a': 1} 字典到列表 这个例子似乎使用价值不大，只是说明zip函数接受任意数目参数的情况。y.items()解包之后是4个参数传递给zip函数，而zip函数的封装逻辑就是如果有人问我，我就把你们这些迭代对象每个取出一个元素，然后用元组包装之后返回。 x1 = ['a','b','c','e'] x2 = [1,2,3,4] y = dict(zip(x1,x2)) print('列表到字典：',y) new_x1,new_x2 = zip(*y.items()) print(new_x1,new_x2) 列表到字典： {'b': 2, 'c': 3, 'a': 1, 'e': 4} ('b', 'c', 'a', 'e') (2, 3, 1, 4) 这个例子如果到更加复杂的情况，我们可以跳过字典形式，来个数据映射对： >>> x1 = ['a','b','c','e'] >>> x2 = ['red','yellow','red','blue'] >>> x3 = [1,2,3,4] >>> list(zip(x1,x2,x3)) [('a', 'red', 1), ('b', 'yellow', 2), ('c', 'red', 3), ('e', 'blue', 4)] >>> new_x1,new_x2,new_x3 = zip(*list(zip(x1,x2,x3))) >>> new_x1 ('a', 'b', 'c', 'e') >>> new_x2 ('red', 'yellow', 'red', 'blue') >>> new_x3 (1, 2, 3, 4) 当然对于多属性数据问题一般还是推荐使用类来处理，不过某些情况下可能不需要使用类，就这样简单处理之。 值得一提的是这种数据存储形式和sql存储是一致的，而且不知道你们注意到没有，这似乎实现了矩阵的转置功能。","tags":"python语言","url":"articles/pythonyu-yan-xue-xi-zhi-yi-qie-jie-dui-xiang.html"},{"title":"python语言学习之-类","text":"在python中一切皆对象。前面学的那些操作对象都是python程序语言自己内部定义的对象（Object），而接下来介绍的类的语法除了更好的理解之前的那些对象之外，再就是可以创造自己的操作对象。一般面向对象(OOP)编程的基本概念这里不重复说明了，如有不明请读者自己随便搜索一篇网页阅读下即可。 python中类的结构 python中的类就好像树叶，所有的类就构成了一棵树，而python中超类，子类，实例的重载或继承关系等就是由一种搜索机制实现的： python首先搜索self有没有这个属性或者方法，如果没有，就向上搜索。比如说实例l1没有，就向上搜索C1，C1没有就向上搜索C2或C3等。 实例继承了创造他的类的属性，创造他的类上面可能还有更上层的超类，类似的概念还有子类，表示这个 类在树形层次中比较低。 well，简单来说类的结构和搜索机制就是这样的，很好地模拟了真实世界知识的树形层次结构。 上面那副图实际编写的代码如下： class C2 : ... class C3 : ... class C1 ( C2 , C3 ) : ... l1 = C1 () l2 = C1 () 其中class语句是创造类，而C1继承自C2和C3，这是多重继承，从左到右是内部的搜索顺序（会影响重载）。l1和l2是根据类C1创造的两个实例。 对于初次接触类这个概念的读者并不指望他们马上就弄懂类这个概念，这个概念倒并一定要涉及很多哲学的纯思考的东西，也可以看作一种编程经验或技术的总结。多接触也许对类的学习更重要，而不是纯哲学抽象概念的讨论，毕竟类这个东西创造出来就是为了更好地描述现实世界的。 最后别人编写的很多模块就是一堆类，你就是要根据这些类来根据自己的情况情况编写自己的子类，为了更好地利用前人的成果，或者你的成果更好地让别人快速使用和上手，那么你需要好好掌握类这个工具。 类的最基础知识 类的创建 class MyClass : something 类的创建语法如上所示，然后你需要想一个好一点的类名。类名规范的写法是首字母大写，这样好和其他变量有所区分。 根据类创建实例 按照如下语句格式就根据MyClass类创建了一个实例myclass001。 myclass001=MyClass() 类的属性 >>> class MyClass: ... name='myclass' ... >>> myclass001=MyClass() >>> myclass001.name 'myclass' >>> MyClass.name 'myclass' >>> myclass001.name='myclass001' >>> myclass001.name 'myclass001' >>> MyClass.name 'myclass' 如上代码所示，我们首先创建了一个类，这个类加上了一个name属性，然后创建了一个实例myclass001，然后这个实例和这个类都有了name属性。然后我们通过实例加上点加上name的这种格式引用了这个实例的name属性，并将其值做了修改。 这个例子简单演示了类的创建，属性添加，实例创建，多态等核心概念。后面类的继承等概念都和这些大同小异了。 类的方法 类的方法就是类似上面类的属性一样加上def语句来定义一个函数，只是函数在类里面我们一般称之为方法。这里演示一个例子，读者看一下就明白了。 >>> class MyClass: ... name='myclass' ... def double(self): ... self.name=self.name*2 ... print(self.name) ... >>> myclass001=MyClass() >>> myclass001.name 'myclass' >>> myclass001.double() myclassmyclass >>> myclass001.name 'myclassmyclass' 这里需要说明的是在类的定义结构里面，self代表着类自身（更多self意义细节请参看 12.4.2 {reference-type=\"ref\" reference=\"sec:self含义\"}），self.name代表着对自身name属性的引用。然后实例在调用自身的这个方法时用的是myclass001.double()这样的结构，这里double函数实际上接受的第一个参数就是自身，也就是myclass001，而不是无参数函数。所以类里面的方法有一个参数self。 类的继承 实例虽然说是根据类创建出来的，但实际上实例和类也是一种继承关系，实例继承自类，而类和类的继承关系也与之类似，只是语法稍有不同。下面我们来看这个例子： class Hero () : def addlevel ( self ) : self . level = self . level + 1 self . hp = self . hp + self . addhp class Garen ( Hero ) : level = 1 hp = 455 addhp = 96 garen001 = Garen () for i in range ( 6 ) : print ( '级别:' , garen001 . level , '生命值：' , garen001 . hp ) garen001 . addlevel () 级别 : 1 生命值： 455 级别 : 2 生命值： 551 级别 : 3 生命值： 647 级别 : 4 生命值： 743 级别 : 5 生命值： 839 级别 : 6 生命值： 935 lei-de-ji-cheng-shi-li 这里就简单的两个类，盖伦Garen类是继承自Hero类的，实例garen001是继承自Garen类的，这样garen001也有了addlevel方法，就是将自己的level属性加一，同时hp生命值也加上一定的值，整个过程还是很直观的。 类的内置方法 如果构建一个类，就只是简单的加上pass语句，什么都不做，python还是会为这个类自动创建一些属性或者方法。 >>> class TestClass: ... pass ... >>> dir(TestClass) ['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__'] 这些变量名字前后都加上双下划线是给python这个语言的设计者用的，一般开发者还是不要这样命名变量。 这些内置方法用户同样也是可以重定义他们从来覆盖掉原来的定义，其中特别值得一讲的就是 __init__ 方法或者称之为构造函数。 __init__方法 __init__ 方法对应的就是该类创建实例的时候的构造函数。比如： >>> class Point: ... def __init__(self,x,y): ... self.x=x ... self.y=y ... >>> point001=Point(5,4) >>> point001.x 5 >>> point001.y 4 这个例子重载了 __init__ 函数，然后让他接受三个参数，self是等下要创建的实例，x，还有y通过下面的语句给这个待创建的实例的属性x和y赋了值。 self意味着什么 self在类中是一个很重要的概念，当类的结构层次较简单时还容易看出来， 当类的层次结构很复杂之后，你可能会弄糊涂。。比如你现在通过调用某个实例的某个方法，这个方法可能是一个远在天边的某个类给出的定义，就算如此，那个定义里面的self还是指调用这个方法的那个实例，这一点要牢记于心。 比如下面这个例子： class Test () : x = 5 def __init__ ( self ) : self . x = 10 test = Test () >>> test . x 10 >>> Test . x 5 其中self.x就是对应的创建的实例的属性x，而前面定义的x则是类Test的属性x。 类的操作第二版 现在我们可以写出和之前那个版本相比更加专业的类的使用版本了。 class Hero () : def addlevel ( self ) : self . level = self . level + 1 self . hp = self . hp + self . addhp class Garen ( Hero ) : def __init__ ( self ) : self . level = 1 self . hp = 455 self . addhp = 96 self . skill = [ '不屈' , '致命打击' , '勇气' , '审判' , '德玛西亚正义' ] garen001 = Garen () for i in range ( 6 ) : print ( '级别:' , garen001 . level , '生命值：' , garen001 . hp ) garen001 . addlevel () print ( '盖伦的技能有：' , \"\" . join ([ x + ' ' for x in garen001 . skill ])) 级别 : 1 生命值： 455 级别 : 2 生命值： 551 级别 : 3 生命值： 647 级别 : 4 生命值： 743 级别 : 5 生命值： 839 级别 : 6 生命值： 935 盖伦的技能有： 不屈 致命打击 勇气 审判 德玛西亚正义 似乎专业的做法类里面多放点方法，最好不要放属性，不太清楚是什么。但确实这样写给人感觉更干净点，方法是方法，如果没有调用代码就放在那里我们不用管它，后面用了构造函数我们就去查看相关类的构造方法，这样很省精力。 类的操作第三版 class Unit () : def __init__ ( self , hp , atk , color ) : self . hp = hp self . atk = atk self . color = color def __str__ ( self ) : return '生命值：{0}，攻击力：{1}，颜色：\\ {2}' . format ( self . hp , self . atk , self . color ) class Hero ( Unit ) : def __init__ ( self , level , hp , atk , color ) : Unit . __init__ ( self , hp , atk , color ) self . level = level def __str__ ( self ) : return '级别：{0},生命值：{1}，攻击力：{2}，\\ 颜色：{3}' . format ( self . level , self . hp , self . atk , self . color ) def addlevel ( self ) : self . level = self . level + 1 self . hp = self . hp + self . addhp self . atk = self . atk + self . addatk class Garen ( Hero ) : def __init__ ( self , color = 'blue' ) : Hero . __init__ ( self , 1 , 455 , 56 , color ) self . name = '盖伦' self . addhp = 96 self . addatk = 3.5 self . skill = [ '不屈' , '致命打击' , '勇气' , '审判' , '德玛西亚正义' ] if __name__ == '__main__' : garen001 = Garen ( 'red' ) garen002 = Garen () print ( garen001 ) unit001 = Unit ( 1000 , 1000 , 'gray' ) print ( unit001 ) for i in range ( 6 ) : print ( garen001 ) garen001 . addlevel () print ( '盖伦的技能有：' , \"\" . join ([ x + ' ' for x in garen001 . skill ])) 级别： 1 , 生命值： 455 ，攻击力： 56 ， 颜色： red 生命值： 1000 ，攻击力： 1000 ，颜色： gray 级别： 1 , 生命值： 455 ，攻击力： 56 ， 颜色： red 级别： 2 , 生命值： 551 ，攻击力： 59.5 ， 颜色： red 级别： 3 , 生命值： 647 ，攻击力： 63.0 ， 颜色： red 级别： 4 , 生命值： 743 ，攻击力： 66.5 ， 颜色： red 级别： 5 , 生命值： 839 ，攻击力： 70.0 ， 颜色： red 级别： 6 , 生命值： 935 ，攻击力： 73.5 ， 颜色： red 盖伦的技能有： 不屈 致命打击 勇气 审判 德玛西亚正义 现在就这个例子相对于第二版所作的改动，也就是核心知识点说明之。其中函数参量列表中这样表述 color='blue' 表示blue是color变量的备选值，也就是color成了可选参量了。 构造函数的继承和重载 上面例子很核心的一个概念就是 __init__ 构造函数的继承和重载。比如我们看到garen001实例的创建，其中就引用了Hero的构造函数，特别强调的是， 比如这里\\ Hero.__init__(self,1,455,56,color) 就是调用了Hero类的构造函数，这个时候需要把self写上，因为self就是最终创建的实例garen001，而不是Hero，而且调用Hero类的构造函数就必须按照它的参量列表形式来。这个概念需要弄清楚！ 理解了这一点，在类的继承关系中的构造函数的继承和重载就好看了。比如这里Hero类的构造函数又是继承自Unit类的构造函数，Hero类额外有一个参量level接下来也要开辟存储空间配置好。 __str__函数的继承和重载 第二个修改是这里重定义了一些类的 __str__ 函数，通过重新定义它可以改变默认print某个类对象是的输出。默认只是一段什么什么类并无具体内容信息。具体就是return一段你想要的字符串样式即可。","tags":"python语言","url":"articles/pythonyu-yan-xue-xi-zhi-lei.html"},{"title":"click模块","text":"简介 click模块是一个类似getopt和argparse的python第三方模块，在简单了解之后，觉得其简直就是python快速创建命令行工具的类似requests之于urllib的存在，writed human-friendly。click的官方文档在 这里 ，下面就让我们来学习这么好的一个模块吧。 官方文档的第一个例子如下: import click @click.command () @click.option ( '--count' , default = 1 , help = 'Number of greetings.' ) @click.option ( '--name' , prompt = 'Your name' , help = 'The person to greet.' ) def hello ( count , name ): \"\"\"Simple program that greets NAME for a total of COUNT times.\"\"\" for x in range ( count ): click . echo ( 'Hello %s !' % name ) if __name__ == '__main__' : hello () 我们看到一切都是很直观明了的， @click.command() 用来装饰一个函数，然后用 @click.option 来具体添加命令行选项。其中第一个就是命令行选项的名字，然后 help ， default 的意义我们是清楚的（类似的还有 type 来控制数据类型）。然后我们注意到某个选项比如上面的name是可以请求输入来获得值的。然后我们可以用 click.echo 来进行打印操作（不是print函数是为了获得更好的python2和3的兼容性，这个是随意的，直接用print函数也是可以的）。 具体脚本运行情况如下所示: wanze@wanze-ubuntu:~/桌面$ python3 test2.py --help Usage: test2.py [OPTIONS] Simple program that greets NAME for a total of COUNT times. Options: --count INTEGER Number of greetings. --name TEXT The person to greet. --help Show this message and exit. 我们看到该函数的 __doc__ 说明文档就直接成了该命令行的描述性文档了。 更棒的是其 prompt 机制和具体命令行输入参数是兼容的: wanze@wanze-ubuntu:~/桌面$ python3 test2.py --count=3 --name=wanze Hello wanze! Hello wanze! Hello wanze! 必填参数，文件操作和如何测试 必填参数用 @click.argument() 来装饰添加之，如下所示: import click @click.command () @click.argument ( 'input' , type = click . File ( 'rb' )) @click.argument ( 'output' , type = click . File ( 'wb' )) def inout ( input , output ): while True : chunk = input . read ( 1024 ) if not chunk : break output . write ( chunk ) if __name__ == '__main__' : inout () 这里的 click.File() 接受一个文件名，然后就已经打开了，在函数里面直接作为一个文件对象可以使用了。文件就推荐使用click模块的这个类型来处理，其对Unicode和bytes处理较好，并有其他优化。当然你也可以使用 click.Path 类型，其在函数里面相当于一个优化的Path文件名，同样提供了Unicode和bytes兼容支持等。 @click.command () @click.argument ( 'f' , type = click . Path ( exists = True )) def touch ( f ): click . echo ( click . format_filename ( f )) 在上面的例子中我们看到脚本最后那里写上: if __name__ == '__main__': inout() 脚本就可以正常测试了: bash>>> python3 test5.py test.py output.txt 但是更好的做法是用测试式开发风格: import click from click.testing import CliRunner def test_inout (): @click.command () @click.argument ( 'input' , type = click . File ( 'rb' )) @click.argument ( 'output' , type = click . File ( 'wb' )) def inout ( input , output ): while True : chunk = input . read ( 1024 ) if not chunk : break output . write ( chunk ) runner = CliRunner () with runner . isolated_filesystem (): string = 'Hello World!' with open ( 'hello.txt' , 'w' ) as f : f . write ( string ) result = runner . invoke ( inout , [ 'hello.txt' , 'hello2.txt' ]) assert result . exit_code == 0 with open ( 'hello2.txt' , 'r' ) as f : s = f . read () assert s == string if __name__ == '__main__' : test_inout () 具体是新建一个 CliRunner 对象，然后调用其 invoke 方法来具体执行某个命令，然后的 Result 对象有 exit_code 和 output 等属性。其中 result.output 一般为屏幕回显的文字。 然后我们看到上面的runner调用了 isolated_filesystem() 方法，通过暂停程序我们会发现这样在 /tmp 文件夹里面会出现一个临时文件夹，然后一切文件操作都在里面进行，完了就会被删除。 标准输入和标准输出 值得一提的是标准输入和标准输出可以用 '-' 简单表示。比如上面的例子: bash>>> python3 test4.py - output.txt test test bash>>> python3 test4.py test.py - 标准输入的那个例子你需要按下 Ctrl-D 来结束文件流。 分组和多个子命令 click模块在分组和建立多个子命令功能上也设计得很简洁: import click @click.group () def cli (): pass @cli.command () def initdb (): click . echo ( 'Initialized the database' ) @cli.command () def dropdb (): click . echo ( 'Dropped the database' ) if __name__ == '__main__' : cli () 通过 @click.group 来定义某个命令组，然后通过这个命令组函数的command方法 @cli.command() 来添加某个子命令。 命令行选项详解 click模块必填参数通过 argument() 引入，然后可选参数通过 option() 引入，这里值得一提的是这两个函数的参数并不完全一样，比如说option可以跟 prompt 来做到当该可选参数没有输入的时候，则请求输入；但argument并无此概念。更多细节请参看下面的请求输入一小节。 default 设置默认值，显然argument必填参数无此概念。 type 控制数据类型，这个都有。 接受多个输入 nargs 如果设置为大于等于1的值，则命令行中要刷入这么多值，这个和argparse模块类似，不同的是不定量的多个值的情况是 nargs=-1 ，相当于内置模块argparse的 * 。然后对应argparse的 + 也就是必须要有一个以上的值的情况，则需要额外加上 required=True 来控制。 count 这个是option有，在某种情景下可能很有用。 @click.command() @click.option('-v', '--verbose', count=True) def log(verbose): click.echo('Verbosity: %s' % verbose) $ log -vvv Verbosity: 3 布尔值 如果默认 default=True 这样设置了，那么默认就是存储的布尔值了，其实际上暗含加上了 is_flag=True 。所以如果没有设置default，则可以通过 is_flag 来控制具体存储的是布尔值。 短名选项和长名选项和布尔值 import sys @click.command () @click.option ( '--shout/--no-shout' , ' /-S' , default = False ) def info ( shout ): rv = sys . platform if shout : rv = rv . upper () + '!!!!111' click . echo ( rv ) bash >>> python3 test . py linux bash >>> python3 test . py -- shout LINUX !!!! 111 bash >>> python3 test . py - S linux 也就是通过上面的这种 / 分割语句来创建这种多个flag的布尔值控制，其中 / 左边是True，右边是False，然后短名选项跟着写入就是了。 注意 上面例子短名情况前面的空格是不可少的。 多个choice选项的用法 @click.command () @click.option ( '--hash-type' , type = click . Choice ([ 'md5' , 'sha1' ])) def digest ( hash_type ): click . echo ( hash_type ) 请求输入prompt控制 这个只是option才有的概念。最简单的情况如下所示: @click.command () @click.option ( '--name' , prompt = 'Your name please' ) def hello ( name ): click . echo ( 'Hello %s !' % name ) 弹出提示只有在你没有输入 --name= 给出值时才会出来。 请求输入密码 如下所示: @click.command () @click.option ( '--password' , prompt = True , hide_input = True , confirmation_prompt = True ) def encrypt ( password ): click . echo ( 'Encrypting password to %s ' % password . encode ( 'rot13' )) 也就是额外加上了两个选项控制: hide_input=True 和 confirmation_prompt=True 。上面的这种组合可以简单写为: @click.command () @click.password_option () def encrypt ( password ): click . echo ( 'Encrypting password to %s ' % password . encode ( 'rot13' )) 请求的默认值控制 请求prompt是可以通过 default 来设置默认值的，在那种情况下你直接按下Enter就相当于输入默认值了。然后你还可以如下来获取系统环境下的某个值作为默认值。 @click.command () @click.option ( '--username' , prompt = True , default = lambda : os . environ . get ( 'USER' , '' )) def hello ( username ): print ( \"Hello,\" , username ) 此外click模块还提供了如下的prompt快捷请求输入命令。 value = click.prompt('Please enter a valid integer', type=int) 还有如下的 confirm 函数也很有用: if click.confirm('Do you want to continue?'): click.echo('Well done!') 全局环境变量控制 命令行选项控制其他动作 如下所示，通过 is_eager=True 来让该选项优先级高于其他选项。然后 expose_value=False 意思是如果没有输入这个选项，则不影响原命令的执行流。然后 callback 就是具体要跳转到的那个函数上。 def print_version ( ctx , param , value ): if not value or ctx . resilient_parsing : return click . echo ( 'Version 1.0' ) ctx . exit () @click.command () @click.option ( '--version' , is_flag = True , callback = print_version , expose_value = False , is_eager = True ) def hello (): click . echo ( 'Hello World!' ) 这里最关键性的问题是理解 ctx param 和 value 这几个参数。 带颜色的终端回显 click借助python模块 colorama 的力量有在终端显示带颜色的字体的功能，首先确认按照了 colorama : pip install colorama 简单的使用就是: import click click . secho ( 'Hello World!' , fg = 'green' ) click . secho ( 'Some more text' , bg = 'white' , fg = 'black' ) click . secho ( 'ATTENTION' , blink = True , bold = True ) 其中fg是前景颜色，也可以说字体颜色吧，颜色选项有: Fore : BLACK , RED , GREEN , YELLOW , BLUE , MAGENTA , CYAN , WHITE . 然后bg是背景颜色: Back : BLACK , RED , GREEN , YELLOW , BLUE , MAGENTA , CYAN , WHITE . 然后还有其他一些style: dim=True bold=True blink=True underline=True reverse=True 其中dim是淡化，bold是加粗，blink意思应该是闪烁，但是没看到效果。underline是下划线，reverse是前景色和背景色翻转。","tags":"python好伙伴","url":"articles/click-module.html"},{"title":"emacs学习笔记","text":"其实在你打开emacs开始输入文本的那一刻起，你就已经入门了。emacs说到底只是一个功能特别强大的文本编辑器，它主要的角色还是文本编辑器，一切都是围绕这个来展开的。 最基本的快捷键操作 快捷键用的最多的是C和M这两个字母，其中C是Control键，而M一般是Alt键吧。然后 C-w 表示同时按下Control键和w字母。然后 C-x C-c 中间有个空格，表示先按Ctrl+字母x，再停顿一下，然后再按Ctrl+字母c——这是退出emacs的命令。 S表示Shift键，小写s表示Super键这个了解下，然后 C-x 0 表示关闭当前窗口， C-x 1 表示只留当前一个窗口， C-x 2 表示下面新开一个窗口， C-x 3 表示右边新开一个窗口， M+x 执行emacs lisp的内部命令， C-g 取消你在minibuff中一般的输入，这些都是很基本的了，读者请记住。 查找和替换 查找和替换操作经常用到，所以快捷键最好也记住。向后查找的按键是 C-s ，你看快捷键这么简短，就说明这是一个很重要的快捷键。然后向前查找是 C-r 。继续向前或向后查找就是继续按 C-s 和 C-r 。 替换操作的按键是 M-% ,先要输入匹配的字符串，然后输入要替换成为什么，然后接下来 按键 y 表示替换，按键 n 表示不替换，按键 ! 表示全部替换。 lisp语法简介 在进入接下来的讨论之前，先简单介绍下lisp的语法，这里不是要让读者学会lisp语言了，而是为了让你对接下来要接触的最基本的emacs lisp语法不会感到恐惧。 以下例子读者如果有兴趣可以进入elisp的交互环境试验一下，具体按键是： M-x ielm lisp语言的一大特色就是里面的程序和数据都是列表，如 '(1, 2, 3) 这样的形式。 这个引号很关键，因为你输入给lisp的字符串都会被eval一次，然后前面加个引号，那么里面的东西eval一次之后就成(1, 2, 3)这样的形式了（即去掉引号），也就是列表数据了。 那么下面这个是什么呢？ x 'x 上面的x如果被送入eval的话，将会发生寻址操作，也就是成变量了；而第二个x加上引号，eval之后，去掉引号，就是x这样的形式了，我们可以把这个x看作字符串，当然如果我们要将其送入eval，那么你可以认为这个x字符串又变成变量了。 然后lisp中程序的结构就是一系列和数学结构类似的括号，学过数学括号结构的都知道，先算里面的再算外面的…….，直到最终算成这样的形式 (+ 1 1) lisp实际上也是类似的这样运算的，上面的(+ 1 1)送入lisp运算就会得到2。lisp处理这样的结构有一个原则，总认为这样的括号的第一个元素是一个函数，如果不是，将会发生错误。然后后面的东西都是一系列管他什么的参数。 然后再来讲讲设置变量和定义函数。 设置变量 设置变量有两个方法，一般为了方便使用的是setq吧。 (set 'x 1) (setq x 1) set和setq的区别就在那个引号，setq不需要加上那个引号，第一个元素的字符形式总被视作变量。 定义函数 最简单的形式如下所示： (defun add (x y) (+ x y)) 这样你就定义了一个add函数，然后(add x y)实际上就是执行的是(+ x y )。 最简单的lisp语法简介就是这么多了，后面还会接触一些，当然要深入起来里面内容还很丰富的，但目前已经够我们继续探索下去了。 最基本的配置 首先是利用emacs的菜单来选择主题和其他相关配置，然后把你的设置保存好。这个我需要吐槽一下了，为什么emacs24了都还没有一个汉化方案，几个菜单汉化工作有那么难吗？就不能照顾一下新手啊。 好了进入主文件夹的.emacs文件 1 ，如果不出意外的读者已经会看到一个关于 custom-set-variables 的一些配置，读者用Enter键将其推到最下面吧，这些配置就放在那里，其内记录着你刚才的主题配置还有开始不要打开向导界面等等，最好还是留着。 加入smex插件 本文档不会讨论其他的插件了，但这个smex插件真的非常有用，就在这里作为emacs插件安装的一般例子在这里说明了。你以后自己编写的插件其实就是一个el文件，其内其实就是一些elisp语言的代码，等你熟悉elisp语法了，编写自己的插件还是很简单的事了的。 smex的官方github站在 这里 ,不过看了我下面的介绍大致也差不多了。 首先当然是git clone下来，很小的一个文件，就单独下载那个smex.el文件也是可以的，然后你将这个文件放在一个你喜欢的地方上，我放在\"~/工作空间/emacs/\"里面的。 然后在.emacs文件中加入如下代码： ;smex插件设置 ;加入新的搜索路径 ( add-to-list 'load-path \"~/工作空间/emacs/smex\" ) ( require 'smex ) ;加载某个模块 ( global-set-key ( kbd \"M-x\" ) 'smex ) ( global-set-key ( kbd \"M-X\" ) 'smex-major-mode-commands ) ;; This is your old M-x. ( global-set-key ( kbd \"C-c C-c M-x\" ) 'execute-extended-command ) 下面详细讲解之。 add-to-list 是一个函数，其接受一个列表变量，然后将后面的一个元素加入该列表中。 请看下面的例子，其中 nil 是一个空列表的意思： ELISP> (set 'x nil) nil ELISP> x nil ELISP> (add-to-list 'x 1) (1) ELISP> (add-to-list 'x 2) (2 1) ELISP> (add-to-list 'x 3) (3 2 1) 这里的 load-path 变量放着的就是emacs加载插件时的搜索路径，这里把一个新的smex插件所在的路径加进来了，注意路径的下面就应该放着目标el文件。 以后你要加载新的插件\"what\"，大致也是类似的配置语句： (add-to-list 'load-path \"~/工作空间/emacs/what\") 把what.el放入emacs文件夹里的what文件夹里面即可。 然后接下来就是实际的加载这个插件了： (require 'smex);加载某个模块 require 函数后面跟着插件的名字，对应的就是那个smex.el文件。 自定义按键配置 接下来是进一步的按键配置： (global-set-key (kbd \"M-x\") 'smex) (global-set-key (kbd \"M-X\") 'smex-major-mode-commands) ;; This is your old M-x. (global-set-key (kbd \"C-c C-c M-x\") 'execute-extended-command) 这种自定义按键配置方式以后我们可以用来随意的配置后面学到的命令。 global-set-key 函数后面跟着 kbd 函数对按键字符的封装，可以把第一个元素看作具体的按键，第二个元素看作具体调用的命令。 这里第一个命令的意思是，如果你按下了Alt+x按键，那么将会触发smex命令。然后之前谈及Alt+x对应的命令实际上就是 execute-extended-command ，而经过这样的配置之后，以后就需要通过这么复杂的按键才能激活了，等于打入冷宫了。 基本使用说明 那么smex插件具体有什么用处了，现在我们重新打开emacs，然后按下M-x，这个时候我们会看到很多选项，这正是smex插件的功能，跟输入法一样基本，所以很有用的。 基本的使用就是输入你想要的命令前面几个字母，smex会给出提示，然后你按下Tab键即可自动补全，然后smex跟输入法一样会记录你的操作习惯。然后就是enter直接输入第一个候选项，方向键向右将第二个候选项变为第一个候选项等等，方向键向左反之，方向键上下使用来切换历史记录的。 基本使用说明就这么多，smex使用久了，会跟输入法一样使得你输入某些命令速度会非常的快，当然你也可以选择自定义按键配置来绑定新的按键。 一些命令一览 set-default-font: 设置默认字体 set-frame-attribute: 设置默认字体大小 以上两个命令一般放入.emacs文件中，如下配置成为全局配置。 (set-default-font \"DejaVu Sans Mono\");设置默认字体 (set-frame-attribute 'default nil :height 110);设置默认字体大小11pt toggle-frame-maximized: 窗口最大化 你可以将其加入.emacs文件让你的emacs一打开就窗口最大化。 注意本命令只适用于emacs24.4+的版本。 (toggle-frame-maximized) 如果是emacs24.4之前的版本你想启动之后就窗口最大化，参考 这个网站 ，在你的emacs初始化脚本上加上这么一句即可： ( add-to-list 'default-frame-alist ' ( fullscreen . maximized )) global-linum-mode: 左侧显示行号 如下加入.emacs文件中你可以让你的emacs左侧永远显示行号，参考了 这个网页 。 (global-linum-mode t) global-visual-line-mode: 显示的段落自动换行 如下加入.emacs文件中你可以让你的emacs显示的文件段落会自动换行。 (global-visual-line-mode t) help-with-tutorial: 默认按键\"C-h t\"，打开新手教程 describe-key: 默认按键是\"C-h k\"，描述某个按键 describe-function: 默认按键\"C-h f\"， 描述某个函数 describe-variable: 默认按键\"C-h v\"，描述某个变量 通过以上三个函数你能够学习到emacs lisp的很多内部知识，是一条不错的获取信息的来源 2 。 比如之前的\"C-x 1\"等等按键对应的命令如下： delete-other-windows: 默认按键\"C-x 1\"，关闭其他窗口 split-window-below: 默认按键\"C-x 2\"，下面新开一个窗口 split-window-right: 默认按键\"C-x 3\"，右边新开一个窗口 delete-window: 默认按键\"C-x 0\"，删除当前窗口 emacs lisp还有很多很多内容，学习到后面当然是参看手册了。 DIY之门 下面这几个命令也很常用，我们可以将其定义为更加简短一点的命令 kill-buffer: 默认按键\"C-x k\"，关闭当前buffer。 switch-to-buffer: 默认按键\"C-x b\"，切换buffer。 find-file: 默认按键\"C-x C-f\"，打开文件 save-buffer: 默认按键\"C-x C-s\"，保存某个buffer，或者说通常意义上的保存文件。 save-some-buffers: 默认按键\"C-x s\"，保存所有buffer，或者说保存所有文件。 save-buffers-kill-terminal: 默认按键\"C-x C-c\"，退出emacs。 你可以通过defun来定义新的函数，这里采用一种简单的机制defalias来给原函数取一个新的名字： (defalias 'open 'find-file) (defalias 'save 'save-buffer) (defalias 'saveall 'save-some-buffers) (defalias 'kill 'kill-buffer) (defalias 'buffer 'switch-to-buffer) 然后我们再进入emacs，我们发现smex里面多了一个open命令，之前没有的，然后原有的find-file命令也还在。 初步的试验已经有那么一点意思了，当然接下来所谓的DIY之门，就是编写自己的插件，这其中很大一部分就是编写自己的函数。elisp语言还有很多内容，不过本章节就此结束了。 术语 基本术语 frame: emacs的图形界面或终端界面 menu: frame上方的菜单栏 tool: 菜单栏下面的工具栏 echo: 主编辑窗口下面的响应信息，minibuffer也在这里显示。 window: tool下面echo上面的主区域就是window区域，emacs可以分出很多个window出来，任何时候指的window是当前选中的那个window，同样emacs可以有很多buffer，当前选中的window对应的buffer为current buffer。 buffer: 每一个window具体编辑的就是一个buffer scroll bar: window的一边有一个scroll bar mode line: window的下面有一行mode line 格式如下: cs:ch-fr buf pos line (major minor) point: 当前window下cursor的位置叫做point，具体emacs光标或覆盖在frob的o上，那么point的位置是在r和o之间。 按键术语 按键 a B SPC（空格） RET（回车） TAB DEL ESC F1 HOME LEFT 组合按键 Control (usually labeled Ctrl), and META (usually labeled Alt) C-a 表示同时按下Control和a ，M-a 表示同时按下Alt和a。 多个按键组合 C-x C-f 表示key sequence ，顺序按下如此键组合。 光标移动 按 C-n 移动到下一列，实际执行命令 (next-line) C-f (forward-char) M-f (forward-word) C-b (backward-char) M-b (backward-word) C-p (previous-line) C-a (move-beginning-of-line) C-e (move-end-of-line) C-x C-s (save-buffer) C-x C-f (find-file) C-x u undo 按 F10 执行menu-bar-open命令，然后图形界面可以键盘方向键选定，终端界面可以上下移动辅以文字选定。 按 C-g 退出minibuffer 按 C-x C-c 退出Emacs (save-buffers-kill-terminal) 按 C-k (kill-line) 删除本行 tab都自动换成space 参考网页： NoTabs 在.emacs文件里加入如下代码： (setq-default indent-tabs-mode nil) 80列规则 控制你的代码不超过80列是一个非常好的习惯，不仅可以起到控制自己写出缩进过于复杂的代码的冲动，而且这样写出来的代码直接复制粘贴就能很好地在网页或pdf文档上显示。 下面是具体的配置文件： ( add-to-list 'load-path \"~/工作空间/myemacs/fill-column-indicator\" ) ( require 'fill-column-indicator ) ( define-globalized-minor-mode global-fci-mode fci-mode ( lambda () ( fci-mode 1 ))) ( global-fci-mode t ) ( setq fci-rule-column 80 ) ( setq fci-rule-color \"light green\" ) 该宏包的github地址在 这里 ，该宏包的emacswiki地址在 这里 。上面代码第五行是设置列宽80，然后第六行是设置竖线颜色。 第三行第四行这样配置之后所有的模式下都会显示竖线，这个看各人的作业文档主要是什么了，如果主要是python脚本等编程语言，那么这样设置也没什么不妥的。如果你的作业文档主要是非编程语言或者有时是org模式之类的，推荐还是如下单独设置。 ( add-hook 'c-mode-hook 'fci-mode ) ( add-hook 'c++-mode-hook 'fci-mode ) ( add-hook 'python-mode-hook 'fci-mode ) ( add-hook 'emacs-lisp-mode-hook 'fci-mode ) python模式 python模式推荐还是使用 python-mode 宏包而不是内置的 python.el 。宏包的下载在 这里 ，如下简单设置之后使用 C-c C-c 就运行该python文件并进入交互模式，很是方便。这次默认的就是python3，我很满意了。我不清楚是不是我的python文件第一行总是有 #!/usr/bin/env python3 所以python-mode.el猜到了，还是只是现在就是简单的默认是调用python3了。如果你需要设置将其设置为python2，该宏包的github地址在 这里 ，然后再结合网络搜索找寻答案吧。 ( add-to-list 'load-path \"~/工作空间/myemacs/python-mode\" ) ;加入新的搜索路径 ( require 'python-mode ) 分窗口控制 参考了 这个网页 ，如果你希望在运行 C-c C-c 之后，弹出的窗口是左右平行的模式，而不是上下模式，可以如下设置: ( setq-default py-split-windows-on-execute-function 'split-window-horizontally ) 这样具体效果如下图所示: 快速删除一行 快捷键是 C-k ，对应的命令是 org-kill-line 。emacs中的kill概念还不太熟悉，不过从表面来看效果就是从当前光标位置直到行尾的字符都将被删除，这通常很有用。 然后所谓 kill 的字符串 可以通过 C-y 召回了。 快速启动emacs 先用 emacs --daemon 命令启动一个后台服务器，这个命令可以考虑加入.bashrc文件中每次启动自动运行一次。 然后把系统的desktop文件（你可以在 /usr/share/applications 那里找到它，你也可以在用户主文件夹的 .local/share/applications 那里再另外新建一个。 ）修改一下: Exec=/usr/bin/emacsclient -c -a \"\" %F 本来是 emacs %F ，改为emacsclient，这里的 -c 参数是启动图形界面。然后-a参数设置为空字符串，这样即使你前面没有建立一个emacs后台服务器，其也会自动创建一个。这样你双击对应emacs关联的文件就自动快速用emacsclient打开了。读者可以尝试一下，这样emacs打开文件确实很快了，但也带来了一些问题。 关闭frame和以前的不同了 emacs daemon是一个后台进程，你可以用 ps aux |grep emacs 来查看一下，哪怕你把所有的emacsclient建立的frame窗口都关闭了，emacs的后台daemon仍然存在。 然后就是emacsclient编辑一个文件之后，不管你保存了没有没有任何提示就直接关闭了，这其实没什么，因为你用emacsclient打开的所有buffer都还是在的，所以你的编辑内容并没有丢失，但这很不符合用户的习惯。 首先通过查看进程号然后kill相应的emacs daemon进程的做法最好不要用，在emacs里面可以输入命令 kill-emacs 来关闭emacs的后台服务进程，这个方法最好也不要用。总之手工kill emacs后台服务进程这个操作最好不要使用，如果你需要调试，就用以前的 emacs test.org 方式来启动另外一个完成的meacs进程来进行调试。 然后如果你觉得接下来应该不需要使用emacs了，那么正确关闭emacs做法是使用快捷键 C-x C-c ，其对应的函数是 save-buffers-kill-terminal ，这个快捷键以前我已经接触过了，在一个完整emacs进程中，其就是退出emacs命令，其将确保所有的buffer都保存了，然后退出。值得一提的是这个函数并没有关闭emacs后台服务进程，实际上在熟悉emacsclient操作之后，最好不要去管emacs daemon这个概念，就认为这个 C-x C-c 就是正常退出emacs的命令即可。 最后是关闭buffer操作，如果你只是简单点击窗口的关闭图标，那么只是关闭frame，buffer还是在那里。如果你编辑完了想要关闭这个buffer，那么执行 kill-buffer 即可，文档没有保存其会提示你的，并且最后还会提示你是否关闭本frame。 字体问题 因为emacs daemon在启动的时候是没有图形界面的，所以之前的字体设置失效了，你需要如下设置 3 : ;; 解决client模式下的字体问题 ( defun myfontset () ( interactive ) ( set-default-font \"DejaVu Sans Mono\" ) ;设置默认字体 ( set-face-attribute 'default nil :height 110 ) ;设置默认字体大小11pt ) ( add-hook 'after-make-frame-functions ( lambda ( frame ) ( select-frame frame ) ; ( myfontset ))) 这里的思路就是等frame加载完成之后再加载之前的那些字体配置。 左侧文件树面板 一般现代IDE最大的一个特色就是左侧有一个文件树面板，方便快速切换文件，这个emacs下的neotree宏包可以实现类似的功能。该项目的github地址在 这里 。 具体使用很简单，就是常规的加载: (add-to-list 'load-path \"/some/path/neotree\") (require 'neotree) (global-set-key [f8] 'neotree-toggle) 这样你就可以按下F8来快速切换到文件树面板了。 pdf文件打开卡住问题 emacs的docview功能可以直接看pdf文件，这有时会带来很大的便利，不过现在打开pdf文件有点卡，这可以通过将 doc-view-continuous 设置为nil来稍微缓和一下。 (custom-set-variables '(doc-view-continuous nil) ) 可能的其他问题 neotree这个项目看得出来还有很多地方可以进一步完善，比如说emacsclient模式下似乎根目录读取有问题。 多个窗口之间的编号切换 window-numbering这个宏包不错，其github项目地址在 这里 。该宏包实现了对各个窗口进行编号，使得你通过按 M-1 之类的就能快速切换各个窗口焦点。 官方推荐的一个配置如下所示: (setq window-numbering-assign-func (lambda () (when (equal (buffer-name) \"*Calculator*\") 9))) 然后还需要加上一句: (window-numbering-mode) 实际开启编号模式，具体效果如下图所示: 更多窗口操作知识请参看 这个网页 ，介绍的挺好的。 markdown模式 markdown-mode这个宏包给emacs加入了markdown的渲染，还有类似org模式的折叠等等功能。其github项目地址在 这里 。 就这样简单配置一下即可: (add-to-list 'load-path \"~/工作空间/myemacs/markdown-mode\") (autoload 'markdown-mode \"markdown-mode\" \"Major mode for editing Markdown files\" t) (add-to-list 'auto-mode-alist '(\"\\\\.text\\\\'\" . markdown-mode)) (add-to-list 'auto-mode-alist '(\"\\\\.markdown\\\\'\" . markdown-mode)) (add-to-list 'auto-mode-alist '(\"\\\\.md\\\\'\" . markdown-mode)) 里面的用法除了Tab折叠功能外，其他再慢慢了解，有些可能会用不到，下面介绍重头戏，markdowon的实时预览功能实现。 markdown实时预览 emacs-livedown这个宏包其是利用nodejs里面的livedown模块的功能，将markdown文档实时显示在网页端。其github项目地址在 这里 。 首先你需要安装npm，然后通过npm安装livedown。 sudo npm install livedown 然后做如下配置: ( custom-set-variables '(livedown:autostart t) ; automatically open preview when opening markdown files ' ( livedown : port 1337 )) ; port for livedown server ; 一般nodejs的服务用这个端口 ( add-to-list 'load-path \"~/工作空间/myemacs/emacs-livedown\") (require ' livedown ) 你就可以用emacs双击一个md文件，然后在网页端就显示渲染好的网页了，而且livedown本身就支持实时根据md文件实时更新。上图片吧: 然后在emacsclient下另外开启一个frame还需要执行一下命令 livedown:preview 网页才会切换到这个md的预览。 文字模式下的emacs操作 通过ssh在远程主机上用emacs编辑文件，那就必须在文字模块下操作emacs，这带来了一些新的问题。 移动光标 参考了 这个网页 。 一般通过键盘上的方向键移动辅助搜索跳转还是很快的，但有时不知怎么方向键移动也会出问题。这是只好借助下面这些快捷键了。 C-f 前进一个字符 C-b 后退一个字符 C-p 上移一行 C-n 下移一行 M-f 前进一个单词 M-b 后退一个单词 C-a 行首 C-e 行尾 切换窗口焦点 这个前面也提过了，但在这里显然是一个重要问题，需要再次强调一下。 C-x o 进行切换各个窗口操作。 Footnotes: 1 一个隐藏配置文件，每次运行emacs之前都会先加载它。 2 参考了[mastering-emacs-in-one-year-guide](https://github.com/redguardtoo/mastering-emacs-in-one-year-guide/blob/master/guide-zh.org) 3 参考了[ 这个网页](http://floss.zoomquiet.io/data/20120229104733/index.html) 。","tags":"others","url":"articles/emacs-learning-notes.html"},{"title":"requests模块","text":"urllib.request内置模块 urllib.request模块我们可以在这里稍微了解一下，但一般实际使用主要是用后面要介绍的 requests 模块。 urlopen函数 urlopen函数在urllib模块的request子模块，其提供了简单的获取目标url网页内容的接口。一个简单的例子如下所示： from urllib.request import urlopen import socket socket . setdefaulttimeout ( 10 ) urls = [ 'https://www.google.com.cn' , 'https://www.google.com' , 'http://www.google.com.cn' ] for url in urls : try : response = urlopen ( url ) html = response . read () . decode ( 'utf-8' ) print ( html ) except socket . timeout as error : print ( error ) except OSError as error : print ( error ) 为什么刚开始就用这么一个稍显复杂的例子作为演示，well，天朝网络的特色。如果你用百度的url http://www.baidu.com ，可能大部分情况下你都不用操心这些问题，但既然我们处在天朝网络这个大背景下，还是早点介绍这个。这个例子的返回的error种类似乎间接地反映了GFW的工作原理。 比如google的.com.cn的https连接还能正常工作（目前暂时。。），只是有时会有点慢，然后其http连接则会返回404错误，这是天朝网络常见的网络错误了，大家的分析是GFW进行了dns投毒。而对于google的.com连接不管是http或者https连接都会返回OSError错误，说的是：Network is unreachable，这表明GFW对于后缀google.com的url采取的完全硬件级别的网络掐断。 然后urlopen函数第一个参数是url连接这不用多说，其还有很多可选项，其中很重要的参数就是 timeout 参数，这个和socket套接字的工作模式相关。如果不加上这个timeout参数，对于某些被墙的网站就会一直尝试然后程序陷入卡死状态了。在后面会介绍 urlretrieve 函数，也在这个urllib.request模块下面，这个函数可以用于网络下载东西，其并没有内置的timeout参数，不过可以通过设置全局网络socket的timeout（前面socket模块的setdefaulttimeout函数），这个全局timeout最好设置得稍微大一点。 这里的套接字socket的timeout参数就是控制阻塞时间的，因为有些网络数据不可能一次就传递完，好比下载过程一样的有个时间，而这个timeout就是控制这个下载时间的，如果超过这个时间了那么直接返回错误。这里有个问题，就是这个程序默认全局socket的timeout都设置为10秒，那么会不会以后用urlretrieve函数下载某个东西，本身就要求超过10秒？参看requests文档的 这里 ，其对timeout有很好的解释，他说timeout仅对连接过程有效，与响应体的下载无关。 因为网络上的情况比较复杂，关于网络的这些异常处理是不可回避的话题。上面虽然只是一个简单读取网页的程序也跟上了这么多异常捕捉，不是为了偏执的追求程序的健壮，而是必要的必须做的工作。 返回的是什么 urlopen函数返回的是urllib.response模块的Response对象，其提供了一些简单的文件风格的操作接口，比如 read() 方法， readline() 方法，需要记住的是read之后返回的是 bytes流 。 这个Response对象还有 geturl() 方法，其返回具体的url字符串，还有 info() 方法，其返回一个字典值，里面有一些关于网页的基本信息。这个请读者自己试验一下。 HTTPError和URLError异常 from urllib.error import HTTPError HTTPError是URLError的子类，URLError是OSError的子类，而OSError是不要加载模块就可以直接引用的，所以简单的处理就用OSError来捕捉。 ContentTooShortError异常 from urllib.error import ContentTooShortError 当 urlretrieve 函数下载的数据量少于预期的数据量时返回这个错误。 访问网页得到401 error 这里以路由器为例 192.168.1.1 或者 192.168.0.1 等，上面的小脚本我们稍作修改有： from urllib.request import urlopen from urllib.error import HTTPError import socket socket . setdefaulttimeout ( 10 ) url = 'http://192.168.1.1' try : response = urlopen ( url ) html = response . read () . decode ( 'utf-8' ) print ( html ) except socket . timeout as error : print ( url , error ) except HTTPError as error : if error . code == 401 : print ( url , ' need password, the 401 error' ) else : print ( url , error ) except OSError as error : print ( url , error ) 运行会返回： http://192.168.1.1 need password, the 401 error 返回了401异常，那么这个网页需要经过网页认证才能访问。下面是一个简单的小脚本附带网页认证功能： from urllib.request import build_opener , HTTPBasicAuthHandler , urlopen import urllib from urllib.error import HTTPError import getpass import socket socket . setdefaulttimeout ( 10 ) url = 'http://192.168.1.1' while True : username = input ( \"Username:\" ) . rstrip () password = getpass . getpass () . rstrip () print ( 'try...' , username , password ) auth_handler = HTTPBasicAuthHandler () auth_handler . add_password ( realm = '' , uri = '' , user = username , passwd = password ) try : opener = build_opener ( auth_handler ) urllib . request . install_opener ( opener ) ###install it gloably so urlopen can use it response = urlopen ( url ) print ( 'I found it' , username , password ) break except socket . timeout as error : print ( url , error ) except HTTPError as error : if error . code == 401 : print ( url , ' need password, the 401 error' ) else : print ( url , error ) except OSError as error : print ( url , error ) 这里的getpass内置模块的getpass函数提供了终端输入密码不显示的功能。然后我们看到 build_opener() 这个函数，其可以接受一系列的handler，根据 HTTPBasicAuthHandler 创建了一个handler实例，其通过 add_password 方法来加入用户名和密码属性，其中realm和uri我还不清楚。似乎通过你要认证的网页head可以看到。 然后调用urllib子模块request的 install_opener 函数，其将全局性的安装这个openr，后面的urlopen函数就会使用这个opener了。如果不这样做，则需要使用opener.open单独打开一个response，这并不推荐。 加上代理功能来翻墙 现在我们修改最初的那个第一个例子，加入代理功能，从理论上这样写似乎应该可以了，但是并没有效果，GFW还是很强大地。。 from urllib.request import urlopen , build_opener import urllib import socket socket . setdefaulttimeout ( 10 ) urls = [ 'https://www.google.com.cn' , 'https://www.google.com' , 'http://www.google.com.cn' ] proxy_handler = urllib . request . ProxyHandler ({ 'http' : 'http://127.0.0.1:8580/' }) opener = urllib . request . build_opener ( proxy_handler ) urllib . request . install_opener ( opener ) for url in urls : try : response = urlopen ( url ) html = response . read () . decode ( 'utf-8' ) print ( html ) except socket . timeout as error : print ( error ) except OSError as error : print ( error ) 通过修改url来GET数据 下面开始对接各个搜索引擎。 from urllib.request import urlopen import urllib import socket socket . setdefaulttimeout ( 10 ) #search_engine = 'http://www.baidu.com/' #search_engine = 'http://www.zhihu.com/' search_engine = 'http://stackoverflow.com/' def addGETdata ( url , string ): p = urllib . parse . urlparse ( url ) if p . netloc == 'www.baidu.com' : return url + 's?' + urllib . parse . urlencode ({ 'wd' : string }) elif p . netloc in [ 'www.zhihu.com' , 'stackoverflow.com' ]: return url + 'search?' + urllib . parse . urlencode ({ 'q' : string }) url = addGETdata ( search_engine , 'python urllib' ) print ( url ) pyout = open ( 'test.html' , 'w' ) try : response = urlopen ( url ) html = response . read () . decode ( 'utf-8' ) print ( html , file = pyout ) except socket . timeout as error : print ( error ) except OSError as error : print ( error ) 这里主要要讲的是addGETdata这个函数，其修改url为目标形式，然后后面都是一样的，这个要根据具体目标搜索引擎网站来了。 通过POST方法来获取数据 这个不太灵活，我们看到前面baidu和zhihu两个并不相同，而如果采用POST方法，默认是加入的中缀search?，这有时不太适合，其次采用POST方法需要给自己伪装头部，否则有些网站会禁止你。这个方法略过了。就直接通过修改url来GET已经很简单了。 requests模块基础 具体网络编程推荐使用requests模块，这是requests的 官网 ，这是中文文档的 链接 。更多信息请参看官方文档。 安装 安装推荐使用pip或者pip3命令简便安装之。 HTTP基本协议支持 下面这几个函数一看名字就知道对应的是HTTP的GET，POST，PUT和DELETE方法，然后HTTP的冷门方法HEAD和OPTIONS requests模块有类似的head函数和options函数。 get函数 这是之前第一个例子的改写： import requests urls = [ 'https://www.google.com.cn' , 'https://www.google.com' , 'http://www.google.com.cn' ] for url in urls : try : response = requests . get ( url , timeout = 10 ) html = response . text print ( html ) except requests . exceptions . Timeout as error : print ( url , error ) except requests . exceptions . RequestException as error : print ( url , error ) 这里使用get函数对应HTTP的GET方法来获取网页的内容，然后注意现在 不能通过socket全局设置timeout了 ，而需要设置一个timeout参数。提取文本内容简单的调用text属性即可，后面是一些错误捕捉，这里就不赘述了。 params参数 params参数就是给url加入一些关键词和值等，带点前面提及的urlencode函数的功能，但整个语句更加简洁方便了。下面通过类似前面的例子来演示之： import requests import urllib ###use the urlparse search_engines = ( 'http://www.baidu.com/s' , 'http://www.zhihu.com/search' , 'http://stackoverflow.com/search' , 'http://www.ask.com/web' , 'http://search.yahoo.com/search' , 'http://cn.bing.com/search' , 'https://www.google.com/#' , 'https://zh.wikipedia.org/w/index.php' , 'https://en.wikipedia.org/wiki/' , ) def addGETparams ( url , search_string ): p = urllib . parse . urlparse ( url ) if p . netloc == 'www.baidu.com' : return { 'wd' : search_string } elif p . netloc in [ 'www.zhihu.com' , 'stackoverflow.com' , 'cn.bing.com' , 'www.ask.com' , 'www.google.com' ]: return { 'q' : search_string } elif p . netloc in [ 'search.yahoo.com' ]: return { 'p' : search_string } elif p . netloc in [ 'zh.wikipedia.org' , 'en.wikipedia.org' ]: return { 'search' : search_string } search_engine = search_engines [ 2 ] params = addGETparams ( search_engine , 'python' ) pyout = open ( 'test.html' , 'w' ) try : response = requests . get ( search_engine , timeout = 10 , params = params ) print ( response . url ) html = response . text print ( html , file = pyout ) except requests . exceptions . Timeout as error : print ( url , error ) except requests . exceptions . RequestException as error : print ( url , error ) pyout . close () 其中search_engin的原始url做了一些修改，使得语法更加的简洁了。 post函数 和get函数一样如下使用： response = requests.put(\"http://httpbin.org/put\") data参数 data参数，就是POST方法实际传输过去的数据，可以是字符串，字典值，或者json数据（需要用json模块的dumps函数处理之）。 >>> payload = {'key1': 'value1', 'key2': 'value2'} >>> r = requests.post(\"http://httpbin.org/post\", data=payload) headers属性 接受一个字典值，用于定制POST方法的HTTP请求头。 put函数 暂时略过。 delete函数 暂时略过。 返回的reponse响应对象 上面这些函数返回的reponse对象 url属性 返回响应具体的url text属性 返回响应的文本内容 encoding属性 返回响应的encoding。 content属性 返回的是响应的二进制形式。我们可以利用这个属性来下载文件。下面这个 download_file 函数参考了 这个网页 。 注意这里用了 stream = True 参数设置，然后 def download_file ( url , filefold = 'download' ): '''简单的根据url下载文件函数，filefold为下载文件存放的下一级文件夹名''' try : os . mkdir ( filefold ) except FileExistsError : pass filename = './' + filefold + '/' + url . split ( '/' )[ - 1 ] # NOTE the stream=True parameter response = requests . get ( url , stream = True ) with open ( filename , 'wb' ) as f : for chunk in response . iter_content ( chunk_size = 1024 ): if chunk : # filter out keep-alive new chunks f . write ( chunk ) f . flush () return filename json方法 如果响应是json文件，那么调用这个方法就自动将json文件解码了（相当于json模块的loads）。 status_code属性 具体响应的状态码，如404之类的。 headers方法 服务器响应的HTTP头信息。 allow_redirects GET OPTIONS POST PUT PATCH DELETE 这些方法重定向默认打开 True 然后HEAD方法默认重定向关闭。 timeout参数 timeout参数控制，如果超时则将抛出 requests.exceptions.Timeout 异常。 异常 下面这些异常了解下： 遇到网络问题（如：DNS查询失败、拒绝连接等）时，Requests会抛出一个 ConnectionError 异常。 遇到罕见的无效HTTP响应时，Requests则会抛出一个 HTTPError 异常。 若请求超时，则抛出一个 Timeout 异常。 若请求超过了设定的最大重定向次数，则会抛出一个 TooManyRedirects 异常。 所有Requests显式抛出的异常都继承自 requests.exceptions.RequestException 。 requests模块高级篇 会话 会话对象可以跨多个requests请求对象保持相同的某些参数设置，比如cookies等。 Session对象有requests API的所有方法，即get，post之类。会话对象之前设置的那些参数都会保留在那里，后面调用的get方法还可以加上额外的一些参数设置，如下所示: s = requests.Session() s.auth = ('user', 'pass') s.headers.update({'x-test': 'true'}) # both 'x-test' and 'x-test2' are sent s.get('http://httpbin.org/headers', headers={'x-test2': 'true'}) SSL验证 加上 verify=True 即要求对目标主机进行SSL验证。 响应体的content 对于响应体含有content却内容较多的情况，可以通过 Stream=True 来让推迟content下载，而只获取header信息。后面遇到 response.content 才实际下载content。 然后还有 Response.iter_content 和 Response.iter_lines 方法来控制工作流，或者以 Response.raw 通过底层urllib3来读取响应对象。 response.iter_content iter_content(chunk_size=1, decode_unicode=False) 迭代读取响应体的content内容，设置一次读取多少 chunk_size 。 response.iter_lines iter_lines(chunk_size=512, decode_unicode=None) 迭代读取响应体的content内容，一次读一行。行的内容应该小于chunk_size，一般不设置即可。 身份验证 >>> from requests.auth import HTTPBasicAuth >>> requests . get ( 'https://api.github.com/user' , auth = HTTPBasicAuth ( 'user' , 'pass' )) < Response [ 200 ] > >>> requests . get ( 'https://api.github.com/user' , auth = ( 'user' , 'pass' )) < Response [ 200 ] > 代理 import requests proxies = { \"http\": \"http://10.10.1.10:3128\", \"https\": \"http://10.10.1.10:1080\", } requests.get(\"http://example.org\", proxies=proxies) 附录 关于HTTP的补充理论知识 HTTP协议就支持四种方法： GET: 从web service 那里提取信息 POST: 往web service 那里发送信息 PUT: 在web service 那里更新信息 DELETE: 在web service 那里删除信息 GET和POST的区别 参考了 这个网页 。前面谈及的修改网页的url来获取资源，实质就是HTTP的GET方法，也就是GET方法的信息就放在url上的，然后web service服务器会分析这些url，从而相应的决定对客户机的回应方式。而POST方法并不修改url，web service服务器接受的url上并没有任何额外的信息，具体POST方法具体会另外传输一个信息包。一般能够通过GET方法和服务器互动的就采用GET方法，但因为url的局限性，可能某些GET方法并不适用，这是就需要服务器支持对应的POST方法来互动了。至于PUT还有DELETE方法就更加少用了，有些服务器甚至根本就不支持这些冷门的方法。 HTTP返回错误码含义 100 : ( 'Continue' , 'Request received, please continue' ), 101 : ( 'Switching Protocols' , 'Switching to new protocol; obey Upgrade header' ), 200 : ( 'OK' , 'Request fulfilled, document follows' ), 201 : ( 'Created' , 'Document created, URL follows' ), 202 : ( 'Accepted' , 'Request accepted, processing continues off-line' ), 203 : ( 'Non-Authoritative Information' , 'Request fulfilled from cache' ), 204 : ( 'No Content' , 'Request fulfilled, nothing follows' ), 205 : ( 'Reset Content' , 'Clear input form for further input.' ), 206 : ( 'Partial Content' , 'Partial content follows.' ), 300 : ( 'Multiple Choices' , 'Object has several resources -- see URI list' ), 301 : ( 'Moved Permanently' , 'Object moved permanently -- see URI list' ), 302 : ( 'Found' , 'Object moved temporarily -- see URI list' ), 303 : ( 'See Other' , 'Object moved -- see Method and URL list' ), 304 : ( 'Not Modified' , 'Document has not changed since given time' ), 305 : ( 'Use Proxy' , 'You must use proxy specified in Location to access this ' 'resource.' ), 307 : ( 'Temporary Redirect' , 'Object moved temporarily -- see URI list' ), 400 : ( 'Bad Request' , 'Bad request syntax or unsupported method' ), 401 : ( 'Unauthorized' , 'No permission -- see authorization schemes' ), 402 : ( 'Payment Required' , 'No payment -- see charging schemes' ), 403 : ( 'Forbidden' , 'Request forbidden -- authorization will not help' ), 404 : ( 'Not Found' , 'Nothing matches the given URI' ), 405 : ( 'Method Not Allowed' , 'Specified method is invalid for this server.' ), 406 : ( 'Not Acceptable' , 'URI not available in preferred format.' ), 407 : ( 'Proxy Authentication Required' , 'You must authenticate with ' 'this proxy before proceeding.' ), 408 : ( 'Request Timeout' , 'Request timed out; try again later.' ), 409 : ( 'Conflict' , 'Request conflict.' ), 410 : ( 'Gone' , 'URI no longer exists and has been permanently removed.' ), 411 : ( 'Length Required' , 'Client must specify Content-Length.' ), 412 : ( 'Precondition Failed' , 'Precondition in headers is false.' ), 413 : ( 'Request Entity Too Large' , 'Entity is too large.' ), 414 : ( 'Request-URI Too Long' , 'URI is too long.' ), 415 : ( 'Unsupported Media Type' , 'Entity body in unsupported format.' ), 416 : ( 'Requested Range Not Satisfiable' , 'Cannot satisfy request range.' ), 417 : ( 'Expectation Failed' , 'Expect condition could not be satisfied.' ), 500 : ( 'Internal Server Error' , 'Server got itself in trouble' ), 501 : ( 'Not Implemented' , 'Server does not support this operation' ), 502 : ( 'Bad Gateway' , 'Invalid responses from another server/proxy.' ), 503 : ( 'Service Unavailable' , 'The server cannot process the request due to a high load' ), 504 : ( 'Gateway Timeout' , 'The gateway server did not receive a timely response' ), 505 : ( 'HTTP Version Not Supported' , 'Cannot fulfill request.' ), 参考资料 Foundations of Python Network Programming ，python网络编程基础，[美] John Goerzen 著，莫迟等译 。 计算机网络 [美] 特南鲍姆 diveintopython3 web services 一章 这是 中文网页 。","tags":"python爬虫","url":"articles/requests-module.html"},{"title":"周易入门之摇卦","text":"摇卦 在摇卦先静心，并问自己所求所疑问之事。 测一卦 原文 解卦 变卦原文 变卦解卦 测一卦... 测一卦... ​ 测一卦... 测一卦... 帮助 主要看主卦，然后主卦和变卦比对可得变爻。一个卦表示一个事件，从初爻到上爻，变爻表示存在变数的环节，君子需参照《周易64卦详解》确定自己的行为准则。","tags":"周易","url":"articles/zhou-yi-yao-gua.html"},{"title":"pelican模块","text":"简介 pelican是一个静态网站生成工具，其是用python编写实现的，所以对于pythoner来说显得格外的亲切。 首先按照官方的quickstart简单的刷一遍吧，下面就一些问题作出一些讨论。 项目基本说明 python的虚拟环境控制这里就不多说了，下面主要讨论 pelicanconf.py 和 publishconf.py 和 Makefile 这个文件作出一些说明，然后项目文档的基本结构相关作出一些说明。 首先说明下 publishconf.py 和 pelicanconf.py 的区别， publishconf.py 文件里面有这样一句话： import os import sys sys . path . append ( os . curdir ) from pelicanconf import * 也就是其将继承所有来自 pelicanconf.py 里面的配置参量，不同的是 publishconf.py 是对阵发布到那边服务器上的，而 pelicanconf.py 的配置只是用于本机调试的。 所以 pelicanconf.py 里面的 SITEURL 变量是空值，而在 publishconf.py 里面是要赋一个具体的值的，该值随你的模板里面的用法不同而不同，具体就是 {{ SITEURL }} 这样的调用。 然后发布到远程机器pulish还会有其他一些额外的东西，比如 DISQUS_SITENAME 这个值，很多模板会根据这个值来决定是否开启disqus的javascript引用，而DISQUS系统在本机调试的时候是没有意义的，一般会不设置这个值从而自动关闭它。 publishconf.py 也许还有其他一些考虑，这里就略过了，下面将集中将 pelicanconf.py 里面的配置。 然后我们看到 Makefile 这个文件，这个脚本很好用，下面这些命令是很经常用到的： make html make serve make github ... 其中make github会把你的output里面的内容刷到github pages对应的项目上去，其依赖于生成目标 publish ，而make publish和make html的惟一区别就是上面讨论的调用的那个具体的配置文件的不同。 这个Makefile文件我做了一些精简，这些都是无关紧要的，惟一值得一提的就是github目标的生成命令我参考官方文档做了一些更改（请 参看这里 ）： github : publish ghp-import -m \"Generate Pelican site\" $( OUTPUTDIR ) git push develop $( GITHUB_PAGES_BRANCH ) :master 这里git的remote我加了一个develop指向目标地，是因为整个项目就是venv大环境作为一个项目是github上的另外一个项目，其已经使用origin这个目标地了，而github pages默认的那个目标地只好用develop这个名字了。 然后 ghp-import 是个命令行工具，在ubuntu下可以直接用 apt 安装之， 老实说这个工具在干嘛我还不太清楚。 content和output文件夹说明 content 文件夹里面放着静态网站生成的源文件，接下来的讨论有些纯粹只是个人的设置偏好了，但都统一一并讲解了，具体DIY看读者自己的个人喜好了。 articles里面放着markdown或者html的源文件，其中articles文件夹下还有一层子文件夹，这些文件夹的名字最后会成为 Category 。而这在设置有： USE_FOLDER_AS_CATEGORY = True 然后html文件需要额外说一下，原网页的body里面的内容都会完整传过去，但是原html网页head部分里面除了必要的meta标签和title标签之外，其他多余的内容是传不过去的。那么css或者js的设置怎么弄呢，这个请参看后面的相关讨论，到时候设置好相关的meta标签即可。 images和pdfs和data和extra文件夹其实名字都是随意的，只是一般这样写罢了，pdfs里面放pdf，images里面放图片等。这几个文件夹都是所谓的静态资源文件夹，等下生成output文件夹的时候，里面的内容都放送入到output文件夹里面去。你需要如下设置： STATIC_PATHS = ['images', 'pdfs', 'data', 'extra',] 引用静态资源 比如在markdown里面引入图片如下所示： ![ img ]( {filename}/images/chemistry/Naphthalene.png ) 这里 {filename} 是pelican特有的写法，表示引用某个文件。然后后面就是具体要引用的文件路径。其他引用类似，这里就不多说了。下面对extra这个文件夹多做一些说明，其是为了让网页加入favicon.ico静态文件的，你还需要如下设置： EXTRA_PATH_METADATA = { 'extra/favicon.ico': {'path': 'favicon.ico'} } 这里参考了 这个网页 。 引用js和css js和css也是静态资源，但和上面的处理有有所不同，前面也提及了html源文件如果在head部分有css引用语句，都是会丢失的。你需要如下加上这样的meta标签语句： <meta name=\"javascripts\" content=\"周易之摇卦.js\" /> 然后你还需要安装pelican-plugins里面的 pelican_javascript 如下所示： PLUGIN_PATHS = ['pelican-plugins'] PLUGINS = ['pelican_javascript', 'tipue_search', 'extract_toc'] 更多信息请参看项目的 github地址 。 output输出控制 ARTICLE_URL = '{category}/{slug}.html' ARTICLE_SAVE_AS = ARTICLE_URL PAGE_URL = '{slug}.html' PAGE_SAVE_AS = PAGE_URL CATEGORY_URL = '{slug}/index.html' CATEGORY_SAVE_AS = CATEGORY_URL TAG_URL = 'tag/{slug}.html' TAG_SAVE_AS = TAG_URL ARTICLE_URL 定义了文章的URL显示，其中slug你可以在文件头属性那边自定义。 ARTICLE_SAVE_AS 定义了该文件在output文件夹那边如何的存储路径 后面类似的有控制 CATEGORY TAG PAGE 页面的URL和具体网页在output文件夹里面的存储路径。 其他技巧 THEME设置或自定义THEME THEME = 'mytheme' 具体自定义THEME其实就是copy一下别人的THEME，然后根据自己的jinja2知识等适当做一些修改。 目录自动生成 你需要安装 extract_toc 插件，然后你的virtuaenv环境里面需要安装了beautifulsoup4, 然后python-markdown那边你需要设置好 toc 插件开启。 MARKDOWN = ['toc'] 然后在markdown那边加上这么一行即可： [TOC] github markdown语法支持 在python-markdown那边开启 fenced_code 插件。 MARKDOWN = ['toc', 'fenced_code','codehilite(css_class=highlight, linenums=True)'] 上面还设置了语法高亮类和显示行数。","tags":"python好伙伴","url":"articles/pelican-module.html"},{"title":"小分子网页显示第一版","text":"使用mhchem宏包 latex可以用基于tikz的chemfig宏包来处理小分子结构显示问题，包括大型有机分子的结构显示问题，然后一些简单的小分子显示推荐 mhchem 宏包。 mhchem看得出来是通过latex的数学环境来显示小分子结构的，所以马上就被html上的mathjax支持了，而chemfig是通过tikz机制，这可能以后永远都不会被mathjax支持（或者通过svg途径？）。首先是加载宏包： \\usepackage [version=3] { mhchem } 就作为一般使用来说，假定读者对latex的数学环境内的语法都很熟悉了，那么可以简单理解为mhchem宏包就是在数学环境下，加入了一个新命令 \\ce{ } ，在这个ce命令里面上标和下标语法是类似数学环境内的语法表示的，不过对于具体化学表达式的显示会更加美观一些。 比如 $\\ce{H_2O}$ 将显示为 \\(\\ce{H_2O}\\) ，然后 $\\ce{AgCl_2&#94;-}$ 将显示为 \\(\\ce{AgCl_2&#94;-}\\) 。 此外还有一种简写写法：比如 $\\ce{H2O}$ 将显示为 \\(\\ce{H2O}\\) ，然后 $\\ce{AgCl2-}$ 将显示为 \\(\\ce{AgCl2-}\\) 。 我们可以看一下没有经过ce命令包装的纯数学环境表达的显示效果： \\(H_2O\\) 和 \\(AgCl_2&#94;-\\) 。区别还是有点的。 数字 数字就直接写上即可 $\\ce{0.5H2O}$ \\(\\ce{0.5H2O}\\) ，值得一提的是，前面的数字分数形式会自动处理： $\\ce{1/2 H2O}$ \\(\\ce{1/2 H2O}\\) 。 你会看到带上小数点的数字显示有点古怪。之前小数点会被解释成为配位化合物和结晶水中间的那个分隔点。如 $\\ce{KCr(SO4)2.12H2O}$ \\(\\ce{KCr(SO4)2.12H2O}\\) 。为了正确显示前面的例子，把这个0.5放入数学环境中即可： $\\ce{$0.5$H2O}$ $$ \\ce{$0.5$H2O} $$ 数学环境 同样，如上所示，mathjax目前是支持ce命令里面再加入数学环境 $ $ 的。 键 - = # 分别表示单键，双键和三键。 \\(\\ce{A-A B=B C#C}\\) 然后使用 \\bond命令还可以加入其他一些额外的键，其中 $\\ce{\\bond{~}}$ 对应 \\(\\ce{\\bond{~}}\\) ，然后 $\\ce{\\bond{~-}}$ 对应 \\(\\ce{\\bond{~-}}\\) ，其他类推。 化学反应式 $$ \\ce { CO2 + C <- 2 CO } $$ $$ \\ce{CO2 + C <- 2CO} $$ $$ \\ce{CO2 + C ->[\\text{加入text命令}] 2CO} \\ce{CO2 + C ->T[是支持][中文的] 2CO} $$ $$ \\ce{CO2 + C ->[\\text{加入text命令}] 2CO} $$ $$ \\ce{CO2 + C ->T[是支持][中文的] 2CO} $$ 如果不使用text命令，那么中文在latex那一边不会正常显示。上面例子第二个没有使用text命令，是因为前面加上了T，然后箭头上下文字都不需要了。 上下箭头 $$ \\ce{SO4&#94;2- + Ba&#94;2+ -> BaSO4 v &#94;} $$ $$ \\ce{SO4&#94;2- + Ba&#94;2+ -> BaSO4 v &#94;} $$ 下降箭头是v，上式箭头是&#94;，需要和前面的内容有一个空格。 mathjax简介 网页之所以能够显示数学公式就是利用的mathjax这个javascript库，然后这里之所以能够显示一些简单的化学是因为mathjax还引入了mhchem.js这个插件。 简单的引入代码如下所示： < script type = \"text/javascript\" > window . MathJax = { tex2jax : { inlineMath : [ [ '$' , '$' ], [ \"\\\\(\" , \"\\\\)\" ] ], processEscapes : true }, TeX : { extensions : [ \"AMSmath.js\" , \"AMSsymbols.js\" , \"noErrors.js\" , \"noUndefined.js\" , \"mhchem.js\" ] } }; < /script> < script type = \"text/javascript\" src = \"https://cdn.bootcss.com/mathjax/2.6.0/MathJax.js?config=TeX-MML-AM_CHTML\" >< /script> 最关键的配置就是 TeX 的 extensions 哪里要引入 mhchem.js 。 参考资料 这个网站 对于这一块内容讲解很详细。 if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js','mhchem.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"chemistry","url":"articles/xiao-fen-zi-wang-ye-xian-shi-di-yi-ban.html"},{"title":"GFW带来的一些问题","text":"pypi下载用国内源 pip install --trusted-host pypi.douban.com -i http://pypi.douban.com/simple carbon 或者修改本机的pypi配置，在当前用户主文件夹下的 .pip/pip.conf 下加入内容: [global] index-url = http://pypi.douban.com/simple windows下是 %HOMEPATH%\\pip\\pip.ini 。 如果你遇到提示说要加入参数 --trusted-host pypi.douban.com ，你可以加上这个选项，或者在pypi配置里面加上： [install] trusted-host = pypi.douban.com js 用国内cdn源 推荐 这个网站 。 ubuntu的更新源 ubuntu的更新源换成国内的源。 android studio sdk更新太慢 请参考 https://github.com/inferjay/AndroidDevTools 。这个网站还有很多和android开发相关的资料。","tags":"others","url":"articles/gfwdai-lai-de-yi-xie-wen-ti.html"},{"title":"化学信息学简介","text":"化学信息学定义 化学信息学(cheminformatics)，是计算机学科和化学的结合学科，其主要研究对化学物质的信息进行存储和检索这一过程。 化学信息学主要解决如下四个问题： 如何存储分子 如何精确找到这个分子 分子结构中子结构的查找 各分子的相似性搜索 MDL 3D坐标表示法，各个原子，具体的x，y，z坐标信息都列入其中了。 线性标记法 WLN Wiswesser Line Notation，魏氏线性标记法。由William J. Wisswesser于十九世纪50年代早期发明。 SMILES Simplified molecular input line entry specification，简化分子线性输入规范。这应该是目前应用最广最为大家熟知的线性标记法了。下面详细介绍一下这个线性标记法的规则，更多细节请参看 这个网页 。 原子：[Na][Cl] ，然后原子的同位素表示如下[2H]，[13C]。 离子：[Na+] [Cl-] [Cu+2] 或者 [Cu++]也是可以的。 离子化合物： 点符号 \".\" 表示两个原子之间不成键，比如氯化钠 [Na+].[Cl-] 。 单质：氢气 [H][H] , 氧气 [O]=[O] ，氮气 [N]#[N] ，这里各个原子外面默认用单键连接，然后 = 表示双键， # 表示三键。 上面的氧气和氮气可以简写为 O=O 和 N#N ，但是氢气不行。因为氢原子比较特殊，其是会自动加上的，这是符合我们日常有机化学各个结构式的表达风格，比如双氧水 表达为 OO 即可。关于如何加氢的规则我觉得就不用多说了，学过有机化学的应该是清楚的。这里值得一提的就是方括号里面是不自动加氢的，于是有[H]就是一个氢原子，而[OH2]就是两个氢原子，这是水分子。 有机化合物：接着上面的讨论，一些基本的有机化合物表达式大家应该能猜出了，比如：CCCC 就是丁烷， CCO 就是乙醇。分支的处理：一是整个有机化合物顺序链根据有机化学中学习的IUPAC命名法来；二是圆括号表示分支子基团() 。比如异丁烷表示为 CC(C)C ，新戊烷表示为 CC(C)(C)C ，醋酸表示为 CC(=O)O ，比如那个双键。 环的表示： 比如环己烷 C1CCCCC1 ,其核心理念就是后面相同编号的原子连键。比如化合物萘： 其SMILES表达就是： c1ccc2ccccc2c1 这其中涉及到萘的具体IUPAC编号问题，按照顺时针从右上那个1开始，然后到4之后跳到5，再678，然后中间那两个碳必须跳一下，这个知识就比较冷门了。这里数字1或2可以互换，是任意的。 这个例子还涉及到一个知识点，那就是有芳香性的原子（也就是苯环上的C，或者其他杂环原子ONS等等）都要小写。这样苯你应该知道怎么写了： c1ccccc1 。 立体化学 在双键的两端 /C=C/ 或者 \\C=C\\ 表示反(trans)双键， 然后 /C=C\\ 或者 \\C=C/ 表示顺(cis)。 手性我还不是很熟悉，暂时略过。 InChI SMARTS name IUPAC name 这个学习有机化学的应该都清楚什么是IUPAC命名法了。 Trade name 商用名 Common name 常用名，比如醋酸等，也叫俗名吧。 子结构搜索 预先建立索引 参考资料 An introduction to the computer science and chemistry of chemical information systems ， 2009 by Craig A. James 维基百科SMILES open smiles 官方文档","tags":"chemistry","url":"articles/cheminformatics-talk-one.html"},{"title":"markdown 简介","text":"markdown中的脚注 这里显示如何插入脚注[&#94;1] [&#94;1]: 这是一个脚注。 具体效果如下所示： 这里显示如何插入脚注 1 markdown中插入描述列表 sqrt : 开平方根函数， sqrt ( x ) 。 sin : 正弦函数，类似的还有 cos ， tan等 ， sin ( x ) 。 sqrt 开平方根函数，sqrt(x)。 sin 正弦函数，类似的还有cos，tan等，sin(x)。 github flavored markdown gfm的官方文档在 这里 。本文大体简要说明一下。 github flavored markdown 也就是github的markdown方言，其主要区别有: 下划线直接为下划线。 URL 直接输入，比如 http://www.google.com ，其将直接转化成为链接。这个只是一个新功能支持，实际上原来的链接插入方式一样有效。 删除线 用: ~~删除线~~ 属于添加的新特性。 当然最有名的就是代码块的染色支持了。 ```elisp (+ 1 1) 其中语言列表可以参看 [这里](https://github.com/github/linguist/blob/master/lib/linguist/languages.yml) 。 这是一个脚注。 ↩","tags":"others","url":"articles/markdown-talk.html"},{"title":"python语言学习之-程序中的逻辑","text":"布尔值 boolean类型，和大多数语言一样，就两个值： True ， False 。然后强制类型转换使用函数 bool 。 其他逻辑小知识 在python中，有些关于逻辑真假上的小知识，需要简单了解下。 数0、空对象或者其他特殊对象None值都认为是假 其他非零的数字或非空的对象都认为是真 前面两条用bool函数可以进行强制类型转换 比较和相等测试会递归作用在数据结构中 比较和相等测试会返回True或False 上面最后两条在说个什么东西，读者请看下面这一小节。 元组和列表的比较大小 元组和列表的相等判断还是很好理解的，而对于这样的东西: >>> (1,-1) < (2,-2) 确实就有点古怪了。请读者参考 这个网页 )，按照官方文档的说明： Tuples and lists are compared lexicographically using comparison of corresponding elements. This means that to compare equal, each element must compare equal and the two sequences must be of the same type and have the same length. 官方文档对于大于小于的情况并没有说得很清楚，然后我们从字里行间大体领会的精神是: 可迭代对象比较大小，是逐个比较的。 可迭代对象比较和相等测试最后一定返回True或False。 逐个比较首先比较是不是相等，如果相等则跳过这个元素的比较，直到遇到某两个不相等的元素，然后返回的就是这两个元素的比较结果。 最后快比较完了（以最小的可迭代对象长度为准），然后如果是相等判断操作，则长度相等就认为两者相等了；而如果是大小判断操作，则认为长度更长的那个对象更大。 下面是一些例子: >>> (1,-1) < (2,-2) True >>> (1,-1) < (-1,-2) False >>> (1,-1,-3) < (1,-1) False >>> (1,-1,) < (1,-1,0) True None 有些函数没有return的值就会返回None值，None值是NoneType对象中的一个值，和列表的空值等是不同的，它和其他任何值都不一样的。比如re.search如果没有找到匹配就会返回None值。这个时候需要知道的是None值在逻辑上是逻辑假，not None是逻辑真。 >>> def f(): ... pass ... >>> y = f() >>> y >>> type(y) <class 'NoneType'> if条件判断 python中的条件语句基本格式如下： if test: 条件判断执行区块 也就是if命令后面跟个条件判断语句，然后记住加个冒号，然后后面缩进的区块都是条件判断为真的时候要执行的语句。 if test: do something001 else : do something002 这里的逻辑是条件判断，如果真，do something001；如果假，do something002。 if test001: do something001 elif test002: do something002 显然你一看就明白了，elif是else和if的结合。 逻辑与或否 and表示逻辑与，or表示逻辑或，not表示逻辑否。 下面编写一个逻辑，判断一个字符串，这个字符串开头必须是a或者b，结尾必须是s，倒数第二个字符不能是单引号'。在这里就演示一下逻辑。。 x='agais' if ((x[0] == 'a' or x[0] == 'b') and x[-1] =='s' and (not x[-2] ==\"'\")): print('yes it is..') yes it is.. 稍复杂的条件判断 现在我们了解了if，elif和else语句，然后还了解了逻辑与或非的组合判断。那么在实际编程中如何处理复杂的条件逻辑呢？ 首先能够用逻辑语句\"与或非\"组合起来的就将其组合起来，而不要过分使用嵌套。如下面代码所示，如果一个情况分成两部分，那么就用if...else...语句， x=-2 if x>0: print('x大于0') else: print('x小于0') 而如果一个情况分成三部分，那么就用if...elif...else语句。同一深度的这些平行语句对应的是\"或\"逻辑，或者说类似其他编程语言的switch语句。 x=2 if x>0: print('x大于0') elif x<0: print('x小于0') else: print('x等于0') 我们再看一看下面的代码，这个代码是 错误的 ，两个if语句彼此并不构成逻辑分析关系。[&#94;7] x=2 if x>0: print('x大于0') if x<0: print('x小于0') else: print('x等于0') 然后我们看到下面的代码，这个例子演示的是在加深一个深度的条件判断语句它当时处于的逻辑判断情况，这个语句的条件判断逻辑是本语句的判断逻辑再和左边（也就是前面）的判断逻辑的\"与\"逻辑，或者说成是\"交集\"。比如说 print('0\\<x\\<2') 这个语句就是本语句的判断逻辑 x\\<2 和上一层判断逻辑 x>0 的\"交集\"，也就是 0\\<x\\<2 。 x=-2 if x>0: print('x大于0') if x>2: print('x>2') elif x<2: print('0<x<2') else: print('x=2') elif x<0: print('x小于0') else: print('x等于0') 整个过程的情况如下图所示： 为了在编程的时候对处于何种判断逻辑之下有一个清晰的认识，强烈建议读者好好思考一下。毕竟磨刀不误砍柴功。 try语句捕捉错误 try语句是编程中用来处理可能出现的错误或者已经出现但并不打算应付的错误最通用的方式。比如一个变量你预先想的是接受一个数值，但是用户却输入了一个字符，这个时候你就可以将这段语句包围在try里面；或者有时你在编程的时候就发现了这种情况，只是懒得理会他们，那么简单的把这块出错的语句包围在try里面，然后后面跟个except语句，打印出一个信息\"出错了\"，即可。用法如下所示： while True: x=input('请输入一个数，将返回它除以2之后的数值\\n输入\"quit\"退出\\n') if x=='quit': break try : num=float(x) print(num/2) except: print('出错了') 异常处理完整语句 try : yourCode except yourError : do something except yourError2 : do something2 ...... else : do somethingN finally : do the funallystuff 这个语句的逻辑是试着执行try区块下的语句，如果出现异常，那么看是不是异常yourError，如果是则执行do something，如果是yourError2，则执行do something2 ......等等，如果没有异常，则执行else字句: do somethingN，如果还有异常，则这个异常将会返回（更上面的控制程序）。 那么finally语句的作用是什么呢，finally语句实际上和整个语句中异常判断情况没有关系，不管有没有异常发生，最后它都将被执行。和简单地不缩进直接写在下面的语句比起来，finally语句的特点就是就算程序发生异常了，它也会先被执行，然后将异常上传给上面的控制程序。 else语句和finally语句是可选的，根据具体情况来看。 for里面放try语句的情况 for语句里面放上try语句还需要细讲一下。 具体try语句相关逻辑前面说过了，这里的问题是for语句的继续执行问题。首先是第一个情况，try字句里面使用return，这在函数里面是会跳出for语句的，也就是执行多次只要成功一次就会被跳出。然后错误捕捉，如果错误捕捉里面再放入一个raise语句，再抛出一个错误，这个时候for语句是会被中止的。然后抛出这个异常。然后是else字句，其逻辑是try多次没有错误，那么将会执行else字句，但是如果你try一次，然后else语句里面加入break命令，则会跳出for语句的。 这里面情况稍微有点复杂，目前我接触到的有如下两种应用: 这是一个mongodb的安全调用的函数装饰器。其在试图调用mongodb的时候，如果发生AutoReconnect异常，那么将会sleep一秒然后再去try 之前的那个调用函数。如果成功了，那么进入return，然后自然就跳出for语句了。 def safe_mongocall ( call ): '''mongodb replica set assistant''' def _safe_mongocall ( * args , ** kwargs ): for i in xrange ( 100 ): # try : return call ( * args , ** kwargs ) except pymongo . AutoReconnect : import time time . sleep ( 1 ) print ( \"try to connect mongodb again...\" ) return _safe_mongocall 第二个例子较为常用，就是在重复做某件事的时候可能会发生错误，然后捕捉这个错误，然后继续执行。然后捕捉的时候计了一下数。 def test(): failcount = 0 for i in range(src_count): try: do something except Exception as ex: failcount += 1 sucess_count = src_count - failcount return sucess_count 其实我们还可以想到另外一种程序结构，那就是try和else在for语句里面构成逻辑分支。当你试着做某件事的时候，try，如果正常则执行else字句然后break，如果发生某个异常则执行异常中的字句，就是try里面的内容不被执行。这有点反常规，但联系实际生活，我们确实也存在这样的逻辑，那就是假想如何如何，发生错误不行则执行else字句，就是假想try里面的内容不实际执行。 in语句 in语句对于可迭代对象都可以做出是否某个元素包含在某个对象之中的判断。 >>> 'a' in ['a',1,2] True >>> dict {'a': 1, 'c': 2, 'b': 3, 'd': 4} >>> 'e' in dict False >>> '2' in dict False 从上面例子可以看到，一般的列表判断元素是否存在和我们之前预料的一致，关于字典需要说的就是in语句，不判断值。 for迭代语句 一般有内部重复操作的程序可以先考虑for迭代结构实现，实在不行才考虑while循环结构，毕竟简单更美更安全。 python的for迭代语句有点类似lisp语言的dolist和dotimes函数，具体例子如下： for x in 'abc': print(x) a b c in后面跟的是 序列 类型，也就是字符串，列表，数组都是可以的。这个语句可以看作先执行x='a'或者类似的匹配赋值操作，然后执行缩进的区块，后面依次类推。（所以for语句也支持序列解包赋值，请参看： 11.5.1 {reference-type=\"ref\" reference=\"sec:序列解包赋值\"}） else分句 for x in 'abc': if x == 'b': print(x) break else: print('test') for语句加上else分句这种形式，如果for迭代完了就会执行else分句。但如果for语句还在迭代过程中，break或者return出来了，那么else分句将不会被执行。 range函数 range函数常和for迭代语句一起使用，其返回一个可迭代对象。 range(1,10,2) range函数的用法如上，表示从1开始到10，步长为2，如果用list函数将其包裹，将会输出[1,3,5,7,9]。如果不考虑步长的话，这个range函数就有点类似于在序列调出多个值那一小节 9.3.3 {reference-type=\"ref\" reference=\"sec:调出多个值\"}谈论的区间的情况。所以range(10)就可以看作[0,10)，range(1,10)就可以看作[1,10)。但是在这里再加上步长的概念和区间的概念又有所不同了。 for x in range(-10,-20,-3): print(x) -10 -13 -16 -19 上面例子还演示了range的负数概念，这里如果用区间概念来考察的话，是不能理解的，之所以行得通，是因为它的步长是负数，如果不是负数，那么情况就会和之前讨论的结果类似，将是一个空值。 迭代加上操作 迭代产生信息流并经过某些操作之后生成目标序列，更多内容请参见列表解析一节 9.5.11 {reference-type=\"ref\" reference=\"sec:列表解析\"}。 >>> squares=[x**2 for x in [1,2,3,4,5]] >>> squares [1, 4, 9, 16, 25] enumerate函数 enumerate函数返回一个enumerate对象，这个对象将偏移值和元素组合起来，成为一个可迭代对象了。 >>> enu = enumerate('abcd') >>> [i for i in enu] [(0, 'a'), (1, 'b'), (2, 'c'), (3, 'd')] while循环 while语句用法和大多数编程语言类似，就是条件控制，循环结构。 while test: do something else : do something 值得一提的是else语句和while语句属于一个整体，通常情况下while执行完了然后执行下面的语句似乎不需要加上else来控制[&#94;8]。不过else语句的一个功用就是如果while循环的时候遇到break那么else语句也不会执行而是直接跳过去了，见下面。 break命令 break跳出最近的while或者for循环结构。前面谈到了else和while语句构成一个整体的时候，break可以跳过else语句。 continue命令 continue命令接下来的循环结构的执行区块将不执行了，跳到条件判断那里看看是不是继续循环。如果是，那么继续循环。同样在for语句中continue命令的意思也是一样的。 pass命令 pass命令就是什么都不做。pass命令即可用于循环语句也可用于条件语句。 pass命令什么都不做似乎没有什么意义，不过作为一个空占位符还是很有用的。比如你编写一个大型的GUI程序，信号－槽机制都构思好了，只是对应的函数暂时还没写好，这个时候你可以将对应的函数，只是空的函数名加上pass语句写上，这样整个程序就可以继续边编写边调试了。","tags":"python语言","url":"articles/pythonyu-yan-xue-xi-zhi-cheng-xu-zhong-de-luo-ji.html"},{"title":"python语言学习之-操作或者函数","text":"函数也是一个对象，叫函数对象。函数名和变量名一样都是引用，函数名后面带个括号才真正实际执行。比如下面不带括号就只是返回了对这个函数对象的引用地址。 >>> print <built-in function print> 要理解函数也是一个对象，比如在下面的例子中，fun刚开始是一个函数列表，然后在for的迭代语句里，意思具体就是multiply这个函数对象，然后接下来又是plus这个函数对象。整个过程是对x*a然后再加上b。即 \\(a*x +b\\) x = 3 def multiply(x,a): return x*a def plus(x,b): return x+b fun = [multiply , plus] para = [3,2] for fun,para in zip(fun,para): x = fun(x,para) print(x) 自定义函数 定义函数用def命令，语句基本结构如下： def yourfunctionname(para001,para002...): do something001 do something002 参数传递问题 函数具体参数的值是通过赋值形式[&#94;9]来传递的，这有助于理解后面的不定变量函数。而函数的参数名是没有意义的，这个可以用lambda函式来理解之，def定义的为有名函数，有具体的引用地址，但内部作用原理还是跟lambda无名函式一样，形式参数名是x啊y啊都无所谓。为了说明这点，下面给出一个古怪的例子： y=1 def test(x,y=y): return x+y print(test(4)) 输出结果是5。我们看到似乎函数的形式参数y和外面的y不是一个东西，同时参数的传递是通过赋值形式进行的，那么具体是怎样的呢？具体的解释就是函数的形式参数y是这个函数自己内部的 本地变量 y，和外面的y不一样，更加深入的理解请看下一节（变量作用域问题）。 然后还有： >>> x=[1,2,3] >>> for x in x: ... print(x) ... 1 2 3 我们知道for语句每进行一次迭代之前也进行了一次赋值操作，所以for语句里面刚开始定义的这个x和外面的x也不是一个东西，刚开始定义的x也是for语句内部的 本地变量 。 想到这里我又想起之前编写removeduplicate函数遇到的一个问题，那就是for语句针对列表这个可变的可迭代对象的工作原理是如何的？具体请看下面的例子： >>> lst=[1,2,3,4] >>> for x in lst: ... print(x,lst) ... del lst[-1] ... 1 [1, 2, 3, 4] 2 [1, 2, 3] 可迭代对象的惰性求值内部机制在我看来很神奇，目前还不太清楚，但从这个例子看来列表的惰性求值并没有记忆内部的数值，只是记忆了（合情合理），然后如果迭代产生了StopIteration异常就终止。 变量作用域问题 python的变量作用域和大部分语言比如c语言或lisp语言的概念都类似，就是函数里面是局部变量，一层套一层，里面可以引用外面，外面不可以引用里面。 具体实现机制是每个函数都有自己的命名空间，（和模块类似）就好像一个盒子一样封装着内部的变量。所谓的本地变量和函数有关，或者其他类似的比如for语句；所谓的全局变量和模块有关，更确切的表述是和文件有关，比如说在现在这个文件里，你可以通过导入其他模块的变量名，但实际上模块导入之后那些变量名都引入到这个文件里面来了。 具体实现和类的继承类似也是一种搜索机制，先搜索本地作用域，然后是上一层(def，lambda，for)的本地作用域，然后是全局作用域，然后是内置作用域。更加的直观的说明如下图所示： 简单来说python的变量作用域问题就是：盒子套盒子，搜索是从盒子最里面然后往外面寻找，里面可以用外面的变量，外面的不可以用里面的。 内置作用域 内置作用域就是由一个 __builtin__ 模块来实现的，python的作用机制最后会自动搜索这个内置模块的变量。这个内置模块里面就是我们前面学习的那些可以直接使用的函数名，比如print，range等等之类的，然后还有一些内置的异常名。 所以我们想到即使对于这些python的内置函数我们也是可以覆盖定义的，事实确实如此： >>> abs(-3) 3 >>> def abs(x): ... print(x) ... >>> abs(3) 3 >>> abs(-3) -3 以后学习单元测试会接触到mock的概念，其作用机制大体也与之类似就是覆盖掉之前定义的某个对象。 global命令 如果希望函数里面定义的变量就是全局变量，在变量声明的时候前面加上 global 命令即可。 通常不建议这么做，除非你确定需要这么做，然后你需要写两行代码才能实现，意思也是不推荐你这么做。 def test(): global var var= 'hello' test() print(var) hello 而且就算你这样做了，这个变量也只能在本py文件中被引用，其他文件用不了。推荐的做法是另外写一个专门用于配置参数的config.py文件，然后那些全局变量都放在里面，如果某个文件要用，就import进来。而对与这个config.py文件的修改会影响所有的py文件配置，这样让全局变量可见可管可控更加通用，才是正确的编程方式。 nonlocal命令 nonlocal命令python3之后才出现，这里实现的概念有点类似于lisp语言的闭包(closure技术)，就是如果你有某个需要，需要函数记忆一点自己的状态，同时又不想这个状态信息是全局变量，也不希望用类的方式来实现，那么就可以用nonlocal命令来简单地完成这个任务。 global意味着命名只存在于一个嵌套的模块中，而nonlocal的查找只限于嵌套的def中。要理解nonlocal首先需要理解函数里面嵌套函数的情况------也就是所谓的工厂函数，一个函数返回一个函数对象。比如说 def add(x): x=x def action(y): return x+y return action >>> add1=add(1) >>> add1(5) 6 >>> add2=add(2) >>> add2(5) 7 这里的return action是返回一个函数对象，这样add1的实际接口是def action那里。熟悉lisp语言的明白，action外面的那个函数的变量叫做自由变量，不过嵌套函数在这里可以引用自由变量[&#94;10]但自由变量。如果我们声明nonlocal x，那么就可以修改嵌套函数外面声明的变量了。 def add(x): x=x def action(y): nonlocal x x=x+1 return x+y return action >>> add2=add(2) >>> add2(5) 8 >>> add2(5) 9 >>> add2(5) 10 然后我们看到这个生产出来的函数具有了运行上的状态性，实际上通过类也能构建出类似的效果，不过对于某些问题可能闭包方式处理显得更适合一些。 下面给出一个稍微合理点的例子： def myrange(n): i=n def action(): nonlocal i while i>0: i=i-1 return i return action >>> myrange5=myrange(5) >>> myrange5() 4 >>> myrange5() 3 >>> myrange5() 2 >>> myrange5() 1 >>> myrange5() 0 >>> myrange5() >>> 下面给出类似的类的实现方法： class myrange : def __init__ ( self , n ) : self . i = n def action ( self ) : while self . i > 0 : self.i -= 1 return self . i >>> myrange5 = myrange ( 5 ) >>> >>> myrange5 . action () 4 >>> myrange5 . action () 3 >>> myrange5 . action () 2 >>> myrange5 . action () 1 >>> myrange5 . action () 0 >>> myrange5 . action () >>> 我们看到从编码思路上基本上没什么差异，可以说稍作修改就可以换成类的实现版本。推荐一般使用类的实现方法。但有的时候可能用类来实现有点不伦不类和大材小用了。这里就不做进一步讨论了，闭包思想是函数编程中很重要的一个思想，学习了解一下也好。 参数和默认参数 定义的函数圆括号那里就是接受的参数，如果参数后面跟个等号，来个赋值语句，那个这个赋的值就是这个参数的默认值。比如下面随便写个演示程序： def test(x='hello'): print(x) test() test('world') hello world 不定参量函数 我们在前面谈到sum函数只接受一个列表，而不支持这样的形式：sum(1,2,3,4,5)。现在我们设计这样一个可以接受不定任意数目参量的函数。首先让我们看看一种奇怪的赋值方式。 序列解包赋值 NOTICE: python2不支持本小节讨论的序列解包赋值。不过python2的函数定义中是支持 *args 这种写法的。 >>> a,b,*c=1,2,3,4,5,6,7,8,9 >>> print(a,b,c,sep=' | ') 1 | 2 | [3, 4, 5, 6, 7, 8, 9] >>> a,*b,c=1,2,3,4,5,6,7,8,9 >>> print(a,b,c,sep=' | ') 1 | [2, 3, 4, 5, 6, 7, 8] | 9 >>> *a,b,c=1,2,3,4,5,6,7,8,9 >>> print(a,b,c,sep=' | ') [1, 2, 3, 4, 5, 6, 7] | 8 | 9 带上一个星号*的变量变得有点类似通配符的味道了，针对后面的序列（数组，列表，字符串），它都会将遇到的元素收集在一个列表里面，然后说是它的。 for语句也支持序列解包赋值，也是将通配到的的元素收集到了一个列表里面，如： for (a,*b,c) in [(1,2,3,4,5,6),(1,2,3,4,5),(1,2,3,4)]: print(b) [2, 3, 4, 5] [2, 3, 4] [2, 3] 函数中的通配符 >>> def test(*args): ... print(args) ... >>> test(1,2,3,'a') (1, 2, 3, 'a') 我们看到类似上面序列解包赋值中的带星号表通配的概念，在定义函数的时候写上一个带星号的参量（我们可以想象在函数传递参数的时候有一个类似的序列解包赋值过程），在函数定义里面，这个args就是接受到的参量组成的 元组 。 mysum函数 def mysum(*args): return sum(args[:]) print(mysum(1,2,3,4,5,6)) 21 这样我们定义的可以接受任意参数的mysum函数，如上所示。具体过程就是将接受到的args（已成一个元组了），然后用sum函数处理了一下即可。 任意数目的可选参数 在函数定义的写上带上两个星号的变量**args，那么args在函数里面的意思就是接受到的可选参数组成的一个字典值。 >>> def test(**args): ... return args ... >>> test(a=1,b=2) {'b': 2, 'a': 1} 我们看到利用这个可以构建出一个简单的词典对象生成器。 解包可迭代对象传递参数 之前*args是在函数定义中，然后通配一些参数放入元组中。这里是在函数调用中，针对可迭代对象，可以用一个*星号将其所包含的元素迭代出来，然后和参数一一对应赋值。 >>> map = map(lambda x:x+2,[1,2,3]) >>> print(*map) 3 4 5 >>> print(*[1,2,3]) 1 2 3 最简单的打印文件命令 前面说到文件也是一个可迭代对象，然后如果在这里解包文件对象将是一个最简单的打印文件命令，简单得惊天地泣鬼神了... print(*open('test.py')) 解包字典成为关键字参数 和上面的类似，通过**args语法可以将某个字典对象解包成为某个函数的关键字参数。还是以上面那个函数f为例子： >>> def f(a,b,c=3): ... print(a,b,c) >>> f(**{'c':6,'b':4,'a':2}) 2 4 6 >>> f(1,2,5) 1 2 5 这个例子也告诉我们不是可选参数的a和b同样也可以通过这种字典形式复制。 参数的顺序 老实说一般参数，可选参数（关键字参数），任意（通配）参数，任意（通配）关键字参数所有这些概念混在一起非常的让人困惑。就一般的顺序是： 一般参数，这个如果有 ，然后通过位置一一对应分配参数。 关键字参数，匹配一些关键字参数。 通配一般参数，其他额外的非关键字的参数分配到*args元组里面。 通配关键字参数，其他额外的关键字参数分配到**kwargs字典里面， 。 具体如下所示： def test(x, y, c=1, d=1, *args, **kwargs): print(x, y, c, d, args, kwargs) 这种写法也是python2和python3兼容的。然后python3又新加入了一个keyword-only参数（读者记住这不是关键字参数就行了），如下所示： def test(x, y, c=1, d=1, *args, z=None ,**kwargs): print(x, y, c, d,args, kwargs,z) 首先强调一点，python2里面没有这个东西，所以要考虑python2和python3兼容性的不用太关注这个东西了。看上面的例子，这个keyword-only参数是个极容易和keyword参数或者我们常说的关键字参数混淆的东西，这个keyword-only参数也确实是类似关键字参数，但它不能像常规的关键字参数那样按照位置赋值，而必须明确的指定名字赋值。 这个keyword-only参数的标志就是跟在那个星号后面。如下所示，你也别把那个z认为是个一般参数了，它只是一个还没有赋予默认值的keyword-only参数。 def test(x, y, c=1, d=1, *args, z ,**kwargs): print(x, y, c, d,args, kwargs,z) 然后有的人就只想用keyword-only参数，对具体通配一般参数根本不感兴趣，会这样写： def test(x, y, c=1, d=1, *, z ,**kwargs): print(x, y, c, d,args, kwargs,z) 这样写的话就没有通配一般参数了，这样上面这个函数最多只能接受4个不指定名字的参数，x，y两个，c和d这两个关键字参数也可以匹配两个。 keyword-only参数的用处 keyword-only的参数的用处就是其是一个不能通过不指定名字而赋值的关键字参数，或者说如果你需要某个关键字参数在后面的使用中必须明确给出名字来使用，那么就可以使用keyword-only参数。 只是有一点，python2不支持这个东西，python2要实现类似的效果要通过 **kwargs 还有后面写上一些甚至很多行代码才行，如下所示： def test(x, y, **kwargs): a = kwargs.pop('a') b = kwargs.pop('b', False) # 第二个参数得到默认参数的效果 if kwargs: raise TypeError(Unexpected kwargs: {0}'.format(kwargs)) 异常信息随便写的，在这里不是重点。 生成器函数 一般函数的定义使用return语句，如果使用yield语句，我们可以构建出一个生成器函数， >>> def test(x): ... for i in range(x): ... yield 2*i+ 1 ... >>> test(3) <generator object test at 0xb704348c> >>> [x for x in test(3)] [1, 3, 5] >>> [x for x in test(5)] [1, 3, 5, 7, 9] 生成器函数返回的是生成器对象（generator object），通过yield这样的形式定义出来的生成器函数返回了一个生成器对象和range对象类似，都是描述性可迭代对象，里面的元素并不立即展开，而是请求一次运算一次，所以这种编程风格对内存压力很小，主要适合那些迭代元素特别多的时候的情况吧。 上面的test函数我们就可以简单理解为2x+1，其中0\\<=x\\<n（赋的值）。 下面给出一个问题作为练习：描述素数的生成器函数。 这是网上流行的素数检验函数，效率还是比较高的了。 def isprime(n): if n ==2: return True #按位与1，前面一定都是0个位数如果是1则 #是奇数则返回1则真则假，如果是偶数则返回 #0则假则真 elif n<2 or not n & 1: return False #埃拉托斯特尼筛法... #查一个正整数N是否为素数，最简单的方法就是试除法， #将该数N用小于等于N**0.5的所有素数去试除， #若均无法整除，则N为素数 for x in range(3,int(n**0.5)+1,2): if n % x == 0: return False return True 然后我们给出两种形式的素数生成器函数，其中prime2的意思是范围到（to）那里。而prime(n)的意思是到第几个素数。我们知道生成器函数是一种惰性求值运算，然后yield每迭代一次函数运算一次（即产生一次yield），但这种机制还是让我觉得好神奇。 def prime2(n): for x in range(n): if isprime(x): yield x def prime(n): i=0 x=1 while i<n: if isprime(x): i +=1 yield x x +=1 在加载这些函数之后我们可以做一些检验： >>> isprime(479) True >>> [x for x in prime2(100)] [2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, ........] >>> [x for x in prime2(1000) if 100< x < 200] [101, 103, 107, 109, 113, 127, 131, 137, 139, 149, .......] >>> len([x for x in prime2(10000) if -1 < x < 3572]) 500 >>> [x for x in prime(1)] [2] >>> [x for x in prime(2)] [2, 3] 递归函式 虽然递归函式能够在某种程度上取代前面的一些循环或者迭代程序结构，不过不推荐这么做。这里谈及递归函式是把某些问题归结为数学函数问题，而这些问题常常用递归算法更加直观（不一定高效）。比如下面的菲波那奇函数： def fib(n): if n==0: return 1 if n==1: return 1 else: return fib(n-1)+fib(n-2) for x in range(5): print(fib(x)) 1 1 2 3 5 我们可以看到，对于这样专门的数学问题来说，用这样的递归算法来表述是非常简洁易懂的。至于其内部细节，我们可以将上面定义的fib称之为函式，函式是一种操作的模式，然后具体操作就是复制出这个函式（函数或者操作都是数据），然后按照这个函式来扩展生成具体的函数或者操作。 下面看通过递归函式来写阶乘函数，非常的简洁，我以为这就是最好最美的方法了。 def fact(n): if n == 0: return 1 else: return n*fact(n-1) print(fact(0),fact(10)) 1 3628800 什么时候用递归？ 最推荐使用递归的情况是这样的情况，那就是一份工作（或函数）执行一遍之后你能够感觉到虽然所有的工作没有做完，但是已经做了一小部分了，有了一定的进展了，就好比是蚂蚁吞大象一样，那么这个时候你就可以使用递归思想了。其次有的时候有那么一种情况虽然表面上看似乎并没有什么进展，但事情在发展，你能感受到有一个条件最终将会终止程序从而得到一个输出，那么这个时候就可以用递归。 递归思想最核心的两个概念就是一做了一小部分工作，你能感觉到做着做着事情就会做完了；二有一个终止判断最终将会起作用。 其实通过递归函式也可以实现类似for的迭代结构，不过我觉得递归函式还是不应该滥用。比如下面通过递归函式生成一种执行某个操作n次的结构： def dosomething(n): if n==0: pass elif n==1: print('do!') else: print('do!') return dosomething(n-1) print(dosomething(5)) do! do! do! do! do! None 可以看到，如果把上面的print语句换成其他的某个操作，比如机器人向前走一步，那么这里dosomething换个名字向前走(5)就成了向前走5步了。 lisp的car-cdr递归技术 在lisp语言中， car-cdr递归技术是很重要的一门技术，它的特长就是遍历随意嵌套的列表结构可以同一对列表中的每一个元素执行某种操作。 首先我们来看下面的例子，一个把任意嵌套列表所有元素放入一个列表中的函数： lst = [[1,2,[3]],[4,[5,[[[[10],11]]]],(1,2,3)],[{'a','b','c'},8,9]] def is_list(thing): return isinstance(thing, list) def flatten(iter): templst = [] for x in iter: if not is_list(x): templst.append(x) else: templst += flatten(x) return templst print(flatten(lst)) [1, 2, 3, 4, 5, 10, 11, (1, 2, 3), {'c', 'b', 'a'}, 8, 9] 这个函数的逻辑是如果是最小元素对象不是列表，那么收集进列表；如果不是，那么把它展开，这里就是调用的原函数继续展开函式。 上面的例子严格意义上来讲还不算lisp的经典car-cdr递归技术，下面给出一个典型的例子，就是复制任意嵌套结构的列表。当然列表的copy方法就可以做这个工作，这里主要通过这个例子来进一步深入car-cdr技术。 def is_list(thing): return isinstance(thing, list) def copy_list(lst): if not is_list(lst): return lst elif lst == []: return [] else: return [copy_list(lst[0])] + copy_list(lst[1:]) print(copy_list([1,[2,6],3])) 这种嵌套列表的复制以及后面的修改等等操作，最合适的就是lisp的car-cdr技术了，但我不得不承认，这种递归写法是递归函式里面最难懂的了。 不管怎么严格，在这个基础之上，因为第一个if not的语句中传递下来的lst实际上已经是非列表的其他元素了，然后我们可以进行一些其他修改操作，这样在保持原列表的复杂嵌套的基础上，等于遍历的对列表中的所有元素进行了某种操作。 比如所有元素都平方： def square(x): return x**2 def square_list(lst): if not is_list(lst): return square(lst) elif lst == []: return [] else: return [square_list(lst[0])] + square_list(lst[1:]) print(square_list([1,[2,6],3])) 我们可以想像更加复杂功能的函数作用于列表中所有的元素同时又不失去原列表复杂的嵌套结构，lisp的car-cdr这种技术了解一下吧，但是不是一定要使用复杂的嵌套结构呢？也许没有必要吧。。 lambda函式 lambda λ表达式这个在刚开始介绍lisp语言的时候已有所说明，简单来说就是函数只是一个映射规则，变量名，函数名都无所谓的。这里就是没有名字的函数的意思。 具体的样子如下面所示： f=lambda x,y,z:x+y+z print(f(1,2,3)) 6 lanmbda函式在有些情况下要用到，比如pyqt里面的信号－槽机制用connect方法的时候，槽比如是函数名或者无参函数，如果用户想加入参量的话，可以使用lamba函式引入。 读者如果对lambda函式表达不太熟悉强烈建议先简单学一学 scheme 语言。 print函数 print函数因为很常用和基础，就放在这里了。 print函数接受任意的参量，逐个打印出来。然后它还有一些关键字参数， sep ：默认值是' '，也就是一个空格，如果修改为空字符串，那么逐个打印出来的字符之间就没有间隔了。 end ：默认值是'\\n'， file 默认值是sys.stdout，也就是在终端显示，你可以修改为某个文件变量，这样直接往某个文件里面输出内容。 if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js','mhchem.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"python语言","url":"articles/python-talk-three.html"},{"title":"python语言学习之-程序中的操作对象","text":"python和c语言不同，c 是什么 int x = 3 ，也就是这个变量是整数啊，字符啊什么的都要明确指定，python不需要这样做，只需要声明 x ＝ 3 即可。但是我们知道任何程序语言它到最后必然要明确某一个变量（这里也包括后面的更加复杂的各个结构对象）的内存分配，只是python语言帮我们将这些工作做了，所以就让我们省下这份心吧。 ''' 这是一个多行注释 你可以在这里写上很多废话 ''' x = 10 print(x,type(x)) python程序由各个模块（modules）组成，模块就是各个文件。模块由声明（statements）组成，声明由表达式（expressions）组成，表达式负责创造和操作对象（objects）。在python中一切皆对象。python语言内置对象（数值、字符串、列表、数组、字典、文件、集合、其他内置对象。）后面会详细说明之。 赋值 python中的赋值语法非常的简单，x=1，就是一个赋值语句了。和c语言不同，c是必须先声明int x之类，开辟一个内存空间，然后才能给这个x赋值。而python的x=1语句实际上至少完成了三个工作：一，判断1的类型（动态类型语言必须要这步）；二，把这个类型的对象存储在内存里面；三，创建x这个名字和这个名字指向这个内存，x似乎可以称之为对应c语言的指针对象。 序列赋值 x,y=1,'a' [z,w]=['b',10] print(x,y,z,w) 1 a b 10 >>> 我们记得python中表达式可以加上圆括号，所以这里 x,y 产生的是一个数组 (x,y) ，然后是对应的数组平行赋值，第二行是列表的平行赋值。这是一个很有用的技巧。 在其他语言里面常常会介绍swap函数，就是接受两个参数然后将这两个参数的值交换一下，交换过程通常要用到临时变量。而在python中不需要再创建一个临时变量了，因为序列赋值会自动生成一个临时的右边的序列（其中的变量都对应原来的原始值），然后再赋值（这里强调一一对应是指两边的序列长度要一致。） 交换两个元素 在python中交换两个元素用序列赋值形式是很便捷的： >>> x = 1 >>> y = 2 >>> x,y = y,x >>> print(x,y) 2 1 这个过程显然不是先执行x=y然后执行y=x，如上所述的，程序首先右边创建一个临时的序列，其中的变量都对应原来的值，即 x,y=(2,1) ，然后再进行序列赋值。 同时赋相同的值 x=y='a' z=w=2 print(x,y,z,w) a a 2 2 >>> 这种语句形式c语言里面也有，不过内部实现机制就非常的不一样了。python当声明x=y的时候，x和y是相同的指针值，然后相同的指针值都指向了'a'这个字符串对象，也可以说x和y就是一个东西，只是取的名字不同罢了。 我们用is语句 1 来测试，显示x和y就是一个东西。 >>> x=y='a' >>> x is y True >>> x == y True 但如果写成这种形式： >>> x = 'a' >>> y = 'a' >>> x is y True x和y还是指向的同一个对象，关于这点python内部是如何实现的我还不太清楚（似乎有点神奇）。为了说明is语句功能正常这里再举个例子吧： >>> x = [1,2,3] >>> y = [1,2,3] >>> x == y True >>> x is y False 我们看到这里就有了两个列表对象。 增强赋值语句 x=x+y可以写作x += y。类似的还有： += &= >>= -= |= \\<\\<= *= \\&#94;= **= /= \\%= //= 序列解包赋值 可迭代对象的迭代赋值 在我们对python语言有了深入的了解之后，我们发现python中迭代思想是深入骨髓的。我们在前面接触了序列的赋值模式之后，发现似乎这种赋值除了临时创建右边的序列之外，还似乎与迭代操作有关，于是我们推测python的这种平行赋值模式可以扩展到可迭代对象，然后我们发现确实如此！ >>> x,y,z= map(lambda x : x+2,[-1,0,1]) >>> print(x,y,z) 1 2 3 最后要强调一点的是确保左边的变量数目和后面的可迭代对象的输出元素数目是一致的，当然进一步扩展的序列解包赋值也是支持的： >>> x,y,*z= map(lambda x : x+2,[-1,0,1,2]) >>> print(x,y,z) 1 2 [3, 4] 通配赋值，我喜欢这样称呼，通配之后收集的元素在列表里面；而函数参数的通配传递，收集的元素是在元组里面。 最后我们总结到，可迭代对象的赋值就是迭代操作加上各个元素的一对一的赋值操作。 数值 python的数值的内置类型有：int，float，complex等 2 。\\ python的基本算术运算操作有加减乘除（+ - * /）。然后'='表示赋值，类似数学书上的中缀表达式和优先级和括号法则等，这些都是一般编程语言说到烂的东西了。 print((1+2)*(10-5)/2) print(2**100) 二进制八进制十六进制 二进制的数字以0b（零比）开头，八进制的数字以0o（零哦）开头，十六进制的数字以0x（零艾克斯）开头。 0b101010, 0o177, 0x9ff 以二进制格式查看数字使用bin命令，以十六进制查看数字使用hex命令。 >>> bin(42) '0b101010' >>> hex(42) '0x2a' 进制转换小程序 number=input(\"请输入一个数字：\") number= eval(number) # radix= input('''请输入你想转换的进制系统 2 表示 二进制 8 表示 八进制 16 表示 十六进制 ''') radix =eval(radix) while True: if radix == 2: print(bin(number)) break elif radix == 8: print(oct(number)) break elif radix == 16: print(hex(number)) break else: print(\"sorry you input the wrong radix\") 程序运行的情况如下所示： 请输入一个数字：20 请输入你想转换的进制系统 2 表示 二进制 8 表示 八进制 16 表示 十六进制 8 0o24 此外基于字符串的进制转换可以用字符串的format方法来处理之。 数学幂方运算 \\(x&#94;y\\) ，x的y次方如上面第二行所述就是用 x**y 这样的形式即可。此外pow函数作用是一样的， pow(x,y) 。 数值比较 数值比较除了之前提及的>，\\<，==之外，>=，\\<=，!=也是有的（大于等于，小于等于，不等于）。此外python还支持连续比较，就是数学格式 \\(a<x<b\\) ，x在区间 \\((a,b)\\) 的判断。在python中可以直接写成如下形式： a<x<b 。这实际实现的过程就是两个比较操作的进一步与操作。 相除取商或余 就作为正整数相除使用 x//y 得到的值意义还是很明显的就是 商 。带上负号感觉有点怪了，这里先略过。相关的还有 取余 数，就是 x%y ，这样就得到x除以y之后的余数了，同样带上负号情况有变，这里先略过。 复数 python直接支持复数， 复数的写法是类似 1+2j 这样的形式，然后如果z被赋值了一个复数，这样它就是一个复数类型，那么这个类具有两个属性量， real 和 imag 。也就是使用 z.real 就给出这个复数的实数部。imag是imaginary number的缩写，虚数，想像出来的数。 abs函数 大家都知道abs函数是绝对值函数，这个python自带的，不需要加载什么模块。作用于复数也是可以的： z=3+4j print(z.real,z.imag) print(abs(z)) 这个和数学中复数绝对值的定义完全一致，也就是复数的模： \\(\\left| z \\right| =\\sqrt { a&#94;{ 2 }+b&#94;{ 2 } }\\) round函数 简单的理解就是这个函数实现了对数值的功能。 >>> round(3.1415926) 3 >>> round(3.1415926,0) 3.0 >>> round(3.1415926,1) 3.1 >>> round(3.1415926,2) 3.14 >>> round(3.1415926,4) 3.1416 这里第二个参数接受0或者负数多少有点没意义了，一般使用还是取1或大于1的数吧，意思就是保留几位小数。 min，max和sum函数 min，max函数的用法和sum的用法稍微有点差异，简单起见可以认为min，max，sum都接受一个元组或者列表（还有其他？），然后返回这个元组或者列表其中的最小值，最大值或者相加总和。此外min和max还支持min(1,2,3)这样的形式，而sum不支持。 >>> min((1,6,8,3,4)) 1 >>> max([1,6,8,3,4]) 8 >>> sum([1,6,8,3,4]) 22 >>> min(1,6,8,3,4) 1 位操作 python支持位操作的，这里简单说一下：位左移操作\\<\\<，位与操作&，位或操作|，位异或操作\\&#94;。 >>> x=0b0001 >>> bin(x << 2) '0b100' >>> bin(x | 0b010) '0b11' >>> bin(x & 0b1) '0b1' >>> bin(x &#94; 0b101) '0b100' math模块 在 from math import * 之后，可以直接用符号pi和e来引用圆周率和自然常数。此外math模块还提供了很多数学函数，比如： sqrt 开平方根函数，sqrt(x)。 sin 正弦函数，类似的还有cos，tan等，sin(x)。 degrees 将弧度转化为角度，三角函数默认输入的是弧度值。 radians 将角度转化位弧度，radians(30)。 log 开对数，log(x,y)，即 \\(\\log_y x\\) ，y默认是e。 exp 指数函数，exp(x)。 pow 扩展了内置方法，现在支持float了。pow(x,y) 这里简单写个例子： >>> from math import * >>> print ( pi ) 3.141592653589793 >>> print ( sqrt ( 85 )) 9.219544457292887 >>> print ( round ( sin ( radians ( 30 )), 1 )) #sin(30°) 0.5 更多内容请参见 官方文档 。 random模块 random模块提供了一些函数来解决随机数问题。 random random函数产生0到1之间的随机实数（包括0）。\\ ​ random()->[0.0, 1.0)。 uniform uniform函数产生从a到b之间的随机实数（a，b的值指定，包括a。）。\\ ​ uniform(a,b)->[a.0, b.0)。 randint randint函数产生从a到b之间的随机整数，包含a和b。\\ ​ randint(a,b)->[a,b] choice choice随机从一个列表或者字符串中取出一个元素。 randrange randrange函数产生从a到b之间的随机整数，步长为c（a，b，c的值指定，相当于choice(range(a,b,c))。整数之间就用randint函数吧，这里函数主要是针对range函数按照步长从而生成一些整数序列的情况。 sample(p,k) sample函数从p中随机选取唯一的元素（p一般是range(n)或集合之类的，这里所谓的唯一的意思就是不放回抽样的意思，但如果p样品里面有重复的元素，最后生成的列表还是会有重复的元素的。）然后组成k长度的列表返回。 下面是一个简单的例子： >>> from random import * >>> print ( random ()) 0.36882919781549717 >>> print ( uniform ( 1 , 10 )) 2.771065174892699 >>> print ( randrange ( 1 , 6 )) 1 >>> print ( randint ( 1 , 10 )) 3 >>> print ( choice ( 'abcdefghij' )) j >>> print ( choice ([ '1' , '2' , '3' ])) 2 作为随机实数，所谓开始包含的那个临界值可能数学意义大于实际价值，你可以写一个类似下面的小脚本看一下，随机实数是很难随机到某个具体的数的。 from random import * i = 0 while True : x = uniform ( 0 , 2 ) if x == 0 : print ( i ) break else : print ( x ) i += 1 从上一个例子我们看到，虽然我不确定随具体随机到某个实数的概率是不是永远也没有可能，但肯定很小很小。所以如果我们要解决某个问题，需要某个确定的概率的话还是用随机整数好一些。 更多内容请参见 官方文档 。 statistics模块 这个模块python3.4才加入进来。 上面的那个例子这里稍作修改，使之成为一个骰子模拟器。其中 i_list 这个列表收集多次实验中掷多少次骰子才遇到6的次数。 from random import * i_list = [] while len ( i_list ) < 100 : i = 1 while True : #一次实验 x = randint ( 1 , 6 ) if x == 6 : print ( 'times:' , i ) break else : print ( x ) i += 1 i_list . append ( i ) print ( i_list ) from statistics import * print ( mean ( i_list )) #平均值 print ( median ( i_list )) #中位数，去掉最高最低... statistics模块中的 mean 函数接受一组数值列表，然后返回这组数值的平均值。而 median 函数返回的是统计学上所谓的中位数，你可以简单看作一组数字不断的去掉一个最高和最低，然后剩下来的一个或者两个（两个要取平均值）的数值的值。 更多内容请参见 官方文档 。 序列 字符串，列表，元组（tuple，这里最好翻译成元组，因为里面的内容不一定是数值。）都是序列（sequence）的子类，所以序列的一些性质他们都具有，最好在这里一起讲方便理解记忆。 len函数 len函数返回序列所含元素的个数： string001='string' list001=['a','b','c'] tuple001=(1,2,3,4) for x in [string001,list001,tuple001]: print(len(x)) 6 3 4 >>> 调出某个值 对于序列来说后面跟个方括号，然后加上序号（程序界的老规矩，从0开始计数。），那么调出对应位置的那个值。还以上面那个例子来说明。 string001='string' list001=['a','b','c'] tuple001=(1,2,3,4) for x in [string001,list001,tuple001]: print(x[2]) r c 3 >>> 倒着来 倒着来计数-1表示倒数第一个，-2表示倒数第二个。依次类推。 string001='string' list001=['a','b','c'] tuple001=(1,2,3,4) for x in [string001,list001,tuple001]: print(x[-1],x[-2]) g n c b 4 3 调出多个值 前面不写表示从头开始，后面不写表示到达尾部。中间加个冒号的形式表示从那里到那里。这里 注意 后面那个元素是进来，看来python区间的默认含义都是包头不包尾。这样如果你想要最后一个元素也进去，只有使用默认的不写形式了。 string001='string' list001 = [ 'a' , 'b' , 'c' ] tuple001= ( 1 , 2 , 3 , 4 ) for x in [ string001 , list001 , tuple001 ] : print ( x [ 1 : 3 ], x [ - 2 :- 1 ], x [:- 1 ], x [ 1 : ], x [ 1 :- 1 ]) tr n strin tring trin [ 'b' , 'c' ] [ 'b' ] [ 'a' , 'b' ] [ 'b' , 'c' ] [ 'b' ] ( 2 , 3 ) ( 3 ,) ( 1 , 2 , 3 ) ( 2 , 3 , 4 ) ( 2 , 3 ) 用数学半开半闭区间的定义来理解这里的包含关系还是很便捷的。 首先是数学半开半闭区间，左元素和右元素都是之前叙述的对应的定位点。左元素包含右元素不包含。 其次方向应该是从左到右，如果定义的区间是从右到左，那么将产生空值。 如果区间超过，那么从左到右包含的所有元素就是结果，。 最后如果左右元素定位点相同，那么将产生空值，比如：\\ string001[2:-4] ，其中2和-4实际上是定位在同一个元素之上的。额外值得一提的列表插入操作，请参看列表的插入操作这一小节。 序列反转 这是python最令人叹为观止的地方了，其他的语言可能对列表啊什么的反转要编写一个复杂的函数，我们python有一种令人感动的方法。 string001='string' list001 = [ 'a' , 'b' , 'c' ] tuple001= ( 1 , 2 , 3 , 4 ) for x in [ string001 , list001 , tuple001 ] : print ( x [ ::- 1 ]) gnirts [ 'c' , 'b' , 'a' ] ( 4 , 3 , 2 , 1 ) 之前在range函数的介绍时提及序列的索引和range函数的参数设置很是类似，这是我们可以参考理解之，序列（列表，字符串等）的索引参数 [start:end:step] 和range函数的参数设置一样，第一个参数是起步值，第二个参数是结束值，第三个参数是步长。这里end不填都好理解，就是迭代完即可，不过如果step是负数，似乎起点不填默认的是-1。 然后range函数生成的迭代器对象同样接受这种索引参数语法，看上去更加的怪异了： >>> range ( 1 , 10 , 2 ) range ( 1 , 10 , 2 ) >>> range ( 1 , 10 , 2 )[ ::- 2 ] range ( 9 , - 1 , - 4 ) >>> list ( range ( 1 , 10 , 2 )) [ 1 , 3 , 5 , 7 , 9 ] >>> list ( range ( 1 , 10 , 2 )[ ::- 2 ]) [ 9 , 5 , 1 ] 我们可以看到对range函数进行切片操作之后返回的仍然是一个range对象，经过了一些修正。似乎这种切片操作和类的某个特殊方法有关，和python的slice对象有关。 序列的可更改性 字符串不可以直接更改，但可以组合成为新的字符串；列表可以直接更改；元组不可以直接更改。 序列的加法和减法 两个字符串相加就是字符串拼接了。乘法就是加法的重复，所以一个字符串乘以一个数字就是自己和自己拼接了几次。列表还有元组和字符串一样大致情况类似。 print('abc'+'def') print('abc'*3) print([1,2,3]+[4,5,6]) print((0,'a')*2) abcdef abcabcabc [1, 2, 3, 4, 5, 6] (0, 'a', 0, 'a') 字符串 python语言不像c语言，字符和字符串是不分的，用单引号或者双引号包起来就表示一个字符串了。单引号和双引号并没有什么特别的区别，只是如果字符串里面有单引号，那么就使用双引号，这样单引号直接作为字符处理而不需要而外的转义处理------所谓转义处理和其他很多编程语言一样用\\符号。比如要显示 ' 就输入 \\' 。 三单引号和三双引号 在单引号或者双引号的情况下，你可以使用 \\n 来换行，其中\\n表示换行。此外还可以使用三单引号\"'或者三双引号\\\"\\\"\\\"来包围横跨多行的字符串，其中换行的意义就是换行，不需要似前面那样的处理。 print('''\\ 这是一段测试文字 this is a test line 其中空白和 换行都所见所得式的保留。''') startswith方法 >>> x = 'helloABC' >>> x 'helloABC' >>> x.startswith('hello') True >>> x.endswith('ABC') True startswith 测试字符串是否以某个子字符串开始 endswith 测试某个字符串是否以某个子字符串结束 find方法 字符串的find方法可用来查找某个子字符串，没有找到返回-1，找到了返回字符串的偏移量。用法就是： s.find('d') 。 replace方法 字符串的replace方法进行替换操作，接受两个参数：第一个参数是待匹配的子字符串，第二个参数是要替换成为的样子。 >>> print('a b 11 de'.replace('de','ding')) a b 11 ding >>> print('1,1,5,4,1,6'.replace('1','replaced')) replaced,replaced,5,4,replaced,6 upper方法 将字符串转换成大写形式。 >>> str='str' >>> str.upper() 'STR' 类似的还有： lower 都变成小写 capitalize 首字母大写，其它都小写。 isdigit方法 isdigit 测试是不是数字 isalpha 测试是不是字母 isalnum 测试是不是数字或字母 。 split方法 字符串的split方法可以将字符串比如有空格或者逗号等分隔符分割而成，可以将其分割成子字符串列表。默认是空格是分隔符。 >>> string='a=1,b=2,c=3' >>> string.split(',') ['a=1', 'b=2', 'c=3'] splitline方法 把一个字符串按照行分开。这个可以用上面的split方法然后接受 \\n 参数来实现，所不同的是splitline方法不需要接受参数： >>> string 'this is line one\\nthis is line two\\nthis is line three' >>> string.splitlines() ['this is line one', 'this is line two', 'this is line three'] >>> string.split('\\n') ['this is line one', 'this is line two', 'this is line three'] join方法 字符串的join方法非常有用，严格来说它接受一个迭代器参数，不过最常见的是列表。将列表中的多个字符串连接起来，我们看到他采用了一种非常优雅的方式，就是只有两个字符串之间才插入某个字符，这正是我们所需要的。具体例子如下所示： >>> list001=['a','b','c'] >>> \"\".join(list001) 'abc' >>> ','.join(list001) 'a,b,c' strip方法 rstrip方法 字符串右边的空格都删除。换行符也会被删除掉。 lstrip方法 类似rstrip方法，字符串左边的空格都删除。换行符也会被删除掉。 format方法 字符串的format方法方便对字符串内的一些变量进行替换操作，其中花括号不带数字跟format方法里面所有的替换量，带数字0表示第一个替换量，后面类推。此外还可以直接用确定的名字引用。 >>> print('1+1={0}，2+2={1}'.format(1+1,2+2)) 1+1=2，2+2=4 >>> print('my name is {name}'.format(name='Jim T Kirk')) my name is Jim T Kirk 转义和不转义 \\n \\t 这是一般常用的转义字符，换行和制表。此外还有 \\\\ 输出\\符号。 如果输出字符串不想转义那么使用如下格式： >>> print(r'\\t \\n \\test') \\t \\n \\test count方法 统计字符串中某个字符或某一连续的子字符串出现的次数。 >>> string = 'this is a test line.' >>> string.count('this') 1 >>> string.count('t') 3 r什么的方法 rfind rindex rjust rsplit ，这些方法有时会很有用，而具体其含义的理解就对应于： find index ljust split。 我想大家应该看一下就知道了，区别就是从右往左了。 列表 方括号包含几个元素就是列表。 列表的插入操作 字符串和数组都不可以直接更改所以不存在这个问题，列表可以。其中列表还可以以一种定位在相同元素的区间的方法来实现插入操作，这个和之前理解的区间多少有点违和，不过考虑到定位在相同元素的区间本来就概念模糊，所以在这里就看作特例，视作在这个插入吧。 list001 = [ 'one' , 'two' , 'three' ] list001 [ 1 :- 2 ] = [ 'four' , 'five' ] print ( list001 ) [ 'one' , 'four' , 'five' , 'two' , 'three' ] extend方法似乎和列表之间的加法重合了，比如list.extend([4,5,6])就和list=list+[4,5,6]是一致的，而且用加法表示还可以自由选择是不是覆盖原定义，这实际上更加自由。 insert方法也就是列表的插入操作： >>> list = [1,2,3,4] >>> list.insert(0,5) >>> list [5, 1, 2, 3, 4] >>> list.insert(2,'a') >>> list [5, 1, 'a', 2, 3, 4] append方法 python的append方法就是在最后面加 一个元素 ，如果你append一个列表那么这一个列表整体作为一个元素。然后append方法会永久的改变了该列表对象的值。 记住，append等等原处修改列表的方法都是没有返回值的。 ​ >>> list = [1,2,3,4] ​ >>> list.append(5) ​ >>> list ​ [1, 2, 3, 4, 5] 如果你希望不改动原列表的附加，请使用加法来操作列表。 reverse方法 reverse方法不接受任何参数，直接将一个列表翻转过来。如果你希望不改变原列表的翻转，有返回值，请使用如下方法： >>> list [ 1 , 2 , 3 , 4 , 5 ] >>> listNew = list [ ::- 1 ] >>> list [ 1 , 2 , 3 , 4 , 5 ] >>> listNew [ 5 , 4 , 3 , 2 , 1 ] copy方法 copy方法复制返回本列表。 sort方法 也就是排序，改变列表。默认是递增排序，可以用 reverse=True 来调成递减排序。 默认的递增排序顺序如果是数字那么意思是数字越来越大，如果是字符那么（似乎）是按照ACSII码编号递增来排序的。如果列表一些是数字一些是字符会报错。 >>> list = ['a','ab','A','123','124','5'] >>> list.sort() >>> list ['123', '124', '5', 'A', 'a', 'ab'] sort方法很重要的一个可选参数 key=function ，这个function函数就是你定义的函数（或者在这里直接使用lambda语句。），这个函数只接受一个参数，就是排序方法（在迭代列表时）接受的当前的那个元素。下面给出一段代码，其中tostr函数将接受的对象返回为字符，这样就不会出错了。 def tostr(item): return str(item) list001 = ['a','ab','A',123,124,5] list001.sort(key=tostr) print(list001) [123, 124, 5, 'A', 'a', 'ab'] sorted函数 sorted函数在这里和列表的sort方法最大的区别是它返回的是而不是原处修改。其次sorted函数的第一个参数严格来说是所谓的可迭代对象，也就是说它还可以接受除了列表之外的比如等可迭代对象。至于用法他们两个差别不大。 >>> sorted((1,156,7,5)) [1, 5, 7, 156] >>> sorted({'andy':5,'Andy':1,'black':9,'Black':55},key=str.lower) ['Andy', 'andy', 'black', 'Black'] 上面第二个例子调用了 str.lower 函数，从而将接受的item，这里比如说'Andy'，转化为andy，然后参与排序。也就成了对英文字母大小写不敏感的排序方式了。 字典按值排序 同样类似的有字典按值排序的方法 3 ： >>> sorted({'andy':5,'Andy':1,'black':9,'Black':55}.items(),key=lambda i: i[1]) [('Andy', 1), ('andy', 5), ('black', 9), ('Black', 55)] 这个例子先用字典的items方法处理返回(key,value)对的可迭代对象，然后用后面的lambda方法返回具体接受item的值，从而根据值来排序。 中文排序 下面这个例子演示了如何对中文名字排序。整个函数的思路就是用 pypinyin （一个第三方模块），将中文姓名的拼音对应出来，然后组成一个列表，然后根据拼音对这个组合列表排序，然后生成目标列表。 list001 = [ '张三' , '李四' , '王二' , '麻子' , '李二' , '李一' ] def zhsort ( lst ): from pypinyin import lazy_pinyin pinyin = [ lazy_pinyin ( lst [ i ]) for i in range ( len ( lst ))] lst0 = [( a , b ) for ( a , b ) in zip ( lst , pinyin )] lst1 = sorted ( lst0 , key = lambda d : d [ 1 ]) return [ x [ 0 ] for x in lst1 ] print ( zhsort ( list001 )) [ '李二' , '李四' , '李一' , '麻子' , '王二' , '张三' ] reversed函数 前面提到过序列反转可以这样做: lst [ ::- 1 ] 不过更加推荐的做法是直接用reversed函数来做，reversed函数返回的是个可迭代对象。 string001='string' list001=['a','b','c'] tuple001=(1,2,3,4) for x in [string001,list001,tuple001]: print(list(reversed(x))) ['g', 'n', 'i', 'r', 't', 's'] ['c', 'b', 'a'] [4, 3, 2, 1] 然后我们马上就想到，列表有 reverse 方法，其是破坏型的方法，然后类似的还有 sort 方法，破坏型的，其对应非破坏型方法有 sorted 。一般使用没有特别需求时都应该使用非破坏型方法，reversed，sorted等等。 删除某个元素 赋空列表值，相当于所有元素都删除了。 pop方法：接受一个参数，就是列表元素的定位值，然后那个元素就删除了，方法并返回那个元素的值。如果不接受参数默认是删除最后一个元素。 remove方法：移除第一个相同的元素，如果没有返回相同的元素，返回错误。 del函数：删除列表中的某个元素。 >>> list001=['a','b','c','d','e'] >>> list001.pop(2) 'c' >>> list001 ['a', 'b', 'd', 'e'] >>> list001.pop() 'e' >>> list001 ['a', 'b', 'd'] >>> list001.remove('a') >>> list001 ['b', 'd'] >>> del list001[1] >>> list001 ['b'] count方法 统计某个元素出现的次数。 >>> list001=[1,'a',100,1,1,1] >>> list001.count(1) 4 index方法 index方法返回某个相同元素的偏移值。 >>> list001=[1,'a',100] >>> list001.index('a') 1 列表解析 我们来看下面这个例子： def square(n): return n*n print(list(map(square,[1,2,3,4,5]))) print([square(x) for x in [1,2,3,4,5]]) [1, 4, 9, 16, 25] [1, 4, 9, 16, 25] map函数将某个函数应用于某个列表的元素中并生成一个map对象（可迭代对象），需要外面加上list函数才能生成列表形式。第二种方式更有python风格，是推荐使用的列表解析方法。 在python中推荐多使用迭代操作和如上的列表解析风格，因为python中的迭代操作是直接用c语言实现的。 列表解析加上过滤条件 for语句后面可以跟一个if子句表示过滤条件，看下面的例子来理解吧： >>> [s*2 for s in ['hello','abc','final','help'] if s[0] == 'h'] ['hellohello', 'helphelp'] 这个例子的意思是列表解析，找到的元素进行乘以2的操作，其中过滤条件为字符是h字母开头的，也就是后面if表达式不为真的元素都被过滤掉了。 完整的列表解析结构 下面给出一个完整的列表解析结构，最常见的情况一般就一两个for语句吧，这里if外加个括号是可选项的意思。 [ expression for var1 in iterable1 [if condition1 ] for var2 in iterable2 [if condition2 ] ........ ] 这里的逻辑是从左到右第一个for语句就是最先执行的for语句，然后是第二个for语句跟着执行。 这里的iterable1是指某个可迭代对象，也就是说那些能够返回可迭代对象的函数比如map，filter，zip，range等函数都可以放进去。不过我们要克制自己在这里别写出太过于晦涩的程序了。还有for循环语句也别嵌套太多了，这样就极容易出错的。 下面这个程序大家看看： >>> [x+str(y) for x in ['a','b','c'] for y in [1,2,3,4,5,6] if y & 1] ['a1', 'a3', 'a5', 'b1', 'b3', 'b5', 'c1', 'c3', 'c5'] >>> [x+str(y) for x in ['a','b','c'] for y in [1,2,3,4,5,6] if not y & 1] ['a2', 'a4', 'a6', 'b2', 'b4', 'b6', 'c2', 'c4', 'c6'] Notice: 推荐不要写带两个for语句以上的列表解析，参看[高质量python代码] 。 列表解析的好处 在熟悉列表解析的语句结构之后，一两个for语句不太复杂的情况下，还是很简单明了的。同时语法也更加精炼，同时运行速度较for循环要至少快上一倍。最后python的迭代思想深入骨髓，以后python的优化工作很多都围绕迭代展开，也就是多用列表解析会让你的代码以后可能运行的更快。 有这么多的好处，加上这么cool的pythonic风格，推荐大家多用列表解析风格解决问题。 元组的生成 这个时候需要明确加个括号表示这是一个元组对象。 >>> [(x,x**2) for x in range(5)] [(0, 0), (1, 1), (2, 4), (3, 9), (4, 16)] for语句中列表可变的影响 一般情况for迭代某个可迭代对象就是可迭代对象返回一个值然后利用这个值赋值并进行下面的操作，但是列表却是一个可变的东西，如果列表在操作中被修改了，情况会怎样呢？ lst = [1,2,3,4,5] index = 0 for x in lst: lst.pop(index) print(x) 1 3 5 具体这个过程的细节我不清楚，但确定的是在这里for语句并没有记忆原列表，而只是记忆了返回次数或者偏移值。 列表元素替换 推荐用列表解析方法来实现列表元素的替换功能。 def replace(x,a,b): if x == a: return b else: return x lst=[1,5,4,1,6] >>> [replace(i,1,'replaced') for i in lst] ['replaced', 5, 4, 'replaced', 6] 列表元素去重 列表元素去重推荐用后来的set集合对象来处理之，其会自动去除重复的元素。 >>> lst = [1,2,3,4,5,1,2,3,4,5] >>> [i for i in set(lst)] [1, 2, 3, 4, 5] 元组 圆括号包含几个元素就是元组(tuple)。元组和列表的不同在于元组是不可改变。元组也是从属于序列对象的，元组的很多方法之前都讲了。而且元组在使用上和列表极其接近，有很多内容这里也略过了。 值得一提的是如果输入的时候写的是 x,y 这样的形式，实际上表达式就加上括号了，也就是一个元组了 (x,y) 。 生成器表达式 类似列表解析，如果元组在这里解析也是返回的元组吗？这里并不是如此，前面谈到python中一般表达式的圆括号是忽略了的，所以这里的元组解析表示式有个更专门的名字叫做生成器表达式，它返回的是生成器对象，和生成器函数具体调用之后返回的对象是一样的。生成器对象具有 __next__ 方法，可以调用next函数。 >>> x = [i for i in [1,2,3]] >>> x [1, 2, 3] >>> y = (i for i in [1,2,3]) >>> y <generator object <genexpr> at 0xb70dbe8c> 字典 与列表一样字典是可变的，可以像列表一样引用然后原处修改，del语句也适用。 并非所有对象都可以做字典key，在python中所有的内置不可变对象都是可散列的，所有的可变对象都是不可散列的。而只有可散列的才可以做字典的key。可散列的对象具有： 具有 __hash__ 方法，这样可以比较大小 具有 __eq__ 方法，这样可以判断相等。 所有值得一提的就是元组是可以做字典的key的。这里顺便提一下元组是如何比较大小的，在python中元组比较大小是： 元组和列表的比较大小 元组和列表的相等判断还是很好理解的，而对于这样的东西: >>> (1,-1) < (2,-2) 确实就有点古怪了。请读者参考 这个网页 )，按照官方文档的说明： Tuples and lists are compared lexicographically using comparison of corresponding elements. This means that to compare equal, each element must compare equal and the two sequences must be of the same type and have the same length. 官方文档对于大于小于的情况并没有说得很清楚，然后我们从字里行间大体领会的精神是: 可迭代对象比较大小，是逐个比较的。 可迭代对象比较和相等测试最后一定返回True或False。 逐个比较首先比较是不是相等，如果相等则跳过这个元素的比较，直到遇到某两个不相等的元素，然后返回的就是这两个元素的比较结果。 最后快比较完了（以最小的可迭代对象长度为准），然后如果是相等判断操作，则长度相等就认为两者相等了；而如果是大小判断操作，则认为长度更长的那个对象更大。 下面是一些例子: >>> (1,-1) < (2,-2) True >>> (1,-1) < (-1,-2) False >>> (1,-1,-3) < (1,-1) False >>> (1,-1,) < (1,-1,0) True 创建字典 字典是一种映射，并没有从左到右的顺序，只是简单地将键映射到值。字典的声明格式如下： dict001={'name':'tom','height':'180','color':'red'} dict001['name'] 或者创建一个空字典，然后一边赋值一边创建对应的键： dict002={} dict002['name']='bob' dict002['height']=195 根据列表创建字典 如果是[['a',1],['b',2],['c',3]]这样的形式，那么直接用dict函数处理就变成字典了，如果是['a','b','c']和[1,2,3]这样的形式那么需要用zip函数处理一下，然后用dict函数处理一次就变成字典了： >>> lst [['a', 1], ['b', 2], ['c', 3]] >>> dict001=dict(lst) >>> dict001 {'a': 1, 'b': 2, 'c': 3} 字典里面有字典 和列表的不同就在于字典的索引方式是根据\"键\"来的。 dict003={'name':{'first':'bob','second':'smith'}} dict003['name']['first'] 字典遍历操作 字典特定顺序的遍历操作的通用做法就是通过字典的keys方法收集键的列表，然后用列表的sort方法处理之后用for语句遍历，如下所示： dict={'a':1,'c':2,'b':3} dictkeys=list(dict.keys()) dictkeys.sort() for key in dictkeys: print(key,'->',dict[key]) 警告 ：上面的例子可能对python早期版本并不使用，保险起见，推荐使用sorted函数，sorted函数是默认对字典的键进行排序并返回键的值组成的列表。 dict={'a':1,'c':3,'b':2} >>> for key in sorted(dict): ... print(key,'->',dict[key]) ... a -> 1 b -> 2 c -> 3 如果你对字典遍历的顺序没有要求，那么就可以简单的这样处理： >>> for key in dict: ... print(key,'->',dict[key]) ... c -> 2 a -> 1 b -> 3 keys方法 收集键值，返回。 values方法 和keys方法类似，收集的值，返回。 >>> dict001.values() dict_values([3, 1, 2]) >>> list(dict001.values()) [3, 1, 2] items方法 和keys和values方法类似，不同的是返回的是(key,value)对的。 >>> dict001.items() dict_items([('c', 3), ('a', 1), ('b', 2)]) >>> list(dict001.items()) [('c', 3), ('a', 1), ('b', 2)] 嗯，python2上面的三个方法是直接返回的列表，python3返回可迭代对象更节省计算资源些。 字典的in语句 可以看到in语句只针对字典的键，不针对字典的值。 >>> dict001={'a':1,'b':2,'c':3} >>> 2 in dict001 False >>> 'b' in dict001 True 字典对象的get方法 get方法是去找某个键的值，为什么不直接引用呢，get方法的好处就是某个键不存在也不会出错。 >>> dict001={'a':1,'b':2,'c':3} >>> dict001.get('b') 2 >>> dict001.get('e') update方法 感觉字典就是一个小型数据库，update方法将另外一个字典里面的键和值覆盖进之前的字典中去，称之为更新，没有的加上，有的覆盖。 >>> dict001={'a':1,'b':2,'c':3} >>> dict002={'e':4,'a':5} >>> dict001.update(dict002) >>> dict001 {'c': 3, 'a': 5, 'e': 4, 'b': 2} pop方法 pop方法类似列表的pop方法，不同引用的是键，而不是偏移地址，这个就不多说了。 字典解析 这种字典解析方式还是很好理解的。 >>> dict001={x:x**2 for x in [1,2,3,4]} >>> dict001 {1: 1, 2: 4, 3: 9, 4: 16} zip函数创建字典 可以利用zip函数来通过两个可迭代对象平行合成一个配对元素的可迭代对象，然后用dict函数将其变成字典对象。 >>> dict001=zip(['a','b','c'],[1,2,3]) >>> dict001 <zip object at 0xb7055eac> >>> dict001=dict(dict001) >>> dict001 {'c': 3, 'b': 2, 'a': 1} 集合 python实现了数学上的无序不重复元素的集合概念，在前面讨论列表去重元素的时候我们提到过正好可以利用集合的这一特性。 >>> list001=[1,2,3,1,2,4,4,5,5,5,7] >>> {x for x in list001} {1, 2, 3, 4, 5, 7} >>> set(list001) {1, 2, 3, 4, 5, 7} 用集合解析的形式表示出来就是强调set命令可以将任何可迭代对象都变成集合类型。当然如果我们希望继续使用列表的话使用list命令强制类型转换为列表类型即可，不过如果我们在应用中确实一致需要元素不重复这一特性，就可以考虑直接使用集合作为主数据操作类型。 集合也是可迭代对象。关于可迭代对象可以进行的列表解析操作等等就不啰嗦了。下面介绍集合的一些操作。 集合添加元素 值得一提的是如果想创建一个空的集合, 需要用set命令，用花括号系统会认为你创建的是空字典。然后我们看到用集合的 add 方法添加，那些重复的元素是添加不进来的。 警告 ：值得一提的是集合只能包括不可变类型，因此列表和字典不能作为集合内部的元素。元组不可变，所以可以加进去。 >>> set001=set() >>> set001.add(1) >>> set001 {1} >>> set001.add(2) >>> set001 {1, 2} >>> set001.add(1) >>> set001 {1, 2} 或者使用update方法一次更新多个元素： >>> set001=set('a') >>> set001.update('a','b','c') >>> set001 {'b', 'a', 'c'} 集合去掉某个元素 有两个集合对象的方法可以用于去掉集合中的某个元素，discard方法和remove方法，其中discard方法如果删除集合中没有的元素那么什么都不会发生，而remove方法如果删除某个不存在的元素那么会产生KeyError。 >>> set001=set('hello') >>> set001.discard('h') >>> set001 {'e', 'o', 'l'} >>> set001.discard('l') >>> set001 {'e', 'o'} remove方法与之类似就不做演示了。 两个集合之间的关系 子集判断 集合对象有一个issubset方法用于判断这个集合是不是那个集合的子集。 >>> set001=set(['a','b']) >>> set002=set(['a','b','c']) >>> set001.issubset(set002) True 还有更加简便的方式比较两个集合之间的关系，那就是>，\\<，>=，\\<=，==这样的判断都是适用的。也就是set001是set002的子集，它的元素set002都包含，那么set001\\<=set002，然后真子集的概念就是set001\\<set002即不等于即可。 两个集合之间的操作 下面的例子演示的是两个集合之间的交集： & ，并集： | ，差集： - 。 >>> set001=set('hello') >>> set002=set('hao') >>> set001 & set002 #交集 {'o', 'h'} >>> set001 | set002 #并集 {'h', 'l', 'a', 'e', 'o'} >>> set001 - set002 #差集 {'e', 'l'} 类似的集合对象还有intersection方法，union方法，difference方法： >>> set001=set('hello') >>> set002=set('hao') >>> set001.intersection(set002) #交集 {'h', 'o'} >>> set001.union(set002) #并集 {'e', 'a', 'h', 'o', 'l'} >>> set001.difference(set002) #差集 {'e', 'l'} clear方法 将一个集合清空。 copy方法 类似列表的copy方法，制作一个集合copy备份然后赋值给其他变量。 pop方法 无序弹出集合中的一个元素，直到没有然后返回KeyError错误。 bytes类型 基本编码知识 具体存储在计算机里面的都是二进制流，而如果要将其正确解析成为对应的字符，是需要建立一定的编码规则的。比如大家熟悉的ASCⅡ编码规则。ACSⅡ编码是Latin-1和utf-8等编码的子集，也就是一连串基于ACSⅡ编码的字符串用utf-8编码也能正确解析。 python2中目前也支持 bytes 类型了 [&#94;5] 。然后python2还有一个 unicode 类型。 bytes简单的理解就是没有任何字符含义的二进制字节流。然后如这样 b'test' ，在前面加个字符b或者B，其将解析为bytes类型。 >>> x = b'test' >>> x b'test' >>> type(x) <class 'bytes'> >>> x[0] 116 >>> x[1] 101 >>> list(x) [116, 101, 115, 116] >>> python在打印时会尽可能打印可见字符，尽管上面的x打印显示出了具体的test这个字符，但我们应该认为x是一连串的数字序列而不具有任何字符串含义，如果我们调用bytes类型的 decode 方法，那么bytes类型解码之后将变成str类型。 >>> y = x.decode('utf-8') >>> y 'test' >>> type(y) <class 'str'> 当然具体编码方式是否正确，是否正确解析了原bytes字节流那又是另外一回事了。比如还可能是big5或者GB什么的编码。 此外字符串str类型有个 encode 方法可以进行编码操作从而输出对应编码的bytes字节流。 使用方法 我们可以如下看一下str类型和bytes类型具体有那些方法差异: >>> set(dir('abc')) - set(dir(b'abc')) {'isdecimal', 'casefold', '__rmod__', 'format_map', 'format', 'encode', '__mod__', 'isnumeric', 'isprintable', 'isidentifier'} >>> set(dir(b'abc')) - set(dir('abc')) {'decode', 'fromhex'} 我们看到bytes和str几乎拥有相同的功能，所以大部分之前学到的用于str字符串类型的那些方法同样可以用于bytes类型中。这多少有点方法泛滥了，因为bytes是字节流类型，内在是没有字符含义的，可能某些方法并不推荐使用。 比如下面的upper方法和replace方法: >>> b't'.upper() b'T' >>> b'testst'.replace(b'st',b'oo') b'teoooo' 然后字节流的连接可以很方便的用加法或join方法来进行，如下所示: >>> b't' + b'e' b'te' >>> b''.join([b'a',b'c']) b'ac' 但是要 注意 ，python2里面不管是加法还是join方法都将丢掉那个b修饰符[&#94;6]: >>> b''.join([b'a',b'c']) 'ac' >>> b'a' + b'b' 'ab' 不过这也无关紧要，因为python2里面我们可以理解str就对应的是python3的bytes类型，然后unicode对应的就是python3的str类型。 bytearray类型 bytearray和bytes类型类似，而且其内部支持的方法和操作也和bytes类型类似，除了其更像是一个列表，可以原处修改而字符串和bytes是不可变的。python2现在也有bytearray类型了，只是内在的文本和二进制是不分的。 文件 文件对象是可迭代对象。 写文件 对文件的操作首先需要用 open 函数创建一个文件对象，简单的理解就是把相应的接口搭接好。文件对象的 write 方法进行对某个文件的写操作，最后需要调用 close 方法写的内容才真的写进去了。 file001 = open('test.txt','w') file001.write('hello world1\\n') file001.write('hello world2\\n') file001.close() 如果你们了解C语言的文件操作，在这里会为python语言的简单便捷赞叹不已。就是这样三句话：创建一个文件对象，然后调用这个文件对象的wirte方法写入一些内容，然后用close方法关闭这个文件即可。 读文件 一般的用法就是用 open 函数创建一个文件对象，然后用 read 方法调用文件的内容。最后记得用 close 关闭文件。 file001 = open('test.txt') filetext=file001.read() print(filetext) file001.close() 此外还有 readline 方法是一行一行的读取某文件的内容。 open函数的处理模式 open函数的处理模式如下： 'r' 默认值，read，读文件。 'w' wirte，写文件，如果文件不存在会创建文件，如果文件已存在，文件原内容会清空。 'a' append，附加内容，也就是后面用write方法内容会附加在原文件之后。 'b' 处理模式设置的选项，'b'不能单独存在，要和上面三个基本模式进行组合，比如'rb'等，意思是二进制数据格式读。 '+' 处理模式设置的选项，同样'+'不能单独存在，要和上面三个基本模式进行组合，比如'r+'等，+是updating更新的意思，也就是既可以读也可以写，那么'r+'，'w+'，'a+'还有什么区别呢？区别就是'r+'不具有文件创建功能，如果文件不存在会报错，然后'r+'不会清空文件，如果'r+'不清空文件用write方法情况会有点复杂；而'w+'具有文件创建功能，然后'w+'的write方法内容都是重新开始的；而'a+'的write方法内容是附加在原文件上的，然后'a+'也有文件创建功能。 用with语句打开文件 类似之前的例子我们可以用with语句来打开文件，这样就不用close方法来关闭文件了。然后with语句来提供了类似try语句的功能可以自动应对打开文件时的一些异常情况。 with open('test.txt','w') as file01: file01.write('hello world1\\n') file01.write('hello world2\\n') with open('test.txt','r') as file01: filetext=file01.read() print(filetext) is语句用来测试对象的同一性，就是真正是内存里的同一个东西，而不仅仅是值相同而已。==只是确保值相同。 ↩ 这些int、float等命令都是强制类型转换命令 ↩ 参考网站 ↩ if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js','mhchem.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"python语言","url":"articles/python-talk-two.html"},{"title":"python语言学习之-第一谈","text":"Python是个成功的脚本语言。它最初由Guido van Rossum开发，在1991年第一次发布。Python由ABC和Haskell语言所启发。Python是一个高级的、通用的、跨平台、解释型的语言。一些人更倾向于称之为动态语言。它很易学，Python是一种简约的语言。它的最明显的一个特征是，不使用分号或括号，Python使用缩进。现在，Python由来自世界各地的庞大的志愿者维护。 python现在主要有两个版本区别，python2和python3。作为新学者推荐完全使用python3编程，本文档完全基于python3。 安装和配置 python的安装和配置在linux没什么好说了，windows下的安装主要是编辑好系统环境变量 PATH 值，好让读者可以在cmd或者powershell下调用python命令。 这个初次安装的时候程序有这个选项的。 进入python的REPL环境 在终端中输入python即进入python语言的REPL环境，很多linux系统目前默认的是python2。你可以运行： python --version 来查看默认的python版本号。 要进入python3在终端中输入python3即可。 python命令行用法 命令行的一般格式就是： python3 [可选项] test.py [可选参数1 可选参数2] 同样类似的运行 python3 --help 即可以查看python3命令的一些可选项。比如加入 -i 选项之后，python执行完脚本之后会进入REPL环境继续等待下一个命令，这个在最后结果一闪而过的时候有用。 python执行脚本参数的传递 上面的命令行接受多个参数都没有问题的，不会报错，哪怕你在py文件并没有用到他们。在py文件中要使用他们，首先导入sys模块，然后sys.argv[0]是现在这个py文件在系统中的文件名，接下来的sys.argv[1]就是之前命令行接受的第一个参数，后面的就依次类推了。 代码注释 python语言的注释符号和bash语言（linux终端的编程语言）一样用的是#符号来注释代码。然后py文件开头一般如下面代码所示： 1 2 #!/usr/bin/env python3 #-*-coding:utf-8-*- 其中代码第一行表示等下如果py文件可执行模式执行那么将用python3来编译 1 ，第二行的意思是py文件编码是utf-8编码的，python3直接支持utf-8各个符号，这是很强大的一个更新。 多行注释可以利用编辑器快速每行前面加上#符号。 Unicode码支持 前面谈及python3是可以直接支持Unicode码的，如果以可执行模式加载，那么第二行需要写上： #-*-coding:utf-8-*- 这么一句。 读者请实验下面这个小例子，这将打印一个笑脸符号： 1 2 3 4 5 6 #!/usr/bin/env python3 #-*-coding:utf-8-*- print ( ' \\u263a ' ) ☺ >>> 上面的数字就是笑脸符号具体的Unicode码（十六进制）。 代码多行表示一行 这个技巧防止代码越界所以经常会用到。用反斜线 \\ 即可。不过更常用的是将表达式用圆括号 () 括起来，这样内部可以直接换行并继续。在python中任何表达式都可以包围在圆括号中。 一行表示多行 python中一般不用分号，但是分号的意义大致和bash或者c语言中的意义类似，表示一行结束的意思。其中c语言我们知道是必须使用分号的。 输入和输出 最基本的input和print命令 input函数请求用户输入，并将这个值赋值给某个变量。注意赋值之后类型是字符串，但后面你可以用强制类型转换------int函数（变成整数），float函数（变成实数），str函数（变成字符串）------将其转变过来。print函数就是一般的输出函数。 读者请运行下面的例子： x=input('请输入一个实数：') string='你输入的这个实数乘以2等于：'+ str(float(x)*2) print(string) __main__和__name__ 按照 这个网站 的讲解，如果当前这个py文件是被执行的，那么 __name__ 在本py文件中的值是 __main__ ，如果这个py文件是被作为模块引入的，那么 __name__ 在那个py文件中的值是本py文件作为模块的模块名。 比如说现在你随便新建一个test.py文件，这个py文件里面就简单打印 __name__ 的值，然后我们再打开终端，运行： python3 test.py 这个时候打印的是： __main__ 。而如果你进入python的REPL环境，再输入： import test 这个时候你会发现 __name__ 的值是字符 \"test\"。 如果是mymodule模块里的mymod.py文件（也就是新建一个mymodule文件夹，里面再新建一个mymod.py文件。），那么mymod.py文件里面其 __name__ 的值是 \"mymodule.mymod\"。 安装python高级知识 从源码安装python 从源码安装python，那么可能有其他一些依赖你需要预先安装。 zlib 和 zlib-devel opensll 和 openssl-devel ，如果遇到什么 ssl.h 文件找不到通常是缺少这个。 sqlite-devel 和你 import sqlite3 有关，否则将会提示找不到 _sqlite3 ，你需要重新编译python。 windows下使用pip windows下使用pip安装，如果是wheel包，那么可能就直接装上了，有些简单的直接安装源码即可，有些要调用cython编译过程的那么就必须确保python装上了 VC++ for python ，官网下载地址在 这里 。 额外提一点的是 Visual C++ Compiler for Python 2.7 的 math里面没有 rint 这个方法，总之和linux下还是稍微差异的。 也就是用chmod加上可执行权限那么可以直接执行了。第一行完整的解释是什么通过 env 程序来搜索python的路径，这样代码更具可移植性。这个问题还可以多说一点，后面会谈到virtualenv这个模块，类似上面这种引用python的写法是可以确保调用的是python虚拟环境下的python解释器。 ↩","tags":"python语言","url":"articles/python-talk-one.html"},{"title":"人工智能第一谈","text":"history 弗朗西斯·克里克在科学美国人中发表了一篇重要的文章《有关大脑的思考》，此君就是DNA结构的发现人之一，他那个时候已经将其天才思考投入到了对大脑的研究之中。 克里克认为尽管一直以来积累了大量有关大脑的详尽知识，但是大脑的工作原理对于人们来说仍是一个难解的迷。 他说：最明显的是在概念上缺乏一个总的框架。 这一振聋发聩的声音唤醒了《人工智能的未来》一书的作者——杰夫·霍金斯心中长久以来的那个愿望，去研究大脑，制造一个智能机器。 人工智能的关键人物首先当然是阿兰·图灵，他提出的\"通用计算\"的概念，证明了尽管建构细节上有所不同，但从根本上讲所有的计算机都是等效的。信息处理就是信息处理，从逻辑上讲，所有的数字计算机都是等效的。 然后图灵就开始考虑如何建造智能机器，他感到电脑可以智能化。然后他提出了一个著名的图灵检验。也就是如果一台电脑可以诱使一个询问者相信他是一个人，那么就可以说这台机器就具有智能了。 关于这点杰夫·霍金斯提出了自己不同的见解，他认为图灵和二十世纪上半叶占主导地位的心理学思潮——行为主义一样都犯了一个错误，他们都试图用行为来定义智能，确实行为是智能的一种表现，绝不是智能的本质或者对于智能的首要解释。当你独自一人思考的时候，你并没有任何外在行为，但是这不能否认你是智能的。 早期的人工智能热潮里面充斥着过度的自信，可以解一些数学证明题，可以虚构一个积木世界，可以下象棋，还有一些专家系统似乎可以解答一些问题。但是甚至是它们的创造者也认为它们不会像人一样思考。 1986年开始，杰夫·霍金斯把工作都辞了，全面开始学习有关智能和大脑功能理论的研究成果。与此同时，人工智能的第二个研究小高峰出现，代表就是神经网络。神经网络建造一个系统，不是编程计算机，而是模拟神经元的连接。这似乎是在一条正确的道路上，但是后来显示进展是令人失望的，弄出的一些仿真预测模型最后证明不用神经网络用一般的传统的编程方法也可以实现。这是因为他们的急功近利的思想，所有神经网络都建立在一些极为简单的模型上，相互少量连接的神经元排成三列。里面既没有反馈也没有时间概念。更重要的是新大脑皮层是一个统一的不断重复的层级结构，而任何神经网络都对这一结构缺乏认识。 真正认识人脑是开发智能机器的必由之路——杰夫·霍金斯 大脑，被一层薄薄的皮包覆着，这层皮就是新大脑皮层。杰夫·霍金斯相信智能就藏在新大脑皮层之中。 杰夫·霍金斯认为所有的智能都产生于新大脑皮层，另外丘脑和海马也有一定的作用。 古脑与人的各种欲望情感有关，所以杰夫·霍金斯认为早期智能机器没有类似人的欲望和情感也是可能的。 正常人的小脑受到损害正常生活也没有太大问题，小脑和原始的时间观念有关，但新大脑皮层会根据事件流产生出新的时间观念。还有其他大脑的一部分器官比如原始的行动控制部分等很大一部分功能都被新大脑皮层取代了。 人类的大脑皮层如果完全展开大约相当于4张A4打印纸的大小。且不管面积大小，大脑皮层纵向还分为六层。有人估计大约有300亿个神经元。我们的思想就是大脑细胞的产物，没有魔力，也没有特殊的浆汁。思想就是神经元和闪动的信息流构成的。我真希望你们能够感受到这一点是多么的奇妙。 蒙卡斯尔的假说 1978年，他发表了一篇论文《大脑功能的组织原则》，文章指出大脑皮层在外表上和结构上都惊人地相似，不论是主管视觉输入和主管触觉的大脑皮层区域、控制肌肉的区域、罗布卡语言区一起其他区域。实际上是完全一样的。他暗示说，这些区域虽然实际发挥的作用千差万别，但是他们完成功能的方法可能是完全相同的。 在蒙卡斯尔之前，就有解剖学家注意到了大脑皮层的惊人相似性，但是他们没有深究其中的含义。但是蒙卡斯尔却相信这种相似性意味着更多的东西。 大脑皮层之所以视觉区域看见，运动区域让肌肉运动，只是因为这些区域和中央神经系统的其他部分连接所决定的。 大脑皮层之间那些细小的差异正是上述不同连接的差异 所有的大脑皮层的功能区域都遵循着一个共同的算法，视觉、听觉、甚至运动输出之间没有任何差异。 威斯康辛州大学的生物医药工程学教授保尔·巴奇·瑞塔发明了一种在人的舌头上显示视觉模式的方法，戴上他的装置，盲人可以通过舌头来看东西了。其原理就是前额戴上一个小型摄像头，然后将影像信息一个像素一个像素地传输到舌头上的压力点上，视觉影像转化为了无数压力点模式。而大脑却很快学会了正确辨别这种模式。 2003年，韦恩使用了这个舌头装置，他看见一个球向他滚过来，他伸手抓起了桌上的一杯饮料。他走出去，看到了门，门框等等。他用舌头看见东西了！ 这个实例十分清楚地告诉我们大脑皮层是十分灵活的，不是死死地说某个区域是主管视觉的某个区域是管语言的。这种分工可能是人脑的基因决定的，但是大脑皮层的能力远不止如此。进入大脑的是模式，这些模式来自哪里并不重要，只要他们在时间上以固定的方式彼此联系，大脑就能感觉他们的存在。 所有感觉信息起初都是某种简单的点状信息。这些信息就是大脑处理的最小信息单元。这些感觉信息最终都会转化为一种空间-时间模式。想象一下，我们的空间观念和时间观念，无限延伸的扩展。所有的信息，一切信息似乎都在这种时空模式中找到了一个属于自己的只属于自己的位置。 这也就是说所有的感觉的模式信息在进入大脑皮层之后都是相同的，这带来一个疑惑，相同的模式信息，相同的处理方式，最后带来不同的理解效果。一个是听到了某个音符，一个是看到了某个颜色。其具体细节尚有不完善之处，但这个理论确实是简洁而优美的。 我们可以设想将来人或者说是机器人将能够直接看红外线，将能够直接感知超声波等等。昆虫就可以，但将来的改进人一定也能。 如果从这种角度来看现在的模式识别还有操控机器人行动的那种方法，简直就是可笑之极了。复杂的编程，最后突然情况稍一变化，机器人就傻了。但是如果对于以上问题，机器人视觉，机器人运动学等都统一到一起，一个算法，那确实将是一场革命。 大脑可以存储模式序列 顺着读字母表，按照乐谱弹钢琴，或者其他做事情的方式，都是一定的模式序列。而你发现大多数你想反过来做都困难重重，因为第一次做还没学习记忆进去。也就是说如果你记忆住了某个东西，那么这个东西是一种模式的序列信息。（一般是按照时间顺序，其实时间顺序和因果关系常常被人弄混，简单来说就是先有因果，再有时间。） 大脑可以自-联想回忆模式 上面存储的模式序列，如果你刚好激发了一个记忆片段，那么你的大脑有一种强烈的趋势要回忆起整个记忆信息。这个在神经网络理论中有一个小分支就是研究这个的，叫做自-匹配记忆模式。 它也是由相互连接的简单的神经元构成，这些神经元在达到某个临界点之后就会激活。但他们之间的连接方式不同，在于其中涉及了大量的反馈。与只能正向传输不同，自-匹配记忆模式可以将各个神经元的输出传回给自己。这种反馈回路有一个有趣的特点就是，当一个行为模式施加到神经元之后，他们就会对这种模式形成记忆。 恒定表征 恒定表征应该是实现类似人脑智能的重中之重。所谓恒定表征是有点类似于柏拉图的理念的那种东西。 比如你认识一个人的脸，你每次见到他灯光，角度，位置等等都会不同，你不可能看到一张（信息）完全相同的脸。但是你却认出那是某个人。再比如你从来没有看见过一个纯正的圆，但是你心里还是知道圆是个啥样子。 抽象，把握了事物内部各个要素的关系的最本质的部分，这种存储起来的信息就是恒定表征。这个恒定表征的问题非常关键！ 大脑不论做什么事情时时刻刻都在预测 （这个时候我意识到，时间不光是一种序列，空间实际上也是一种序列。比如我们进入一个房子，我们是不可能一下吸收那么多信息的，《人工智能的未来》一书有一个例子是说一个实验，用了观察人看到一张人脸之后眼睛关注点的移动情况，实际上人不光脖子动，平时眼球的运动也很频繁。他们的实验显示这些眼睛关注点的移动画出来就好像一张人脸的素描。） 因此当我们进入我们自己的房间的时候，我们实际上都是有一系列默认的空间扫描序列，然后我们时时对这个序列中可能出现的下一个信息作出预测，因为我们对自己的房间再熟悉不过了。这个时候我们突然发现桌子上多了一只袜子，这个以前没有的。马上我们的好奇心被触发了，然后这个发现不一致信号的神经元可能会采取进一步的行动，（比如将信号上传到海马区等等——海马区负责瞬时记忆的。） 实际上这种关注点的扫描序列和很多因素相关，甚至和文化相关。比如人们常说中国人习惯看总体性的东西。但是我们要知道总体总是根于局部，也就是中国人一定也有一定的扫描序列。我想这个可能和中国字还有西方识别字母有关系吧。因为西方需要将几个字母彻底辨认清楚才知道这个单词，但是中国字的识别则是一种笔画式的框架式的。 当你走路的时候，你会预测脚什么时候着地；当你听歌的时候，你会预测下一个音符；甚至当你听别人说话的时候，你会预测下面你可能会听到什么。当然你可能会预测错误，这个时候你的好奇心就被挑逗起来了，这是一个好的文学作品的必备素质。 再多谈论一下我们用眼睛观察周围事物，并对空间体验的方式。我们发现我们对于事物的某些确定位置并不十分在意。我们的空间的架构是基于各个事物之间的关系。时间当然是一种关系，空间也是一种关系。这告诉我们我们的大脑更多地关注的不是具体事物的某些属性信息，而是各个事物之间的关系。 预测当然和行动相互相成，但是一个独自思考不做任何外部行动的人我们不能否认他具有智能。他时时刻刻也在做出各种预测。因为行动不光包括手和脚眼睛等等外部感官器官的运动，当然还包括大脑本身的运动。什么？大脑对大脑本身做出预测？大脑在想大脑下一步要想些什么，大脑在想大脑下一步可能会怎么做。然后大脑发现自己预测错了，还发现了一个自己还不认识的全新的自我。哦，这就是人所谓的独自思考吗？但是大脑自己可以操纵自己的下一步行动啊，是啊，我们通过手脚和客观世界不断保持着交流，然后大自然总是给我们上了新鲜的一课。然后我们发现我们错了，但是对于我们自己，我们怎么可能预测错了。 新大脑皮层的更多细节 新大脑皮层纵向分为六层： 之所以认为大脑皮层分为六层，而且这样的细胞垂直柱是皮层中最基本的计算单元理由如下： 从解剖学角度，大脑皮层是分为六层的。 第一层细胞很少，主要是由皮层平面平行延展的轴突所组成。 第二层细胞和第三层细胞很相似，他们由\"锥体细胞\"（如上图所示像一个小小的金字塔形状）的神经元组成。 第四层有一种星形细胞。 第五层除了有正常大小的锥体细胞之外，还有一种巨大的金字塔形状的细胞。 第六层也有几类独特的细胞。 从神经兴奋来讨论 这些神经细胞垂直柱通常他们对同一刺激是同时产生兴奋的，具体是第四层一个被激活的细胞会让第三层和第二层的细胞兴奋起来，然后引起第五层和第六层的细胞兴奋起来。也就是兴奋状态在细胞垂直柱是上下传递的，在第一层是水平传递的。 早在1979年，蒙卡斯尔就认为存在着一种单一的皮层算法，而且他认为在这种算法中皮层垂直柱就是最小的计算单元。 上面谈到的皮层垂直柱，最小的计算单元。这些计算单元和其他计算单元之间发生着联系。但是这种联系中存在着一定的规律。即总是以这样的形式扩展开来。 这种形式简单理解就是一种统一的算法使得信息向上走向抽象，向下走向具体。当然在这里并不是说一个皮层柱只能向下扩展两个皮层柱，向下扩展多个皮层柱也是可能的。 然后以此类推，新大脑皮层记忆的知识建立了一种庞大复杂的网络，这种网络呈现出一种层级结构，而这种层级结构正是对应着客观世界的各个物体的嵌套关系。 如果你头脑中的某个模式序列在你与外部世界的交互行为中做出了精确的预测，那么大脑就认为他们之间存在着因果关系。 大量的输入模式再三出现在同一个关系中的几率几乎微乎其微，所以这种可靠的预测以铁定的事实说明了世界上不同的事件是相互联系着的。（发现了客观世界的更加本质的规律，这绝不简单。） 大自然颜色是无穷尽的，但是我们大致可以将其分为几类，然后遇到一种新的颜色，如果我们懒于开辟新的记忆模式，那么我们就简单地归为类似红色和黄色。如果你勤快一点，你精确定义了黄红色——橙色。事情大体如此。(按照这种处理模式，一些输入的歧义也不会让我们的大脑死机。。） 皮层柱的三种工作模式 信息向上的汇聚流 第四层也就是那些星形细胞承担了汇流输入的工作，第四层是主要输入层。 星形细胞将信息汇聚之后，会投射到第二层和第三层的细胞上（锥形细胞），然后继续向上传输。 信息向下的扩散模式 可以确认的是在皮层柱第一层，信息流就完成了大部分扩散工作。其他过程尚不清晰。似乎从第一层开始，第二三五六层都有时会被激发。 经由丘脑的延迟反馈模式 在皮层柱的第五层，也就是那些巨大的金字塔细胞，研究显示他们轴突一分为二，一部分通向了运动区，甚至直接操纵眼球的运动；一部分通向了丘脑。丘脑非常复杂，如果受损，人将成植物人。但是有一条信息投射可能满足了我们的兴趣，那就是丘脑将信息投射回了皮层柱第一层。 这一反馈回路无疑让我们知道自己干了什么，自-联想学习记忆模式，能够学习模式序列。 大脑皮层的这些皮层柱，也许某种活跃态就意外着某种信息，比如某个皮层柱的第四层细胞判断了一下，然后决定我要兴奋。然后我们大脑阅读的信息是红色。然后另外一个也兴奋了，我们阅读是黄色。然后有一次这两个都兴奋了，我们说是橙色。——如果我们已经学会了橙色。 总结 现在我试图从头到尾扫一遍，皮层柱第六层也就是最下面那层很明显是感官神经的第一汇集地。这些感官神经应该都是某一个局部区域的刺激信号。 这些信号将会被皮层柱第四层的星形细胞汇集。这些信号都是早期的空间信号序列。 星形细胞被激发之后将会刺激上面的第二层或者第三层的细胞，这其中是有区别的： 第三层细胞又分为两种，最先接触到的是一类细胞，用来判断这个序列我是不是认识，如果不认识那么将会将这一序列上传给海马组织，海马组织的功能就是快速记住一个新模式，然后将其下载到皮层柱内。 具体是下载到该皮层柱的第二层细胞中，并给这个序列取了一个名字。 上面讲得第三层细胞的第二种细胞是一类细胞，这类细胞判断这个序列我是不是认识，然后他说我认识，然后他就会抑制上面谈到的哪一类细胞，不让其上传给海马组织。 然后因为这个序列是认识的，所以有了一个名字，然后第四层细胞将会直接激活第二层细胞的名字细胞，这个时候信息就不是整个序列了，而是转变成了一种简写。然后第二层细胞进入第一层细胞到达其他皮层柱了。 而上面的第三层细胞的第二类细胞一是判断我认识这个模式了，然后抑制上传；二是将信息激活，上传到上面去了，这里的激活的是整个序列信息，用于人脑内部对这个模式序列接下来的要激活哪个皮层柱的预测。 我们假设这个序列的下一个皮层柱的星形细胞正要激活了，而这个时候上面谈到的第三层的第二类细胞也将信号传输到了这个皮层柱的对应的第三层的第二类细胞中，这个时候该细胞实际上已经处于一种亚激活状态。因为这条线路早就打通了，然后下面的信号有冲了上了，又激活了一下。这样这条线路同时激活了两下，变得非常活跃和兴奋。也就是我预测对了。yes！ 这样那种名字的简写信号就进入到了上面的谈及的那种更加宏大的层架结构中去了，这个时候这种简写信号实际上就相当于信息的又一次汇集。然后不同的简写信号再一次在另外一个皮层柱的星形细胞中汇集成一个序列。 这里我有必要插入描述一下时间序列信号是如何产生的。多个皮层柱信号向下被激活之后，指令一方面传递到了运动区，另一方面传递到了丘脑。在某个有效的判据下，比如说一连串连续的皮层柱信号，然后一段休止空白。这个时候丘脑会将这一系列皮层柱信号，视作在某个短小时间段内的皮层柱激活时间序列。打包好了之后，上传到了皮层脑顶部，看看我认不认识这个序列，然后什么什么的操作我们上面谈论过了。 接着上面的序列继续写道，然后星形细胞被激活之后，然后又是类似的算法处理，然后又一次到了另外一个皮层柱等等。如此信息流向上不断抽象不断汇集。 我们再来看一下大脑如何产生具体的运动指令，也就是信息流不断向下从抽象的我要，我需要什么直到具体的一系列运动指令序列。 首先是最简单的情况，那就是这种情况你以前遇到过。 首先是最抽象的需求指令向下，不断在不同的皮层柱中搜索。这种向下搜索流可能并不那么简单了，第二层细胞——简写细胞应该会涉及到，第三层第二类细胞——预测细胞也会涉及到。 这里我们谈论的是这种情况你以前遇到过，也就是恰好在一个简写细胞中搜索到了。 搜索到之后，上面进一步发动指令，激活简写细胞，简写细胞有的会传输到第六层细胞，然后又会回传到另外的一个皮层柱，如此等等，知道所有的简写细胞完全展开为行动指令序列，也就是激活了皮层柱的第五层细胞——运动细胞。第五层也就那个巨大的金字塔细胞专门负责运动指令的发送（所以才会那么巨大，因为要激活很大的冲动刺激下面的神经细胞吧。） 这个时候所有的指令序列有的会传递到运动区，可能还要进一步编码。有的就直接操纵运动器官了。而与此同时这些运动指令将在丘脑封包，上传。记住我已经做了些什么。由于这种情况和运动指令我们以前遇到过所以大抵查到了之后就没有后续内容了。 如果这种情况没有遇到过，那么最精彩的创造力部分就出来了。所谓创造力其实并不那么神奇，说简单一点就是讲你以前没有遇到的情况分化，简单来说就是边做边看。也许你会问有的时候人不需要边做边看，能够在脑中想象下一步客体世界可能会如何反应。是的，虚拟一个客体世界，这将会耗费更大的存储空间，但在我们上面的讨论中我们发现很多东西也许并不如我们之前想象的那么困难。 以前我在哲学上讨论过一种机制，这种机制基于最小的逻辑判断元——模板判断，然后通过最简单的两种连接——正生，反生线路--类似于激活和抑制。就能构造出逻辑推理操作的最简单的单元，那么我们可以想象更加复杂的逻辑推理操作也不是不可能的了。 进化史 我看了一下，霍金斯的HTM算法如果做到完美的话也只是一个完美模拟皮层脑的信息存储机构。但是还缺少一些东西。 那就是不管人脑有其自身进化史，整个人类甚至整个宇宙的信息都有其历史或者说进化史。脱离整个宇宙的信息进化史来单独谈论智能，我认为总是会感觉少了点东西的。 神经系统所包含的信息超过了基因的信息——代表着个体的生存也很重要 皮层脑的信息超过了本能脑的信息——代表着现在比过去的程序式的反应重要 语言文字的信息超过了大脑的信息——代表着社会的文化发展有时比个体的生存还重要。 大脑中的神经细胞应该具有某种内在统一性，但是依进化阶段专门化为四个部分：一是本能脑，即死板的程序式的反应部分；二是皮层脑，近似于自动的吸收和存储信息并能够进行某些前期程序式的信息处理；三是额脑，产生人行为目的部分，人按照这个目的从而制定出计划；四是情绪脑，对于目的的效益性判断。 四脑学说，本能脑负责从外部接受信息，皮层脑负责把接受到的信息转化为额脑能够读懂的信息，额脑就是我们的欲念世界。但是在这里还多了一个情绪脑，情绪脑的作用就是更快速地执行。当某种情绪激活之后，某一类信息会特别活跃，于是可以迅速地做出反应和指定对策，以及执行。如果说前面三个调配的是信息的话，那么情绪脑调配的就是能量（活化能）。在总能量不变的情况下，实现能量的最好利用。 （所谓先验概念就是进化史中遗留下来的最优秀的神经联系网络模式。比如说空间联合区，其中很大一部分信息已经固化了的。初生儿只要稍微调试下就有了空间的观念了的。） 这样我们看到，霍金斯的工作主要集中在了皮层脑这一块。但是要发展处真正意义上得智能，其他几个功能部分的开发也不可缺少。其中本能脑的概念不用多谈，就是编好最底层的子程序即可。 而情绪脑，就作为目的的效益判断，对于人工智能体系来说也不是说非要不可。（情绪脑有两种功能：一是大脑的本能脑，二是额脑的帮手。） 之前我想到这个四脑学说的时候，对额脑这个概念非常的看重。因为那个时候我似乎还仔细地拨弄了一下直立人的一次迁徙和智人的一次迁徙。然后得出直立人主要发展皮层脑，而智人则主要发展额脑。额脑将智人和直立人区别了开来。 同时我又认识到了额脑和语言和宗教和信仰和意志力和人的社会性等等都有关系。 那么额脑和皮层脑有什么区别呢？既然额脑是皮层脑靠近额部那一块进化出来的。我就谈到了，皮层脑，只活在现在。他大量接受现在的信息，存储起来，还能做一些早期简单的信息处理工作。但是那个时候的人只是生活在现在，沉浸在现在的世界里。仅此而已，可能他们脑中唯一的非现实世界的创造就是做梦——皮层脑神经连接的随机漫游。 当这种随机漫游一旦被证明是有用的，那么一方面将大大地给这个物种带来利益，另一方面大脑极度兴奋地加强。哪怕只是偶尔的一次有意义的漫游。（比如直立人突然发现火的用处等，而以前都不敢靠近它。） 而额脑的作用就是控制并主动地创造这种随机漫游。 我们思维部分的从底向上，从上向下两种思考风格，实际上都是主动的随机漫游行为。 由于智人日益进化的额脑，他们获得了更加积极主动的随机漫游行为，于是他们积极探求，积极行动。而不是活在皮层脑中——现在，而是活在额脑中——未来——或者说另外一个创造出来的主观世界之中。 参考 人工智能的未来 杰夫·霍金斯","tags":"思想","url":"articles/ren-gong-zhi-neng-di-yi-tan.html"}]}